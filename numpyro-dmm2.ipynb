{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "afe5ebbfdd63d5f53bf49e6aa62793990f23c9b8ec75185fbb6f3054c1465b21"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "covShared tensor([[1.0000, 0.9500],\n",
      "        [0.9500, 1.0000]])\n",
      "residualCovariance tensor([[1, 0],\n",
      "        [0, 1]])\n",
      "PD1 threshold, PD2 threshold tensor(-2.3263) tensor(-2.3263)\n",
      "pDsWithBoth tensor([0.0100, 0.0100, 0.0067], dtype=torch.float64)\n",
      "pdThresh tensor([2.3263, 2.3263])\n",
      "pdTarget tensor([0.0300, 0.0200])\n",
      "pdvthresh tensor([1.8808, 2.0537])\n",
      "meanEffect tensor([0.4456, 0.2726])\n",
      "meanEffectsAcrossAllGenes tensor([0.4456, 0.2726])\n",
      "allEffects tensor([[-0.3891, -0.2083],\n",
      "        [-0.5965, -0.4642],\n",
      "        [-0.3894, -0.2065],\n",
      "        ...,\n",
      "        [-0.4650, -0.3077],\n",
      "        [-0.4061, -0.1636],\n",
      "        [-0.5730, -0.3954]])\n",
      "PD1GivenV.mean() tensor(0.0307) PD2GivenV.mean() tensor(0.0205)\n",
      "allEffects[i] tensor([-0.3891, -0.2083])\n",
      "PDBothGivenV.mean tensor(0.0171, dtype=torch.float64)\n",
      "PDBothGivenV / PDBoth tensor(2.5597, dtype=torch.float64)\n",
      "pdsCovarOnMean.mean(0) tensor([0.0307, 0.0205, 0.0171], dtype=torch.float64)\n",
      "np.corrcoef(pdvInBoth[:,0], pdvInBoth[:,1])\n",
      " [[1.         0.94908539]\n",
      " [0.94908539 1.        ]]\n",
      "np.corrcoef(pdvInBoth[:,0], pdvInBoth[:,2])\n",
      " [[1.         0.97611623]\n",
      " [0.97611623 1.        ]]\n",
      "PDBoth1GivenV tensor([0.0229, 0.0223, 0.0213,  ..., 0.0151, 0.0180, 0.0188])\n",
      "PDBoth2GivenV tensor([0.0142, 0.0139, 0.0144,  ..., 0.0105, 0.0150, 0.0132])\n",
      "np.corrcoef(PD1Vsingle, PD2Vsingle)\n",
      " [[ 1.         -0.00440697]\n",
      " [-0.00440697  1.        ]]\n",
      "np.corrcoef(PD1Vsingle, PDBoth1GivenV)\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "np.corrcoef(PD2Vsingle, PDBoth1GivenV)\n",
      " [[ 1.         -0.00440697]\n",
      " [-0.00440697  1.        ]]\n",
      "np.corrcoef(PD2Vsingle, PDBoth2GivenV)\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "pdvsGeneAffects1.mean tensor([0.0224, 0.0219, 0.0210,  ..., 0.0159, 0.0183, 0.0190])\n",
      "afs.dist tensor(0.0001) +/- tensor(1.4384e-05)\n",
      "afs.shape torch.Size([20000])\n",
      "pvd_base tensor([[[1.0000, 1.0000, 1.0000],\n",
      "         [3.4185, 1.0000, 3.4185],\n",
      "         [1.0000, 2.1126, 2.1126],\n",
      "         [2.6356, 1.7085, 2.1335]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000],\n",
      "         [3.3341, 1.0000, 3.3341],\n",
      "         [1.0000, 2.0724, 2.0724],\n",
      "         [4.1833, 3.1292, 3.8409]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000],\n",
      "         [3.1783, 1.0000, 3.1783],\n",
      "         [1.0000, 2.1544, 2.1544],\n",
      "         [2.6377, 1.7009, 2.1272]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000],\n",
      "         [2.2499, 1.0000, 2.2499],\n",
      "         [1.0000, 1.5742, 1.5742],\n",
      "         [3.1346, 2.1760, 2.6886]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000],\n",
      "         [2.6884, 1.0000, 2.6884],\n",
      "         [1.0000, 2.2463, 2.2463],\n",
      "         [2.7412, 1.5279, 1.9891]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000],\n",
      "         [2.8119, 1.0000, 2.8119],\n",
      "         [1.0000, 1.9702, 1.9702],\n",
      "         [3.9774, 2.6747, 3.3829]]], dtype=torch.float64)\n",
      "afs tensor([9.9049e-05, 7.9525e-05, 9.5261e-05,  ..., 9.4744e-05, 8.3979e-05,\n",
      "        9.2094e-05])\n",
      "pvds tensor([[[9.9049e-05, 9.9049e-05, 9.9049e-05],\n",
      "         [3.3859e-04, 9.9049e-05, 3.3859e-04],\n",
      "         [9.9049e-05, 2.0925e-04, 2.0925e-04],\n",
      "         [2.6106e-04, 1.6923e-04, 2.1132e-04]],\n",
      "\n",
      "        [[7.9525e-05, 7.9525e-05, 7.9525e-05],\n",
      "         [2.6514e-04, 7.9525e-05, 2.6515e-04],\n",
      "         [7.9525e-05, 1.6481e-04, 1.6481e-04],\n",
      "         [3.3267e-04, 2.4885e-04, 3.0545e-04]],\n",
      "\n",
      "        [[9.5261e-05, 9.5261e-05, 9.5261e-05],\n",
      "         [3.0277e-04, 9.5261e-05, 3.0277e-04],\n",
      "         [9.5261e-05, 2.0523e-04, 2.0523e-04],\n",
      "         [2.5127e-04, 1.6202e-04, 2.0264e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[9.4744e-05, 9.4744e-05, 9.4744e-05],\n",
      "         [2.1316e-04, 9.4744e-05, 2.1316e-04],\n",
      "         [9.4744e-05, 1.4914e-04, 1.4914e-04],\n",
      "         [2.9698e-04, 2.0616e-04, 2.5473e-04]],\n",
      "\n",
      "        [[8.3979e-05, 8.3979e-05, 8.3979e-05],\n",
      "         [2.2577e-04, 8.3979e-05, 2.2577e-04],\n",
      "         [8.3979e-05, 1.8864e-04, 1.8864e-04],\n",
      "         [2.3021e-04, 1.2831e-04, 1.6704e-04]],\n",
      "\n",
      "        [[9.2094e-05, 9.2094e-05, 9.2094e-05],\n",
      "         [2.5896e-04, 9.2094e-05, 2.5896e-04],\n",
      "         [9.2094e-05, 1.8145e-04, 1.8145e-04],\n",
      "         [3.6629e-04, 2.4632e-04, 3.1154e-04]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from mvl import genData\n",
    "from torch import tensor\n",
    "\n",
    "liabParams55cov = genData.genParams(pis=tensor([.1, .1, .05]), rrMeans=tensor([3., 2.]), afMean = tensor(1e-4), pDs = tensor([.01, .01]), afShape=tensor(50.), nCases=tensor([1.5e4, 1.5e4, 4e3]), nCtrls=tensor(5e4), covShared=tensor([ [1, .95], [.95, 1] ]), meanEffectCovarianceScale=tensor(.01))[0]\n",
    "liabParams55cov[\"pDs\"] = liabParams55cov[\"pDs\"][0:2]\n",
    "liabData55cov = genData.v6liability(**liabParams55cov)\n",
    "liabParams55cov[\"pDs\"] = liabData55cov[\"PDs\"] #TODO: normalized names, and indicate that the params pDs are incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.0100, 0.0100, 0.0067], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "liabParams55cov[\"pDs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'pDsample'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f6f9a1b3c377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mliabParams55cov\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pDsample\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'pDsample'"
     ]
    }
   ],
   "source": [
    "liabParams55cov[\"pDsample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pdsAll [0.59523809 0.17857143 0.17857143 0.04761905]\n[[0.5952381  0.17857143 0.17857143 0.04761905]\n [0.5952381  0.17857143 0.17857143 0.04761905]\n [0.5952381  0.17857143 0.17857143 0.04761905]\n [0.5952381  0.17857143 0.17857143 0.04761905]\n [0.5952381  0.17857143 0.17857143 0.04761905]\n [0.5952381  0.17857143 0.17857143 0.04761905]]\n(4,)\n(4,)\nnHypotheses 6\n"
     ]
    }
   ],
   "source": [
    "import numpyro\n",
    "from numpyro.distributions import Multinomial, Beta, Dirichlet, Gamma, Beta, Categorical, Uniform, MultivariateNormal, Normal, LogNormal, Exponential\n",
    "from jax import random\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "numpyro.set_host_device_count(6)\n",
    "numpyro.enable_x64()\n",
    "\n",
    "def mix_weights(beta: jnp.array):\n",
    "    beta_cumprod = (1 - beta).cumprod(-1)\n",
    "    return jnp.pad(beta, (0,1), constant_values=1) * jnp.pad(beta_cumprod, (1,0), constant_values = 1)\n",
    "\n",
    "\n",
    "# mu_exp, var_exp = get_log_params(liabParams55cov[\"afMean\"].numpy(), 1)\n",
    "\n",
    "nHypotheses = 6\n",
    "kConditions = 4\n",
    "altCounts = liabData55cov[\"altCounts\"].numpy()\n",
    "N = len(liabData55cov[\"altCounts\"])\n",
    "\n",
    "nCases = liabParams55cov[\"nCases\"].numpy()\n",
    "nCtrls = liabParams55cov[\"nCtrls\"].numpy()\n",
    "samplePDs = nCases / (nCases.sum() + nCtrls)\n",
    "pdsAll = np.array([1 - samplePDs.sum(), *samplePDs])\n",
    "print(\"pdsAll\", pdsAll)\n",
    "\n",
    "# TODO: do this in numpy natively\n",
    "pdsAllShaped = jnp.asarray(tensor(pdsAll).expand(nHypotheses, kConditions).numpy())\n",
    "pdsAllnp = [1 - samplePDs.sum(), *samplePDs]\n",
    "pdsAll = jnp.asarray([1 - samplePDs.sum(), *samplePDs])\n",
    "print(pdsAllShaped)\n",
    "print(pdsAll.shape)\n",
    "print((1/pdsAll).shape)\n",
    "alpha = .01\n",
    "print(\"nHypotheses\", nHypotheses)\n",
    "\n",
    "component_af_means = jnp.array([.005, .006, .006, .013])\n",
    "exponential_prior = jnp.array([.001]).repeat(kConditions)\n",
    "# exponential_prior = jnp.array([[.001]]).repeat((kConditions, nHypotheses))\n",
    "# print(\"exponential_prior\", exponential_prior)\n",
    "\n",
    "def model(data):\n",
    "    with numpyro.plate(\"conc_plate\", kConditions):\n",
    "        conc = numpyro.sample('conc', Exponential(.001))\n",
    "\n",
    "    with numpyro.plate(\"beta_plate\", nHypotheses-1):\n",
    "        beta = numpyro.sample(\"beta\", Beta(1, alpha))\n",
    "\n",
    "    with numpyro.plate(\"prob_plate\", nHypotheses):\n",
    "        probs = numpyro.sample(\"probs\", Dirichlet(conc))\n",
    "\n",
    "    with numpyro.plate(\"data\", N):\n",
    "        z = numpyro.sample(\"z\", Categorical(mix_weights(beta)))\n",
    "        return numpyro.sample(\"obs\", Multinomial(probs=probs[z]*pdsAll), obs=data)\n",
    "\n",
    "def modelLogNormal(data):\n",
    "    with numpyro.plate(\"conc_plate\", kConditions):\n",
    "        conc = numpyro.sample('conc', Exponential(.001))\n",
    "\n",
    "    with numpyro.plate(\"beta_plate\", nHypotheses-1):\n",
    "        beta = numpyro.sample(\"beta\", Beta(1, alpha))\n",
    "\n",
    "    with numpyro.plate(\"prob_plate\", nHypotheses):\n",
    "        probs = numpyro.sample(\"probs\", Dirichlet(conc))\n",
    "\n",
    "    with numpyro.plate(\"data\", N):\n",
    "        z = numpyro.sample(\"z\", Categorical(mix_weights(beta)))\n",
    "        return numpyro.sample(\"obs\", Multinomial(probs=probs[z]*pdsAll), obs=data)\n",
    "        return numpyro.sample(\"obs\", Multinomial(probs=probs[z]), obs=data)\n",
    "\n",
    "def modelPDScaledDeterministic(data):\n",
    "    pdsSite = numpyro.deterministic(\"pDs\", pdsAll)\n",
    "    # mu = numpyro.sample('mu', Uniform(jnp.ones(kConditions), 1000))\n",
    "    # print(\"mu\", mu)\n",
    "    # concentrations = numpyro.sample(\"concentrations\", Uniform(1, 1000))\n",
    "    # print(\"concentrations\", concentrations)\n",
    "    with numpyro.plate(\"beta_plate2\", nHypotheses-1):\n",
    "        beta = numpyro.sample(\"beta\", Beta(1, alpha))\n",
    "\n",
    "    with numpyro.plate(\"mu_plate\", nHypotheses):\n",
    "        mu = numpyro.sample('mu', Uniform(jnp.ones(kConditions), 1000))\n",
    "        probs = numpyro.sample(\"probs\", Dirichlet(mu))\n",
    "        # print(\"probs\", probs)\n",
    "        probs = numpyro.deterministic(\"probs_scaled\", probs * pdsAll)\n",
    "        # print(\"probs after scaling\", probs)\n",
    "\n",
    "    with numpyro.plate(\"data\", N):\n",
    "        z = numpyro.sample(\"z\", Categorical(mix_weights(beta)))\n",
    "        return numpyro.sample(\"obs\", Multinomial(probs=probs[z]), obs=data)\n",
    "\n",
    "\n",
    "def modelAf(data):\n",
    "    # pds = numpyro.deterministic(\"pds\", liabParams55cov[\"afMean\"].numpy())# numpyro.sample(\"af\", LogNormal(mu_exp, var_exp)\n",
    "    # print(\"af\", af)\n",
    "    # mu = numpyro.sample('mu', Uniform(jnp.ones(kConditions), 1000))\n",
    "    # print(\"mu\", mu)\n",
    "    # concentrations = numpyro.sample(\"concentrations\", Uniform(1, 1000))\n",
    "    # print(\"concentrations\", concentrations)\n",
    "    with numpyro.plate(\"beta_plate2\", nHypotheses-1):\n",
    "        beta = numpyro.sample(\"beta\", Beta(1, alpha))\n",
    "\n",
    "    with numpyro.plate(\"mu_plate\", nHypotheses):\n",
    "        conc = numpyro.sample('conc', Uniform(jnp.ones(kConditions), 1000))\n",
    "        # doing this speeds up MCMC by 2x\n",
    "        pdconc = numpyro.deterministic(\"pdconc\", conc * pdsAll)\n",
    "        probs = numpyro.sample(\"probs\", Dirichlet(pdconc))\n",
    "        # print(\"probs\", probs)\n",
    "        # probs = numpyro.deterministic(\"probs_scaled\", probs * af)\n",
    "        # print(\"probs after scaling\", probs)\n",
    "\n",
    "    with numpyro.plate(\"data\", N):\n",
    "        z = numpyro.sample(\"z\", Categorical(mix_weights(beta)))\n",
    "        probs = probs[z] / component_af_means[z]\n",
    "        return numpyro.sample(\"obs\", Multinomial(probs=probs[z]), obs=data)\n",
    "\n",
    "\n",
    "# def modelLogNormal(data):\n",
    "#     # tau = numpyro.param('tau', MultivariateNormal(jnp.zeros(kConditions), 3 * jnp.eye(kConditions)))\n",
    "#     with numpyro.plate(\"beta_plate\", nHypotheses-1):\n",
    "#         beta = numpyro.sample(\"beta\", Beta(1, alpha))\n",
    "\n",
    "#     with numpyro.plate(\"mu_plate\", nHypotheses):\n",
    "#         # rrMean = numpyro.param(\"rrMean\")\n",
    "#         rr = numpyro.sample(\"rr\", LogNormal(jnp.eye(kConditions), jnp.eye(kConditions)).to_event(1))\n",
    "#         af = numpyro.sample(\"af\", LogNormal(jnp.array(liabParams55cov[\"afMean\"]), jnp.ones(kConditions)).to_event(1))\n",
    "#         pvd = rr * af\n",
    "#         print(\"pvd\", pvd)\n",
    "#         pvdpv = pvd*pdsAll\n",
    "#         print(\"pvdpv\", pvdpv)\n",
    "        \n",
    "#         probs = numpyro.sample(\"probs\", Dirichlet(pvdpv))\n",
    "#         # just slows things down probs = numpyro.deterministic(\"probs_scaled\", probs * pdsAll)\n",
    "\n",
    "#     with numpyro.plate(\"data\", N):\n",
    "#         z = numpyro.sample(\"z\", Categorical(mix_weights(beta)))\n",
    "#         return numpyro.sample(\"obs\", Multinomial(probs=pvdpv[z]), obs=data)\n",
    "\n",
    "# def modelGamma(data):\n",
    "#     with numpyro.plate(\"beta_plate\", nHypothesis - 1):\n",
    "#         beta = numpyro.sample(\"beta\", Beta(1, alpha))\n",
    "\n",
    "#     with numpyro.plate(\"mu_plate\", nHypotheses):\n",
    "#         rrMean = numpyro.param(\"rrMean\")\n",
    "#         rr = numpyro.sample(\"rr\", Gamma(jnp.ones(kConditions), jnp.ones(kConditions)))\n",
    "#         af = numpyro.sample(\"af\", Gamma(liabParams55cov[\"afMean\"], jnp.ones(kConditions)))\n",
    "#         pvd = rr * liabParams55cov[\"afMean\"]\n",
    "#         pvdpv = pvd*pdsAll\n",
    "        \n",
    "#         probs = numpyro.sample(\"probs\", Dirichlet(np.ones(kConditions)))\n",
    "#         # just slows things down probs = numpyro.deterministic(\"probs_scaled\", probs * pdsAll)\n",
    "\n",
    "#     with numpyro.plate(\"data\", N):\n",
    "#         z = numpyro.sample(\"z\", Categorical(mix_weights(beta)))\n",
    "#         return numpyro.sample(\"obs\", Multinomial(probs=probs[z]), obs=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shape (1,) (2,)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-df8cc479e7ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shape (1,) (2,)"
     ]
    }
   ],
   "source": [
    "np.array([.001]).repeat((4,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([0.006, 0.013, 0.005, 0.006, 0.006, 0.006], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "component_af_means[jnp.array([2,3,0,1,1,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "sample: 100%|██████████| 1100/1100 [04:04<00:00,  4.51it/s, 127 steps of size 2.99e-02. acc. prob=0.93]\n",
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "   beta[0]      0.10      0.03      0.10      0.06      0.15     82.90      1.02\n",
      "   beta[1]      0.12      0.04      0.12      0.06      0.18     13.57      1.05\n",
      "   beta[2]      0.90      0.04      0.90      0.84      0.97     50.15      1.00\n",
      "   beta[3]      0.96      0.13      1.00      0.91      1.00    108.03      1.00\n",
      "   beta[4]      0.94      0.16      1.00      0.83      1.00    810.88      1.00\n",
      "   conc[0]     18.25      6.97     17.18      6.10     27.63    503.21      1.00\n",
      "   conc[1]     10.13      3.92      9.45      3.89     16.16    492.12      1.00\n",
      "   conc[2]      8.82      3.35      8.46      3.46     13.85    415.62      1.00\n",
      "   conc[3]      3.60      1.39      3.41      1.46      5.87    574.65      1.00\n",
      "probs[0,0]      0.44      0.03      0.45      0.39      0.48      8.21      1.16\n",
      "probs[0,1]      0.19      0.11      0.14      0.11      0.39      4.08      1.39\n",
      "probs[0,2]      0.28      0.09      0.32      0.11      0.36      4.09      1.40\n",
      "probs[0,3]      0.09      0.01      0.08      0.07      0.11      6.12      1.24\n",
      "probs[1,0]      0.38      0.03      0.38      0.33      0.41      9.57      1.06\n",
      "probs[1,1]      0.36      0.03      0.37      0.32      0.40     10.96      1.03\n",
      "probs[1,2]      0.17      0.06      0.13      0.10      0.26      5.39      1.09\n",
      "probs[1,3]      0.09      0.01      0.10      0.07      0.11      6.22      1.07\n",
      "probs[2,0]      0.60      0.00      0.60      0.59      0.60    748.07      1.01\n",
      "probs[2,1]      0.18      0.00      0.18      0.17      0.18    728.24      1.00\n",
      "probs[2,2]      0.18      0.00      0.18      0.17      0.18    577.37      1.01\n",
      "probs[2,3]      0.05      0.00      0.05      0.05      0.05    912.38      1.01\n",
      "probs[3,0]      0.37      0.05      0.36      0.31      0.47      5.19      1.16\n",
      "probs[3,1]      0.29      0.10      0.34      0.12      0.39      4.06      1.49\n",
      "probs[3,2]      0.25      0.07      0.25      0.11      0.36      5.33      1.42\n",
      "probs[3,3]      0.08      0.01      0.08      0.06      0.11     11.76      1.02\n",
      "probs[4,0]      0.45      0.09      0.45      0.30      0.58    864.85      1.00\n",
      "probs[4,1]      0.25      0.08      0.25      0.13      0.38    491.26      1.00\n",
      "probs[4,2]      0.21      0.07      0.21      0.09      0.32    434.63      1.00\n",
      "probs[4,3]      0.09      0.05      0.08      0.01      0.16    702.72      1.00\n",
      "probs[5,0]      0.45      0.09      0.45      0.29      0.58   1416.38      1.00\n",
      "probs[5,1]      0.25      0.08      0.24      0.10      0.36   1556.68      1.00\n",
      "probs[5,2]      0.21      0.08      0.21      0.10      0.34    842.23      1.00\n",
      "probs[5,3]      0.09      0.05      0.08      0.01      0.16    799.48      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "# 1/3rd as fast as not having deterministic\n",
    "# this runs after mcmc fits, not during\n",
    "def postprocess(arg):\n",
    "    print(\"postprocess arg\", arg)\n",
    "    return arg\n",
    "init_rng_key = random.PRNGKey(12273)\n",
    "mcmcAf = MCMC(NUTS(model), 100, 1000, jit_model_args=True)\n",
    "mcmcAf.run(init_rng_key, altCounts)\n",
    "mcmcAf.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.4398996  0.19456017 0.27839905 0.08714116]\n [0.37654528 0.36484608 0.16515735 0.09345128]\n [0.59867483 0.17613707 0.1781984  0.04698981]\n [0.3738497  0.29160115 0.25154197 0.08300716]\n [0.44515297 0.25354034 0.21096157 0.09034516]\n [0.44809085 0.24717084 0.2149813  0.08975691]]\ninferred stick-breaking weights [0.10477007 0.10960675 0.7080873  0.07608418 0.00531045 0.00123203]\n"
     ]
    }
   ],
   "source": [
    "# Scaling by pDs gives absolutely no difference in concentrations or probabilities.\n",
    "sAf = mcmcAf.get_samples()[\"probs\"]\n",
    "print(sAf.mean(0))\n",
    "\n",
    "# concs = mcmcAf.get_samples()[\"conc\"]\n",
    "# print(\"conc std\", concs.std(0))\n",
    "# print(\"conc mean\", concs.mean(0))\n",
    "# print(\"DIrichlet version\", Dirichlet(concs.mean(0)).mean)\n",
    "\n",
    "betaScaledInDirichlet = mcmcAf.get_samples()['beta']\n",
    "print(\"inferred stick-breaking weights\", mix_weights(betaScaledInDirichlet).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.39795864 0.38242096 0.11334935 0.10627104]\n [0.34449634 0.34402916 0.23187748 0.07959706]\n [0.5973565  0.176043   0.17932664 0.04727379]\n [0.44580635 0.12760615 0.342677   0.08391044]\n [0.2525074  0.30790552 0.2199237  0.21966338]\n [0.24689339 0.27714565 0.23167437 0.24428658]]\ninferred stick-breaking weights [0.10958774 0.08479752 0.72028106 0.08632846 0.00186985 0.0010561 ]\n"
     ]
    }
   ],
   "source": [
    "# Scaling by pDs gives absolutely no difference in concentrations or probabilities.\n",
    "sAf = mcmcAf.get_samples()[\"probs\"]\n",
    "print(sAf.mean(0))\n",
    "\n",
    "# concs = mcmcAf.get_samples()[\"conc\"]\n",
    "# print(\"conc std\", concs.std(0))\n",
    "# print(\"conc mean\", concs.mean(0))\n",
    "# print(\"DIrichlet version\", Dirichlet(concs.mean(0)).mean)\n",
    "\n",
    "betaScaledInDirichlet = mcmcAf.get_samples()['beta']\n",
    "print(\"inferred stick-breaking weights\", mix_weights(betaScaledInDirichlet).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pdv tensor([0.5953, 0.1786, 0.1786, 0.0476], dtype=torch.float64)\npdv scaled tensor([0.5952, 0.1786, 0.1786, 0.0476], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pdv = (liabData55cov[\"afs\"][liabData55cov[\"unaffectedGenes\"]]).mean(0) / liabParams55cov[\"afMean\"]# PD|V\n",
    "print(\"pdv\", pdv)\n",
    "print(\"pdv scaled\", pdv/pdv.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pdv tensor([0.5738, 0.5486, 0.1785, 0.1463], dtype=torch.float64)\npdv scaled tensor([0.3965, 0.3791, 0.1233, 0.1011], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pdv = (liabData55cov[\"afs\"][liabData55cov[\"affectedGenes\"][0]]).mean(0) / liabParams55cov[\"afMean\"]# PD|V\n",
    "print(\"pdv\", pdv)\n",
    "print(\"pdv scaled\", pdv/pdv.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pdv tensor([0.5836, 0.1784, 0.3703, 0.0987], dtype=torch.float64)\npdv scaled tensor([0.4741, 0.1449, 0.3008, 0.0802], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pdv = (liabData55cov[\"afs\"][liabData55cov[\"affectedGenes\"][1]]).mean(0) / liabParams55cov[\"afMean\"]# PD|V\n",
    "print(\"pdv\", pdv)\n",
    "print(\"pdv scaled\", pdv/pdv.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pdv tensor([0.5717, 0.5500, 0.3674, 0.1223], dtype=torch.float64)\npdv scaled tensor([0.3548, 0.3413, 0.2280, 0.0759], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pdv = (liabData55cov[\"afs\"][liabData55cov[\"affectedGenes\"][2]]).mean(0) / liabParams55cov[\"afMean\"]# PD|V\n",
    "print(\"pdv\", pdv)\n",
    "print(\"pdv scaled\", pdv/pdv.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[0.01911611 0.01343591 0.01555622 0.00563713]\n",
    "#  [0.00406165 0.00276914 0.00327851 0.00133072]\n",
    "#  [0.01090826 0.00992517 0.0113952  0.00424665]\n",
    "#  [0.01858757 0.02309512 0.02210252 0.01013227]]\n",
    "# [[0.47631553 0.10743626 0.26105177 0.03134572]\n",
    "#  [0.60844487 0.14429386 0.14502415 0.01706672]\n",
    "#  [0.40694135 0.31180432 0.09986749 0.0380971 ]\n",
    "#  [0.35437214 0.26981634 0.2043957  0.02945131]]\n",
    "# conc std [ 12.166306  71.86332   67.61688  157.65123 ]\n",
    "# conc mean [ 36.537464 213.60443  190.46646  793.18304 ]\n",
    "# DIrichlet version [0.02961397 0.17312849 0.15437493 0.64288265]\n",
    "# inferred stick-breaking weights [0.11452598 0.665086   0.13667543 0.08672265]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pdv tensor([0.5717, 0.5500, 0.3674, 0.1223], dtype=torch.float64)\npdvpv tensor([5.7167e-05, 5.5000e-05, 3.6744e-05, 1.2231e-05], dtype=torch.float64)\npdvpv.sum() tensor(0.0002, dtype=torch.float64)\npdvpv scaled tensor([0.3548, 0.3413, 0.2280, 0.0759], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pdvpv = (liabData55cov[\"afs\"][liabData55cov[\"affectedGenes\"][2]]).mean(0) #/ liabParams55cov[\"afMean\"]# PD|V\n",
    "pdv = pdvpv / liabParams55cov[\"afMean\"]\n",
    "print(\"pdv\", pdv)\n",
    "print(\"pdvpv\", pdvpv)\n",
    "print(\"pdvpv.sum()\", pdvpv.sum())\n",
    "# This matches our DM results perfectly; so the DM result matches scale\n",
    "# how to allow our pdv values to work ok...\n",
    "print(\"pdvpv scaled\", pdvpv/pdvpv.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[4., 3., 3., 0.],\n",
       "        [8., 3., 0., 1.],\n",
       "        [6., 3., 2., 0.],\n",
       "        ...,\n",
       "        [5., 8., 1., 1.],\n",
       "        [3., 3., 5., 2.],\n",
       "        [6., 5., 2., 0.]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "liabData55cov[\"altCounts\"][liabData55cov[\"affectedGenes\"][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1.6114, dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "pdv.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([5.7167e-05, 5.5000e-05, 3.6744e-05, 1.2231e-05], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "(liabData55cov[\"afs\"][liabData55cov[\"affectedGenes\"][2]]).mean(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([5.7375e-05, 5.4857e-05, 1.7848e-05, 1.4628e-05], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "liabData55cov[\"afs\"][liabData55cov[\"affectedGenes\"][0]].mean(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.5952380895614624, 0.17857143, 0.17857143, 0.04761905]"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "pdsAllnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1.0000e-04)"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "liabParams55cov[\"afMean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([5.7375e-05, 5.4857e-05, 1.7848e-05, 1.4628e-05], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "liabData55cov[\"afs\"][liabData55cov[\"affectedGenes\"][0]].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1.0000e-04)"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "liabParams55cov[\"afMean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1000, 4, 4)\n",
    "# [[0.00514663 0.00313207 0.00355292 0.00149964]\n",
    "#  [0.01928454 0.04950465 0.04956334 0.0065191 ]\n",
    "#  [0.02503735 0.04772532 0.03840724 0.00905628]\n",
    "#  [0.06047119 0.05520838 0.05940869 0.03415463]]\n",
    "# [[0.607701   0.1456876  0.14313476 0.01758165]\n",
    "#  [0.45891437 0.14094748 0.24490298 0.03002501]\n",
    "#  [0.45052725 0.23326729 0.15602364 0.03166293]\n",
    "#  [0.4925649  0.1685785  0.18608962 0.03147438]]\n",
    "# conc std [18.310623   7.338482   7.672899   2.7556536]\n",
    "# conc mean [46.069946 18.652845 19.728569  6.812487]\n",
    "# DIrichlet version [0.50479954 0.20438373 0.2161707  0.07464606]\n",
    "# inferred stick-breaking weights [0.6861298  0.14098327 0.1566307  0.01916244]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}