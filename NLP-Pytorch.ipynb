{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun: 56712.08203125\n",
    "       message: 'Optimization terminated successfully.'\n",
    "          nfev: 1286\n",
    "           nit: 414\n",
    "        status: 0\n",
    "       success: True\n",
    "             x: array([2.17507271e-01, 6.68290234e-02, 6.02503642e-03, 3.11701327e+04,\n",
    "       1.50929989e+02, 1.80605742e+02, 4.19481041e+03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import torch\n",
    "from torch import tensor\n",
    "from pyro.distributions import Dirichlet, Beta, DirichletMultinomial as DM, Multinomial, LogNormal, Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.lgamma(1 + tensor(2.0,dtype=torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(is_sparse=True, concentration=tensor([ 6.94358849e+03,\n",
    "       3.42261484e+02, 2.88434875e+02, 3.43087928e+04], dtype=torch.double)).log_prob(tensor(.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([5.13379907e+03,\n",
    "       4.73718801e+03, 4.48497620e+03, 3.15466320e+04])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([3.27633494e+04,\n",
    "       2.83978623e+02, 2.71735494e+02, 7.29106887e+03])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([1.11277492e+04,\n",
    "       4.78012719e+03, 4.69497849e+03, 2.55812574e+04])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([1.75637015e+04,\n",
    "       2.81087516e+03, 3.07357980e+03, 5.10828082e+03])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([3.67968382e+04,\n",
    "       4.71664044e+03, 1.34100715e+03, 6.33673565e+02])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = tensor([0.4156, 0.0056, 0.0047, 0.5742])\n",
    "alpha1= alphas[1]\n",
    "\n",
    "\n",
    "Beta(alpha1, alphas.sum() - alpha1).sample([10_000, ]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([tensor(17716.9375), tensor(18139.4492), tensor(19317.7422), tensor(12943.7344)])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([2.30539340e+04,\n",
    "       2.62614394e+03, 2.47748207e+03, 3.03769349e+03])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([1.59403035e+04,\n",
    "       2.26238457e+03, 1.40300754e+03, 9.03945767e+03])).sample([10_000,]).mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([ 1.94390627e+01,\n",
    "       1.99240417e+00, 2.07841816e+00, 2.53949348e+00])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([1.67319273e+04,\n",
    "       8.27414401e+03, 6.84802281e+03, 2.71042895e+04])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best of genData2 + function idx 3\n",
    "# pis: 7.02865381e-02, 1.06889511e-01, 5.09662635e-02\n",
    "# this is actually fucking close; .07, .1 and .05\n",
    "Dirichlet(tensor([3.70873017e+04,\n",
    "       7.73578433e+03, 8.70734635e+03, 4.40364835e+03])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0790 * (.1/(.1 + .05)) + .3156 * (.05/(.1 + .05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pVgivenD(rr, pV):\n",
    "    return (rr * pV) / (rr * pV + (1 - pV))\n",
    "\n",
    "# pD: prevalence, tensor of mConditions x 1\n",
    "# pVgivenD: tensor of mConditions x 1\n",
    "# pV: allele frequency\n",
    "def pVgivenNotD(pD, pV, pVgivenD):\n",
    "    p = (pV - (pD*pVgivenD).sum()) / (1 - pD.sum())\n",
    "    assert(p >= 0)\n",
    "    return p\n",
    "\n",
    "# def pVgivenNotD(pD, pV, pVgivenD):\n",
    "#     p = (pV - (pD*pVgivenD)) / (1 - pD)\n",
    "#     assert(p >= 0)\n",
    "#     return p\n",
    "\n",
    "def pDgivenV(pD, pVgivenD, pV):\n",
    "    return pVgivenD * pD / pV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(V) = P(V|D1)P(D1) + P(V|D2)P(D2) + P(V|DBoth)P(DBoth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(D) = P(D1|V)P(V) + P(D2|V)P(V) + P(DBoth|V)P(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = P(D|V) / P(D|!V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(D|V) = P(D1|V) + P(D2|V) + P(DBoth|V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([3.09019048e+04,\n",
    "       4.19213154e+03, 4.21335767e+03, 4.26188535e+03])).sample([10_000]).mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([1.80304463e+04,\n",
    "       4.22627298e+03, 4.08179035e+03, 2.08259009e+03])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([3.89260152e+04,\n",
    "       6.21964619e+03, 6.44190860e+03, 3.01255992e+03])).sample([10_000]).mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DirichletMultinomial(tensor[10e4, 1e3, 1e3, 1e3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat) )\n",
    "def oneProbDMN(n, alphas, counts):\n",
    "    return torch.exp( DirichletMultinomial(total_count=n, concentration=alphas).log_prob(counts) )\n",
    "\n",
    "def oneProbMN(n, probs, counts):\n",
    "    return torch.exp( Multinomial(total_count=n, probs=tensor(probs)).log_prob(tensor(counts)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedCount = 2.\n",
    "iCount1 = 1.\n",
    "iCount2 = 1.\n",
    "\n",
    "# in shared genes\n",
    "sample1Count = iCount1 + sharedCount\n",
    "sample2Count = iCount2 + sharedCount\n",
    "sampleBothCount = iCount1 + iCount2 + sharedCount\n",
    "oneProbMN(4., [.1,.1,.1], [1.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DirichletMultinomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([1.54761107e+01,\n",
    "       6.02123698e-01, 1.21507139e+00, 1.54442097e-04])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([18.3388,  1.8321,  0.5886,  0.0941])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([34300.5433,  3441.8291,  1440.9554,   127.5581])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal = tensor([1., 2., 0, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(Multinomial(probs=tensor([0.01, 0.01, 0.01, 0.01])).log_prob(marginal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([1.67153400e+04,\n",
    "       1.18286093e+03, 1.40517890e+03, 1.44319379e+03])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([2.59400775e+04,\n",
    "       2.47609775e+03, 2.29825512e+03, 3.59544889e+02])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([2.33948260e+04,\n",
    "       1.41297532e+03, 1.46910198e+03, 1.56015665e+02])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genData4, likelihood2i, epoch 1\n",
    "Dirichlet(tensor([2.11498113e+04,\n",
    "       3.32979065e+03, 3.31985949e+03, 3.88146710e+03])).sample([10_000]).mean(0)\n",
    "\n",
    "# genData4, likelihood2i ,epoch 2\n",
    "Dirichlet(tensor([5.70757138e+01,\n",
    "       8.66106939e+00, 8.56601513e+00, 1.01019871e+01])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([2.46362341e+04,\n",
    "       3.87863391e+03, 3.86748009e+03, 4.52212702e+03])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([5.70061092e+01,\n",
    "       8.63865940e+00, 8.57262742e+00, 1.00505577e+01])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([4.93612217e+04,\n",
    "       6.23437490e+03, 6.17674668e+03, 3.64023421e+03])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([2.27326493e+04,\n",
    "       2.87094354e+03, 2.84417493e+03, 1.67617095e+03])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([3.10033120e+04,\n",
    "       3.91561327e+03, 3.87910403e+03, 2.28663592e+03])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tensor([0,1,22,31,40,52,6,7,8,91,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[-tensor([0,3,10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pVgivenD(rr, pV):\n",
    "    return (rr * pV) / (rr * pV + (1 - pV))\n",
    "\n",
    "# pD: prevalence, tensor of mConditions x 1\n",
    "# pVgivenD: tensor of mConditions x 1\n",
    "# pV: allele frequency\n",
    "def pVgivenNotD(pD, pV, pVgivenD):\n",
    "    p = (pV - (pD*pVgivenD).sum()) / (1 - pD.sum())\n",
    "    if(p < 0):\n",
    "        raise ValueError(f\"pVgivenNotD: invalid params: pD: {pD}, pV: {pV}, pVgivenD: {pVgivenD} yield: p = {p}\")\n",
    "    return p\n",
    "\n",
    "# def pVgivenNotD(pD, pV, pVgivenD):\n",
    "#     p = (pV - (pD*pVgivenD)) / (1 - pD)\n",
    "#     assert(p >= 0)\n",
    "#     return p\n",
    "\n",
    "def pDgivenV(pD, pVgivenD, pV):\n",
    "    return pVgivenD * pD / pV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = 10\n",
    "pV = 1e-4\n",
    "\n",
    "pvgivend = pVgivenD(rr, pV)\n",
    "print(pvgivend)\n",
    "pDgivenV(pD = .01, pVgivenD = pvgivend, pV=pV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM(tensor([7.86794799e+02,\n",
    "       9.71017825e+03, 9.99508241e+03, 1.14765185e+04])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0216 * .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".66 * 0.3048 * .1 + .33 * .1 * (0.3048 + 0.3567)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2M round 1 final number:\n",
    "DM(tensor([0.7389, 0.7504, 0.1959])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples1\n",
    ".66 * .1 * .7389 + .33 * .1 * (0.7389 + 0.1959)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DirichletMultinomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best 2 params for round 1 of rr = 5, rr = 5 , rr = 2 and model 2l\n",
    "DM(tensor([2.73908616e+04,\n",
    "       1.59702502e+03, 1.69733393e+03, 4.46021382e+02])).sample([10_000,]).mean(0)\n",
    "\n",
    "DM(tensor([4.38209361e+02,\n",
    "       2.46545176e+01, 2.63717375e+01, 7.22616621e+00])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 best for rr = 3, rr = 3 , rr = 1.5 and model 2l\n",
    "DM(tensor([1.00697359e+03,\n",
    "       3.61357400e+01, 3.75683988e+01, 9.63759760e+00])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM(tensor([5.87372505e+03,\n",
    "       2.13632552e+04, 2.11317348e+04, 9.39869442e+03])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM(tensor([6.08863291e+02,\n",
    "       2.08288623e+01, 2.08965160e+01, 6.25787127e+00])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM(tensor([2.73667035e+04,\n",
    "       1.41288604e+03, 1.12626550e+03, 1.68162263e-03])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM(tensor([3.70329944e+02,\n",
    "       1.02952233e+01, 1.11533395e+01, 2.44187071e+00])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM(tensor([2.39872919e+04,\n",
    "       8.93246165e+02, 8.55821572e+02, 9.28781215e+01])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM(tensor([1.84832811e+04,\n",
    "       2.27506360e+03, 2.18035721e+03, 4.17154933e+02])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best epoch of rr 5 rr 5 rr 2 fractions .05 .05 .05 likelihood2l, first run\n",
    "DM(tensor([4.43312407e+02,\n",
    "       2.52019987e+01, 2.54726471e+01, 2.55182419e+00])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd run\n",
    "DM(tensor([1.34015028e+04,\n",
    "       8.00831023e+02, 8.28118710e+02, 6.14283168e+01])).sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "import torch\n",
    "\n",
    "\n",
    "def truncated_normal(size, threshold=1):\n",
    "    values = truncnorm.rvs(-threshold, threshold, size=size)\n",
    "    return values\n",
    "\n",
    "# usage example\n",
    "x= truncnorm([10, 20], threshold=1)   # sample 10x20 sized tensor\n",
    "x = torch.from_numpy(x).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncnorm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = tensor([3.,2.])\n",
    "cov = tensor([[1., .9],[.9,1.]])\n",
    "\n",
    "from torch.distributions import MultivariateNormal\n",
    "mvn = MultivariateNormal(mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = mvn.sample([1000])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testOne = MultivariateNormal(loc=tensor([5., 5.]), covariance_matrix=tensor([[1., 0.],[0., 1]])).sample([20_000])\n",
    "testOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(testOne[:, 0], testOne[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MultivariateNormal(loc=tensor([7., 7., 12.]), covariance_matrix=tensor([[1., 0.9, 0.9],[0.9, 1, 0.9], [0.9, 0.9, 1.]])).sample([20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1\", test[:, 0].min())\n",
    "print(\"1\", test[:, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(test[:, 0], test[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LogNormal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "m.sample([10_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stats.multivariate_normal.cdf(test, mean, cov)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multinomial.cdf(value=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([6.37228665e+05,\n",
    "       3.94523352e+04, 3.58150096e+04, 4.00801714e+03])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multinomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([3.45767546e+02,\n",
    "       2.02085162e+01, 1.89984386e+01, 2.06313145e+00])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([4.58943594e+02,\n",
    "       1.62079432e+01, 1.39259322e+01, 1.74798837e+00])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P(V|D)P(D) = P(D|V)P(V) or P(V|D)P(D) ~ P(D|V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([2.62689297e+02,\n",
    "       1.46873198e+03, 1.28028588e+03, 9.60504829e+02])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([1070.0174, 6370.6853, 5331.2606, 3840.4440])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([4.85336455e+03,\n",
    "       2.50057173e+04, 2.79659395e+04, 1.49752803e+04])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([2.63195506e+03,\n",
    "       2.99568070e+02, 3.03870925e+02, 2.64435039e+01])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([2.63195506e+03,2.99568070e+02, 3.03870925e+02, 2.64435039e+01])).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = tensor([0.9785, 0.0098, 0.0098, 0.0020])\n",
    "alphas = tensor([1.84813348e+03, 2.09636601e+04, 2.13425518e+04, 9.79171130e+03])\n",
    "print(\"P(D|V) inferred in first component is:\", Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0))\n",
    "print(\"P(D|V) inferred in first component is:\", Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = MultivariateNormal(tensor([5, 5, 2.]), tensor([[1,0, 0.], [0, 1, 0], [0, 0, 1]])).sample([10_000])\n",
    "r.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Gamma(50, 50/2).sample([10_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first run\n",
    "# res = tensor([6.02019095e-03, 1.67553253e-02, 9.74496445e-03, 7.69605932e+03,\n",
    "#        1.69769687e+04, 1.27275565e+04, 1.37402223e+04])\n",
    "# best run\n",
    "res = tensor([1.95625714e-03, 4.34741045e-03, 7.93597145e-03, 9.49925716e+03,\n",
    "       2.27481847e+04, 1.94932489e+04, 1.71843974e+04])\n",
    "inferredPis = res[0:3]\n",
    "inferredAlphas = res[3:]\n",
    "pDsRun = tensor([0.0280, 0.0280, 0.0112])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvl import genData, likelihoods\n",
    "\n",
    "rrsSimRun = tensor([1.5, 1.5, 1.5])\n",
    "pisSimRun = tensor([.01, .01, .01])\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(5e5)\n",
    "afMeanRun = 1e-4\n",
    "\n",
    "paramsRun = genData.genParams(rrMeans=rrsSimRun, pis=pisSimRun, afMean=afMeanRun, rrShape=tensor(50.), afShape=tensor(50.), nCases=nCases, nCtrls=nCtrls)[0]\n",
    "\n",
    "pDsRun = paramsRun[\"pDs\"]\n",
    "pisRun = paramsRun[\"diseaseFractions\"]\n",
    "print(\"params are:\", paramsRun)\n",
    "\n",
    "generatingFn = genData.v6\n",
    "\n",
    "resPointer = generatingFn(**paramsRun)\n",
    "\n",
    "afsRun = resPointer[\"afs\"]\n",
    "xsRun = resPointer[\"altCounts\"]\n",
    "afsRun = resPointer[\"afs\"]\n",
    "affectedGenesRun = resPointer[\"affectedGenes\"]\n",
    "unaffectedGenesRun = resPointer[\"unaffectedGenes\"]\n",
    "\n",
    "                \n",
    "component1Afs = afsRun[affectedGenesRun[0]]\n",
    "afMeanRun \n",
    "c1true = (component1Afs / afMeanRun).mean(0)\n",
    "\n",
    "component2Afs = afsRun[affectedGenesRun[1]]\n",
    "c2true = (component2Afs / afMeanRun).mean(0)\n",
    "\n",
    "componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "cBothTrue = (componentBothAfs / afMeanRun).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = tensor([1-pDsRun.sum(), *pDsRun])\n",
    "alphas = inferredAlphas.numpy()\n",
    "c1inferred = Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "c2inferred = Dirichlet(tensor([alphas[0], alphas[0], alphas[2], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "cBothInferred = Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\\nresults for rrs: {rrsSimRun}, pis: {pisSimRun}\")\n",
    "print(\"Inferred pis:\", inferredPis)\n",
    "print(\"\\nP(D|V) true ans in component 1:\", c1true)\n",
    "print(\"P(D|V) inferred in component 1:\", c1inferred)\n",
    "print(\"\\nP(D|V) true ans in component 1:\", c2true)\n",
    "print(\"P(D|V) inferred in component both:\", c2inferred)\n",
    "print(\"\\nP(D|V) true ans in component both:\", cBothTrue)\n",
    "print(\"P(D|V) inferred in component both:\", cBothInferred,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#https://github.com/zachjennings/truncMVN/blob/master/truncMVN.pyimport numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import mvn\n",
    "\n",
    "class truncMVN(object):\n",
    "    \"\"\"\n",
    "    Class to calculate PDF of a 2D truncated multivariate normal distribution.\n",
    "    \n",
    "    Uses method of Alan Genz to calculate MVN CDF, implemented in scipy.\n",
    "    \n",
    "    low_int_limit: lower limit for *integration* of the CDFs. This is different than the lower\n",
    "    limit of the bound we want to normalize! Setting to a value several SDs lower than mean should be fine.\n",
    "    \n",
    "    low: lower limit for the bound that we want to normalize over. Again, different from the\n",
    "    lower integration limit!\n",
    "    \n",
    "    high: upper limit for the bound that we want to normalize over\n",
    "    \n",
    "    calc_norm: If true, calculate normalization at initialization. \n",
    "    \"\"\"\n",
    "    def __init__(self, mean=None,cov=None,low=None,high=None,re_norm=True,low_int_limit=np.array([-10.,-10.]),calc_norm=False):                    \n",
    "        self.low_int_limit = low_int_limit\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.re_norm = re_norm\n",
    "        \n",
    "        if calc_norm:\n",
    "            self.norm = self.normalize(mean,cov,high,low)\n",
    "            \n",
    "    \n",
    "    def normalize(self,mean=None,cov=None,low=None,high=None):\n",
    "        \"\"\"\n",
    "        Calculate normalization term for the truncated MVN.\n",
    "        \n",
    "        Involves calculation of four CDF terms:\n",
    "        P(4) - P(3) - P(2) + P(1)\n",
    "        \"\"\"\n",
    "        #calculate CDF of full region\n",
    "        cdf_4,i = mvn.mvnun(self.low_int_limit,high,mean,cov)\n",
    "        \n",
    "        #calculate CDFs of outside regions\n",
    "        cdf_3,i = mvn.mvnun(self.low_int_limit,np.array([high[0],low[1]]),mean,cov)\n",
    "        cdf_2,i = mvn.mvnun(self.low_int_limit,np.array([low[0],high[1]]),mean,cov)\n",
    "        \n",
    "        #calculate CDF of lower-left corner region\n",
    "        cdf_1,i = mvn.mvnun(self.low_int_limit,low,mean,cov)\n",
    "        \n",
    "        reg_prob = (cdf_4 - cdf_3 - cdf_2 + cdf_1)\n",
    "                \n",
    "        return 1./reg_prob\n",
    "            \n",
    "        \n",
    "    def logpdf(self,data,mean=np.array([]),cov=np.array([]),re_norm=True,approx=False):\n",
    "        \"\"\"\n",
    "        Calculate the logpdf for a truncated MVN\n",
    "        \n",
    "        data = 2 x n array containing data to calc PDFs for.\n",
    "        mean: 2 x 1 array value for MVN mean\n",
    "        cov:  2x2 covariance matrix\n",
    "        \n",
    "        re_norm: if true, re-calculate normalization of the pdf\n",
    "        \n",
    "        approx: if sigmas are small, normalization is very\n",
    "        close to 1 and might throw errors, so just skip. \n",
    "        \"\"\"\n",
    "        lpdf = stats.multivariate_normal.logpdf(data,mean=mean,cov=cov)\n",
    "        \n",
    "        \n",
    "        if re_norm:\n",
    "            #if the covaraince terms are really small, re-normalization\n",
    "            #seems to throw NaNs and we probably don't need to anyway.\n",
    "            #could be dangerous.\n",
    "            if ((cov[0,0] < 1e-3) or (cov[1,1] < 1e-3)) and approx:\n",
    "                norm = 1.\n",
    "                \n",
    "            else:\n",
    "                norm = self.normalize(mean,cov,self.low,self.high)\n",
    "        else:\n",
    "            norm = self.norm\n",
    "            \n",
    "        return np.log(norm) + lpdf\n",
    "        \n",
    "        \n",
    "    def pdf(self,data,mean=np.array([]),cov=np.array([]),re_norm=True):\n",
    "        \"\"\"\n",
    "        Calculate the pdf for a truncated MVN\n",
    "        \n",
    "        data = 2 x n array containing data to calc PDFs for.\n",
    "        mean: 2 x 1 array value for MVN mean\n",
    "        cov:  2x2 covariance matrix\n",
    "        \"\"\"\n",
    "        pdf = stats.multivariate_normal.logpdf(data,mean=mean,cov=cov)\n",
    "        \n",
    "        if re_norm:\n",
    "            norm = self.normalize(mean,cov,self.low,self.high)\n",
    "        else:\n",
    "            norm = self.norm\n",
    "            \n",
    "        return norm * pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def __init__(self, mean=None,cov=None,low=None,high=None,re_norm=True,low_int_limit=np.array([-10.,-10.]),calc_norm=False):  \n",
    "x = truncMVN(mean=[1.5,2], cov=[[1,1],[1,1]], low=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyper\n",
      "  Downloading PypeR-1.1.2.tar.gz (15 kB)\n",
      "Building wheels for collected packages: pyper\n",
      "  Building wheel for pyper (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyper: filename=PypeR-1.1.2-py3-none-any.whl size=11268 sha256=4d5802adac9f268d6012e688a0ae7fa37d7f8b79ea49dd384ad2982afa437758\n",
      "  Stored in directory: /Users/alexkotlar/Library/Caches/pip/wheels/6a/5c/2c/b525230bf0acc367f94ca31c3d98aa38f453a07223fbc788a8\n",
      "Successfully built pyper\n",
      "Installing collected packages: pyper\n",
      "Successfully installed pyper-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1\n",
      "0  11.851355  3.914554\n",
      "1   9.604210  1.531117\n",
      "2  13.059306  2.129262\n",
      "3   9.686183  2.281915\n",
      "4  10.544949  3.627168\n"
     ]
    }
   ],
   "source": [
    "from pyper import *\n",
    "import pandas as pd\n",
    "r=R(use_pandas=True)\n",
    "x = 10\n",
    "r(f'''\n",
    "    library(tmvtnorm)\n",
    "    sigma <- matrix(c(4,2,2,3), ncol=2)\n",
    "    x <- rtmvnorm(n=500, mean=c({x},2), sigma=sigma, lower=c(1,1))\n",
    "\n",
    "         ''')\n",
    "out = pd.DataFrame(r.get('x'))\n",
    "print(out.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = r.get('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.42407528],\n",
       "       [0.42407528, 1.        ]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(t[:,1], t[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "nGenes = 20_000\n",
    "rrMeans = [5, 5, 2]\n",
    "\n",
    "r=R(use_pandas=True)\n",
    "r(f'''\n",
    "    library(tmvtnorm)\n",
    "    sigma <- matrix(c(1,.7,.7, .7, 1, .7 , .7, .7, 1), ncol=3)\n",
    "    x <- rtmvnorm(n={nGenes}, mean=c({rrMeans[0] + rrMeans[2]}, {rrMeans[1] + rrMeans[2]}, {rrMeans[0] + rrMeans[1] + rrMeans[2]}), sigma=sigma, lower=c(1,1,1))\n",
    "  ''')\n",
    "rrsShared = tensor(r.get('x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.69978293],\n",
       "       [0.69978293, 1.        ]])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(rrsShared[:, 0], rrsShared[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.0052,  7.0020, 12.0014], dtype=torch.float64)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrsShared.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.5747,  5.0169, 11.5317],\n",
      "        [ 9.3174,  8.2048, 12.8711],\n",
      "        [ 6.7278,  5.3465, 11.7076],\n",
      "        ...,\n",
      "        [ 6.4923,  5.5736, 11.8726],\n",
      "        [ 6.3579,  7.0421, 10.4092],\n",
      "        [ 8.8812,  9.1703, 13.1311]], dtype=torch.float64)\n",
      "tensor([[3.4565, 4.8227],\n",
      "        [3.5324, 5.2254],\n",
      "        [5.0791, 4.6884],\n",
      "        ...,\n",
      "        [5.4115, 4.7791],\n",
      "        [4.3682, 4.8309],\n",
      "        [7.8831, 5.0392]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "r(f'''\n",
    "    library(tmvtnorm)\n",
    "    sigma <- matrix(c(1,.7,.7, .7, 1, .7 , .7, .7, 1), ncol=3)\n",
    "    rrsShared <- rtmvnorm(n={nGenes}, mean=c({rrMeans[0] + rrMeans[2]}, {rrMeans[1] + rrMeans[2]}, {rrMeans[0] + rrMeans[1] + rrMeans[2]}), sigma=sigma, lower=c(1,1,1))\n",
    "    sigma <- matrix(c(1, 0, 0, 1), ncol=2)\n",
    "    rrsOne <- rtmvnorm(n={nGenes}, mean=c({rrMeans[0]}, {rrMeans[1]}), sigma=sigma, lower=c(1,1))\n",
    "  ''')\n",
    "rrsShared = tensor(r.get('rrsShared'))\n",
    "rrsOne = tensor(r.get('rrsOne'))\n",
    "print(rrsShared)\n",
    "print(rrsOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-344-7aea9289945a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrr2\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mrtmvnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mnGenes\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mrrMeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mrrMeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   ''')\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrrsOne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rr2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# rrsOne = tensor(r.get('rrsOne'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrrsOne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of NoneType"
     ]
    }
   ],
   "source": [
    "r(f'''\n",
    "    sigma <- matrix(c(1, 0, 0, 1), ncol=2)\n",
    "    rr2 <- rtmvnorm(n={nGenes}, mean=c({rrMeans[0]}, {rrMeans[1]}), sigma=sigma, lower=c(1,1,1))\n",
    "  ''')\n",
    "rrsOne = tensor(r.get('rr2'))\n",
    "# rrsOne = tensor(r.get('rrsOne'))\n",
    "print(rrsOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
