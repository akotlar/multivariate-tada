{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyro-ppl in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: tqdm>=4.36 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (4.42.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (1.4.0)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (0.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (1.18.2)\n",
      "Requirement already satisfied: blackbox in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (0.7.1)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.4.1-cp37-cp37m-macosx_10_6_intel.whl (28.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.4 MB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scipy) (1.18.2)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.4.1\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "!pip install pyro-ppl\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import torch.tensor as tensor\n",
    "import pyro.distributions as dist\n",
    "from pyro.distributions import Binomial, Categorical, Dirichlet, DirichletMultinomial, Beta, BetaBinomial, Uniform, Gamma\n",
    "\n",
    "import scipy\n",
    "from collections import namedtuple\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Samples = namedtuple(\"Samples\", [\"ctrls\", \"cases\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0574)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of how to go from log_prob to prob\n",
    "d = dist.Binomial(total_count=10,probs=.1)\n",
    "torch.exp(d.log_prob(tensor(3.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Scalar version took: 0.10182571411132812\n",
      "Done\n",
      "Tensor version took: 3.2070868015289307\n",
      "Done\n",
      "Tensor convert array version took: 0.13137578964233398\n"
     ]
    }
   ],
   "source": [
    "# Measuring overhead\n",
    "import time\n",
    "\n",
    "# .1s\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(i)\n",
    "\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Scalar version took: {time.time() - start}\")\n",
    "\n",
    "# 30x slower, 3.2s\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(tensor(i))\n",
    "\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Tensor version took: {time.time() - start}\")\n",
    "\n",
    "# do it in one pass\n",
    "# this wraps the array in tensor, aka tensor([]),\n",
    "# but accessing a single element gives back a tensor\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(i)\n",
    "\n",
    "# .13s \n",
    "l = torch.tensor(l)\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Tensor convert array version took: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood functions\n",
    "# These assume univariate currently\n",
    "\n",
    "# rr: relative risk\n",
    "def pVgivenD(rr, pV):\n",
    "    return (rr * pV) / (rr * pV + (1 - pV))\n",
    "\n",
    "# pD: prevalence\n",
    "# pV: allele frequency\n",
    "def pVgivenNotD(pD, pV, pVgivenD):\n",
    "    p = (pV - pD*pVgivenD) / (1 - pD)\n",
    "    assert(p >= 0)\n",
    "    return p\n",
    "    \n",
    "def llUnivariateSingleGene(xCtrl, xCase, pD, pi0, pi1, pDgivenV):\n",
    "    n = xCtrl + xCase\n",
    "    return torch.log(pi0 * torch.exp(Binomial(total_count=n, probs=pD).log_prob(xCase)) + pi1*torch.exp(Binomial(total_count=n, probs=pDgivenV).log_prob(xCase)))\n",
    "\n",
    "# shape of altCountsByGene: [nGenes, nConditions, 2]\n",
    "# last dimension is \n",
    "# 2nd dimension altCountsCasesByGene must match controls, or the control nConditions must be 1 (pooled controls)\n",
    "# all values are torch tensors\n",
    "# returns negative log likelihood for use as cost function\n",
    "def likelihoodUnivariate(altCountsByGene, pD):\n",
    "    nGenes = len(xCtrlAllGenes)\n",
    "    \n",
    "    # passed to optimization function, we optimize pDgivenV and pi1 by maximizing likelihood\n",
    "    def likelihood(pDgivenV, pi1):\n",
    "        pi0 - 1 - pi\n",
    "        \n",
    "        if(pDgivenV >= 1 or pDgivenV < 0 or pi1 < 0 or pi1 > 1):\n",
    "            return float(\"-inf\")\n",
    "    \n",
    "        logLikelihood = 0\n",
    "        penaltyCount = float(nGenes)\n",
    "        \n",
    "        # shap\n",
    "        for geneIdx in range(nGenes):\n",
    "            ctrlAltCount = altCountsByGene[geneIdx, 0, 0]\n",
    "            caseAltCount = altCountsByGene[geneIdx, 0, 1]\n",
    "            \n",
    "            if ctrlAltCount == 0 or caseAltCont == 0:\n",
    "                next\n",
    "\n",
    "            # likelihoodUnivariateSingleGene = function(xCtrl, xCase1, prevalence1, pi0, pi1, pDiseaseGivenVariant)\n",
    "            ll = llUnivariateSingleGene(ctrlCount, caseCount, pD, pi0, pi1, pDgivenV)\n",
    "            \n",
    "            if torch.isnan(ll) or torch.isinf(ll):\n",
    "                print(f\"nan or 0 likelihood: like: {like}, p1: {pi1}, pDgivenV: {pDgivenV}, gene: {geneIdx}, ctrlCount: {ctrlCount}, caseCount: {caseCount}\")\n",
    "                penaltyCount -= 1\n",
    "                next\n",
    "                \n",
    "            logLikelihood += ll\n",
    "        \n",
    "    \n",
    "        if penaltyCount == 0:\n",
    "            penaltyCount = 1\n",
    "    \n",
    "        -logLikelihood * (nGenes / penaltyCount)\n",
    "\n",
    "def cb(x, f, context):\n",
    "    print(\"got callback\", x, f, context)\n",
    "\n",
    "# TODO: update for multivariate\n",
    "def fitFnUniveriate(altCountsByGene, pD, nEpochs = 10):\n",
    "    costFn = likelihoodUnivariate(altCountsByGene, pD)\n",
    "    \n",
    "    res = {\"ll\": [], \"parameters\": []}\n",
    "    lls = res[\"ll\"]\n",
    "    params = res[\"parameters\"]\n",
    "\n",
    "    minLLDiff = 1\n",
    "    minLLThresholdCount = 5\n",
    "    thresholdHitCount = 0\n",
    "    \n",
    "    randomDist = Uniform(0, 1)\n",
    "    fnArgs = [0, 0]\n",
    "    # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "    # P(V|D) * P(D) / P(V)\n",
    "    nGenes = len(altCountsByGene)\n",
    "    pDgivenVbounds = ( pVgivenD(2, 1e-6) * .001 / 1e-6, pVgivenD(100, 1e-2) * .1 / 1e-2 )\n",
    "    # above .5 (for 2 hypothesis cas) we've flipped labels\n",
    "    # TODO: update for multivariate\n",
    "    nHypotheses = 2 #H0, H1\n",
    "    pi1Bounds = ( 1/nGenes,  1/nHypotheses )\n",
    "    bounds = [pDgivenVbounds, pi1Bounds]\n",
    "    for i in range(nEpochs):\n",
    "        # pDgivenV\n",
    "        fnArgs[0] = randomDist.sample()\n",
    "        # pi1\n",
    "        fnArgs[1] = randomDist.sample()\n",
    "                \n",
    "        try:\n",
    "            fit = scipy.optimize.dual_annealing(costFn, bounds = bounds, x0 = fnArgs, callback = cb, seed = seed)\n",
    "        except(e):\n",
    "            print(f\"Couldn't fit using: pi1guess: {pi1guess}, pDgivenVguess: {pDgivenVguess}\")\n",
    "            next\n",
    "        \n",
    "        print(fit)\n",
    "#         if(is.null(fit) || fit$value == 0 || fit$convergence != 0 || fit$par[[\"pi1\"]] <= 0 || fit$par[[\"pi1\"]] >= 1 || fit$par[[\"pDiseaseGivenVariant\"]] <= 0 || fit$par[[\"pDiseaseGivenVariant\"]] >= 1 ) {\n",
    "#           print(\"Failed to converge\")\n",
    "#           print(fit)\n",
    "#           next\n",
    "#         }\n",
    "\n",
    "        if len(lls) == 0:\n",
    "            lls.append(1)\n",
    "            params.append(1)\n",
    "            next\n",
    "    \n",
    "#         if(length(results$ll) == 0) {\n",
    "#           results$ll = append(results$ll, fit$value)\n",
    "#           results$par = append(results$par, data.frame(fit$par))\n",
    "#           next\n",
    "#         }\n",
    "        \n",
    "        maxPrevious = max(lls)\n",
    "        \n",
    "        if fit[\"value\"] != maxPrevious and (fit[\"value\"] - maxPrevious) > minLLDiff:\n",
    "            thresholdHitCount = 0\n",
    "            print(f\"fit: {fit}\")\n",
    "            lls.append(fit[\"ll\"])\n",
    "            params.append(fit[\"params\"])\n",
    "            next\n",
    "        \n",
    "    \n",
    "        #         if(fit$value != maxPrevious && (fit$value - maxPrevious) > minLLDiff) {\n",
    "        #           thresholdHitCount = 0\n",
    "        #           print(fit)\n",
    "        #           results$ll = append(results$ll, fit$value)\n",
    "        #           results$par = append(results$par, data.frame(fit$par))\n",
    "        #           next\n",
    "        #         }\n",
    "\n",
    "        thresholdHitCount += 1\n",
    "        \n",
    "        if thresholdHitCount == minLLThresholdCount:\n",
    "            break\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0100e+05, 1.0000e+03, 1.0000e+02])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nSamples.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrMeans = tensor([10., 10., 5.])\n",
    "rrShape = tensor(10.)\n",
    "rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input arguments must all be instances of numbers.Number or torch.tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-be3e608b86ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnSamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/distributions/binomial.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, total_count, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Either `probs` or `logits` must be specified, but not both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mis_scalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/distributions/utils.py\u001b[0m in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input arguments must all be instances of numbers.Number or torch.tensor.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input arguments must all be instances of numbers.Number or torch.tensor."
     ]
    }
   ],
   "source": [
    "Binomial(total_count=nSamples[0].numpy, probs=[tensor(.1),tensor(.1)]).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genData(nSamples, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "    # TODO: assert shapes match\n",
    "    print(\"TESTING WITH: nSamples\", nSamples, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "    nConditions = len(nSamples)\n",
    "    results = []\n",
    "    afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "    rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "    rrNullDist = Gamma(concentration=rrShape,rate=rrShape)\n",
    "    for geneIdx in range(nGenes):\n",
    "        af = afDist.sample()\n",
    "        \n",
    "        rrs = rrDist.sample()\n",
    "        rrNulls = rrNullDist.sample([nConditions,])\n",
    "        \n",
    "        geneRes = []\n",
    "        for conditionIdx in range(nConditions):\n",
    "            # TODO: sample from uniform\n",
    "            if geneIdx < nGenes * diseaseFractions[conditionIdx]:\n",
    "                rr = rrs[conditionIdx]\n",
    "            else:\n",
    "                rr = rrNulls[conditionIdx]\n",
    "            \n",
    "            probVgivenD = pVgivenD(rr, af)\n",
    "            probVgivenNotD = pVgivenNotD(pDs[conditionIdx], af, probVgivenD)\n",
    "            \n",
    "            altCounts = Binomial(total_count=nSamples, probs=tensor([probVgivenNotD, probVgivenD])).sample()\n",
    "            geneRes.append(altCounts)\n",
    "        \n",
    "        results.append(geneRes)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH: nSamples tensor([[100000.,   1000.],\n",
      "        [     0.,   1000.],\n",
      "        [     0.,    100.]]) rrMean tensor([10., 10.,  5.]) rrShape tensor(10.) afMean tensor(1.0000e-04) afShape tensor(10.) diseaseFractions tensor([0.1000, 0.1000, 0.0500]) pDs tensor([0.0100, 0.0100, 0.0030])\n"
     ]
    }
   ],
   "source": [
    "disease1 = Samples(1e5, 1e3)\n",
    "disease2 = Samples(0, 1e3)\n",
    "diseaseBoth = Samples(0, 1e2)\n",
    "\n",
    "nSamples = [disease1, disease2, diseaseBoth]\n",
    "nSamples = tensor(nSamples)\n",
    "\n",
    "pDs = tensor([.01, .01, .003])\n",
    "diseaseFractions = tensor([.1, .1, .05])\n",
    "rrShape = tensor(10.)\n",
    "rrMeans = tensor([10., 10., 5.])\n",
    "afMean = tensor(1e-4)\n",
    "afShape = tensor(10.)\n",
    "\n",
    "genData(nSamples=nSamples, pDs=pDs, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
