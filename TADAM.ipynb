{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.5.0-cp37-none-macosx_10_9_x86_64.whl (80.5 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from torch) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: future in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from torch) (0.18.2)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "Successfully installed torch-1.5.0\n",
      "Requirement already up-to-date: pyro-ppl in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.36 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (4.42.1)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.4.0 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pyro-api>=0.1.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (0.1.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: future in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from torch>=1.4.0->pyro-ppl) (0.18.2)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-macosx_10_6_intel.whl (28.4 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scipy) (1.18.2)\n",
      "\u001b[31mERROR: hail 0.2.37 has requirement scipy<1.4,>1.2, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.3.3\n",
      "    Uninstalling scipy-1.3.3:\n",
      "      Successfully uninstalled scipy-1.3.3\n",
      "Successfully installed scipy-1.4.1\n",
      "Requirement already up-to-date: matplotlib in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "Requirement already up-to-date: scikit-optimize in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.19.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.0 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: pyaml>=16.9 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (20.3.1)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyaml>=16.9->scikit-optimize) (5.3.1)\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "!pip install --upgrade torch\n",
    "!pip install --upgrade pyro-ppl\n",
    "!pip install --upgrade scipy\n",
    "!pip install --upgrade matplotlib\n",
    "!pip install --upgrade scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import torch.tensor as tensor\n",
    "import pyro.distributions as dist\n",
    "# from torch.distributions import Binomial, Gamma, Uniform\n",
    "from pyro.distributions import Binomial, Bernoulli, Categorical, Dirichlet, DirichletMultinomial, Beta, BetaBinomial, Uniform, Gamma, Multinomial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from skopt import gp_minimize \n",
    "from scipy.stats import binom as ScipyBinom\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from collections import namedtuple\n",
    "import time\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Scalar version took: 0.11874699592590332\n",
      "Done\n",
      "Tensor version took: 3.508963108062744\n",
      "Done\n",
      "Tensor convert array version took: 0.14176106452941895\n"
     ]
    }
   ],
   "source": [
    "# Measuring overhead\n",
    "import time\n",
    "\n",
    "# .1s\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(i)\n",
    "\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Scalar version took: {time.time() - start}\")\n",
    "\n",
    "# 30x slower, 3.2s\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(tensor(i))\n",
    "\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Tensor version took: {time.time() - start}\")\n",
    "\n",
    "# do it in one pass\n",
    "# this wraps the array in tensor, aka tensor([]),\n",
    "# but accessing a single element gives back a tensor\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(i)\n",
    "\n",
    "# .13s \n",
    "l = torch.tensor(l)\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Tensor convert array version took: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Likelihood functions\n",
    "# These assume univariate currently\n",
    " \n",
    "# TODO:\n",
    "# 1) Explore constraining alphas using prevalence estimate, namely E(P(D)) = alpha0 / (alpha0 + alpha1 + alpha2 + alphaBoth) (as long as all case counts are mutually exclusive)\n",
    "# 2) Can DM approximate NB + Multinomial? If so do we need mixture at all? But if we don't have that how do we model % disease-afffecting genes in each hypothesis(maybe proportion of alphas?)\n",
    "# rr: relative risk\n",
    "# P(V|D) = P(D|V)*P(V) / P(D)\n",
    "# rr * P(D|!V) = P(D|V)\n",
    "# P(V|D) = rr * P(D|!V) * P(V) / P(D)\n",
    "# P(D) = (P(D|V)P(V) + P(D|!V)P(!V))\n",
    "# P(D) = P(D|V) + P(D|!V)(1-P(V))\n",
    "# P(V|D) = ( rrP(D|!V)) ) * P(V) ) / ( (P(D|V)P(V) + P(D|!V)(1-P(V))) )\n",
    "# let a = ( rrP(D|!V)) ) * P(V) )\n",
    "# P(V|D) = a / P(D|!V) / ( P(D|V)P(V) + P(D|!V) - P(D|!V)P(V) ) / P(D|!V)\n",
    "# = ( rr*P(V) ) / ( rr*P(V) + 1 - P(V) )\n",
    "def pVgivenD(rr, pV):\n",
    "    return (rr * pV) / (rr * pV + (1 - pV))\n",
    "\n",
    "# pD: prevalence, tensor of mConditions x 1\n",
    "# pVgivenD: tensor of mConditions x 1\n",
    "# pV: allele frequency\n",
    "def pVgivenNotD(pD, pV, pVgivenD):\n",
    "    p = (pV - (pD*pVgivenD).sum()) / (1 - pD.sum())\n",
    "    if(p < 0):\n",
    "        raise ValueError(f\"pVgivenNotD: invalid params: pD: {pD}, pV: {pV}, pVgivenD: {pVgivenD} yield: p = {p}\")\n",
    "    return p\n",
    "\n",
    "# def pVgivenNotD(pD, pV, pVgivenD):\n",
    "#     p = (pV - (pD*pVgivenD)) / (1 - pD)\n",
    "#     assert(p >= 0)\n",
    "#     return p\n",
    "\n",
    "def pDgivenV(pD, pVgivenD, pV):\n",
    "    return pVgivenD * pD / pV\n",
    "\n",
    "# works like shit\n",
    "def llUnivariateSingleGeneJensen(xCtrl, xCase, pD, pi0, pi1, pDgivenV):\n",
    "    n = xCtrl + xCase\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    return pi0 * Binomial(total_count=n, probs=pD).log_prob(xCase) + pi1*Binomial(total_count=n, probs=pDgivenV).log_prob(xCase)\n",
    "\n",
    "def llUnivariateSingleGene(xCtrl, xCase, pD, pi0, pi1, pDgivenV):\n",
    "    n = xCtrl + xCase\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    return torch.log(pi0 * torch.exp(Binomial(total_count=n, probs=pD).log_prob(xCase)) + pi1*torch.exp(Binomial(total_count=n, probs=pDgivenV).log_prob(xCase)))\n",
    "\n",
    "# alphas shape: [2] #corresponding to cases and controls\n",
    "def llUnivariateSingleGeneBetaBinomial(xCtrl, xCase, pD, alphas, pi0, pi1):\n",
    "    n = xCtrl + xCase\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    # what is the \n",
    "    h0 = pi0 * torch.exp( Binomial(total_count=n, probs=pD).log_prob(xCase) )\n",
    "    h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alphas[1], concentration0=alphas[0]).log_prob(xCase) )\n",
    "    return torch.logalpha3( h0 + h1 )\n",
    "\n",
    "# TODO: support pooled and non-pooled controls\n",
    "# TODO: think about whether we need overlapping cases (both disease1 + disease2) or whether that can be inferred\n",
    "# altCounts.shape = [1 control + nConditions cases, 1]\n",
    "# alphas shape: [nConditions + 2] #1 ctrl + nCondition cases; for now the last condition in nCondition cases is for individuals who has all of the previous nConditions\n",
    "# in a more multivariate setting we will need more information, aka mapping to which combinations of conditions these people have\n",
    "# xCases: we have nConditions cases\n",
    "# pDs shape: [nConditions]\n",
    "# TODO: make this more effificent by taking alphas tensor of shape (1 + nConditions)\n",
    "def llPooledBivariateSingleGene(altCounts, pDs, alpha0, alpha1, alpha2, alphaBoth, pi0, pi1, pi2, piBoth):\n",
    "    # currently assume altCounts are all independent (in simulation), or 0 for everything but first condition\n",
    "    n = altCounts.sum()\n",
    "    alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "    print(\"n is \", n)\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    # what is the \n",
    "    case1nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[0]).log_prob(altCounts[1]) )\n",
    "    case2nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[1]).log_prob(altCounts[2]) )\n",
    "    h0 = pi0 * case1nullLikelihood * case2nullLikelihood\n",
    "    h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCounts[1]) ) * case2nullLikelihood\n",
    "    h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCounts[2]) ) * case1nullLikelihood\n",
    "    h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCounts))\n",
    "    print(f\"h0: {h0}, h1: {h1}, h2: {h2}, h3: {h3}\")\n",
    "    return torch.log( h0 + h1 + h2 + h3 )\n",
    "\n",
    "# shape of altCountsByGene: [nGenes, nConditions, 2]\n",
    "# last dimension is \n",
    "# 2nd dimension altCountsCasesByGene must match controls, or the control nConditions must be 1 (pooled controls)\n",
    "def likelihoodUnivariate(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    \n",
    "    # passed to optimization function, we optimize pDgivenV and pi1 by maximizing likelihood\n",
    "    def likelihood(params):\n",
    "        pDgivenV = params[0]\n",
    "        pi1 = params[1]\n",
    "        pi0 = 1 - pi1\n",
    "        \n",
    "        if(pDgivenV >= 1 or pDgivenV < 0 or pi1 < 0 or pi1 > 1):\n",
    "            print(\"returning inf\")\n",
    "            return float(\"-inf\")\n",
    "    \n",
    "        logLikelihood = 0\n",
    "        penaltyCount = float(nGenes)\n",
    "        \n",
    "        # \n",
    "        for geneIdx in range(nGenes):\n",
    "            ctrlAltCount = altCountsByGene[geneIdx, 0, 0]\n",
    "            caseAltCount = altCountsByGene[geneIdx, 0, 1]\n",
    "            pd = pDs[0]\n",
    "            \n",
    "            if ctrlAltCount == 0 and caseAltCount == 0:\n",
    "                print(\"skipping\", geneIdx)\n",
    "                continue\n",
    "\n",
    "            # this is insanely slow\n",
    "            ll = llUnivariateSingleGene(ctrlAltCount, caseAltCount, pd, pi0, pi1, pDgivenV)\n",
    "\n",
    "            if torch.isnan(ll) or torch.isinf(ll):\n",
    "                print(f\"nan or 0 likelihood: like: {like}, p1: {pi1}, pDgivenV: {pDgivenV}, gene: {geneIdx}, ctrlCount: {ctrlAltCount}, caseCount: {caseAltCount}\")\n",
    "                penaltyCount -= 1\n",
    "                continue\n",
    "                \n",
    "            logLikelihood += ll\n",
    "        \n",
    "    \n",
    "        if penaltyCount == 0:\n",
    "            penaltyCount = 1\n",
    "    \n",
    "        return -logLikelihood * (nGenes / penaltyCount)\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "def likelihoodUnivariateFast(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    geneSums = altCountsByGene[:, 0, :].sum(1)\n",
    "        \n",
    "    caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "    pD = pDs[0]\n",
    "    def likelihood(params):\n",
    "        pi1, pDgivenV = params\n",
    "\n",
    "        pi0 = 1.0 - pi1\n",
    "\n",
    "        if(pDgivenV > 1 or pDgivenV < 0 or pi1 < 0 or pi1 > 1):\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        binomH0 = Binomial(total_count=geneSums, probs=pD)\n",
    "        binomH1 = Binomial(total_count=geneSums, probs=pDgivenV)\n",
    "        \n",
    "        component0 = pi0 * torch.exp(binomH0.log_prob(caseAltCounts))\n",
    "        component1 = pi1 * torch.exp(binomH1.log_prob(caseAltCounts))\n",
    "        \n",
    "        return - torch.log(component0 + component1).sum()\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "def likelihoodUnivariateBetaBinomialFast(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    geneSums = altCountsByGene[:, 0, :].sum(1)\n",
    "        \n",
    "    caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "    pD = pDs[0]\n",
    "    def likelihood(params):\n",
    "        pi1, alpha1, alpha0 = params\n",
    "\n",
    "        if alpha1 < 0 or alpha0 < 0 or pi1 < 0 or pi1 > 1:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - pi1\n",
    "\n",
    "        binomH0 = Binomial(total_count=geneSums, probs=pD)\n",
    "        binomH1 = BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alpha0)\n",
    "        \n",
    "        component0 = pi0 * torch.exp(binomH0.log_prob(caseAltCounts))\n",
    "        component1 = pi1 * torch.exp(binomH1.log_prob(caseAltCounts))\n",
    "\n",
    "        return - torch.log(component0 + component1).sum()\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "def getUnivariateAlpha0(alpha1, pD):\n",
    "    return ((1-pD) / pD)*alpha1\n",
    "\n",
    "# doesn't really work constraint looks wrong\n",
    "def likelihoodUnivariateBetaBinomialConstrainedFast(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    geneSums = altCountsByGene[:, 0, :].sum(1)\n",
    "        \n",
    "    caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "    pD = pDs[0]\n",
    "    pNotDRatio = (1 - pD)/pD\n",
    "    def likelihood(params):\n",
    "        pi1, alpha1 = params\n",
    "        \n",
    "        if alpha1 < 0 or pi1 < 0 or pi1 > 1:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - pi1\n",
    "        \n",
    "        alpha0 = pNotDRatio*alpha1\n",
    "        \n",
    "        assert(alpha0 > 0)\n",
    "        \n",
    "        print(\"alpha0\",alpha0)\n",
    "        \n",
    "        binomH0 = Binomial(total_count=geneSums, probs=pD)\n",
    "        binomH1 = BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alpha0)\n",
    "        \n",
    "        component0 = pi0 * torch.exp(binomH0.log_prob(caseAltCounts))\n",
    "        component1 = pi1 * torch.exp(binomH1.log_prob(caseAltCounts))\n",
    "\n",
    "        return - torch.log(component0 + component1).sum()\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "# Bivariate likelihood function modeled on:\n",
    "#def llPooledBivariateSingleGene(altCounts, pDs, alpha0, alpha1, alpha2, alphaBoth, pi0, pi1, pi2, piBoth):\n",
    "# # currently assume altCounts are all independent (in simulation), or 0 for everything but first condition\n",
    "# n = altCounts.sum()\n",
    "# alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "# case1nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[0]).log_prob(altCounts[1]) )\n",
    "# case2nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[1]).log_prob(altCounts[2]) )\n",
    "# h0 = pi0 * case1nullLikelihood * case2nullLikelihood\n",
    "# h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCounts[1]) ) * case2nullLikelihood\n",
    "# h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCounts[2]) ) * case1nullLikelihood\n",
    "# h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCounts))\n",
    "# print(f\"h0: {h0}, h1: {h1}, h2: {h2}, h3: {h3}\")\n",
    "# return torch.log( h0 + h1 + h2 + h3 )\n",
    "def likelihoodBivariateFast(altCountsByGene, pDs):\n",
    "    globalCount = nSamples\n",
    "    nGenes = altCountsByGene.shape[0]\n",
    "\n",
    "    geneSums = altCountsByGene[:, :, :].sum([1,2])\n",
    "\n",
    "    ctrlCounts = altCountsByGene[:, 0, 0]\n",
    "    altCountsCases = altCountsByGene[:, :, 1]\n",
    "    \n",
    "    altCountsFlat = []\n",
    "    for geneIdx in range(nGenes):\n",
    "        altCountsFlat.append([ctrlCounts[geneIdx], *altCountsByGene[geneIdx, :, 1].flatten()])\n",
    "\n",
    "    altCountsFlat = tensor(altCountsFlat)\n",
    "    # nGenes x 4 \n",
    "    xCtrl = altCountsFlat[:, 0]\n",
    "    xCase1 = altCountsFlat[:, 1]\n",
    "    xCase2 = altCountsFlat[:, 2]\n",
    "    xCase12 = altCountsFlat[:, 3]\n",
    "    # nGenes x 1\n",
    "    n = xCtrl + xCase1 + xCase2 + xCase12\n",
    "    print(\"altCountsFlat\", altCountsFlat)\n",
    "    print(\"n\", n)\n",
    "    print(\"xCase1, xCase2, xCase12\", xCase1)\n",
    "    print(\"xCase1, xCase2, xCase12\", xCase2)\n",
    "    print(\"xCase1, xCase2, xCase12\", xCase12)\n",
    "    \n",
    "    pd1 = pDs[0]\n",
    "    pd2 = pDs[1]\n",
    "    pdBoth = pDs[2]\n",
    "\n",
    "    case1Null = torch.exp(Binomial(total_count=n, probs=pd1).log_prob(xCase1))\n",
    "    case2Null = torch.exp(Binomial(total_count=n, probs=pd2).log_prob(xCase2))\n",
    "    caseBothNull = torch.exp(Binomial(total_count=n, probs=pdBoth).log_prob(xCase12))\n",
    "    allNull = case1Null * case2Null * caseBothNull\n",
    "    allNull2 = torch.exp(Multinomial(probs=tensor([1-pDs.sum(), pDs[0], pDs[1], pDs[2]])).log_prob(altCountsFlat))\n",
    "    print(\"allNull2\", allNull2)\n",
    "    def likelihood1(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1) ) * case2Null * caseBothNull\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(xCase2) ) * case1Null * caseBothNull\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood1a(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1) ) * case2Null\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(xCase2) ) * case1Null\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood1b(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1 + xCase12) ) * case2Null\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(xCase2 + xCase12) ) * case1Null\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihoodConstrained(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "        \n",
    "        # idea 1\n",
    "        # alpha1 and alpha0 determined\n",
    "        # A gene has counts from gene1 samples 2 , from gene2 samples 1 geneBoth count\n",
    "        # if i have some people that only have 1, that is evidence for gene1 liability, but says nothing for liability for \n",
    "        # the more shared risk there is, the more the count will be in the \"both category\", \n",
    "        # the fewer people will be only one or the other\n",
    "        # so eventually all \n",
    "        # \n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1 + xCase12) ) * case2Null\n",
    "        \n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1 + xCase12) ) * case2Null\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(xCase2 + xCase12) ) * case1Null\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood2(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1) ) * case2Null * torch.exp( BetaBinomial(total_count=n, concentration1=alphaBoth, concentration0=alphasSum - alphaBoth).log_prob(xCase12) )\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(xCase2) ) * case1Null * torch.exp( BetaBinomial(total_count=n, concentration1=alphaBoth, concentration0=alphasSum - alphaBoth).log_prob(xCase12) )\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood2a(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1 + alphaBoth, concentration0=alphasSum - alpha1).log_prob(xCase1) ) * case2Null\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2 + alphaBoth, concentration0=alphasSum - alpha2).log_prob(xCase2) ) * case1Null \n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    \n",
    "    def likelihood2b(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha0, alpha1])).log_prob(altCountsFlat) )\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha0, alpha2, alpha2])).log_prob(altCountsFlat) )\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alphaBoth, alphaBoth, alphaBoth])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood2c(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1+alphaBoth, alpha0, alpha1+alphaBoth])).log_prob(altCountsFlat) )\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha0, alpha2+alphaBoth, alpha2+alphaBoth])).log_prob(altCountsFlat) )\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1+alphaBoth, alpha2+alphaBoth, alpha1+alphaBoth+alpha2])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood2c(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha0, alpha1])).log_prob(altCountsFlat) )\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha0, alpha2, alpha2])).log_prob(altCountsFlat) )\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood2d(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "        \n",
    "        # From E(P2_null) = P(D2) = a2 / (a0 + a1 + a2 + aB)\n",
    "        alpha2Null = pDs[1] * (alpha0 + alpha1 + alphaBoth) / (1 - pDs[1])\n",
    "        # h1 is that the genes in this component only increse risk for disease 1\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2Null, alpha1])).log_prob(altCountsFlat) )\n",
    "        alpha1Null = pDs[0] * (alpha0 + alpha2 + alphaBoth) / (1 - pDs[0])\n",
    "        # h2 is that the genes in this component only increse risk for disease 2\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1Null, alpha2, alpha2])).log_prob(altCountsFlat) )\n",
    "        # h3 is that the alleles in these genes increase risk for both diseases\n",
    "        # we model by individual and shared components ; hower in this component do samples affected only by disease 1 necessarily have the probability of seeing\n",
    "        # an allele that is the same as in the other cases? I think no, I think this is higher\n",
    "        # as the shared component becomes large and larger, if it is added to the other alpha1 (the individual copmonet only), alpha1 will equal alphaBoth, i.e\n",
    "        # they will be perfectly correlated\n",
    "        # else, alpha0 will be some amount larger than alphaBoth\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood2e(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "        \n",
    "        # From E(P2_null) = P(D2) = a2 / (a0 + a1 + a2 + aB)\n",
    "        # P(D2)(others) / (1-PD2) = a2\n",
    "        alpha2Null = pDs[1] * (alpha0 + alpha1 + alphaBoth) / (1 - pDs[1])\n",
    "        # h1 is that the genes in this component only increse risk for disease 1\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2Null, alpha1])).log_prob(altCountsFlat) )\n",
    "        alpha1Null = pDs[0] * (alpha0 + alpha2 + alphaBoth) / (1 - pDs[0])\n",
    "        # h2 is that the genes in this component only increse risk for disease 2\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1Null, alpha2, alpha2])).log_prob(altCountsFlat) )\n",
    "        # h3 is that the alleles in these genes increase risk for both diseases\n",
    "        # we model by individual and shared components ; hower in this component do samples affected only by disease 1 necessarily have the probability of seeing\n",
    "        # an allele that is the same as in the other cases? I think no, I think this is higher\n",
    "        # as the shared component becomes large and larger, if it is added to the other alpha1 (the individual copmonet only), alpha1 will equal alphaBoth, i.e\n",
    "        # they will be perfectly correlated\n",
    "        # else, alpha0 will be some amount larger than alphaBoth\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1 + alphaBoth, alpha2 + alphaBoth, alphaBoth + alpha1 + alpha2])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum\n",
    "        \n",
    "    # like 2d, but alphaBoth is the last component in each case\n",
    "    # this allows ffor inference of a weighted alphaBoth\n",
    "    # following the example of h3, where alpha1 is alpha1, not alpha1 + alphaBoth\n",
    "    def likelihood2f(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "        \n",
    "        # From E(P2_null) = P(D2) = a2 / (a0 + a1 + a2 + aB)\n",
    "        alpha2Null = pDs[1] * (alpha0 + alpha1 + alphaBoth) / (1 - pDs[1])\n",
    "        # h1 is that the genes in this component only increse risk for disease 1\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2Null, alphaBoth])).log_prob(altCountsFlat) )\n",
    "        alpha1Null = pDs[0] * (alpha0 + alpha2 + alphaBoth) / (1 - pDs[0])\n",
    "        # h2 is that the genes in this component only increse risk for disease 2\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1Null, alpha2, alphaBoth])).log_prob(altCountsFlat) )\n",
    "        # h3 is that the alleles in these genes increase risk for both diseases\n",
    "        # we model by individual and shared components ; hower in this component do samples affected only by disease 1 necessarily have the probability of seeing\n",
    "        # an allele that is the same as in the other cases? I think no, I think this is higher\n",
    "        # as the shared component becomes large and larger, if it is added to the other alpha1 (the individual copmonet only), alpha1 will equal alphaBoth, i.e\n",
    "        # they will be perfectly correlated\n",
    "        # else, alpha0 will be some amount larger than alphaBoth\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "        \n",
    "    # Like 2D, except alphaBoth in h1 and h2 is scaled by P(DBoth/PD1) or P(DBoth)/P(D1), since that is what is required\n",
    "    # to go to P(D|V) given a shared P(V|D), which is all we mean when we try to equate alpha1 and alphaboth in component 1\n",
    "    def likelihood2g(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "        \n",
    "        # From E(P2_null) = P(D2) = a2 / (a0 + a1 + a2 + aB)\n",
    "        alpha2Null = pDs[1] * (alpha0 + alpha1 + alphaBoth) / (1 - pDs[1])\n",
    "        # h1 is that the genes in this component only increse risk for disease 1\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2Null, alpha1 * pDs[2] / pDs[0]])).log_prob(altCountsFlat) )\n",
    "        alpha1Null = pDs[0] * (alpha0 + alpha2 + alphaBoth) / (1 - pDs[0])\n",
    "        # h2 is that the genes in this component only increse risk for disease 2\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1Null, alpha2, alpha2 * pDs[2] / pDs[1]])).log_prob(altCountsFlat) )\n",
    "        # h3 is that the alleles in these genes increase risk for both diseases\n",
    "        # we model by individual and shared components ; hower in this component do samples affected only by disease 1 necessarily have the probability of seeing\n",
    "        # an allele that is the same as in the other cases? I think no, I think this is higher\n",
    "        # as the shared component becomes large and larger, if it is added to the other alpha1 (the individual copmonet only), alpha1 will equal alphaBoth, i.e\n",
    "        # they will be perfectly correlated\n",
    "        # else, alpha0 will be some amount larger than alphaBoth\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alpha1 + alpha2 + alphaBoth])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "     # Like 2g, except follows the principle of the shared component being additive to individual components,\n",
    "    # in the shared component\n",
    "    def likelihood2h(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "        \n",
    "        # From E(P2_null) = P(D2) = a2 / (a0 + a1 + a2 + aB)\n",
    "        alpha2Null = pDs[1] * (alpha0 + alpha1 + alphaBoth) / (1 - pDs[1])\n",
    "        alphaBothFrom1 = alpha1 * pDs[2] / pDs[0]\n",
    "        # h1 is that the genes in this component only increse risk for disease 1\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2Null, alphaBothFrom1])).log_prob(altCountsFlat) )\n",
    "        alpha1Null = pDs[0] * (alpha0 + alpha2 + alphaBoth) / (1 - pDs[0])\n",
    "        alphaBothFrom2 = alpha2 * pDs[2] / pDs[1]\n",
    "        # h2 is that the genes in this component only increse risk for disease 2\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1Null, alpha2, alphaBothFrom2])).log_prob(altCountsFlat) )\n",
    "        # h3 is that the alleles in these genes increase risk for both diseases\n",
    "        # we model by individual and shared components ; hower in this component do samples affected only by disease 1 necessarily have the probability of seeing\n",
    "        # an allele that is the same as in the other cases? I think no, I think this is higher\n",
    "        # as the shared component becomes large and larger, if it is added to the other alpha1 (the individual copmonet only), alpha1 will equal alphaBoth, i.e\n",
    "        # they will be perfectly correlated\n",
    "        # else, alpha0 will be some amount larger than alphaBoth\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1 + alphaBoth, alpha2 + alphaBoth, alpha1 + alpha2 + alphaBoth])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "        \n",
    "    # just let everything vary\n",
    "    def likelihood2i(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "        # h1 is that the genes in this component only increse risk for disease 1\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat) ) \n",
    "        # h2 is that the genes in this component only increse risk for disease 2\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat) )\n",
    "        # h3 is that the alleles in these genes increase risk for both diseases\n",
    "        # we model by individual and shared components ; hower in this component do samples affected only by disease 1 necessarily have the probability of seeing\n",
    "        # an allele that is the same as in the other cases? I think no, I think this is higher\n",
    "        # as the shared component becomes large and larger, if it is added to the other alpha1 (the individual copmonet only), alpha1 will equal alphaBoth, i.e\n",
    "        # they will be perfectly correlated\n",
    "        # else, alpha0 will be some amount larger than alphaBoth\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "     # Like 2h except unfucked\n",
    "    def likelihood2j(params):\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "        \n",
    "        alphaBothFrom1 = alpha1 * pDs[2] / pDs[0]\n",
    "        # From E(P2_null) = P(D2) = a2 / (a0 + a1 + a2 + aB)\n",
    "        alpha2Null = pDs[1] * (alpha0 + alpha1 + alphaBothFrom1) / (1 - pDs[1])\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1, alpha2Null, alphaBothFrom1])).log_prob(altCountsFlat) )\n",
    "        \n",
    "        alphaBothFrom2 = alpha2 * pDs[2] / pDs[1]\n",
    "        alpha1Null = pDs[0] * (alpha0 + alpha2 + alphaBothFrom2) / (1 - pDs[0])\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1Null, alpha2, alphaBothFrom2])).log_prob(altCountsFlat) )\n",
    "\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(is_sparse=True, total_count=n, concentration=tensor([alpha0, alpha1 + alphaBoth, alpha2 + alphaBoth, alpha1 + alpha2 + alphaBoth])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "     # Like 2j except allow last multinomial to freely vary as alpha1, alpha2, alphaBoth\n",
    "    def likelihood2k(params):\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "        \n",
    "        alphaBothFrom1 = alpha1 * pDs[2] / pDs[0]\n",
    "        # From E(P2_null) = P(D2) = a2 / (a0 + a1 + a2 + aB)\n",
    "        alpha2Null = pDs[1] * (alpha0 + alpha1 + alphaBothFrom1) / (1 - pDs[1])\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2Null, alphaBothFrom1])).log_prob(altCountsFlat) )\n",
    "        \n",
    "        alphaBothFrom2 = alpha2 * pDs[2] / pDs[1]\n",
    "        alpha1Null = pDs[0] * (alpha0 + alpha2 + alphaBothFrom2) / (1 - pDs[0])\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1Null, alpha2, alphaBothFrom2])).log_prob(altCountsFlat) )\n",
    "\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood2l(params):\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull2\n",
    "        \n",
    "        alphaBothFrom1 = alpha1 * pDs[2] / pDs[0]\n",
    "        # From E(P2_null) = P(D2) = a2 / (a0 + a1 + a2 + aB)\n",
    "        alpha2Null = pDs[1] * (alpha0 + alpha1 + alphaBothFrom1) / (1 - pDs[1])\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2Null, alphaBothFrom1])).log_prob(altCountsFlat) )\n",
    "        \n",
    "        alphaBothFrom2 = alpha2 * pDs[2] / pDs[1]\n",
    "        alpha1Null = pDs[0] * (alpha0 + alpha2 + alphaBothFrom2) / (1 - pDs[0])\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1Null, alpha2, alphaBothFrom2])).log_prob(altCountsFlat) )\n",
    "        \n",
    "        alphaBoth1 = alphaBoth * pDs[0] / pDs[2]\n",
    "        alphaBoth2 = alphaBoth * pDs[1] / pDs[2]\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1 + alphaBoth1, alpha2 + alphaBoth2, alphaBothFrom1 + alphaBothFrom2 + alphaBoth])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "\n",
    "    return likelihood1, likelihood1a, likelihood1b, likelihood2, likelihood2a, likelihood2b, likelihood2c, likelihood2d, likelihood2e, likelihood2f, likelihood2g, likelihood2h, likelihood2i, likelihood2j, likelihood2k, likelihood2l\n",
    "\n",
    "def cb(f, context):\n",
    "    print(\"got callback\", f, context)\n",
    "\n",
    "# TODO: update for multivariate\n",
    "def fitFnUniveriate(altCountsByGene, pDs, nEpochs = 100, minLLThresholdCount = 100, debug = False):\n",
    "    costFn = likelihoodUnivariateFast(altCountsByGene, pDs)\n",
    "    \n",
    "    lls = []\n",
    "    params = []\n",
    "\n",
    "    minLLDiff = 1\n",
    "    thresholdHitCount = 0\n",
    "    \n",
    "    nGenes = len(altCountsByGene)\n",
    "\n",
    "    randomDist = Uniform(1/nGenes, .5)\n",
    "    randomDist2 = Uniform(0, 1)\n",
    "    \n",
    "        # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "    # P(V|D) * P(D) / P(V)\n",
    "#     pDgivenVbounds = ( pVgivenD(2, 1e-6) * .001 / 1e-6, pVgivenD(100, 1e-2) * .1 / 1e-2 )\n",
    "#     pi1Bounds = ( 1/nGenes,  1 )\n",
    "#     bounds = [pDgivenVbounds, pi1Bounds]\n",
    "    for i in range(nEpochs):\n",
    "        best = float(\"inf\")\n",
    "        bestParams = []\n",
    "        for y in range(100):\n",
    "            # pi1, p(D|V)\n",
    "            fnArgs = [randomDist.sample(), randomDist2.sample()]\n",
    "            ll = costFn(fnArgs)\n",
    "            if ll < best:\n",
    "                best = ll\n",
    "                bestParams = fnArgs\n",
    "                \n",
    "        if debug:\n",
    "            print(f\"best ll: {best}, params: {bestParams}\")\n",
    "\n",
    "        fit = scipy.optimize.minimize(costFn, x0 = bestParams, method='Nelder-Mead', options={\"maxiter\": 10000, \"adaptive\": True})#gp_minimize(costFn, [(1e-7, .9),(1/nGenes, .99)])#scipy.optimize.minimize(costFn, x0 = fnArgs, method=\"Nelder-Mead\", options={\"maxiter\": 10000})\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"epoch {i}\")\n",
    "            print(fit)\n",
    "\n",
    "        if not fit[\"success\"] is True:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        pi1, pDgivenV= fit[\"x\"]\n",
    "        if pDgivenV < 0 or pDgivenV > 1 or pi1 < 1/nGenes or pi1 > 1:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        ll = fit[\"fun\"]\n",
    "        if len(lls) == 0:\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            continue\n",
    "\n",
    "        minPrevious = min(lls)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"minPrevious\", minPrevious)\n",
    "            \n",
    "        # TODO: take mode of some pc-based cluster of parameters, or some auto-encoded cluster\n",
    "        if ll < minPrevious and (minPrevious - ll) >= minLLDiff:\n",
    "            if debug:\n",
    "                print(f\"better by at >= {minLLDiff}; new ll: {fit}\")\n",
    "\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            \n",
    "            thresholdHitCount = 0\n",
    "            continue\n",
    "\n",
    "        thresholdHitCount += 1\n",
    "        \n",
    "        if thresholdHitCount == minLLThresholdCount:\n",
    "            break\n",
    "            \n",
    "    return {\"lls\": lls, \"params\": params}\n",
    "\n",
    "\n",
    "# TODO: maybe beta distribution should be constrained such that variance is that of the data?\n",
    "# or maybe there's an analog to 0 mean liability variance?\n",
    "def fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs = 100, minLLThresholdCount = 100, debug = False):\n",
    "    costFn = likelihoodUnivariateBetaBinomialFast(altCountsByGene, pDs)\n",
    "    \n",
    "    llsAll = []\n",
    "    lls = []\n",
    "    params = []\n",
    "\n",
    "    minLLDiff = 1\n",
    "    thresholdHitCount = 0\n",
    "    \n",
    "    nGenes = len(altCountsByGene)\n",
    "    remainingEpochs = nEpochs\n",
    "    \n",
    "    randomDist = Uniform(1/nGenes, .5)\n",
    "    randomDist2 = Uniform(100, 25000)\n",
    "    # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "    # P(V|D) * P(D) / P(V)\n",
    "    while remainingEpochs > 0:\n",
    "        best = float(\"inf\")\n",
    "        bestParams = []\n",
    "        for i in range(50):\n",
    "            # pi1, alpha1, alpha0\n",
    "            fnArgs = [randomDist.sample(), randomDist2.sample(), randomDist2.sample()]\n",
    "            ll = costFn(fnArgs)\n",
    "            if ll < best:\n",
    "                best = ll\n",
    "                bestParams = fnArgs\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"best ll: {best}, bestParams: {bestParams}\")\n",
    "\n",
    "        fit = scipy.optimize.minimize(costFn, x0 = bestParams, method='Nelder-Mead', options={\"maxiter\": 10000, \"adaptive\": True})#gp_minimize(costFn, [(1e-7, .9),(1/nGenes, .99)])#scipy.optimize.minimize(costFn, x0 = fnArgs, method=\"Nelder-Mead\", options={\"maxiter\": 10000})\n",
    "        #fit = scipy.optimize.basinhopping(costFn, x0 = bestParams)\n",
    "        if debug:\n",
    "            print(f\"epoch {remainingEpochs}\")\n",
    "            print(fit)\n",
    "\n",
    "        if not fit[\"success\"] is True:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        pi1, alpha1, alpha0 = fit[\"x\"]\n",
    "        # TODO: is pi1 > .5 restriction sound?\n",
    "        if pi1 < 1/nGenes or pi1 > .5 or alpha1 <= 0 or alpha0 <= 0:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "            \n",
    "        remainingEpochs -= 1\n",
    "        \n",
    "        ll = fit[\"fun\"]\n",
    "        llsAll.append(ll)\n",
    "        if len(lls) == 0:\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            continue\n",
    "\n",
    "        minPrevious = min(lls)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"minPrevious\", minPrevious)\n",
    "            \n",
    "        # TODO: take mode of some pc-based cluster of parameters, or some auto-encoded cluster\n",
    "        if ll < minPrevious and (minPrevious - ll) >= minLLDiff:\n",
    "            if debug:\n",
    "                print(f\"better by at >= {minLLDiff}; new ll: {fit}\")\n",
    "\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            \n",
    "            thresholdHitCount = 0\n",
    "            continue\n",
    "\n",
    "        thresholdHitCount += 1\n",
    "        \n",
    "        if thresholdHitCount == minLLThresholdCount:\n",
    "            break\n",
    "            \n",
    "    return {\"lls\": lls, \"params\": params, \"llTrajectory\": llsAll}\n",
    "\n",
    "# TODO: maybe beta distribution should be constrained such that variance is that of the data?\n",
    "# or maybe there's an analog to 0 mean liability variance\n",
    "def fitFnBivariate(altCountsByGene, pDs, nEpochs = 100, minLLThresholdCount = 100, K = 4, debug = False, costFnIdx = 0):\n",
    "    costFunctions = likelihoodBivariateFast(altCountsByGene, pDs)\n",
    "        \n",
    "    costFn = costFunctions[costFnIdx]\n",
    "    print(\"past\", costFn)\n",
    "    llsAll = []\n",
    "    lls = []\n",
    "    params = []\n",
    "\n",
    "    minLLDiff = 1\n",
    "    thresholdHitCount = 0\n",
    "    \n",
    "    nGenes = len(altCountsByGene)\n",
    "    \n",
    "    # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "    # P(V|D) * P(D) / P(V)\n",
    "    pi0Dist = Uniform(.5, 1)\n",
    "    alphasDist = Uniform(100, 25000)    \n",
    "    for i in range(nEpochs):\n",
    "        # TODO: should we constrain alpha0 to the pD, i.e\n",
    "        # E[P(D)] = alpha1 / sum(alphasRes)\n",
    "        # P(D) * (alphasRes) = alpha1\n",
    "        best = float(\"inf\")\n",
    "        bestParams = []\n",
    "        for y in range(100):\n",
    "            pi0 = pi0Dist.sample()\n",
    "            pis = Uniform(1/nGenes, 1-pi0).sample([K-1])\n",
    "            pis = pis/(pis.sum() + pi0)\n",
    "#             print(\"pi0\", pi0, \"pis\", pis, \"sum\", pis.sum())\n",
    "            fnArgs = [*pis, *alphasDist.sample([K,])]\n",
    "\n",
    "            ll = costFn(fnArgs)\n",
    "            if ll < best:\n",
    "                best = ll\n",
    "                bestParams = fnArgs\n",
    "        \n",
    "        print(f\"best ll: {best}, bestParams: {bestParams}\")\n",
    "\n",
    "#         fnArgs = [probs[0], probs[1], probs[2], *alphas]\n",
    "        fit = scipy.optimize.minimize(costFn, x0 = bestParams, method='Nelder-Mead', options={\"maxiter\": 10000, \"adaptive\": True})\n",
    "\n",
    "        if debug:\n",
    "            print(f\"epoch {i}\")\n",
    "            print(fit)\n",
    "\n",
    "        if not fit[\"success\"] is True:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = fit[\"x\"]\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi1 > 1 or pi2 < 0 or pi2 > 1 or piBoth < 0 or piBoth > 1:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        ll = fit[\"fun\"]\n",
    "        llsAll.append(ll)\n",
    "        if len(lls) == 0:\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            continue\n",
    "\n",
    "        minPrevious = min(lls)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"minPrevious\", minPrevious)\n",
    "            \n",
    "        # TODO: take mode of some pc-based cluster of parameters, or some auto-encoded cluster\n",
    "        if ll < minPrevious and (minPrevious - ll) >= minLLDiff:\n",
    "            if debug:\n",
    "                print(f\"better by at >= {minLLDiff}; new ll: {fit}\")\n",
    "\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            \n",
    "            thresholdHitCount = 0\n",
    "            continue\n",
    "\n",
    "        thresholdHitCount += 1\n",
    "        \n",
    "        if thresholdHitCount == minLLThresholdCount:\n",
    "            break\n",
    "            \n",
    "    return {\"lls\": lls, \"params\": params, \"llTrajectory\": llsAll}\n",
    "\n",
    "\n",
    "\n",
    "def initBetaParams(mu, variance):\n",
    "    alpha = ((1 - mu) / variance - 1 / variance) * mu**2\n",
    "    beta = alpha * (1/mu -1)\n",
    "    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### all named tuples used\n",
    "\n",
    "Samples = namedtuple(\"Samples\", [\"ctrls\", \"cases\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nSamples shape: [nConditions, 2] , last dim is ctrls, cases\n",
    "# Generating process\n",
    "\n",
    "# I am gene 1\n",
    "# i have 3 possible contributions to diseases 1, 2\n",
    "# 1) I contribute to disease 1 only\n",
    "# 2) I contribute to disease 2 only\n",
    "# 3) I contribute to both\n",
    "\n",
    "# For each gene I have some counts. Some people are only disease 1, some are only disease 2, some are both\n",
    "# My probability of contributing to disease 1 is a sum of 1 & both, because P(D1|V) = P(D1Only|V) + P(D1And2|V)\n",
    "# My probability of contributing to diesase 2 is sum of 2 & both\n",
    "\n",
    "# I have some counts. Those people that are only known only to have disease 1 we estimate are contributing only to disease 1\n",
    "# Some of\n",
    "\n",
    "# what is correlation between disease 1 and 2.\n",
    "\n",
    "\n",
    "# this is insanely slow for some reason, and almost all time is in the expanded binomial sampling\n",
    "# def genData(nSamples, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "#     # TODO: assert shapes match\n",
    "#     print(\"TESTING WITH: nSamples\", nSamples, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "#     nConditions = len(nSamples)\n",
    "#     probs = []\n",
    "#     afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "#     rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "#     rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "#     # shape == [nGenes, nConditions]\n",
    "#     afs = afDist.sample([nGenes,])   \n",
    "#     rrs = rrDist.sample([nGenes,])\n",
    "#     rrNulls = rrNullDist.sample([nGenes,])\n",
    "#     for geneIdx in range(nGenes):\n",
    "#         geneProbs = []\n",
    "#         for conditionIdx in range(nConditions):\n",
    "#             # TODO: sample from uniform\n",
    "#             if geneIdx < nGenes * diseaseFractions[conditionIdx]:\n",
    "#                 rr = rrs[geneIdx, conditionIdx]\n",
    "#             else:\n",
    "#                 rr = rrNulls[geneIdx, conditionIdx]\n",
    "            \n",
    "#             probVgivenD = pVgivenD(rr, afs[geneIdx])\n",
    "#             probVgivenNotD = pVgivenNotD(pDs[conditionIdx], afs[geneIdx], probVgivenD)\n",
    "            \n",
    "#             geneProbs.append([probVgivenNotD, probVgivenD])\n",
    "#         probs.append(geneProbs)\n",
    "#     probs = tensor(probs)\n",
    "\n",
    "#     # This should not be slow but is\n",
    "#     # https://github.com/pytorch/pytorch/issues/11389\n",
    "#     start = time.time()\n",
    "#     altCounts = Binomial(total_count=nSamples.expand([nGenes, *nSamples.shape]), probs=probs).sample()\n",
    "#     print(\"final sampling took\", time.time() - start)\n",
    "    \n",
    "#     return altCounts, probs\n",
    "\n",
    "def genDataSequential(nSamples, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "    # TODO: assert shapes match\n",
    "    print(\"TESTING WITH: nSamples\", nSamples, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "    nConditions = len(nSamples)\n",
    "    assert(nConditions == 3)\n",
    "    altCounts = []\n",
    "    probs = []\n",
    "    afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "    rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "    rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "    # shape == [nGenes, nConditions]\n",
    "    afs = afDist.sample([nGenes,])   \n",
    "    rrs = rrDist.sample([nGenes,])\n",
    "    rrNulls = rrNullDist.sample([nGenes,])\n",
    "    \n",
    "    endIndices = nGenes * diseaseFractions\n",
    "    startIndices = []\n",
    "    for i in range(len(diseaseFractions)):\n",
    "        if i == 0:\n",
    "            startIndices.append(0)\n",
    "            continue\n",
    "        endIndices[i] += endIndices[i-1]\n",
    "        startIndices.append(endIndices[i-1])\n",
    "    \n",
    "    print(\"startIndices\", startIndices, \"endIndices\", endIndices)\n",
    "    affectsCond1Only, affectsCond2Only, affectsBoth = False, False, False\n",
    "    for geneIdx in range(nGenes):\n",
    "        geneAltCounts = [0, 0, 0]\n",
    "        geneProbs = [0, 0, 0]\n",
    "        rrs = [1, 1, 1]\n",
    "        # Each gene gets only 1 state: affects condition 1 only, condition 2 only, or both\n",
    "        # currently, in the both case, the increased in counts (rr) is. the same for both conditions\n",
    "        for conditionIdx in range(nConditions):\n",
    "            if geneIdx >= startIndices[conditionIdx] and geneIdx < endIndices[conditionIdx]:\n",
    "                if conditionIdx == 0:\n",
    "                    affectsCond1Only = True\n",
    "                elif conditionIdx == 1:\n",
    "                    affectsCond2Only = True\n",
    "                else:\n",
    "                    affectsBoth = True\n",
    "        \n",
    "        # gene affects one of 3 states\n",
    "        # based on which state it affects, sampleCase1, samplesCase2, samplesBoth get different rrs for this gene\n",
    "        # controls always get the same value, and that is based on 1 - sum(rrs)\n",
    "        if affectsCond1Only:\n",
    "            rrs[0] = rrs[geneIdx, conditionIdx]\n",
    "            rrs[1] = rrNulls[geneIdx, conditionIdx]\n",
    "            rrs[2] = rrs[geneIdx, conditionIdx] #both always gets a rr of non-1\n",
    "        elif affectsCond2Only:\n",
    "            rrs[0] = rrNulls[geneIdx, conditionIdx]\n",
    "            rrs[1] = rrs[geneIdx, conditionIdx]\n",
    "            rrs[2] = rrs[geneIdx, conditionIdx]\n",
    "        elif affectsBoth:\n",
    "            # q: should these really get the same value?\n",
    "            # where is the concept of covariance here?\n",
    "            rrs[0] = rrs[geneIdx, conditionIdx]\n",
    "            rrs[1] = rrs[geneIdx, conditionIdx]\n",
    "            rrs[2] = rrs[geneIdx, conditionIdx]\n",
    "            \n",
    "            probVgivenDs = pVgivenD(rr, afs[geneIdx])\n",
    "            altCountsCases = Binomial(total_count=nSamples[conditionIdx][1], probs=probVgivenD).sample()\n",
    "            \n",
    "            # we can use one simulation to study pooled an separate samples\n",
    "            # in the pooled model, we could sum control samples during inference\n",
    "            probVgivenNotD = pVgivenNotD(pDs[conditionIdx], afs[geneIdx], probVgivenD)\n",
    "            altCountsCtrls = Binomial(total_count=nSamples[conditionIdx][0], probs=probVgivenNotD).sample()\n",
    "            \n",
    "            geneAltCounts.append([altCountsCtrls, altCountsCases])\n",
    "            geneProbs.append([probVgivenNotD, probVgivenD])\n",
    "        altCounts.append(geneAltCounts)\n",
    "        probs.append(geneProbs)\n",
    "    altCounts = tensor(altCounts)\n",
    "    probs = tensor(probs)\n",
    "    \n",
    "    return altCounts, probs\n",
    "\n",
    "def genDataSequentialPooledCtrls(nCases, nCtrls, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "    # TODO: assert shapes match\n",
    "    print(\"TESTING POOLED WITH: nCases\", nCases, \"nCtrls\", nCtrls, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "    nConditions = len(nCases)\n",
    "    altCounts = []\n",
    "    probs = []\n",
    "    afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "    rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "    rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "    # shape == [nGenes, nConditions]\n",
    "    afs = afDist.sample([nGenes,])   \n",
    "    rrs = rrDist.sample([nGenes,])\n",
    "    rrNulls = rrNullDist.sample([nGenes,])\n",
    "    \n",
    "    endIndices = nGenes * diseaseFractions\n",
    "    startIndices = []\n",
    "    for i in range(len(diseaseFractions)):\n",
    "        if i == 0:\n",
    "            startIndices.append(0)\n",
    "            continue\n",
    "        endIndices[i] += endIndices[i-1]\n",
    "        startIndices.append(endIndices[i-1])\n",
    "    \n",
    "    print(\"startIndices\", startIndices, \"endIndices\", endIndices)\n",
    "    for geneIdx in range(nGenes):\n",
    "        geneAltCounts = []\n",
    "        geneProbs = []\n",
    "\n",
    "        probVgivenDs = []\n",
    "        for conditionIdx in range(nConditions):\n",
    "            # TODO: sample from uniform\n",
    "            if geneIdx >= startIndices[conditionIdx] and geneIdx < endIndices[conditionIdx]:\n",
    "                rr = rrs[geneIdx, conditionIdx]\n",
    "            else:\n",
    "                rr = rrNulls[geneIdx, conditionIdx]\n",
    "            probVgivenDs.append(pVgivenD(rr, afs[geneIdx]))\n",
    "\n",
    "        probVgivenDs = tensor(probVgivenDs)\n",
    "#         print(\"probVgivenDs\", probVgivenDs)\n",
    "        altCountsCases = Binomial(total_count=nCases, probs=probVgivenDs).sample()\n",
    "\n",
    "#         print(\"altCountsCases\", altCountsCases, \"altCountCases.shape\", altCountsCases.shape)\n",
    "#         print(\"0 index\", altCountsCases[0])\n",
    "        # we can use one simulation to study pooled an separate samples\n",
    "        # in the pooled model, we could sum control samples during inference\n",
    "        probVgivenNotD = pVgivenNotD(pDs, afs[geneIdx], probVgivenDs)\n",
    "#         print(\"probVgivenNotD\", probVgivenNotD)\n",
    "        \n",
    "        altCountsCtrls = Binomial(total_count=nCtrls, probs=probVgivenNotD).sample()\n",
    "#         print(\"altCountsCtrls\", altCountsCtrls)\n",
    "        \n",
    "        for conditionIdx in range(nConditions):\n",
    "            if conditionIdx == 0:\n",
    "                geneAltCounts.append([altCountsCtrls, altCountsCases[conditionIdx]])\n",
    "            else:\n",
    "                geneAltCounts.append([0, altCountsCases[conditionIdx]])\n",
    "            geneProbs.append([probVgivenNotD, probVgivenDs[conditionIdx]])\n",
    "\n",
    "        altCounts.append(geneAltCounts)\n",
    "        probs.append(geneProbs)\n",
    "    altCounts = tensor(altCounts)\n",
    "    probs = tensor(probs)\n",
    "    \n",
    "    return altCounts, probs\n",
    "\n",
    "## Another view on generative process\n",
    "# there is some contribution to disease 1 with probability P(V|D1)\n",
    "# there is some contribution to disease 2 with probability P(V|D2)\n",
    "# there is some contribution to both diseases with probability P(V|DBoth)\n",
    "# there is some contribution to no diseases with probability P(V|None)\n",
    "# The total P(V) = P(V|D1)*P(D1) + P(V|D2)*P(D2) + P(V|DBoth)*P(DBoth) + P(V|Ctrl)*P(Ctrl) = (say) 1e-4\n",
    "\n",
    "\n",
    "# P(V|D1) = (P(D1|V) * P(V)) / P(D1)\n",
    "\n",
    "# When do we see counts for diseases 1? When P(V|D1) + P(V|DBoth)\n",
    "# A person who is ascertained as having both diseases must be the contribution of 1 - P(V|Ctrl) (P(D1|V) + P(D2|V) + P(V|DBoth))\n",
    "# A person who has 1 : P(V|D1) + P(V|DBoth) and for person 2 : P(V|D2) + P(V|DBoth)\n",
    "\n",
    "# If we didn't people ascertained for both, we could use 1 - P(V|Ctrl1) + P(V|Ctrl2) ?\n",
    "\n",
    "# in our components, component 1 and 2 give no contribution whatsoever, so they are measuring singular effect\n",
    "# in our \n",
    "\n",
    "# def intersection(list1, list2):\n",
    "\n",
    "# TODO: this generates bivariate data, expand to multinomial\n",
    "\n",
    "# If i'm a sample with disease1 only, I get the effect1 component for the gene, null2 component for the gene, and the effectBoth component for the gene\n",
    "# If i'm a sample with disease2 only, I get the null1 component for the gene, effect2 component for the gene, and the effectBoth component for the gene\n",
    "# If I'm a sample with both, I always get the full contribution\n",
    "\n",
    "# Finally, genes are either in categories none, 1only, 2only, or both\n",
    "# For each gene, I think we should sample the state in each category only once\n",
    "\n",
    "# If I'm a case1only, and if the gene is a risk gene, my count should reflect P(V|D2)\n",
    "# If I'm a ctrl and gene is associated, the count should reflect P(!D|V)\n",
    "# If I'm a case2only, I should have P(V|D2)\n",
    "# If I'm a both case, I think my P(V|D) should reflect a relative risk that is the sum of rr1 + rrLatentBoth if \n",
    "\n",
    "# In Dave's picture, a gene that affects disease 1 only adds the same liability to all indviduals \n",
    "def genData2(nCases, nCtrls, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "    # TODO: assert shapes match\n",
    "    print(\"TESTING WITH: nSamples\", nSamples, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "    nConditions = len(nSamples)\n",
    "    assert(nConditions == 3)\n",
    "    altCounts = []\n",
    "    probs = []\n",
    "    afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "    rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "    print(\"rrDist mean\", rrDist.sample([10_000,]).mean())\n",
    "    rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "    # shape == [nGenes, nConditions]\n",
    "    afs = afDist.sample([nGenes,])   \n",
    "    rrs = rrDist.sample([nGenes,])\n",
    "#     print(\"rrs\", rrs);\n",
    "    rrNulls = rrNullDist.sample([nGenes,])\n",
    "    \n",
    "    endIndices = nGenes * diseaseFractions\n",
    "    startIndices = []\n",
    "    for i in range(len(diseaseFractions)):\n",
    "        if i == 0:\n",
    "            startIndices.append(0)\n",
    "            continue\n",
    "        endIndices[i] += endIndices[i-1]\n",
    "        startIndices.append(endIndices[i-1])\n",
    "    \n",
    "    print(\"startIndices\", startIndices, \"endIndices\", endIndices)\n",
    "#     print(\"rrs\", rrs[0:2000,0].mean())\n",
    "    for geneIdx in range(nGenes):\n",
    "        geneAltCounts = []\n",
    "        geneProbs = []\n",
    "        rrSamples = tensor([1., 1., 1.])\n",
    "        affects = 0\n",
    "        # Each gene gets only 1 state: affects condition 1 only, condition 2 only, or both\n",
    "        # currently, in the both case, the increased in counts (rr) is. the same for both conditions\n",
    "        for conditionIdx in range(nConditions):\n",
    "            if geneIdx >= startIndices[conditionIdx] and geneIdx < endIndices[conditionIdx]:\n",
    "                if conditionIdx == 0:\n",
    "                    affects = 1\n",
    "                elif conditionIdx == 1:\n",
    "                    affects = 2\n",
    "                elif conditionIdx == 2:\n",
    "                    affects = 3\n",
    "                else:\n",
    "                    assert(conditionIdx <= 2)\n",
    "                    \n",
    "        rrSamples = rrNulls[geneIdx, :]\n",
    "        \n",
    "        # gene affects one of 3 states\n",
    "        # based on which state it affects, sampleCase1, samplesCase2, samplesBoth get different rrs for this gene\n",
    "        # controls always get the same value, and that is based on 1 - sum(rrs)\n",
    "        if affects == 0:\n",
    "            rrSamples = rrNulls[geneIdx, :] # Maybe just have == 1, follows \n",
    "        elif affects == 1:\n",
    "#             print(f\"affects1: {geneIdx}\")\n",
    "            rrSamples[0] = rrs[geneIdx, 0] #rr for  samples affected with disease 1\n",
    "            rrSamples[1] = rrNulls[geneIdx, 1] #samples affected with diseases 2\n",
    "            rrSamples[2] = rrs[geneIdx, 0] #both always gets a rr of non-1\n",
    "        elif affects == 2:\n",
    "#             print(f\"affects2: {conditionIdx}\")\n",
    "            rrSamples[0] = rrNulls[geneIdx, 0]\n",
    "            rrSamples[1] = rrs[geneIdx, 1]\n",
    "            rrSamples[2] = rrs[geneIdx, 1]\n",
    "        elif affects == 3:\n",
    "#             print(f\"affectsBoth: {conditionIdx}\")\n",
    "            # q: should these really get the same value?\n",
    "            # where is the concept of covariance here?\n",
    "            rrSamples[0] = rrs[geneIdx, 2]\n",
    "            rrSamples[1] = rrs[geneIdx, 2]\n",
    "            rrSamples[2] = rrs[geneIdx, 2]\n",
    "        \n",
    "        probVgivenDs = pVgivenD(rrSamples, afs[geneIdx])\n",
    "#         print(\"rrs\", rrSamples, rrNulls[geneIdx, :], rrs[geneIdx, :])\n",
    "#         print(probVgivenDs)\n",
    "#         print(\"probVgivenDs\", probVgivenDs, \"for rrs\", rrSamples)\n",
    "        altCountsCases = Binomial(total_count=nCases, probs=probVgivenDs).sample()\n",
    "#         print(\"altCountsCases\", altCountsCases)\n",
    "        # we can use one simulation to study pooled an separate samples\n",
    "        # in the pooled model, we could sum control samples during inference\n",
    "        probVgivenNotD = pVgivenNotD(pDs, afs[geneIdx], probVgivenDs)\n",
    "#         print(\"nCases\", nCases, \"probVgivenDs/probVgivenNotD\", probVgivenDs / probVgivenNotD)\n",
    "        altCountsCtrls = Binomial(total_count=nCtrls, probs=probVgivenNotD).sample()\n",
    "#         print(\"altCountsCtrls\", altCountsCtrls)\n",
    "        \n",
    "        for conditionIdx in range(nConditions):\n",
    "            if conditionIdx == 0:\n",
    "                geneAltCounts.append([altCountsCtrls, altCountsCases[conditionIdx]])\n",
    "            else:\n",
    "                geneAltCounts.append([0, altCountsCases[conditionIdx]])\n",
    "            geneProbs.append([probVgivenNotD, probVgivenDs[conditionIdx]])\n",
    "#         print(f\"geneAltCoutns {geneAltCounts} \\n\")\n",
    "        altCounts.append(geneAltCounts)\n",
    "        probs.append(geneProbs)\n",
    "#     print(\"altCounts\", altCounts)\n",
    "    altCounts = tensor(altCounts)\n",
    "    probs = tensor(probs)\n",
    "    \n",
    "    return altCounts, probs\n",
    "\n",
    "# like 2, but in \"both\" component, samples that are case1 only get rr1, samples that are case2 only get rr2, samples that are both get rrBoth\n",
    "# If i'm a sample that is affected by both conditions, that means\n",
    "# that I get the invididual contribution from each, and I also get the shared component\n",
    "# XShared ~ X1 + X3 + X2\n",
    "# If I'm an individual only affected by d1, I get Y1 = X1 + X3\n",
    "# If I'm an individual only affected by d2 I get Y2 = X2 + X3\n",
    "# If I'm an individual affected by both I think I get Y3 = X1 + X2 + X3\n",
    "# What if: in genes that affect only 1 disease give X1, genes that affect d2 only give X2, genes that affect both get d2,\n",
    "def genData3(nCases, nCtrls, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "    # TODO: assert shapes match\n",
    "    print(\"TESTING WITH: nSamples\", nSamples, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "    nConditions = len(nSamples)\n",
    "    assert(nConditions == 3)\n",
    "    altCounts = []\n",
    "    probs = []\n",
    "    afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "    rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "    print(\"rrDist mean\", rrDist.sample([10_000,]).mean())\n",
    "    rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "    # shape == [nGenes, nConditions]\n",
    "    afs = afDist.sample([nGenes,])   \n",
    "    rrs = rrDist.sample([nGenes,])\n",
    "#     print(\"rrs\", rrs);\n",
    "    rrNulls = rrNullDist.sample([nGenes,])\n",
    "    \n",
    "    endIndices = nGenes * diseaseFractions\n",
    "    startIndices = []\n",
    "    for i in range(len(diseaseFractions)):\n",
    "        if i == 0:\n",
    "            startIndices.append(0)\n",
    "            continue\n",
    "        endIndices[i] += endIndices[i-1]\n",
    "        startIndices.append(endIndices[i-1])\n",
    "    \n",
    "    print(\"startIndices\", startIndices, \"endIndices\", endIndices)\n",
    "#     print(\"rrs\", rrs[0:2000,0].mean())\n",
    "    for geneIdx in range(nGenes):\n",
    "        geneAltCounts = []\n",
    "        geneProbs = []\n",
    "        rrSamples = tensor([1., 1., 1.])\n",
    "        affects = 0\n",
    "        # Each gene gets only 1 state: affects condition 1 only, condition 2 only, or both\n",
    "        # currently, in the both case, the increased in counts (rr) is. the same for both conditions\n",
    "        for conditionIdx in range(nConditions):\n",
    "            if geneIdx >= startIndices[conditionIdx] and geneIdx < endIndices[conditionIdx]:\n",
    "                if conditionIdx == 0:\n",
    "                    affects = 1\n",
    "                elif conditionIdx == 1:\n",
    "                    affects = 2\n",
    "                elif conditionIdx == 2:\n",
    "                    affects = 3\n",
    "                else:\n",
    "                    assert(conditionIdx <= 2)\n",
    "                    \n",
    "        rrSamples = rrNulls[geneIdx, :]\n",
    "        \n",
    "        # gene affects one of 3 states\n",
    "        # based on which state it affects, sampleCase1, samplesCase2, samplesBoth get different rrs for this gene\n",
    "        # controls always get the same value, and that is based on 1 - sum(rrs)\n",
    "        if affects == 0:\n",
    "            rrSamples = rrNulls[geneIdx, :]\n",
    "        elif affects == 1:\n",
    "#             print(f\"affects1: {geneIdx}\")\n",
    "            rrSamples[0] = rrs[geneIdx, 0]\n",
    "            rrSamples[1] = rrNulls[geneIdx, 1]\n",
    "            rrSamples[2] = rrs[geneIdx, 0] #both always gets a rr of non-1\n",
    "        elif affects == 2:\n",
    "#             print(f\"affects2: {conditionIdx}\")\n",
    "            rrSamples[0] = rrNulls[geneIdx, 0]\n",
    "            rrSamples[1] = rrs[geneIdx, 1]\n",
    "            rrSamples[2] = rrs[geneIdx, 1]\n",
    "        elif affects == 3:\n",
    "#           # Here is the difference, samples with both get their own risk\n",
    "            rrSamples = rrs[geneIdx, :]\n",
    "        \n",
    "        probVgivenDs = pVgivenD(rrSamples, afs[geneIdx])\n",
    "#         print(\"rrs\", rrSamples, rrNulls[geneIdx, :], rrs[geneIdx, :])\n",
    "\n",
    "#         print(\"probVgivenDs\", probVgivenDs, \"for rrs\", rrSamples)\n",
    "        altCountsCases = Binomial(total_count=nCases, probs=probVgivenDs).sample()\n",
    "#         print(\"altCountsCases\", altCountsCases)\n",
    "        # we can use one simulation to study pooled an separate samples\n",
    "        # in the pooled model, we could sum control samples during inference\n",
    "        probVgivenNotD = pVgivenNotD(pDs, afs[geneIdx], probVgivenDs)\n",
    "#         print(\"nCases\", nCases, \"probVgivenDs/probVgivenNotD\", probVgivenDs / probVgivenNotD)\n",
    "        altCountsCtrls = Binomial(total_count=nCtrls, probs=probVgivenNotD).sample()\n",
    "#         print(\"altCountsCtrls\", altCountsCtrls)\n",
    "        \n",
    "        for conditionIdx in range(nConditions):\n",
    "            if conditionIdx == 0:\n",
    "                geneAltCounts.append([altCountsCtrls, altCountsCases[conditionIdx]])\n",
    "            else:\n",
    "                geneAltCounts.append([0, altCountsCases[conditionIdx]])\n",
    "            geneProbs.append([probVgivenNotD, probVgivenDs[conditionIdx]])\n",
    "#         print(f\"geneAltCoutns {geneAltCounts} \\n\")\n",
    "        altCounts.append(geneAltCounts)\n",
    "        probs.append(geneProbs)\n",
    "#     print(\"altCounts\", altCounts)\n",
    "    altCounts = tensor(altCounts)\n",
    "    probs = tensor(probs)\n",
    "    \n",
    "    return altCounts, probs\n",
    "\n",
    "# like 2, but in \"both\" component, samples that are case1 only get rr1, samples that are case2 only get rr2, samples that are both get rr1+rrBoth, rr2+rrBoth, or rr1 + rr2 + rrBoth\n",
    "# I think this one assumes that rrBoth is small (it's not the relative risk of genes that contribute to both, but the shared contribution...genes that contribute to both diseases\n",
    "# confer with rr1only, rr2only, rr1only + rr2only + rrBoth)\n",
    "# If i'm a sample that is affected by both conditions, that means\n",
    "# that I get the invididual contribution from each, and I also get the shared component\n",
    "# XShared ~ X1 + X3 + X2\n",
    "# If I'm an individual only affected by d1, I get Y1 = X1 + X3\n",
    "# If I'm an individual only affected by d2 I get Y2 = X2 + X3\n",
    "# If I'm an individual affected by both I think I get Y3 = X1 + X2 + X3\n",
    "# What if: in genes that affect only 1 disease give X1, genes that affect d2 only give X2, genes that affect both get d2,\n",
    "def genData4(nCases, nCtrls, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "    # TODO: assert shapes match\n",
    "    print(\"TESTING WITH: nSamples\", nSamples, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "    nConditions = len(nSamples)\n",
    "    assert(nConditions == 3)\n",
    "    altCounts = []\n",
    "    probs = []\n",
    "    afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "    rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "    print(\"rrDist mean\", rrDist.sample([10_000,]).mean())\n",
    "    rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "    # shape == [nGenes, nConditions]\n",
    "    afs = afDist.sample([nGenes,])   \n",
    "    rrs = rrDist.sample([nGenes,])\n",
    "#     print(\"rrs\", rrs);\n",
    "    rrNulls = rrNullDist.sample([nGenes,])\n",
    "    \n",
    "    endIndices = nGenes * diseaseFractions\n",
    "    startIndices = []\n",
    "    for i in range(len(diseaseFractions)):\n",
    "        if i == 0:\n",
    "            startIndices.append(0)\n",
    "            continue\n",
    "        endIndices[i] += endIndices[i-1]\n",
    "        startIndices.append(endIndices[i-1])\n",
    "    \n",
    "    print(\"startIndices\", startIndices, \"endIndices\", endIndices)\n",
    "#     print(\"rrs\", rrs[0:2000,0].mean())\n",
    "    for geneIdx in range(nGenes):\n",
    "        geneAltCounts = []\n",
    "        geneProbs = []\n",
    "        rrSamples = tensor([1., 1., 1.])\n",
    "        affects = 0\n",
    "        # Each gene gets only 1 state: affects condition 1 only, condition 2 only, or both\n",
    "        # currently, in the both case, the increased in counts (rr) is. the same for both conditions\n",
    "        for conditionIdx in range(nConditions):\n",
    "            if geneIdx >= startIndices[conditionIdx] and geneIdx < endIndices[conditionIdx]:\n",
    "                if conditionIdx == 0:\n",
    "                    affects = 1\n",
    "                elif conditionIdx == 1:\n",
    "                    affects = 2\n",
    "                elif conditionIdx == 2:\n",
    "                    affects = 3\n",
    "                else:\n",
    "                    assert(conditionIdx <= 2)\n",
    "                    \n",
    "        rrSamples = rrNulls[geneIdx, :]\n",
    "        \n",
    "        # gene affects one of 3 states\n",
    "        # based on which state it affects, sampleCase1, samplesCase2, samplesBoth get different rrs for this gene\n",
    "        # controls always get the same value, and that is based on 1 - sum(rrs)\n",
    "        if affects == 0:\n",
    "            rrSamples = rrNulls[geneIdx, :]\n",
    "        elif affects == 1:\n",
    "#             print(f\"affects1: {geneIdx}\")\n",
    "            rrSamples[0] = rrs[geneIdx, 0]\n",
    "            rrSamples[1] = rrNulls[geneIdx, 1]\n",
    "            rrSamples[2] = rrs[geneIdx, 0] #both always gets a rr of non-1\n",
    "        elif affects == 2:\n",
    "#             print(f\"affects2: {conditionIdx}\")\n",
    "            rrSamples[0] = rrNulls[geneIdx, 0]\n",
    "            rrSamples[1] = rrs[geneIdx, 1]\n",
    "            rrSamples[2] = rrs[geneIdx, 1]\n",
    "        elif affects == 3:\n",
    "            rrSamples[0] = rrs[geneIdx, 0] + rrs[geneIdx, 2]\n",
    "            rrSamples[1] = rrs[geneIdx, 1] + rrs[geneIdx, 2]\n",
    "            rrSamples[2] = rrs[geneIdx, 0] + rrs[geneIdx, 1] + rrs[geneIdx, 2]\n",
    "        \n",
    "        probVgivenDs = pVgivenD(rrSamples, afs[geneIdx])\n",
    "        probVgivenNotD = pVgivenNotD(pDs, afs[geneIdx], probVgivenDs)\n",
    "\n",
    "        altCountsCases = Binomial(total_count=nCases, probs=probVgivenDs).sample()\n",
    "        \n",
    "#         print(\"nCases\", nCases, \"probVgivenDs/probVgivenNotD\", probVgivenDs / probVgivenNotD)\n",
    "        altCountsCtrls = Binomial(total_count=nCtrls, probs=probVgivenNotD).sample()\n",
    "#         print(\"altCountsCtrls\", altCountsCtrls)\n",
    "        \n",
    "        for conditionIdx in range(nConditions):\n",
    "            if conditionIdx == 0:\n",
    "                geneAltCounts.append([altCountsCtrls, altCountsCases[conditionIdx]])\n",
    "            else:\n",
    "                geneAltCounts.append([0, altCountsCases[conditionIdx]])\n",
    "            geneProbs.append([probVgivenNotD, probVgivenDs[conditionIdx]])\n",
    "#         print(f\"geneAltCounts {geneAltCounts} \\n\")\n",
    "        altCounts.append(geneAltCounts)\n",
    "        probs.append(geneProbs)\n",
    "#     print(\"altCounts\", altCounts)\n",
    "    altCounts = tensor(altCounts)\n",
    "    probs = tensor(probs)\n",
    "    \n",
    "    return altCounts, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = Bernoulli(tensor(.1)).sample([20_000,]).nonzero()\n",
    "\n",
    "r2 = Bernoulli(tensor(.1)).sample([20_000,]).nonzero()\n",
    " \n",
    "r3 = Bernoulli(tensor(.1)).sample([20_000,]).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(r2) & set(r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cases tensor([5000., 5000., 2500.]) pDsGlobalSmall tensor([0.0099, 0.0099, 0.0050]) pDsGlobalLarge tensor([0.0098, 0.0098, 0.0049]) pDsConsideringBothLarge tensor([0.0146, 0.0146, 0.0049])\n"
     ]
    }
   ],
   "source": [
    "nGenes = 20_000\n",
    "disease1 = Samples(1e5, 1e3)\n",
    "disease2 = Samples(1e5, 1e3)\n",
    "diseaseBoth = Samples(1e5, 5e2)\n",
    "\n",
    "nSamples = [disease1, disease2, diseaseBoth]\n",
    "nSamples = tensor(nSamples)\n",
    "\n",
    "pDsGlobalSmall = nSamples[:, 1]/nSamples.sum(1)\n",
    "diseaseFractions = tensor([.1, .1, .05])\n",
    "rrShape = tensor(10.)\n",
    "rrMeans = tensor([10., 10., 10.])\n",
    "rrMeansCovary = tensor([10., 10., 5.])\n",
    "afMean = tensor(1e-4)\n",
    "afShape = tensor(10.)\n",
    "\n",
    "rrMeansLow = tensor([2., 2., 2.])\n",
    "rrMeans3 = tensor([3., 3., 3.])\n",
    "\n",
    "## For pooled version, want more samples for diseasesBoth\n",
    "pDsGlobalBothLarge = 5e-3\n",
    "nCtrlsLarge = tensor(5e5)\n",
    "nCasesBothLarge = nCtrlsLarge * pDsGlobalBothLarge\n",
    "nCases1onlyLarge = 5e3\n",
    "nCases2onlyLarge = 5e3\n",
    "nCasesLarge = tensor([nCases1onlyLarge, nCases2onlyLarge, nCasesBothLarge])\n",
    "\n",
    "pDsGlobalLarge = nCasesLarge / (nCasesLarge.sum() + nCtrlsLarge)\n",
    "pDsConsideringBothLarge = tensor([nCasesLarge[0] + nCasesBothLarge, nCasesLarge[1] + nCasesBothLarge, nCasesBothLarge]) / (nCasesLarge.sum() + nCtrlsLarge)\n",
    "\n",
    "print(\"cases\", nCasesLarge, \"pDsGlobalSmall\", pDsGlobalSmall, \"pDsGlobalLarge\", pDsGlobalLarge, \"pDsConsideringBothLarge\", pDsConsideringBothLarge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "altCountsByGene, afsByGene = genDataSequential(nSamples=nSamples, pDs=pDsGlobalSmall, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "altCountsByGeneRR2, afsByGeneRR2 = genDataSequential(nSamples=nSamples, pDs=pDsGlobalSmall, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansLow, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "altCountsByGeneRR3, afsByGeneRR3 = genDataSequential(nSamples=nSamples, pDs=pDsGlobalSmall, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans3, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "altCountsByGenePooledCtrls, afsByGenePooledCtrls = genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "altCountsByGenePooledCtrls2, afsByGenePooledCtrls2 = genData2(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "altCountsByGenePooledCtrls2a, afsByGenePooledCtrls2a = genData2(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "altCountsByGenePooledCtrls2b, afsByGenePooledCtrls2b = genData2(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "altCountsByGenePooledCtrls3, afsByGenePooledCtrls3 = genData3(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "altCountsByGenePooledCtrls3novar, afsByGenePooledCtrls3novar = genData3(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=tensor(10000.), rrMeans=rrMeans, afMean=afMean, afShape=tensor(10000.), nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH: nSamples tensor([[100000.,   1000.],\n",
      "        [100000.,   1000.],\n",
      "        [100000.,    500.]]) rrMean tensor([10., 10.,  5.]) rrShape tensor(10.) afMean tensor(1.0000e-04) afShape tensor(10.) diseaseFractions tensor([0.1000, 0.1000, 0.0500]) pDs tensor([0.0098, 0.0098, 0.0049])\n",
      "rrDist mean tensor(8.3683)\n",
      "startIndices [0, tensor(2000.), tensor(4000.)] endIndices tensor([2000., 4000., 5000.])\n",
      "took 90.89645004272461\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "altCountsByGenePooledCtrls4, afsByGenePooledCtrls4 = genData4(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(altCountsByGenePooledCtrls4[4000:5000, 2, 1], altCountsByGenePooledCtrls4[4000:5000, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.6273e-05, 1.0045e-03],\n",
       "         [5.6273e-05, 6.5915e-05],\n",
       "         [5.6273e-05, 1.0045e-03]],\n",
       "\n",
       "        [[6.9010e-05, 8.2065e-04],\n",
       "         [6.9010e-05, 8.4283e-05],\n",
       "         [6.9010e-05, 8.2065e-04]],\n",
       "\n",
       "        [[6.6955e-05, 6.4380e-04],\n",
       "         [6.6955e-05, 6.3285e-05],\n",
       "         [6.6955e-05, 6.4380e-04]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.1973e-04, 1.2629e-04],\n",
       "         [1.1973e-04, 1.2869e-04],\n",
       "         [1.1973e-04, 1.0916e-04]],\n",
       "\n",
       "        [[7.4592e-05, 6.0543e-05],\n",
       "         [7.4592e-05, 1.0365e-04],\n",
       "         [7.4592e-05, 5.1924e-05]],\n",
       "\n",
       "        [[1.2380e-04, 1.2117e-04],\n",
       "         [1.2380e-04, 1.6280e-04],\n",
       "         [1.2380e-04, 1.4429e-04]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afsByGenePooledCtrls4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 10., 15.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "altCountsByGenePooledCtrls2 tensor([[[57.,  5.],\n",
      "         [ 0.,  0.],\n",
      "         [ 0.,  3.]],\n",
      "\n",
      "        [[33.,  4.],\n",
      "         [ 0.,  1.],\n",
      "         [ 0.,  1.]],\n",
      "\n",
      "        [[32.,  8.],\n",
      "         [ 0.,  0.],\n",
      "         [ 0.,  4.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[79.,  2.],\n",
      "         [ 0.,  2.],\n",
      "         [ 0.,  1.]],\n",
      "\n",
      "        [[57.,  1.],\n",
      "         [ 0.,  1.],\n",
      "         [ 0.,  0.]],\n",
      "\n",
      "        [[62.,  0.],\n",
      "         [ 0.,  0.],\n",
      "         [ 0.,  0.]]])\n",
      "afsByGenePooledCtrls2 tensor([[[1.1584e-04, 1.8107e-03],\n",
      "         [1.1584e-04, 0.0000e+00],\n",
      "         [1.1584e-04, 1.8107e-03]],\n",
      "\n",
      "        [[6.6629e-05, 1.1572e-03],\n",
      "         [6.6629e-05, 8.2746e-05],\n",
      "         [6.6629e-05, 1.1572e-03]],\n",
      "\n",
      "        [[7.3478e-05, 2.6415e-03],\n",
      "         [7.3478e-05, 0.0000e+00],\n",
      "         [7.3478e-05, 2.6415e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.3780e-04, 1.3780e-04],\n",
      "         [1.3780e-04, 1.3780e-04],\n",
      "         [1.3780e-04, 1.3780e-04]],\n",
      "\n",
      "        [[1.2472e-04, 1.2472e-04],\n",
      "         [1.2472e-04, 1.2472e-04],\n",
      "         [1.2472e-04, 1.2472e-04]],\n",
      "\n",
      "        [[1.3106e-04, 0.0000e+00],\n",
      "         [1.3106e-04, 0.0000e+00],\n",
      "         [1.3106e-04, 0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"altCountsByGenePooledCtrls2\", altCountsByGenePooledCtrls2)\n",
    "print(\"afsByGenePooledCtrls2\", afsByGenePooledCtrls2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenAltCounts(altCounts, afs):\n",
    "    altCountsFlatPooled = []\n",
    "    afsFlatPooled = []\n",
    "    for geneIdx in range(nGenes):\n",
    "        altCountsFlatPooled.append([altCounts[geneIdx, 0, 0], *altCounts[geneIdx, :, 1].flatten()])\n",
    "        afsFlatPooled.append([afs[geneIdx, 0, 0], *afs[geneIdx, :, 1].flatten()])\n",
    "\n",
    "    altCountsFlatPooled = tensor(altCountsFlatPooled)\n",
    "    afsFlatPooled = tensor(afsFlatPooled)\n",
    "    print(\"altCountsFlatPooled\", altCountsFlatPooled)\n",
    "    print(\"afsFlatPooled\", afsFlatPooled)\n",
    "\n",
    "    flattenedData = []\n",
    "\n",
    "    for geneAfData in afs:\n",
    "        flattenedData.append([geneAfData[0][0],*geneAfData[:, 1]])\n",
    "    flattenedData = tensor(flattenedData)\n",
    "    \n",
    "    return altCountsFlatPooled, afsFlatPooled, flattenedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "altCountsFlatPooled tensor([[41.,  3.,  1.,  3.],\n",
      "        [20.,  3.,  1.,  0.],\n",
      "        [48.,  5.,  2.,  2.],\n",
      "        ...,\n",
      "        [50.,  0.,  0.,  0.],\n",
      "        [50.,  0.,  1.,  0.],\n",
      "        [72.,  2.,  0.,  1.]])\n",
      "afsFlatPooled tensor([[8.6933e-05, 7.6084e-04, 8.4495e-05, 7.6084e-04],\n",
      "        [5.3346e-05, 4.7881e-04, 1.0357e-04, 4.7881e-04],\n",
      "        [8.0309e-05, 1.2285e-03, 8.6144e-05, 1.2285e-03],\n",
      "        ...,\n",
      "        [9.7155e-05, 1.1197e-04, 1.4983e-04, 6.8495e-05],\n",
      "        [1.1968e-04, 9.2315e-05, 1.5075e-04, 1.9200e-04],\n",
      "        [1.4755e-04, 1.5299e-04, 1.6652e-04, 1.6753e-04]])\n",
      "altCountsFlatPooled tensor([[49.,  2.,  1.,  1.],\n",
      "        [70.,  6.,  0.,  2.],\n",
      "        [25.,  0.,  0.,  2.],\n",
      "        ...,\n",
      "        [51.,  0.,  0.,  3.],\n",
      "        [92.,  0.,  1.,  1.],\n",
      "        [66.,  0.,  0.,  0.]])\n",
      "afsFlatPooled tensor([[1.0318e-04, 7.1909e-04, 2.1672e-04, 7.1909e-04],\n",
      "        [1.2506e-04, 1.1996e-03, 1.1220e-04, 1.1996e-03],\n",
      "        [5.9096e-05, 5.4921e-04, 4.7854e-05, 5.4921e-04],\n",
      "        ...,\n",
      "        [9.5681e-05, 2.9140e-05, 8.1306e-05, 1.7900e-04],\n",
      "        [1.6374e-04, 9.5763e-05, 1.5421e-04, 2.9972e-04],\n",
      "        [1.3953e-04, 2.3317e-04, 1.2681e-04, 1.7601e-04]])\n"
     ]
    }
   ],
   "source": [
    "altCountsFlatPooled2, afsFlatPooled2, flattenedData2 = flattenAltCounts(altCountsByGenePooledCtrls2b, afsByGenePooledCtrls2b)\n",
    "altCountsFlatPooled3, afsFlatPooled3, flattenedData3 = flattenAltCounts(altCountsByGenePooledCtrls3, afsByGenePooledCtrls3)\n",
    "altCountsFlatPooled4, afsFlatPooled4, flattenedData4 = flattenAltCounts(altCountsByGenePooledCtrls4, afsByGenePooledCtrls4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "altCountsFlatPooled tensor([[26.,  0.,  0.,  4.],\n",
      "        [37.,  2.,  1.,  2.],\n",
      "        [34.,  4.,  0.,  3.],\n",
      "        ...,\n",
      "        [55.,  1.,  0.,  0.],\n",
      "        [32.,  1.,  0.,  0.],\n",
      "        [57.,  1.,  0.,  1.]])\n",
      "afsFlatPooled tensor([[5.6273e-05, 1.0045e-03, 6.5915e-05, 1.0045e-03],\n",
      "        [6.9010e-05, 8.2065e-04, 8.4283e-05, 8.2065e-04],\n",
      "        [6.6955e-05, 6.4380e-04, 6.3285e-05, 6.4380e-04],\n",
      "        ...,\n",
      "        [1.1973e-04, 1.2629e-04, 1.2869e-04, 1.0916e-04],\n",
      "        [7.4592e-05, 6.0543e-05, 1.0365e-04, 5.1924e-05],\n",
      "        [1.2380e-04, 1.2117e-04, 1.6280e-04, 1.4429e-04]])\n"
     ]
    }
   ],
   "source": [
    "altCountsFlatPooled4, afsFlatPooled4, flattenedData4 = flattenAltCounts(altCountsByGenePooledCtrls4, afsByGenePooledCtrls4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.46369028],\n",
       "       [0.46369028, 1.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(afsFlatPooled4[0:2000, 1], afsFlatPooled4[0:2000, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.6273e-05, 1.0045e-03, 6.5915e-05, 1.0045e-03],\n",
      "        [6.9010e-05, 8.2065e-04, 8.4283e-05, 8.2065e-04],\n",
      "        [6.6955e-05, 6.4380e-04, 6.3285e-05, 6.4380e-04],\n",
      "        ...,\n",
      "        [1.1973e-04, 1.2629e-04, 1.2869e-04, 1.0916e-04],\n",
      "        [7.4592e-05, 6.0543e-05, 1.0365e-04, 5.1924e-05],\n",
      "        [1.2380e-04, 1.2117e-04, 1.6280e-04, 1.4429e-04]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffd80d27d90>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(flattenedData4)\n",
    "pyplot.clf()\n",
    "pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(afsFlatPooled4[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr for 1 & both in both [[1.         0.90279585]\n",
      " [0.90279585 1.        ]]\n",
      "corr for 1 & both in 1only [[1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"corr for 1 & both in both\", np.corrcoef(afsFlatPooled4[4000:5000, 2], afsFlatPooled4[4000:5000, 3]))\n",
    "print(\"corr for 1 & both in 1only\", np.corrcoef(afsFlatPooled4[0:2000, 1], afsFlatPooled4[0:2000, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0015)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.6793e-05)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(afsFlatPooled2[0:5000, 3].mean())\n",
    "afsFlatPooled2[5000:, 3].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical rr for both tensor(13.0779)\n",
      "empirical rr for 1 tensor(10.0151)\n",
      "empirical rr for 2 tensor(12.5486)\n"
     ]
    }
   ],
   "source": [
    "print(\"empirical rr for both\", afsFlatPooled4[0:5000, 3].mean()/ afsFlatPooled4[5000:, 3].mean())\n",
    "print(\"empirical rr for 1\", ((afsFlatPooled4[0:2000, 1].mean()))/ afsFlatPooled4[2000:4000, 1].mean())\n",
    "print(\"empirical rr for 2\", ((afsFlatPooled4[2000:4000, 2].mean() + afsFlatPooled4[4000:5000, 2].mean())/2)/ afsFlatPooled4[:2000, 2].mean())\n",
    "# print(\"nullLikelihoodGlobal 1\", (nullLikelihoodsGlobal[0:2000, 0] + nullLikelihoodsGlobal[4000:5000, 0]).mean(), nullLikelihoodsGlobal[2000:, 0].mean())\n",
    "# print(\"nullLikelihoodGlobal 2\", nullLikelihoodsGlobal[2000:4000, 1].mean(), nullLikelihoodsGlobal[4000:, 1].mean())\n",
    "# print(\"nullLikelihoodGlobal Both\", nullLikelihoodsGlobal[4000:5000, 2].mean(), nullLikelihoodsGlobal[0:4000, 2].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llPooledBivariateSingleGene(tensor([10.,1.,1.,20000.]), tensor([.01,.01,.05]), tensor(13.), tensor(10.), tensor(10.), tensor(100000.), tensor(.77), tensor(.1), tensor(.1), tensor(.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this gives -2.401 log(likelihoodUnivariateSingleGene(xCtrl = 10, xCase1 = 1, prevalence1 = .01, pi0 = .9, pi1 = .1, pDiseaseGivenVariant = .001))\n",
    "#tensor(-2.5290): llUnivariateSingleGeneJensen(xCtrl = tensor(10.), xCase = tensor(1.), pD = tensor(.01), pi0 = tensor(.9), pi1 = tensor(.1), pDgivenV = tensor(.001))\n",
    "r = llUnivariateSingleGeneNoJensen(xCtrl = tensor(10.), xCase = tensor(1.), pD = tensor(.01), pi0 = tensor(.9), pi1 = tensor(.1), pDgivenV = tensor(.001))\n",
    "assert(abs(-r + tensor(-2.4010)) < .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altCounts = tensor([10., 2., 3., 1.])\n",
    "n = altCounts.sum()\n",
    "\n",
    "testAlpha = tensor([16., 20., 30., 15.])\n",
    "print(f\"test data: testAlpha: {testAlpha}, n: {n}, altCounts: {altCounts}\")\n",
    "DirichletMultinomial(total_count=n, concentration=testAlpha).log_prob(altCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV(.01, afsByGene[0:2000, 0, 1], 1e-4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test functions\n",
    "pDgivenV(.01, afsByGeneRR2[0:2000, 0, 1], afsByGeneRR2Shape5[0:2000, 0, 0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance is wrong\n",
    "def betaVariance(alpha, beta):\n",
    "    return (alpha * beta) / ( ((alpha + beta)**2) + (alpha + beta + 1) )\n",
    "\n",
    "def betaMean(alpha, beta):\n",
    "    return alpha / (alpha + beta)\n",
    "\n",
    "print(\"variance\", betaVariance(6.47e1,5.39e3))\n",
    "print(\"mean\", betaMean(6.47e1,5.39e3))\n",
    "print(\"true varianc\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = afsByGene[0:2000, 0, 1].mean()\n",
    "m2 = afsByGeneRR2[0:2000, 0, 1].mean()/afsByGeneRR2[2000:, 0, 1].mean()\n",
    "m1 - m2\n",
    "print(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res = fitFnUniveriate(altCountsByGene, pDs, nEpochs=20, minLLThresholdCount=20, debug=True)\n",
    "print((time.time() - start) / 20, \"per iteration\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriate(altCountsByGeneRR2, pDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV(pDs[0], afsByGeneRR2Shape5[0:2000, 0, 1], afsByGeneRR2Shape5[0:2000, 0, 0]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pDs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-9622e5cc5545>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfitFnUniveriate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsByGenePooledCtrls4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pDs' is not defined"
     ]
    }
   ],
   "source": [
    "fitFnUniveriate(altCounts, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR2, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR2Shape5, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(2.23307950e+02, 2.52700651e+04).sample([10_000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(2.20865706e+02, 1.73544747e+04).sample([10_000,]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR3, pDs, nEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(2.50432693e+02, 1.87756988e+04).sample([10_000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriate(altCountsByGeneRR3, pDs, nEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(3.84376856e+02, 2.37879954e+04).sample([10_000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsRR2Shape5 = []\n",
    "for i in range(1):\n",
    "    res = fitFnUniveriateBetaBinomial(altCountsByGeneRR2Shape5, pDs, nEpochs=50, minLLThresholdCount=50, debug=False)\n",
    "    resultsRR2Shape5.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsRR2Shape5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(1.96912591e+02, 1.61461738e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=50, minLLThresholdCount=50, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(3.30289057e+03, 2.94460355e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't really work resConstrained = fitFnUniveriateBetaBinomialConstrained(altCountsByGeneRR2Shape5, pDs, nEpochs=10, minLLThresholdCount=10, debug=True)\n",
    "#resConstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=10, minLLThresholdCount=10, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": []}\n",
    "cachedData = [[altCountsByGenePooledCtrls, afsByGenePooledCtrls, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean\n",
    "        }]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": [], \"costFnIdx\": []}\n",
    "cachedData2 = [[altCountsByGenePooledCtrls2, afsByGenePooledCtrls2, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean,\n",
    "        }]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i >= len(cachedData):\n",
    "        start = time.time()\n",
    "        altCountsByGenePooledCtrls, afsByGenePooledCtrls = genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData.append([altCountsByGenePooledCtrls, afsByGenePooledCtrls, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean\n",
    "        }])\n",
    "        \n",
    "    res = fitFnBivariate(cachedData[i][0], pDsGlobalLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=0)\n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3])\n",
    "    print(\"inferredPis\", inferredPis)\n",
    "    inferredAlphas = tensor(bestRes[3:])\n",
    "    print(\"inferredAlphas\", inferredAlphas)\n",
    "    \n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "    params[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params[\"inferredPis\"].append(inferredPis)\n",
    "    params[\"inferredPDVs\"].append(inferredPDs)\n",
    "\n",
    "    truth1 = pDgivenV(pDsGlobalLarge[0], afsByGenePooledCtrls[0:2000, 0, 1], afsByGenePooledCtrls[0:2000, 0, 0]).mean()\n",
    "    truth2 = pDgivenV(pDsGlobalLarge[1], afsByGenePooledCtrls[2000:4000, 1, 1], afsByGenePooledCtrls[2000:4000, 0, 0]).mean()\n",
    "    truth3 = pDgivenV(pDsGlobalLarge[2], afsByGenePooledCtrls[4000:5000, 2, 1], afsByGenePooledCtrls[4000:5000, 0, 0]).mean()\n",
    "    truth0 = 1 - (truth1 + truth2 + truth3)\n",
    "    print(\"truth0\", truth0, \"truth1\", truth1, \"truth2\", truth2, \"truthBoth\", truth3)\n",
    "\n",
    "    params[\"trueMeanPDVs\"].append(tensor([truth0, truth1, truth2, truth3]))\n",
    "    params[\"truePis\"].append(tensor(diseaseFractions))\n",
    "\n",
    "    print(f\"params on run {i}\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i >= len(cachedData2):\n",
    "        start = time.time()\n",
    "        altCountsByGenePooledCtrls2, afsByGenePooledCtrls2 = genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData2.append([altCountsByGenePooledCtrls2, afsByGenePooledCtrls2, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean,\n",
    "        }])\n",
    "    runCostFnIdx = 6\n",
    "    # todo append all entries to indciate failure\n",
    "    params2[\"costFnIdx\"].append(runCostFnIdx)\n",
    "\n",
    "    res = fitFnBivariate(cachedData2[i][0], pDsGlobalLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "    \n",
    "    \n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3])\n",
    "    print(\"inferredPis\", inferredPis)\n",
    "    inferredAlphas = tensor(bestRes[3:])\n",
    "    print(\"inferredAlphas\", inferredAlphas)\n",
    "    \n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "    params2[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params2[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params2[\"inferredPis\"].append(inferredPis)\n",
    "    params2[\"inferredPDVs\"].append(inferredPDs)\n",
    "\n",
    "    truth1 = pDgivenV(pDsGlobalLarge[0], cachedData2[i][1][0:2000, 0, 1], cachedData2[i][1][0:2000, 0, 0]).mean()\n",
    "    truth2 = pDgivenV(pDsGlobalLarge[1], cachedData2[i][1][2000:4000, 1, 1], cachedData2[i][1][2000:4000, 0, 0]).mean()\n",
    "    truth3 = pDgivenV(pDsGlobalLarge[2], cachedData2[i][1][4000:5000, 2, 1], cachedData2[i][1][4000:5000, 0, 0]).mean()\n",
    "    truth0 = 1 - (truth1 + truth2 + truth3)\n",
    "    print(\"truth0\", truth0, \"truth1\", truth1, \"truth2\", truth2, \"truthBoth\", truth3)\n",
    "\n",
    "    params2[\"trueMeanPDVs\"].append(tensor([truth0, truth1, truth2, truth3]))\n",
    "    params2[\"truePis\"].append(tensor(diseaseFractions))\n",
    "    \n",
    "    print(f\"params on run {i}\", params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": [], \"costFnIdx\": []}\n",
    "cachedData3 = [[altCountsByGenePooledCtrls3, afsByGenePooledCtrls3, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean,\n",
    "        }]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    if i >= len(cachedData3):\n",
    "        start = time.time()\n",
    "        altCountsByGenePooledCtrls3, afsByGenePooledCtrls3 = genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData3.append([altCountsByGenePooledCtrls3, afsByGenePooledCtrls3, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean,\n",
    "        }])\n",
    "    runCostFnIdx = 7\n",
    "    # todo append all entries to indciate failure\n",
    "    params3[\"costFnIdx\"].append(runCostFnIdx)\n",
    "\n",
    "    res = fitFnBivariate(cachedData3[i][0], pDsGlobalLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "    \n",
    "    \n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3])\n",
    "    print(\"inferredPis\", inferredPis)\n",
    "    inferredAlphas = tensor(bestRes[3:])\n",
    "    print(\"inferredAlphas\", inferredAlphas)\n",
    "    \n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "    params3[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params3[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params3[\"inferredPis\"].append(inferredPis)\n",
    "    params3[\"inferredPDVs\"].append(inferredPDs)\n",
    "\n",
    "    truth1 = pDgivenV(pDsGlobalLarge[0], cachedData3[i][1][0:2000, 0, 1], cachedData3[i][1][0:2000, 0, 0]).mean()\n",
    "    truth2 = pDgivenV(pDsGlobalLarge[1], cachedData3[i][1][2000:4000, 1, 1], cachedData3[i][1][2000:4000, 0, 0]).mean()\n",
    "    truth3 = pDgivenV(pDsGlobalLarge[2], cachedData3[i][1][4000:5000, 2, 1], cachedData3[i][1][4000:5000, 0, 0]).mean()\n",
    "    truth0 = 1 - (truth1 + truth2 + truth3)\n",
    "    print(\"truth0\", truth0, \"truth1\", truth1, \"truth2\", truth2, \"truthBoth\", truth3)\n",
    "\n",
    "    params3[\"trueMeanPDVs\"].append(tensor([truth0, truth1, truth2, truth3]))\n",
    "    params3[\"truePis\"].append(tensor(diseaseFractions))\n",
    "    \n",
    "    print(f\"params on run {i}\", params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4 = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": [], \"costFnIdx\": []}\n",
    "cachedData4 = [[altCountsByGenePooledCtrls4, afsByGenePooledCtrls4, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean,\n",
    "        }]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.44921331],\n",
       "       [0.44921331, 1.        ]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd = cachedData4[1][1]\n",
    "np.corrcoef(cd[4000:5000, 1, 1], cd[4000:5000, 2, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH: nSamples tensor([[100000.,   1000.],\n",
      "        [100000.,   1000.],\n",
      "        [100000.,    500.]]) rrMean tensor([10., 10.,  5.]) rrShape tensor(10.) afMean tensor(1.0000e-04) afShape tensor(10.) diseaseFractions tensor([0.1000, 0.1000, 0.0500]) pDs tensor([0.0098, 0.0098, 0.0049])\n",
      "rrDist mean tensor(8.3435)\n",
      "startIndices [0, tensor(2000.), tensor(4000.)] endIndices tensor([2000., 4000., 5000.])\n",
      "took 85.64463114738464\n",
      "altCountsFlat tensor([[26.,  0.,  0.,  4.],\n",
      "        [37.,  2.,  1.,  2.],\n",
      "        [34.,  4.,  0.,  3.],\n",
      "        ...,\n",
      "        [55.,  1.,  0.,  0.],\n",
      "        [32.,  1.,  0.,  0.],\n",
      "        [57.,  1.,  0.,  1.]])\n",
      "n tensor([30., 42., 41.,  ..., 56., 33., 59.])\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 4.,  ..., 1., 1., 1.])\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 0.,  ..., 0., 0., 0.])\n",
      "xCase1, xCase2, xCase12 tensor([4., 2., 3.,  ..., 0., 0., 1.])\n",
      "allNull2 tensor([8.1657e-06, 2.2616e-04, 3.5738e-07,  ..., 1.4049e-01, 1.4609e-01,\n",
      "        3.9861e-02])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2l at 0x7ffdb0cd5b90>\n",
      "best ll: 82874.3203125, bestParams: [tensor(0.1729), tensor(0.1921), tensor(0.1227), tensor(20100.6035), tensor(3598.7944), tensor(3720.5325), tensor(1546.6392)]\n",
      "epoch 0\n",
      " final_simplex: (array([[9.13188468e-02, 9.33986426e-02, 4.76603676e-02, 3.10033120e+04,\n",
      "        3.91561327e+03, 3.87910403e+03, 2.28663592e+03],\n",
      "       [9.13188467e-02, 9.33986423e-02, 4.76603680e-02, 3.10033120e+04,\n",
      "        3.91561328e+03, 3.87910403e+03, 2.28663593e+03],\n",
      "       [9.13188468e-02, 9.33986420e-02, 4.76603681e-02, 3.10033121e+04,\n",
      "        3.91561329e+03, 3.87910404e+03, 2.28663593e+03],\n",
      "       [9.13188468e-02, 9.33986424e-02, 4.76603677e-02, 3.10033120e+04,\n",
      "        3.91561327e+03, 3.87910403e+03, 2.28663592e+03],\n",
      "       [9.13188464e-02, 9.33986430e-02, 4.76603676e-02, 3.10033119e+04,\n",
      "        3.91561326e+03, 3.87910402e+03, 2.28663592e+03],\n",
      "       [9.13188463e-02, 9.33986432e-02, 4.76603675e-02, 3.10033119e+04,\n",
      "        3.91561325e+03, 3.87910402e+03, 2.28663591e+03],\n",
      "       [9.13188465e-02, 9.33986430e-02, 4.76603675e-02, 3.10033119e+04,\n",
      "        3.91561326e+03, 3.87910402e+03, 2.28663592e+03],\n",
      "       [9.13188467e-02, 9.33986425e-02, 4.76603677e-02, 3.10033120e+04,\n",
      "        3.91561327e+03, 3.87910403e+03, 2.28663592e+03]]), array([78178.21715289, 78178.21715297, 78178.21715374, 78178.21715448,\n",
      "       78178.21715591, 78178.21715601, 78178.21715617, 78178.21715654]))\n",
      "           fun: 78178.2171528865\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1255\n",
      "           nit: 561\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.13188468e-02, 9.33986426e-02, 4.76603676e-02, 3.10033120e+04,\n",
      "       3.91561327e+03, 3.87910403e+03, 2.28663592e+03])\n",
      "best ll: 85126.453125, bestParams: [tensor(0.0089), tensor(0.2063), tensor(0.1169), tensor(23024.5977), tensor(1466.7189), tensor(1395.2167), tensor(782.3361)]\n",
      "epoch 1\n",
      " final_simplex: (array([[9.52363761e-02, 9.75387669e-02, 4.67837027e-02, 1.26704900e+02,\n",
      "        1.56768700e+01, 1.54978372e+01, 9.63616347e+00],\n",
      "       [9.52363754e-02, 9.75387669e-02, 4.67837030e-02, 1.26704899e+02,\n",
      "        1.56768697e+01, 1.54978372e+01, 9.63616351e+00],\n",
      "       [9.52363741e-02, 9.75387682e-02, 4.67837030e-02, 1.26704898e+02,\n",
      "        1.56768695e+01, 1.54978371e+01, 9.63616352e+00],\n",
      "       [9.52363751e-02, 9.75387680e-02, 4.67837014e-02, 1.26704899e+02,\n",
      "        1.56768698e+01, 1.54978373e+01, 9.63616355e+00],\n",
      "       [9.52363742e-02, 9.75387674e-02, 4.67837033e-02, 1.26704898e+02,\n",
      "        1.56768695e+01, 1.54978372e+01, 9.63616353e+00],\n",
      "       [9.52363752e-02, 9.75387677e-02, 4.67837017e-02, 1.26704898e+02,\n",
      "        1.56768696e+01, 1.54978370e+01, 9.63616346e+00],\n",
      "       [9.52363753e-02, 9.75387664e-02, 4.67837026e-02, 1.26704899e+02,\n",
      "        1.56768698e+01, 1.54978370e+01, 9.63616346e+00],\n",
      "       [9.52363742e-02, 9.75387672e-02, 4.67837021e-02, 1.26704896e+02,\n",
      "        1.56768693e+01, 1.54978367e+01, 9.63616347e+00]]), array([77950.50322467, 77950.50323325, 77950.50323957, 77950.50324929,\n",
      "       77950.50325154, 77950.5032545 , 77950.50326452, 77950.50328111]))\n",
      "           fun: 77950.50322467272\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2436\n",
      "           nit: 1300\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.52363761e-02, 9.75387669e-02, 4.67837027e-02, 1.26704900e+02,\n",
      "       1.56768700e+01, 1.54978372e+01, 9.63616347e+00])\n",
      "minPrevious 78178.2171528865\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.52363761e-02, 9.75387669e-02, 4.67837027e-02, 1.26704900e+02,\n",
      "        1.56768700e+01, 1.54978372e+01, 9.63616347e+00],\n",
      "       [9.52363754e-02, 9.75387669e-02, 4.67837030e-02, 1.26704899e+02,\n",
      "        1.56768697e+01, 1.54978372e+01, 9.63616351e+00],\n",
      "       [9.52363741e-02, 9.75387682e-02, 4.67837030e-02, 1.26704898e+02,\n",
      "        1.56768695e+01, 1.54978371e+01, 9.63616352e+00],\n",
      "       [9.52363751e-02, 9.75387680e-02, 4.67837014e-02, 1.26704899e+02,\n",
      "        1.56768698e+01, 1.54978373e+01, 9.63616355e+00],\n",
      "       [9.52363742e-02, 9.75387674e-02, 4.67837033e-02, 1.26704898e+02,\n",
      "        1.56768695e+01, 1.54978372e+01, 9.63616353e+00],\n",
      "       [9.52363752e-02, 9.75387677e-02, 4.67837017e-02, 1.26704898e+02,\n",
      "        1.56768696e+01, 1.54978370e+01, 9.63616346e+00],\n",
      "       [9.52363753e-02, 9.75387664e-02, 4.67837026e-02, 1.26704899e+02,\n",
      "        1.56768698e+01, 1.54978370e+01, 9.63616346e+00],\n",
      "       [9.52363742e-02, 9.75387672e-02, 4.67837021e-02, 1.26704896e+02,\n",
      "        1.56768693e+01, 1.54978367e+01, 9.63616347e+00]]), array([77950.50322467, 77950.50323325, 77950.50323957, 77950.50324929,\n",
      "       77950.50325154, 77950.5032545 , 77950.50326452, 77950.50328111]))\n",
      "           fun: 77950.50322467272\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2436\n",
      "           nit: 1300\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.52363761e-02, 9.75387669e-02, 4.67837027e-02, 1.26704900e+02,\n",
      "       1.56768700e+01, 1.54978372e+01, 9.63616347e+00])\n",
      "best ll: 81383.5078125, bestParams: [tensor(0.1336), tensor(0.0873), tensor(0.0858), tensor(13237.3818), tensor(1208.1730), tensor(2771.1833), tensor(252.6810)]\n",
      "epoch 2\n",
      " final_simplex: (array([[9.58203856e-02, 9.50800712e-02, 4.76370036e-02, 1.27333124e+02,\n",
      "        1.57354624e+01, 1.56065622e+01, 9.66121951e+00],\n",
      "       [9.58203854e-02, 9.50800715e-02, 4.76370035e-02, 1.27333133e+02,\n",
      "        1.57354636e+01, 1.56065634e+01, 9.66121865e+00],\n",
      "       [9.58203854e-02, 9.50800717e-02, 4.76370033e-02, 1.27333145e+02,\n",
      "        1.57354653e+01, 1.56065642e+01, 9.66122081e+00],\n",
      "       [9.58203856e-02, 9.50800708e-02, 4.76370040e-02, 1.27333132e+02,\n",
      "        1.57354625e+01, 1.56065646e+01, 9.66121850e+00],\n",
      "       [9.58203856e-02, 9.50800709e-02, 4.76370039e-02, 1.27333144e+02,\n",
      "        1.57354646e+01, 1.56065651e+01, 9.66121961e+00],\n",
      "       [9.58203856e-02, 9.50800714e-02, 4.76370034e-02, 1.27333082e+02,\n",
      "        1.57354573e+01, 1.56065585e+01, 9.66121477e+00],\n",
      "       [9.58203854e-02, 9.50800717e-02, 4.76370033e-02, 1.27333124e+02,\n",
      "        1.57354627e+01, 1.56065616e+01, 9.66121906e+00],\n",
      "       [9.58203853e-02, 9.50800714e-02, 4.76370037e-02, 1.27333218e+02,\n",
      "        1.57354750e+01, 1.56065729e+01, 9.66122413e+00]]), array([77951.16935263, 77951.16936176, 77951.16936645, 77951.16937304,\n",
      "       77951.16938019, 77951.16938516, 77951.16938533, 77951.16939849]))\n",
      "           fun: 77951.16935263453\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1601\n",
      "           nit: 820\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.58203856e-02, 9.50800712e-02, 4.76370036e-02, 1.27333124e+02,\n",
      "       1.57354624e+01, 1.56065622e+01, 9.66121951e+00])\n",
      "minPrevious 77950.50322467272\n",
      "best ll: 86076.09375, bestParams: [tensor(0.0577), tensor(0.0595), tensor(0.0557), tensor(22842.3926), tensor(8646.8691), tensor(5052.2773), tensor(100.9276)]\n",
      "epoch 3\n",
      " final_simplex: (array([[9.69792460e-02, 9.72142864e-02, 4.73141465e-02, 1.26384536e+02,\n",
      "        1.56086204e+01, 1.54558423e+01, 9.61980659e+00],\n",
      "       [9.69792481e-02, 9.72142854e-02, 4.73141454e-02, 1.26384587e+02,\n",
      "        1.56086235e+01, 1.54558481e+01, 9.61981260e+00],\n",
      "       [9.69792500e-02, 9.72142867e-02, 4.73141423e-02, 1.26384538e+02,\n",
      "        1.56086180e+01, 1.54558407e+01, 9.61980850e+00],\n",
      "       [9.69792445e-02, 9.72142836e-02, 4.73141501e-02, 1.26384629e+02,\n",
      "        1.56086292e+01, 1.54558553e+01, 9.61981545e+00],\n",
      "       [9.69792440e-02, 9.72142845e-02, 4.73141499e-02, 1.26384538e+02,\n",
      "        1.56086194e+01, 1.54558428e+01, 9.61980680e+00],\n",
      "       [9.69792426e-02, 9.72142834e-02, 4.73141520e-02, 1.26384582e+02,\n",
      "        1.56086240e+01, 1.54558488e+01, 9.61981163e+00],\n",
      "       [9.69792564e-02, 9.72142876e-02, 4.73141340e-02, 1.26384581e+02,\n",
      "        1.56086236e+01, 1.54558459e+01, 9.61981200e+00],\n",
      "       [9.69792500e-02, 9.72142867e-02, 4.73141423e-02, 1.26384537e+02,\n",
      "        1.56086180e+01, 1.54558406e+01, 9.61980842e+00]]), array([77950.86202284, 77950.86204762, 77950.86206372, 77950.86206929,\n",
      "       77950.86207298, 77950.86208224, 77950.86208426, 77950.86209682]))\n",
      "           fun: 77950.86202283573\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2070\n",
      "           nit: 1144\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.69792460e-02, 9.72142864e-02, 4.73141465e-02, 1.26384536e+02,\n",
      "       1.56086204e+01, 1.54558423e+01, 9.61980659e+00])\n",
      "minPrevious 77950.50322467272\n",
      "best ll: 96511.4765625, bestParams: [tensor(0.0039), tensor(0.0045), tensor(0.0027), tensor(23016.5234), tensor(1374.9342), tensor(1735.3005), tensor(7804.1172)]\n",
      "epoch 4\n",
      " final_simplex: (array([[9.48193842e-02, 9.76423084e-02, 4.65107626e-02, 1.26798196e+02,\n",
      "        1.56978748e+01, 1.55069133e+01, 9.64641080e+00],\n",
      "       [9.48193842e-02, 9.76423084e-02, 4.65107626e-02, 1.26798196e+02,\n",
      "        1.56978748e+01, 1.55069133e+01, 9.64641080e+00],\n",
      "       [9.48193842e-02, 9.76423084e-02, 4.65107626e-02, 1.26798196e+02,\n",
      "        1.56978748e+01, 1.55069133e+01, 9.64641080e+00],\n",
      "       [9.48193843e-02, 9.76423081e-02, 4.65107626e-02, 1.26798196e+02,\n",
      "        1.56978746e+01, 1.55069132e+01, 9.64641083e+00],\n",
      "       [9.48193843e-02, 9.76423082e-02, 4.65107626e-02, 1.26798198e+02,\n",
      "        1.56978749e+01, 1.55069134e+01, 9.64641089e+00],\n",
      "       [9.48193843e-02, 9.76423082e-02, 4.65107626e-02, 1.26798195e+02,\n",
      "        1.56978746e+01, 1.55069132e+01, 9.64641071e+00],\n",
      "       [9.48193843e-02, 9.76423081e-02, 4.65107626e-02, 1.26798193e+02,\n",
      "        1.56978744e+01, 1.55069129e+01, 9.64641058e+00],\n",
      "       [9.48193844e-02, 9.76423078e-02, 4.65107625e-02, 1.26798195e+02,\n",
      "        1.56978746e+01, 1.55069131e+01, 9.64641073e+00]]), array([77950.535859  , 77950.53585903, 77950.53585907, 77950.53586483,\n",
      "       77950.53586563, 77950.53586934, 77950.5358702 , 77950.5358772 ]))\n",
      "           fun: 77950.53585899745\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 3498\n",
      "           nit: 1917\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.48193842e-02, 9.76423084e-02, 4.65107626e-02, 1.26798196e+02,\n",
      "       1.56978748e+01, 1.55069133e+01, 9.64641080e+00])\n",
      "minPrevious 77950.50322467272\n",
      "best ll: 89998.359375, bestParams: [tensor(0.0481), tensor(0.0530), tensor(0.0096), tensor(21426.8906), tensor(7886.3301), tensor(6937.9771), tensor(1640.3784)]\n",
      "epoch 5\n",
      " final_simplex: (array([[9.52141113e-02, 9.85174745e-02, 4.73657743e-02, 1.26500721e+02,\n",
      "        1.56470407e+01, 1.54499156e+01, 9.62172393e+00],\n",
      "       [9.52141114e-02, 9.85174750e-02, 4.73657740e-02, 1.26500755e+02,\n",
      "        1.56470402e+01, 1.54499179e+01, 9.62173152e+00],\n",
      "       [9.52141118e-02, 9.85174744e-02, 4.73657743e-02, 1.26500730e+02,\n",
      "        1.56470393e+01, 1.54499164e+01, 9.62172642e+00],\n",
      "       [9.52141097e-02, 9.85174758e-02, 4.73657740e-02, 1.26500798e+02,\n",
      "        1.56470478e+01, 1.54499242e+01, 9.62173208e+00],\n",
      "       [9.52141106e-02, 9.85174754e-02, 4.73657743e-02, 1.26500651e+02,\n",
      "        1.56470319e+01, 1.54499062e+01, 9.62172029e+00],\n",
      "       [9.52141115e-02, 9.85174748e-02, 4.73657742e-02, 1.26500712e+02,\n",
      "        1.56470371e+01, 1.54499132e+01, 9.62172556e+00],\n",
      "       [9.52141074e-02, 9.85174757e-02, 4.73657743e-02, 1.26500727e+02,\n",
      "        1.56470398e+01, 1.54499154e+01, 9.62172651e+00],\n",
      "       [9.52141063e-02, 9.85174759e-02, 4.73657743e-02, 1.26500720e+02,\n",
      "        1.56470391e+01, 1.54499147e+01, 9.62172587e+00]]), array([77950.67984125, 77950.67987168, 77950.67987438, 77950.67988298,\n",
      "       77950.67989952, 77950.67990537, 77950.67993119, 77950.67993315]))\n",
      "           fun: 77950.67984125411\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1584\n",
      "           nit: 824\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.52141113e-02, 9.85174745e-02, 4.73657743e-02, 1.26500721e+02,\n",
      "       1.56470407e+01, 1.54499156e+01, 9.62172393e+00])\n",
      "minPrevious 77950.50322467272\n",
      "best ll: 93254.0546875, bestParams: [tensor(0.0047), tensor(0.0607), tensor(0.0343), tensor(21309.3750), tensor(5318.2988), tensor(2182.8018), tensor(21953.2344)]\n",
      "epoch 6\n",
      " final_simplex: (array([[9.52495181e-02, 9.75447659e-02, 4.67864359e-02, 1.26756275e+02,\n",
      "        1.56856252e+01, 1.55047908e+01, 9.63869832e+00],\n",
      "       [9.52495153e-02, 9.75447754e-02, 4.67864299e-02, 1.26756299e+02,\n",
      "        1.56856271e+01, 1.55047943e+01, 9.63870007e+00],\n",
      "       [9.52495106e-02, 9.75447832e-02, 4.67864260e-02, 1.26756285e+02,\n",
      "        1.56856249e+01, 1.55047925e+01, 9.63869946e+00],\n",
      "       [9.52495149e-02, 9.75447749e-02, 4.67864300e-02, 1.26756287e+02,\n",
      "        1.56856256e+01, 1.55047932e+01, 9.63869938e+00],\n",
      "       [9.52495101e-02, 9.75447842e-02, 4.67864253e-02, 1.26756344e+02,\n",
      "        1.56856317e+01, 1.55048006e+01, 9.63870329e+00],\n",
      "       [9.52495116e-02, 9.75447744e-02, 4.67864310e-02, 1.26756294e+02,\n",
      "        1.56856269e+01, 1.55047935e+01, 9.63870004e+00],\n",
      "       [9.52495165e-02, 9.75447682e-02, 4.67864340e-02, 1.26756314e+02,\n",
      "        1.56856305e+01, 1.55047952e+01, 9.63870109e+00],\n",
      "       [9.52495124e-02, 9.75447747e-02, 4.67864302e-02, 1.26756295e+02,\n",
      "        1.56856269e+01, 1.55047938e+01, 9.63869993e+00]]), array([77950.50335305, 77950.50336386, 77950.50336425, 77950.50337268,\n",
      "       77950.503381  , 77950.50342553, 77950.50343742, 77950.5034473 ]))\n",
      "           fun: 77950.50335304573\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2380\n",
      "           nit: 1289\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.52495181e-02, 9.75447659e-02, 4.67864359e-02, 1.26756275e+02,\n",
      "       1.56856252e+01, 1.55047908e+01, 9.63869832e+00])\n",
      "minPrevious 77950.50322467272\n",
      "best ll: 90711.2890625, bestParams: [tensor(0.0805), tensor(0.0501), tensor(0.0226), tensor(22322.9492), tensor(7516.6909), tensor(1438.2825), tensor(8028.8940)]\n",
      "epoch 7\n",
      " final_simplex: (array([[9.14221307e-02, 9.33866021e-02, 4.77218909e-02, 1.94073306e+04,\n",
      "        2.45061962e+03, 2.42893482e+03, 1.43091593e+03],\n",
      "       [9.14221307e-02, 9.33866022e-02, 4.77218907e-02, 1.94073306e+04,\n",
      "        2.45061963e+03, 2.42893483e+03, 1.43091594e+03],\n",
      "       [9.14221307e-02, 9.33866019e-02, 4.77218910e-02, 1.94073306e+04,\n",
      "        2.45061961e+03, 2.42893482e+03, 1.43091593e+03],\n",
      "       [9.14221306e-02, 9.33866021e-02, 4.77218910e-02, 1.94073306e+04,\n",
      "        2.45061961e+03, 2.42893482e+03, 1.43091593e+03],\n",
      "       [9.14221309e-02, 9.33866019e-02, 4.77218909e-02, 1.94073306e+04,\n",
      "        2.45061961e+03, 2.42893482e+03, 1.43091593e+03],\n",
      "       [9.14221307e-02, 9.33866020e-02, 4.77218909e-02, 1.94073306e+04,\n",
      "        2.45061962e+03, 2.42893482e+03, 1.43091593e+03],\n",
      "       [9.14221305e-02, 9.33866022e-02, 4.77218910e-02, 1.94073306e+04,\n",
      "        2.45061961e+03, 2.42893482e+03, 1.43091592e+03],\n",
      "       [9.14221304e-02, 9.33866023e-02, 4.77218910e-02, 1.94073306e+04,\n",
      "        2.45061961e+03, 2.42893482e+03, 1.43091592e+03]]), array([78176.80726631, 78176.80726691, 78176.80727691, 78176.80727707,\n",
      "       78176.80727707, 78176.80727712, 78176.80727713, 78176.80727716]))\n",
      "           fun: 78176.80726631466\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1432\n",
      "           nit: 644\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.14221307e-02, 9.33866021e-02, 4.77218909e-02, 1.94073306e+04,\n",
      "       2.45061962e+03, 2.42893482e+03, 1.43091593e+03])\n",
      "minPrevious 77950.50322467272\n",
      "best ll: 91199.046875, bestParams: [tensor(0.0544), tensor(0.0292), tensor(0.0078), tensor(16735.0703), tensor(4036.6323), tensor(1425.1892), tensor(14398.7529)]\n",
      "epoch 8\n",
      " final_simplex: (array([[9.52342084e-02, 9.75133767e-02, 4.67680465e-02, 1.26827694e+02,\n",
      "        1.56928441e+01, 1.55130860e+01, 9.64663646e+00],\n",
      "       [9.52341965e-02, 9.75133923e-02, 4.67680428e-02, 1.26827783e+02,\n",
      "        1.56928583e+01, 1.55130963e+01, 9.64664403e+00],\n",
      "       [9.52342077e-02, 9.75133766e-02, 4.67680472e-02, 1.26827695e+02,\n",
      "        1.56928442e+01, 1.55130860e+01, 9.64663666e+00],\n",
      "       [9.52342041e-02, 9.75133797e-02, 4.67680480e-02, 1.26827680e+02,\n",
      "        1.56928429e+01, 1.55130835e+01, 9.64663569e+00],\n",
      "       [9.52341986e-02, 9.75133785e-02, 4.67680536e-02, 1.26827700e+02,\n",
      "        1.56928454e+01, 1.55130858e+01, 9.64663652e+00],\n",
      "       [9.52342081e-02, 9.75133753e-02, 4.67680462e-02, 1.26827694e+02,\n",
      "        1.56928442e+01, 1.55130860e+01, 9.64663645e+00],\n",
      "       [9.52341883e-02, 9.75133820e-02, 4.67680609e-02, 1.26827690e+02,\n",
      "        1.56928442e+01, 1.55130842e+01, 9.64663578e+00],\n",
      "       [9.52342103e-02, 9.75133786e-02, 4.67680422e-02, 1.26827720e+02,\n",
      "        1.56928481e+01, 1.55130893e+01, 9.64663893e+00]]), array([77950.50318099, 77950.50318467, 77950.50320778, 77950.5032192 ,\n",
      "       77950.50322099, 77950.50322192, 77950.50324177, 77950.50324966]))\n",
      "           fun: 77950.50318098711\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2515\n",
      "           nit: 1389\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.52342084e-02, 9.75133767e-02, 4.67680465e-02, 1.26827694e+02,\n",
      "       1.56928441e+01, 1.55130860e+01, 9.64663646e+00])\n",
      "minPrevious 77950.50322467272\n",
      "best ll: 94109.28125, bestParams: [tensor(0.0673), tensor(0.0329), tensor(0.2100), tensor(13084.9443), tensor(2389.0979), tensor(3154.8628), tensor(22816.1328)]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.14262305e-02, 9.35687309e-02, 4.76917070e-02, 1.61365943e+04,\n",
      "        2.03716197e+03, 2.01848652e+03, 1.19039657e+03],\n",
      "       [9.14262327e-02, 9.35687314e-02, 4.76917040e-02, 1.61365943e+04,\n",
      "        2.03716197e+03, 2.01848652e+03, 1.19039657e+03],\n",
      "       [9.14262341e-02, 9.35687297e-02, 4.76917044e-02, 1.61365944e+04,\n",
      "        2.03716198e+03, 2.01848655e+03, 1.19039655e+03],\n",
      "       [9.14262327e-02, 9.35687304e-02, 4.76917049e-02, 1.61365943e+04,\n",
      "        2.03716195e+03, 2.01848652e+03, 1.19039658e+03],\n",
      "       [9.14262335e-02, 9.35687299e-02, 4.76917046e-02, 1.61365944e+04,\n",
      "        2.03716199e+03, 2.01848655e+03, 1.19039655e+03],\n",
      "       [9.14262337e-02, 9.35687296e-02, 4.76917047e-02, 1.61365943e+04,\n",
      "        2.03716194e+03, 2.01848653e+03, 1.19039660e+03],\n",
      "       [9.14262325e-02, 9.35687296e-02, 4.76917058e-02, 1.61365943e+04,\n",
      "        2.03716196e+03, 2.01848652e+03, 1.19039658e+03],\n",
      "       [9.14262295e-02, 9.35687316e-02, 4.76917067e-02, 1.61365942e+04,\n",
      "        2.03716196e+03, 2.01848653e+03, 1.19039658e+03]]), array([78176.04751612, 78176.04752079, 78176.04752096, 78176.04752124,\n",
      "       78176.04752298, 78176.04752329, 78176.0475249 , 78176.04752715]))\n",
      "           fun: 78176.0475161183\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1397\n",
      "           nit: 662\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.14262305e-02, 9.35687309e-02, 4.76917070e-02, 1.61365943e+04,\n",
      "       2.03716197e+03, 2.01848652e+03, 1.19039657e+03])\n",
      "minPrevious 77950.50322467272\n",
      "best ll: 88662.3984375, bestParams: [tensor(0.1404), tensor(0.2369), tensor(0.0993), tensor(24820.5234), tensor(5608.1738), tensor(4651.5684), tensor(9490.3125)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "#     if i >= len(cachedData4):\n",
    "    start = time.time()\n",
    "    altCountsByGenePooledCtrls4, afsByGenePooledCtrls4 = genData4(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "    print(\"took\", time.time() - start)\n",
    "    cachedData4.append([altCountsByGenePooledCtrls4, afsByGenePooledCtrls4, {\n",
    "        \"nCases\": nCasesLarge,\n",
    "        \"nCtrls\": nCtrlsLarge,\n",
    "        \"pDs\": pDsGlobalLarge,\n",
    "        \"diseaseFractions\": diseaseFractions,\n",
    "        \"rrShape\": rrShape,\n",
    "        \"rrMeans\": rrMeansCovary,\n",
    "        \"afShape\": afShape,\n",
    "        \"afMean\": afMean,\n",
    "    }])\n",
    "    runCostFnIdx = 15\n",
    "\n",
    "    res = fitFnBivariate(cachedData4[i][0], pDsGlobalLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "    \n",
    "    \n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3])\n",
    "    print(\"inferredPis\", inferredPis)\n",
    "    inferredAlphas = tensor(bestRes[3:])\n",
    "    print(\"inferredAlphas\", inferredAlphas)\n",
    "    \n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "    params4[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params4[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params4[\"inferredPis\"].append(inferredPis)\n",
    "    params4[\"inferredPDVs\"].append(inferredPDs)\n",
    "\n",
    "    truth1 = pDgivenV(pDsGlobalLarge[0], cachedData4[i][1][0:2000, 0, 1], cachedData4[i][1][0:2000, 0, 0]).mean()\n",
    "    truth2 = pDgivenV(pDsGlobalLarge[1], cachedData4[i][1][2000:4000, 1, 1], cachedData4[i][1][2000:4000, 0, 0]).mean()\n",
    "    truth3 = pDgivenV(pDsGlobalLarge[2], cachedData4[i][1][4000:5000, 2, 1], cachedData4[i][1][4000:5000, 0, 0]).mean()\n",
    "    truth0 = 1 - (truth1 + truth2 + truth3)\n",
    "    print(\"truth0\", truth0, \"truth1\", truth1, \"truth2\", truth2, \"truthBoth\", truth3)\n",
    "\n",
    "    params4[\"trueMeanPDVs\"].append(tensor([truth0, truth1, truth2, truth3]))\n",
    "    params4[\"truePis\"].append(tensor(diseaseFractions))\n",
    "    \n",
    "     # todo append all entries to indciate failure\n",
    "    params4[\"costFnIdx\"].append(runCostFnIdx)\n",
    "\n",
    "    \n",
    "    print(f\"params on run {i}\", params4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.46762262],\n",
       "       [0.46762262, 1.        ]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(afsByGenePooledCtrls4[0:2000, 0, 1], afsByGenePooledCtrls4[0:2000, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(inputAltCounts, inputAfs, costFnIdx):\n",
    "    params = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": []}\n",
    "    cachedData = [[inputAltCounts, inputAfs, {\n",
    "                \"nCases\": nCasesLarge,\n",
    "                \"nCtrls\": nCtrlsLarge,\n",
    "                \"pDs\": pDsGlobalLarge,\n",
    "                \"diseaseFractions\": diseaseFractions,\n",
    "                \"rrShape\": rrShape,\n",
    "                \"rrMeans\": rrMeans,\n",
    "                \"afShape\": afShape,\n",
    "                \"afMean\": afMean\n",
    "            }]]\n",
    "    for i in range(10):\n",
    "        if i >= len(cachedData2):\n",
    "            start = time.time()\n",
    "            altCounts, afs = genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)\n",
    "            print(\"took\", time.time() - start)\n",
    "            cachedData2.append([altCounts, afs, {\n",
    "                \"nCases\": nCasesLarge,\n",
    "                \"nCtrls\": nCtrlsLarge,\n",
    "                \"pDs\": pDsGlobalLarge,\n",
    "                \"diseaseFractions\": diseaseFractions,\n",
    "                \"rrShape\": rrShape,\n",
    "                \"rrMeans\": rrMeans,\n",
    "                \"afShape\": afShape,\n",
    "                \"afMean\": afMean\n",
    "            }])\n",
    "\n",
    "        res = fitFnBivariate(cachedData[i][0], pDsGlobalLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=costFnIdx)\n",
    "        bestRes = res[\"params\"][-1]\n",
    "\n",
    "        inferredPis = tensor(bestRes[0:3])\n",
    "        print(\"inferredPis\", inferredPis)\n",
    "        inferredAlphas = tensor(bestRes[3:])\n",
    "        print(\"inferredAlphas\", inferredAlphas)\n",
    "\n",
    "        inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "        params[\"lls\"].append(res[\"lls\"][-1])\n",
    "        params[\"inferredAlphas\"].append(inferredAlphas)\n",
    "        params[\"inferredPis\"].append(inferredPis)\n",
    "        params[\"inferredPDVs\"].append(inferredPDs)\n",
    "\n",
    "        truth1 = pDgivenV(pDsGlobalLarge[0], cachedData[i][1][0:2000, 0, 1], cachedData[i][1][0:2000, 0, 0]).mean()\n",
    "        truth2 = pDgivenV(pDsGlobalLarge[1], cachedData[i][1][2000:4000, 1, 1], cachedData[i][1][2000:4000, 0, 0]).mean()\n",
    "        truth3 = pDgivenV(pDsGlobalLarge[2], cachedData[i][1][4000:5000, 2, 1], cachedData[i][1][4000:5000, 0, 0]).mean()\n",
    "        truth0 = 1 - (truth1 + truth2 + truth3)\n",
    "        print(\"truth0\", truth0, \"truth1\", truth1, \"truth2\", truth2, \"truthBoth\", truth3)\n",
    "\n",
    "        params[\"trueMeanPDVs\"].append(tensor([truth0, truth1, truth2, truth3]))\n",
    "        params[\"truePis\"].append(tensor(diseaseFractions))\n",
    "\n",
    "        print(f\"params on run {i}\", params)\n",
    "        \n",
    "        return params, cachedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4, cachedData2 = runModel(altCountsByGenePooledCtrls2, afsByGenePooledCtrls2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = altCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-408cb9ef4c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'params4' is not defined"
     ]
    }
   ],
   "source": [
    "params4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-84e613715e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inferredPis\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "tensor([*params[\"inferredPis\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fitFnBivariate(cachedData[0][0], pDsLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = fitFnBivariate(cachedData[0][0], pDsLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = fitFnBivariate(cachedData[0][0], pDsLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"res0\", res0)\n",
    "print(\"\\nres0\", \"pis\", res0[\"params\"][-1][0:3], \"mean P(D|V)'s\", Dirichlet(tensor(res0[\"params\"][-1][3:])).sample([10_000]).mean(0))\n",
    "\n",
    "print(\"\\n\\n\\nres1\", res1)\n",
    "print(\"\\nres1\", \"pis\", res1[\"params\"][-1][0:3], \"mean P(D|V)'s\", Dirichlet(tensor(res1[\"params\"][-1][3:])).sample([10_000]).mean(0))\n",
    "\n",
    "print(\"\\n\\n\\nres2\", res2)\n",
    "print(\"\\nres2\", \"pis\", res2[\"params\"][-1][0:3], \"mean P(D|V)'s\", Dirichlet(tensor(res2[\"params\"][-1][3:])).sample([10_000]).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb88903ef50>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(res0[\"llTrajectory\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb84a498610>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(res1[\"llTrajectory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb849d71f90>]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(res2[\"llTrajectory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(afsByGenePooledCtrls[2000:4000, 1, 1]/afsByGenePooledCtrls[2000:4000, 0, 0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pDgivenV(pD., afsByGenePooledCtrls[0:2000, :, 1], afsByGenePooledCtrls[0:2000, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dirichlet(tensor(1/4.0).expand(4)).sample()\n",
    "test = test[0:3]\n",
    "r = [0,1,2,3]\n",
    "r[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnBivariate(altCountsByGenePooledCtrls, pDs, nEpochs=100, minLLThresholdCount=100, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dirichlet(concentration=tensor([1.40625703e+04,\n",
    "         5.56195520e+03, 1.57978682e+02, 2.33518936e+04]))\n",
    "d.sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(7.74788652e+02, 2.58170768e+04 + 9.72956833e+02 + 5.18278100e+03).sample([10000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(3.05871723e+04, 3.25256694e+02 + 3.75135881e+03 +4.52942294e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res = fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=100, minLLThresholdCount=100, debug=False)\n",
    "print(\"fitFnUniveriateBetaBinomial took for 100 epochs: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(res[\"llTrajectory\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomH0 = Binomial(total_count=tensor([1.,1]), probs=pDs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomH0.log_prob(tensor(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn2 = likelihoodUnivariateFast(altCountsByGene, pDs)\n",
    "# print(costFn2([1e-9, .999999]))\n",
    "print(costFn2([1e-9, 1e-9]))\n",
    "print(costFn2([0.08845797,0.11094360])) #gives ~12067 using jensen's method, and ~9887 using exponentiation of the log\n",
    "\n",
    "# best result from R\n",
    "#  0.08845797           0.11094360 , ll -10127.23, and with jensen's version, \"example -12037.4347455843\"\n",
    "# pDgivenV, pi1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn = likelihoodUnivariate(altCountsByGene, pDs)\n",
    "print(\"costFn1:\", costFn([.001, .01]),\"costFn2:\",costFn2([.001, .01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn([0.0001,0.11094360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(costFn2([0.0001,0.11094360]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Binomial(total_count=tensor([14., 0., 9.]), probs=tensor(.0099))\n",
    "d.log_prob(tensor([0.,0.,0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn2([1e-9, .999999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomH0 = Binomial(total_count=geneSums, probs=.001)\n",
    "binomH1 = Binomial(total_count=geneSums, probs=.01)\n",
    "caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "print(caseAltCounts)\n",
    "component0 = binomH0.log_prob(caseAltCounts)\n",
    "print(\"component0\", component0, .5*component0)\n",
    "component1 = binomH1.log_prob(caseAltCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV(pDs[0], afsByGene2[0:2000, 0, 1].mean(), afMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition1 = altCountsByGene2[:, 0, :]\n",
    "condition1\n",
    "pDs[0]\n",
    "\n",
    "afsByGene2[0:2000,:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(afsByGene2[:, 0, 1:2].flatten())\n",
    "pyplot.plot(afsByGene2[:, 0, 0:1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 0, 0:1].flatten())\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 0, 1:2].flatten())\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 1, 1:2].flatten())\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 2, 1:2].flatten())\n",
    "# pyplot.plot(afsByGeneRR2[:, 0, 1:2].flatten())\n",
    "# pyplot.plot(afsByGeneRR2[:, 0, 0:1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrlCounts = altCountsByGene[:, 0, 0]\n",
    "altCountsCases = altCountsByGene[:, :, 1]\n",
    "\n",
    "altCountsFlat = []\n",
    "for geneIdx in range(nGenes):\n",
    "    altCountsFlat.append([ctrlCounts[geneIdx], *altCountsByGene[geneIdx, :, 1].flatten()])\n",
    "altCountsFlat = tensor(altCountsFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altCountsFlat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DirichletMultinomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "K = 4  # Fixed number of components.\n",
    "\n",
    "@config_enumerate\n",
    "def model(data):\n",
    "    # Global variables.\n",
    "    weights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(K)))\n",
    "    alpha0 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "    alpha1 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "    alpha2 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "    alpha3 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "\n",
    "    with pyro.plate('components', K):\n",
    "        concentrations = pyro.sample('concentrations', dist.Dirichlet(0.5 * torch.ones(K)))\n",
    "\n",
    "    with pyro.plate('data', len(data)):\n",
    "        # Local variables.\n",
    "        component = pyro.sample('assignment', dist.Categorical(weights))\n",
    "        print(f\"concentrations: {concentrations[component]}\")\n",
    "        pyro.sample('obs', DirichletMultinomial(concentration=concentrations[component], total_count=data.sum(1)), obs=data)\n",
    "\n",
    "optim = pyro.optim.Adam({'lr': 0.1, 'betas': [0.8, 0.99]})\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_loc_fn(site):\n",
    "    if site[\"name\"] == \"weights\":\n",
    "        # Initialize weights to uniform.\n",
    "        return torch.ones(K) / K\n",
    "    if site[\"name\"] == \"concentrations\":\n",
    "        return torch.ones(K) / K\n",
    "    raise ValueError(site[\"name\"])\n",
    "\n",
    "def initialize(seed):\n",
    "    global global_guide, svi\n",
    "    pyro.set_rng_seed(seed)\n",
    "    pyro.clear_param_store()\n",
    "    global_guide = AutoDelta(poutine.block(model, expose=['weights', 'concentrations']),\n",
    "                             init_loc_fn=init_loc_fn)\n",
    "    svi = SVI(model, global_guide, optim, loss=elbo)\n",
    "    return svi.loss(model, global_guide, altCountsFlat)\n",
    "\n",
    "# Choose the best among 100 random initializations.\n",
    "loss, seed = min((initialize(seed), seed) for seed in range(2))\n",
    "initialize(seed)\n",
    "print('seed = {}, initial_loss = {}'.format(seed, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register hooks to monitor gradient norms.\n",
    "gradient_norms = defaultdict(list)\n",
    "for name, value in pyro.get_param_store().named_parameters():\n",
    "    value.register_hook(lambda g, name=name: gradient_norms[name].append(g.norm().item()))\n",
    "\n",
    "losses = []\n",
    "for i in range(200 if not smoke_test else 2):\n",
    "    loss = svi.step(altCountsFlat)\n",
    "    losses.append(loss)\n",
    "    print('.' if i % 100 else '\\n', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-b35e8b608158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(figsize=(10,3), dpi=100).set_facecolor('white')\n",
    "pyplot.plot(losses)\n",
    "pyplot.xlabel('iters')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.yscale('log')\n",
    "pyplot.title('Convergence of SVI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, grad_norms in gradient_norms.items():\n",
    "    pyplot.plot(grad_norms, label=name)\n",
    "pyplot.xlabel('iters')\n",
    "pyplot.ylabel('gradient norm')\n",
    "pyplot.yscale('log')\n",
    "pyplot.legend(loc='best')\n",
    "pyplot.title('Gradient norms during SVI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimates = global_guide(altCountsFlat)\n",
    "weights = map_estimates['weights']\n",
    "locs = map_estimates['concentrations']\n",
    "print('weights = {}'.format(weights.data.numpy()))\n",
    "print('concentrations = {}'.format(locs.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([0.8973397  , 0.0494441,  0.04917945, 0.00403667])).sample([10_000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
