{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: torch in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (1.4.0)\n",
      "Collecting pyro-ppl\n",
      "  Downloading pyro_ppl-1.3.1-py3-none-any.whl (520 kB)\n",
      "\u001b[K     |████████████████████████████████| 520 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pyro-api>=0.1.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (0.1.1)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.36 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (4.42.1)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.4.0 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (1.18.2)\n",
      "Installing collected packages: pyro-ppl\n",
      "  Attempting uninstall: pyro-ppl\n",
      "    Found existing installation: pyro-ppl 1.3.0\n",
      "    Uninstalling pyro-ppl-1.3.0:\n",
      "      Successfully uninstalled pyro-ppl-1.3.0\n",
      "Successfully installed pyro-ppl-1.3.1\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-macosx_10_6_intel.whl (28.4 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scipy) (1.18.2)\n",
      "\u001b[31mERROR: hail 0.2.36 has requirement scipy<1.4,>1.2, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.3.3\n",
      "    Uninstalling scipy-1.3.3:\n",
      "      Successfully uninstalled scipy-1.3.3\n",
      "Successfully installed scipy-1.4.1\n",
      "Requirement already up-to-date: matplotlib in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "Requirement already up-to-date: scikit-optimize in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.19.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: pyaml>=16.9 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (20.3.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.0 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyaml>=16.9->scikit-optimize) (5.3.1)\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "!pip install --upgrade torch\n",
    "!pip install --upgrade pyro-ppl\n",
    "!pip install --upgrade scipy\n",
    "!pip install --upgrade matplotlib\n",
    "!pip install --upgrade scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import torch.tensor as tensor\n",
    "import pyro.distributions as dist\n",
    "# from torch.distributions import Binomial, Gamma, Uniform\n",
    "from pyro.distributions import Binomial, Bernoulli, Categorical, Dirichlet, DirichletMultinomial, Beta, BetaBinomial, Uniform, Gamma\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from skopt import gp_minimize \n",
    "from scipy.stats import binom as ScipyBinom\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from collections import namedtuple\n",
    "import time\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Scalar version took: 0.11273598670959473\n",
      "Done\n",
      "Tensor version took: 3.4068148136138916\n",
      "Done\n",
      "Tensor convert array version took: 0.14068198204040527\n"
     ]
    }
   ],
   "source": [
    "# Measuring overhead\n",
    "import time\n",
    "\n",
    "# .1s\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(i)\n",
    "\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Scalar version took: {time.time() - start}\")\n",
    "\n",
    "# 30x slower, 3.2s\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(tensor(i))\n",
    "\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Tensor version took: {time.time() - start}\")\n",
    "\n",
    "# do it in one pass\n",
    "# this wraps the array in tensor, aka tensor([]),\n",
    "# but accessing a single element gives back a tensor\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(i)\n",
    "\n",
    "# .13s \n",
    "l = torch.tensor(l)\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Tensor convert array version took: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Likelihood functions\n",
    "# These assume univariate currently\n",
    "\n",
    "# TODO:\n",
    "# 1) Explore constraining alphas using prevalence estimate, namely E(P(D)) = alpha0 / (alpha0 + alpha1 + alpha2 + alphaBoth) (as long as all case counts are mutually exclusive)\n",
    "# 2) Can DM approximate NB + Multinomial? If so do we need mixture at all? But if we don't have that how do we model % disease-afffecting genes in each hypothesis(maybe proportion of alphas?)\n",
    "# rr: relative risk\n",
    "def pVgivenD(rr, pV):\n",
    "    return (rr * pV) / (rr * pV + (1 - pV))\n",
    "\n",
    "# pD: prevalence, tensor of mConditions x 1\n",
    "# pVgivenD: tensor of mConditions x 1\n",
    "# pV: allele frequency\n",
    "def pVgivenNotD(pD, pV, pVgivenD):\n",
    "    p = (pV - (pD*pVgivenD).sum()) / (1 - pD.sum())\n",
    "    assert(p >= 0)\n",
    "    return p\n",
    "\n",
    "# def pVgivenNotD(pD, pV, pVgivenD):\n",
    "#     p = (pV - (pD*pVgivenD)) / (1 - pD)\n",
    "#     assert(p >= 0)\n",
    "#     return p\n",
    "\n",
    "def pDgivenV(pD, pVgivenD, pV):\n",
    "    return pVgivenD * pD / pV\n",
    "\n",
    "# works like shit\n",
    "def llUnivariateSingleGeneJensen(xCtrl, xCase, pD, pi0, pi1, pDgivenV):\n",
    "    n = xCtrl + xCase\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    return pi0 * Binomial(total_count=n, probs=pD).log_prob(xCase) + pi1*Binomial(total_count=n, probs=pDgivenV).log_prob(xCase)\n",
    "\n",
    "def llUnivariateSingleGene(xCtrl, xCase, pD, pi0, pi1, pDgivenV):\n",
    "    n = xCtrl + xCase\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    return torch.log(pi0 * torch.exp(Binomial(total_count=n, probs=pD).log_prob(xCase)) + pi1*torch.exp(Binomial(total_count=n, probs=pDgivenV).log_prob(xCase)))\n",
    "\n",
    "# alphas shape: [2] #corresponding to cases and controls\n",
    "def llUnivariateSingleGeneBetaBinomial(xCtrl, xCase, pD, alphas, pi0, pi1):\n",
    "    n = xCtrl + xCase\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    # what is the \n",
    "    h0 = pi0 * torch.exp( Binomial(total_count=n, probs=pD).log_prob(xCase) )\n",
    "    h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alphas[1], concentration0=alphas[0]).log_prob(xCase) )\n",
    "    return torch.log( h0 + h1 )\n",
    "\n",
    "# TODO: support pooled and non-pooled controls\n",
    "# TODO: think about whether we need overlapping cases (both disease1 + disease2) or whether that can be inferred\n",
    "# altCounts.shape = [1 control + nConditions cases, 1]\n",
    "# alphas shape: [nConditions + 2] #1 ctrl + nCondition cases; for now the last condition in nCondition cases is for individuals who has all of the previous nConditions\n",
    "# in a more multivariate setting we will need more information, aka mapping to which combinations of conditions these people have\n",
    "# xCases: we have nConditions cases\n",
    "# pDs shape: [nConditions]\n",
    "# TODO: make this more effificent by taking alphas tensor of shape (1 + nConditions)\n",
    "def llPooledBivariateSingleGene(altCounts, pDs, alpha0, alpha1, alpha2, alphaBoth, pi0, pi1, pi2, piBoth):\n",
    "    # currently assume altCounts are all independent (in simulation), or 0 for everything but first condition\n",
    "    n = altCounts.sum()\n",
    "    alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "    print(\"n is \", n)\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    # what is the \n",
    "    case1nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[0]).log_prob(altCounts[1]) )\n",
    "    case2nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[1]).log_prob(altCounts[2]) )\n",
    "    h0 = pi0 * case1nullLikelihood * case2nullLikelihood\n",
    "    h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCounts[1]) ) * case2nullLikelihood\n",
    "    h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCounts[2]) ) * case1nullLikelihood\n",
    "    h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCounts))\n",
    "    print(f\"h0: {h0}, h1: {h1}, h2: {h2}, h3: {h3}\")\n",
    "    return torch.log( h0 + h1 + h2 + h3 )\n",
    "\n",
    "# shape of altCountsByGene: [nGenes, nConditions, 2]\n",
    "# last dimension is \n",
    "# 2nd dimension altCountsCasesByGene must match controls, or the control nConditions must be 1 (pooled controls)\n",
    "def likelihoodUnivariate(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    \n",
    "    # passed to optimization function, we optimize pDgivenV and pi1 by maximizing likelihood\n",
    "    def likelihood(params):\n",
    "        pDgivenV = params[0]\n",
    "        pi1 = params[1]\n",
    "        pi0 = 1 - pi1\n",
    "        \n",
    "        if(pDgivenV >= 1 or pDgivenV < 0 or pi1 < 0 or pi1 > 1):\n",
    "            print(\"returning inf\")\n",
    "            return float(\"-inf\")\n",
    "    \n",
    "        logLikelihood = 0\n",
    "        penaltyCount = float(nGenes)\n",
    "        \n",
    "        # \n",
    "        for geneIdx in range(nGenes):\n",
    "            ctrlAltCount = altCountsByGene[geneIdx, 0, 0]\n",
    "            caseAltCount = altCountsByGene[geneIdx, 0, 1]\n",
    "            pd = pDs[0]\n",
    "            \n",
    "            if ctrlAltCount == 0 and caseAltCount == 0:\n",
    "                print(\"skipping\", geneIdx)\n",
    "                continue\n",
    "\n",
    "            # this is insanely slow\n",
    "            ll = llUnivariateSingleGene(ctrlAltCount, caseAltCount, pd, pi0, pi1, pDgivenV)\n",
    "\n",
    "            if torch.isnan(ll) or torch.isinf(ll):\n",
    "                print(f\"nan or 0 likelihood: like: {like}, p1: {pi1}, pDgivenV: {pDgivenV}, gene: {geneIdx}, ctrlCount: {ctrlAltCount}, caseCount: {caseAltCount}\")\n",
    "                penaltyCount -= 1\n",
    "                continue\n",
    "                \n",
    "            logLikelihood += ll\n",
    "        \n",
    "    \n",
    "        if penaltyCount == 0:\n",
    "            penaltyCount = 1\n",
    "    \n",
    "        return -logLikelihood * (nGenes / penaltyCount)\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "def likelihoodUnivariateFast(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    geneSums = altCountsByGene[:, 0, :].sum(1)\n",
    "        \n",
    "    caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "    pD = pDs[0]\n",
    "    def likelihood(params):\n",
    "        pi1, pDgivenV = params\n",
    "\n",
    "        pi0 = 1.0 - pi1\n",
    "\n",
    "        if(pDgivenV > 1 or pDgivenV < 0 or pi1 < 0 or pi1 > 1):\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        binomH0 = Binomial(total_count=geneSums, probs=pD)\n",
    "        binomH1 = Binomial(total_count=geneSums, probs=pDgivenV)\n",
    "        \n",
    "        component0 = pi0 * torch.exp(binomH0.log_prob(caseAltCounts))\n",
    "        component1 = pi1 * torch.exp(binomH1.log_prob(caseAltCounts))\n",
    "        \n",
    "        return - torch.log(component0 + component1).sum()\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "def likelihoodUnivariateBetaBinomialFast(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    geneSums = altCountsByGene[:, 0, :].sum(1)\n",
    "        \n",
    "    caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "    pD = pDs[0]\n",
    "    def likelihood(params):\n",
    "        pi1, alpha1, alpha0 = params\n",
    "\n",
    "        if alpha1 < 0 or alpha0 < 0 or pi1 < 0 or pi1 > 1:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - pi1\n",
    "\n",
    "        binomH0 = Binomial(total_count=geneSums, probs=pD)\n",
    "        binomH1 = BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alpha0)\n",
    "        \n",
    "        component0 = pi0 * torch.exp(binomH0.log_prob(caseAltCounts))\n",
    "        component1 = pi1 * torch.exp(binomH1.log_prob(caseAltCounts))\n",
    "\n",
    "        return - torch.log(component0 + component1).sum()\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "def getUnivariateAlpha0(alpha1, pD):\n",
    "    return ((1-pD) / pD)*alpha1\n",
    "\n",
    "# doesn't really work constraint looks wrong\n",
    "def likelihoodUnivariateBetaBinomialConstrainedFast(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    geneSums = altCountsByGene[:, 0, :].sum(1)\n",
    "        \n",
    "    caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "    pD = pDs[0]\n",
    "    pNotDRatio = (1 - pD)/pD\n",
    "    def likelihood(params):\n",
    "        pi1, alpha1 = params\n",
    "        \n",
    "        if alpha1 < 0 or pi1 < 0 or pi1 > 1:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - pi1\n",
    "        \n",
    "        alpha0 = pNotDRatio*alpha1\n",
    "        \n",
    "        assert(alpha0 > 0)\n",
    "        \n",
    "        print(\"alpha0\",alpha0)\n",
    "        \n",
    "        binomH0 = Binomial(total_count=geneSums, probs=pD)\n",
    "        binomH1 = BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alpha0)\n",
    "        \n",
    "        component0 = pi0 * torch.exp(binomH0.log_prob(caseAltCounts))\n",
    "        component1 = pi1 * torch.exp(binomH1.log_prob(caseAltCounts))\n",
    "\n",
    "        return - torch.log(component0 + component1).sum()\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "# Bivariate likelihood function modeled on:\n",
    "#def llPooledBivariateSingleGene(altCounts, pDs, alpha0, alpha1, alpha2, alphaBoth, pi0, pi1, pi2, piBoth):\n",
    "# # currently assume altCounts are all independent (in simulation), or 0 for everything but first condition\n",
    "# n = altCounts.sum()\n",
    "# alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "# case1nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[0]).log_prob(altCounts[1]) )\n",
    "# case2nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[1]).log_prob(altCounts[2]) )\n",
    "# h0 = pi0 * case1nullLikelihood * case2nullLikelihood\n",
    "# h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCounts[1]) ) * case2nullLikelihood\n",
    "# h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCounts[2]) ) * case1nullLikelihood\n",
    "# h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCounts))\n",
    "# print(f\"h0: {h0}, h1: {h1}, h2: {h2}, h3: {h3}\")\n",
    "# return torch.log( h0 + h1 + h2 + h3 )\n",
    "def likelihoodBivariateFast(altCountsByGene, pDs):\n",
    "    nGenes = altCountsByGene.shape[0]\n",
    "\n",
    "    geneSums = altCountsByGene[:, :, :].sum([1,2])\n",
    "\n",
    "    ctrlCounts = altCountsByGene[:, 0, 0]\n",
    "    altCountsCases = altCountsByGene[:, :, 1]\n",
    "    \n",
    "    altCountsFlat = []\n",
    "    for geneIdx in range(nGenes):\n",
    "        altCountsFlat.append([ctrlCounts[geneIdx], *altCountsByGene[geneIdx, :, 1].flatten()])\n",
    "\n",
    "    altCountsFlat = tensor(altCountsFlat)\n",
    "    # nGenes x 4 \n",
    "    xCtrl = altCountsFlat[:, 0]\n",
    "    xCase1 = altCountsFlat[:, 1]\n",
    "    xCase2 = altCountsFlat[:, 2]\n",
    "    xCase12 = altCountsFlat[:, 3]\n",
    "    # nGenes x 1\n",
    "    n = xCtrl + xCase1 + xCase2 + xCase12\n",
    "    print(\"altCountsFlat\", altCountsFlat)\n",
    "    print(\"n\", n)\n",
    "    print(\"xCase1, xCase2, xCase12\", xCase1)\n",
    "    print(\"xCase1, xCase2, xCase12\", xCase2)\n",
    "    print(\"xCase1, xCase2, xCase12\", xCase12)\n",
    "    \n",
    "    pd1 = pDs[0]\n",
    "    pd2 = pDs[1]\n",
    "    pdBoth = pDs[2]\n",
    "\n",
    "    case1Null = torch.exp(Binomial(total_count=n, probs=pd1).log_prob(xCase1))\n",
    "    case2Null = torch.exp(Binomial(total_count=n, probs=pd2).log_prob(xCase2))\n",
    "    caseBothNull = torch.exp(Binomial(total_count=n, probs=pdBoth).log_prob(xCase12))\n",
    "    allNull = case1Null * case2Null * caseBothNull\n",
    "    def likelihood1(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1) ) * case2Null * caseBothNull\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(xCase2) ) * case1Null * caseBothNull\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood1a(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1) ) * case2Null\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(xCase2) ) * case1Null\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood1b(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1 + xCase12) ) * case2Null\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(xCase2 + xCase12) ) * case1Null\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihoodConstrained(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "        \n",
    "        # idea 1\n",
    "        # alpha1 and alpha0 determined\n",
    "        # A gene has counts from gene1 samples 2 , from gene2 samples 1 geneBoth count\n",
    "        # if i have some people that only have 1, that is evidence for gene1 liability, but says nothing for liability for \n",
    "        # the more shared risk there is, the more the count will be in the \"both category\", \n",
    "        # the fewer people will be only one or the other\n",
    "        # so eventually all \n",
    "        # \n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1 + xCase12) ) * case2Null\n",
    "        \n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1 + xCase12) ) * case2Null\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(xCase2 + xCase12) ) * case1Null\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood2(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(xCase1) ) * case2Null * torch.exp( BetaBinomial(total_count=n, concentration1=alphaBoth, concentration0=alphasSum - alphaBoth).log_prob(xCase12) )\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(xCase2) ) * case1Null * torch.exp( BetaBinomial(total_count=n, concentration1=alphaBoth, concentration0=alphasSum - alphaBoth).log_prob(xCase12) )\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood2a(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1 + alphaBoth, concentration0=alphasSum - alpha1).log_prob(xCase1) ) * case2Null\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2 + alphaBoth, concentration0=alphasSum - alpha2).log_prob(xCase2) ) * case1Null \n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    \n",
    "    def likelihood2b(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha0, alpha1])).log_prob(altCountsFlat) )\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha0, alpha2, alpha2])).log_prob(altCountsFlat) )\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alphaBoth, alphaBoth, alphaBoth])).log_prob(altCountsFlat) )\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "#     def likelihood1b(params):\n",
    "#         # TODO: better to do constrained or unconstrained alpha1?\n",
    "#         pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "#         if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "#         if pi0 < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "#         h0 = pi0 * allNull\n",
    "\n",
    "#         h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1]) )\n",
    "#         h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2]) )\n",
    "#         h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "#         return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "#     def likelihood2(params):\n",
    "#         # TODO: better to do constrained or unconstrained alpha1?\n",
    "#         pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "#         if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "#         if pi0 < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "#         h0 = pi0 * allNull\n",
    "\n",
    "#         h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1] + altCountsFlat[:, 3]) ) * case2andBothNull\n",
    "#         h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2] + altCountsFlat[:, 3]) ) * case1andBothNull\n",
    "#         h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "#         return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "#     def likelihood2a(params):\n",
    "#         # TODO: better to do constrained or unconstrained alpha1?\n",
    "#         pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "#         if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "#         if pi0 < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "#         h0 = pi0 * allNull\n",
    "\n",
    "#         h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1] + altCountsFlat[:, 3]) ) * case2null\n",
    "#         h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2] + altCountsFlat[:, 3]) ) * case1null\n",
    "#         h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "#         return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "\n",
    "#     def likelihood2b(params):\n",
    "#         # TODO: better to do constrained or unconstrained alpha1?\n",
    "#         pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "#         if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "#         if pi0 < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "#         h0 = pi0 * allNull\n",
    "\n",
    "#         h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1] + altCountsFlat[:, 3]) )\n",
    "#         h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2] + altCountsFlat[:, 3]) )\n",
    "#         h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "#         return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "#     def likelihood3(params):\n",
    "#         # TODO: better to do constrained or unconstrained alpha1?\n",
    "#         pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "#         if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "#         if pi0 < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "#         h0 = pi0 * allNull\n",
    "\n",
    "#         h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1] + altCountsFlat[:, 2] + altCountsFlat[:, 3]) )\n",
    "#         h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2] + altCountsFlat[:, 1] + altCountsFlat[:, 3]) )\n",
    "#         h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "#         return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "#     def likelihood4(params):\n",
    "#         # TODO: better to do constrained or unconstrained alpha1?\n",
    "#         pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "#         if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "#         if pi0 < 0:\n",
    "#             return float(\"inf\")\n",
    "        \n",
    "#         alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "#         h0 = pi0 * allNull\n",
    "\n",
    "#         h1 = pi1 * torch.exp( DirichletMultinomial(total_count=geneSums - altCountsFlat[:, 3], concentration=tensor([alpha1, alpha2])).log_prob(altCountsFlat[:, 1:3]))\n",
    "#         h2 = pi2 * torch.exp( DirichletMultinomial(total_count=geneSums , concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "#         return -torch.log( h0 + h1 + h2 ).sum()\n",
    "\n",
    "    return likelihood1, likelihood1a, likelihood1b, likelihood2, likelihood2a, likelihood2b #likelihood1b, likelihood2, likelihood2a, likelihood2b, likelihood3, likelihood4\n",
    "\n",
    "def cb(f, context):\n",
    "    print(\"got callback\", f, context)\n",
    "\n",
    "# TODO: update for multivariate\n",
    "def fitFnUniveriate(altCountsByGene, pDs, nEpochs = 100, minLLThresholdCount = 100, debug = False):\n",
    "    costFn = likelihoodUnivariateFast(altCountsByGene, pDs)\n",
    "    \n",
    "    lls = []\n",
    "    params = []\n",
    "\n",
    "    minLLDiff = 1\n",
    "    thresholdHitCount = 0\n",
    "    \n",
    "    nGenes = len(altCountsByGene)\n",
    "\n",
    "    randomDist = Uniform(1/nGenes, .5)\n",
    "    randomDist2 = Uniform(0, 1)\n",
    "    \n",
    "        # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "    # P(V|D) * P(D) / P(V)\n",
    "#     pDgivenVbounds = ( pVgivenD(2, 1e-6) * .001 / 1e-6, pVgivenD(100, 1e-2) * .1 / 1e-2 )\n",
    "#     pi1Bounds = ( 1/nGenes,  1 )\n",
    "#     bounds = [pDgivenVbounds, pi1Bounds]\n",
    "    for i in range(nEpochs):\n",
    "        best = float(\"inf\")\n",
    "        bestParams = []\n",
    "        for y in range(100):\n",
    "            # pi1, p(D|V)\n",
    "            fnArgs = [randomDist.sample(), randomDist2.sample()]\n",
    "            ll = costFn(fnArgs)\n",
    "            if ll < best:\n",
    "                best = ll\n",
    "                bestParams = fnArgs\n",
    "                \n",
    "        if debug:\n",
    "            print(f\"best ll: {best}, params: {bestParams}\")\n",
    "\n",
    "        fit = scipy.optimize.minimize(costFn, x0 = bestParams, method='Nelder-Mead', options={\"maxiter\": 10000, \"adaptive\": True})#gp_minimize(costFn, [(1e-7, .9),(1/nGenes, .99)])#scipy.optimize.minimize(costFn, x0 = fnArgs, method=\"Nelder-Mead\", options={\"maxiter\": 10000})\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"epoch {i}\")\n",
    "            print(fit)\n",
    "\n",
    "        if not fit[\"success\"] is True:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        pi1, pDgivenV= fit[\"x\"]\n",
    "        if pDgivenV < 0 or pDgivenV > 1 or pi1 < 1/nGenes or pi1 > 1:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        ll = fit[\"fun\"]\n",
    "        if len(lls) == 0:\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            continue\n",
    "\n",
    "        minPrevious = min(lls)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"minPrevious\", minPrevious)\n",
    "            \n",
    "        # TODO: take mode of some pc-based cluster of parameters, or some auto-encoded cluster\n",
    "        if ll < minPrevious and (minPrevious - ll) >= minLLDiff:\n",
    "            if debug:\n",
    "                print(f\"better by at >= {minLLDiff}; new ll: {fit}\")\n",
    "\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            \n",
    "            thresholdHitCount = 0\n",
    "            continue\n",
    "\n",
    "        thresholdHitCount += 1\n",
    "        \n",
    "        if thresholdHitCount == minLLThresholdCount:\n",
    "            break\n",
    "            \n",
    "    return {\"lls\": lls, \"params\": params}\n",
    "\n",
    "\n",
    "# TODO: maybe beta distribution should be constrained such that variance is that of the data?\n",
    "# or maybe there's an analog to 0 mean liability variance?\n",
    "def fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs = 100, minLLThresholdCount = 100, debug = False):\n",
    "    costFn = likelihoodUnivariateBetaBinomialFast(altCountsByGene, pDs)\n",
    "    \n",
    "    llsAll = []\n",
    "    lls = []\n",
    "    params = []\n",
    "\n",
    "    minLLDiff = 1\n",
    "    thresholdHitCount = 0\n",
    "    \n",
    "    nGenes = len(altCountsByGene)\n",
    "    remainingEpochs = nEpochs\n",
    "    \n",
    "    randomDist = Uniform(1/nGenes, .5)\n",
    "    randomDist2 = Uniform(100, 25000)\n",
    "    # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "    # P(V|D) * P(D) / P(V)\n",
    "    while remainingEpochs > 0:\n",
    "        best = float(\"inf\")\n",
    "        bestParams = []\n",
    "        for i in range(50):\n",
    "            # pi1, alpha1, alpha0\n",
    "            fnArgs = [randomDist.sample(), randomDist2.sample(), randomDist2.sample()]\n",
    "            ll = costFn(fnArgs)\n",
    "            if ll < best:\n",
    "                best = ll\n",
    "                bestParams = fnArgs\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"best ll: {best}, bestParams: {bestParams}\")\n",
    "\n",
    "        fit = scipy.optimize.minimize(costFn, x0 = bestParams, method='Nelder-Mead', options={\"maxiter\": 10000, \"adaptive\": True})#gp_minimize(costFn, [(1e-7, .9),(1/nGenes, .99)])#scipy.optimize.minimize(costFn, x0 = fnArgs, method=\"Nelder-Mead\", options={\"maxiter\": 10000})\n",
    "        #fit = scipy.optimize.basinhopping(costFn, x0 = bestParams)\n",
    "        if debug:\n",
    "            print(f\"epoch {remainingEpochs}\")\n",
    "            print(fit)\n",
    "\n",
    "        if not fit[\"success\"] is True:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        pi1, alpha1, alpha0 = fit[\"x\"]\n",
    "        # TODO: is pi1 > .5 restriction sound?\n",
    "        if pi1 < 1/nGenes or pi1 > .5 or alpha1 <= 0 or alpha0 <= 0:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "            \n",
    "        remainingEpochs -= 1\n",
    "        \n",
    "        ll = fit[\"fun\"]\n",
    "        llsAll.append(ll)\n",
    "        if len(lls) == 0:\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            continue\n",
    "\n",
    "        minPrevious = min(lls)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"minPrevious\", minPrevious)\n",
    "            \n",
    "        # TODO: take mode of some pc-based cluster of parameters, or some auto-encoded cluster\n",
    "        if ll < minPrevious and (minPrevious - ll) >= minLLDiff:\n",
    "            if debug:\n",
    "                print(f\"better by at >= {minLLDiff}; new ll: {fit}\")\n",
    "\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            \n",
    "            thresholdHitCount = 0\n",
    "            continue\n",
    "\n",
    "        thresholdHitCount += 1\n",
    "        \n",
    "        if thresholdHitCount == minLLThresholdCount:\n",
    "            break\n",
    "            \n",
    "    return {\"lls\": lls, \"params\": params, \"llTrajectory\": llsAll}\n",
    "\n",
    "# Constrain alpha0 by using 1-P(D)\n",
    "# def fitFnUniveriateBetaBinomialConstrained(altCountsByGene, pDs, nEpochs = 100, minLLThresholdCount = 100, debug = False):\n",
    "#     costFn = likelihoodUnivariateBetaBinomialConstrainedFast(altCountsByGene, pDs)\n",
    "    \n",
    "#     llsAll = []\n",
    "#     lls = []\n",
    "#     params = []\n",
    "\n",
    "#     minLLDiff = 1\n",
    "#     thresholdHitCount = 0\n",
    "    \n",
    "#     randomDist = Uniform(0, 1)\n",
    "#     randomDist2 = Uniform(1, 10000)\n",
    "#     fnArgs = [0, 0]\n",
    "#     # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "#     # P(V|D) * P(D) / P(V)\n",
    "#     nGenes = len(altCountsByGene)\n",
    "#     remainingEpochs = nEpochs\n",
    "#     while remainingEpochs > 0:\n",
    "#         # pi1\n",
    "#         fnArgs[0] = randomDist.sample()\n",
    "#         # alpha1\n",
    "#         fnArgs[1] = randomDist2.sample()\n",
    "#         fit = scipy.optimize.minimize(costFn, x0 = fnArgs, method='Nelder-Mead', options={\"maxiter\": 10000})#gp_minimize(costFn, [(1e-7, .9),(1/nGenes, .99)])#scipy.optimize.minimize(costFn, x0 = fnArgs, method=\"Nelder-Mead\", options={\"maxiter\": 10000})\n",
    "        \n",
    "#         if debug:\n",
    "#             print(f\"epoch {remainingEpochs}\")\n",
    "#             print(fit)\n",
    "\n",
    "#         if not fit[\"success\"] is True:\n",
    "#             if debug:\n",
    "#                 print(\"Failed to converge\")\n",
    "#                 print(fit)\n",
    "#             continue\n",
    "        \n",
    "        \n",
    "#         pi1, alpha1 = fit[\"x\"]\n",
    "#         # TODO: is pi1 > .5 restriction sound?\n",
    "#         if pi1 < 1/nGenes or pi1 > .5 or alpha1 <= 0:\n",
    "#             if debug:\n",
    "#                 print(\"Failed to converge\")\n",
    "#                 print(fit)\n",
    "#             continue\n",
    "            \n",
    "#         remainingEpochs -= 1\n",
    "        \n",
    "#         ll = fit[\"fun\"]\n",
    "#         llsAll.append(ll)\n",
    "#         if len(lls) == 0:\n",
    "#             lls.append(ll)\n",
    "#             params.append(fit[\"x\"])\n",
    "#             continue\n",
    "\n",
    "#         minPrevious = min(lls)\n",
    "        \n",
    "#         if debug:\n",
    "#             print(\"minPrevious\", minPrevious)\n",
    "            \n",
    "#         # TODO: take mode of some pc-based cluster of parameters, or some auto-encoded cluster\n",
    "#         if ll < minPrevious and (minPrevious - ll) >= minLLDiff:\n",
    "#             if debug:\n",
    "#                 print(f\"better by at >= {minLLDiff}; new ll: {fit}\")\n",
    "\n",
    "#             lls.append(ll)\n",
    "#             params.append(fit[\"x\"])\n",
    "            \n",
    "#             thresholdHitCount = 0\n",
    "#             continue\n",
    "\n",
    "#         thresholdHitCount += 1\n",
    "        \n",
    "#         if thresholdHitCount == minLLThresholdCount:\n",
    "#             break\n",
    "            \n",
    "#     return {\"lls\": lls, \"params\": params, \"llTrajectory\": llsAll}\n",
    "\n",
    "# TODO: maybe beta distribution should be constrained such that variance is that of the data?\n",
    "# or maybe there's an analog to 0 mean liability variance\n",
    "def fitFnBivariate(altCountsByGene, pDs, nEpochs = 100, minLLThresholdCount = 100, K = 4, debug = False, costFnIdx = 0):\n",
    "    costFunctions = likelihoodBivariateFast(altCountsByGene, pDs)\n",
    "        \n",
    "    costFn = costFunctions[costFnIdx]\n",
    "    print(\"past\", costFn)\n",
    "    llsAll = []\n",
    "    lls = []\n",
    "    params = []\n",
    "\n",
    "    minLLDiff = 1\n",
    "    thresholdHitCount = 0\n",
    "    \n",
    "    nGenes = len(altCountsByGene)\n",
    "    \n",
    "    # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "    # P(V|D) * P(D) / P(V)\n",
    "    pi0Dist = Uniform(.5, 1)\n",
    "    alphasDist = Uniform(100, 25000)    \n",
    "    for i in range(nEpochs):\n",
    "        # TODO: should we constrain alpha0 to the pD, i.e\n",
    "        # E[P(D)] = alpha1 / sum(alphasRes)\n",
    "        # P(D) * (alphasRes) = alpha1\n",
    "        best = float(\"inf\")\n",
    "        bestParams = []\n",
    "        for y in range(100):\n",
    "            pi0 = pi0Dist.sample()\n",
    "            pis = Uniform(1/nGenes, 1-pi0).sample([K-1])\n",
    "            pis = pis/(pis.sum() + pi0)\n",
    "#             print(\"pi0\", pi0, \"pis\", pis, \"sum\", pis.sum())\n",
    "            fnArgs = [*pis, *alphasDist.sample([K,])]\n",
    "\n",
    "            ll = costFn(fnArgs)\n",
    "            if ll < best:\n",
    "                best = ll\n",
    "                bestParams = fnArgs\n",
    "        \n",
    "        print(f\"best ll: {best}, bestParams: {bestParams}\")\n",
    "\n",
    "#         fnArgs = [probs[0], probs[1], probs[2], *alphas]\n",
    "        fit = scipy.optimize.minimize(costFn, x0 = bestParams, method='Nelder-Mead', options={\"maxiter\": 10000, \"adaptive\": True})\n",
    "\n",
    "        if debug:\n",
    "            print(f\"epoch {i}\")\n",
    "            print(fit)\n",
    "\n",
    "        if not fit[\"success\"] is True:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = fit[\"x\"]\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi1 > 1 or pi2 < 0 or pi2 > 1 or piBoth < 0 or piBoth > 1:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        ll = fit[\"fun\"]\n",
    "        llsAll.append(ll)\n",
    "        if len(lls) == 0:\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            continue\n",
    "\n",
    "        minPrevious = min(lls)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"minPrevious\", minPrevious)\n",
    "            \n",
    "        # TODO: take mode of some pc-based cluster of parameters, or some auto-encoded cluster\n",
    "        if ll < minPrevious and (minPrevious - ll) >= minLLDiff:\n",
    "            if debug:\n",
    "                print(f\"better by at >= {minLLDiff}; new ll: {fit}\")\n",
    "\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            \n",
    "            thresholdHitCount = 0\n",
    "            continue\n",
    "\n",
    "        thresholdHitCount += 1\n",
    "        \n",
    "        if thresholdHitCount == minLLThresholdCount:\n",
    "            break\n",
    "            \n",
    "    return {\"lls\": lls, \"params\": params, \"llTrajectory\": llsAll}\n",
    "\n",
    "\n",
    "\n",
    "def initBetaParams(mu, variance):\n",
    "    alpha = ((1 - mu) / variance - 1 / variance) * mu**2\n",
    "    beta = alpha * (1/mu -1)\n",
    "    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### all named tuples used\n",
    "\n",
    "Samples = namedtuple(\"Samples\", [\"ctrls\", \"cases\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nSamples shape: [nConditions, 2] , last dim is ctrls, cases\n",
    "# Generating process\n",
    "\n",
    "# I am gene 1\n",
    "# i have 3 possible contributions to diseases 1, 2\n",
    "# 1) I contribute to disease 1 only\n",
    "# 2) I contribute to disease 2 only\n",
    "# 3) I contribute to both\n",
    "\n",
    "# For each gene I have some counts. Some people are only disease 1, some are only disease 2, some are both\n",
    "# My probability of contributing to disease 1 is a sum of 1 & both, because P(D1|V) = P(D1Only|V) + P(D1And2|V)\n",
    "# My probability of contributing to diesase 2 is sum of 2 & both\n",
    "\n",
    "# I have some counts. Those people that are only known only to have disease 1 we estimate are contributing only to disease 1\n",
    "# Some of\n",
    "\n",
    "# what is correlation between disease 1 and 2.\n",
    "\n",
    "\n",
    "# this is insanely slow for some reason, and almost all time is in the expanded binomial sampling\n",
    "# def genData(nSamples, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "#     # TODO: assert shapes match\n",
    "#     print(\"TESTING WITH: nSamples\", nSamples, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "#     nConditions = len(nSamples)\n",
    "#     probs = []\n",
    "#     afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "#     rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "#     rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "#     # shape == [nGenes, nConditions]\n",
    "#     afs = afDist.sample([nGenes,])   \n",
    "#     rrs = rrDist.sample([nGenes,])\n",
    "#     rrNulls = rrNullDist.sample([nGenes,])\n",
    "#     for geneIdx in range(nGenes):\n",
    "#         geneProbs = []\n",
    "#         for conditionIdx in range(nConditions):\n",
    "#             # TODO: sample from uniform\n",
    "#             if geneIdx < nGenes * diseaseFractions[conditionIdx]:\n",
    "#                 rr = rrs[geneIdx, conditionIdx]\n",
    "#             else:\n",
    "#                 rr = rrNulls[geneIdx, conditionIdx]\n",
    "            \n",
    "#             probVgivenD = pVgivenD(rr, afs[geneIdx])\n",
    "#             probVgivenNotD = pVgivenNotD(pDs[conditionIdx], afs[geneIdx], probVgivenD)\n",
    "            \n",
    "#             geneProbs.append([probVgivenNotD, probVgivenD])\n",
    "#         probs.append(geneProbs)\n",
    "#     probs = tensor(probs)\n",
    "\n",
    "#     # This should not be slow but is\n",
    "#     # https://github.com/pytorch/pytorch/issues/11389\n",
    "#     start = time.time()\n",
    "#     altCounts = Binomial(total_count=nSamples.expand([nGenes, *nSamples.shape]), probs=probs).sample()\n",
    "#     print(\"final sampling took\", time.time() - start)\n",
    "    \n",
    "#     return altCounts, probs\n",
    "\n",
    "def genDataSequential(nSamples, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "    # TODO: assert shapes match\n",
    "    print(\"TESTING WITH: nSamples\", nSamples, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "    nConditions = len(nSamples)\n",
    "    assert(nConditions == 3)\n",
    "    altCounts = []\n",
    "    probs = []\n",
    "    afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "    rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "    rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "    # shape == [nGenes, nConditions]\n",
    "    afs = afDist.sample([nGenes,])   \n",
    "    rrs = rrDist.sample([nGenes,])\n",
    "    rrNulls = rrNullDist.sample([nGenes,])\n",
    "    \n",
    "    endIndices = nGenes * diseaseFractions\n",
    "    startIndices = []\n",
    "    for i in range(len(t)):\n",
    "        if i == 0:\n",
    "            startIndices.append(0)\n",
    "            continue\n",
    "        endIndices[i] += endIndices[i-1]\n",
    "        startIndices.append(endIndices[i-1])\n",
    "    \n",
    "    print(\"startIndices\", startIndices, \"endIndices\", endIndices)\n",
    "    affectsCond1Only, affectsCond2Only, affectsBoth = False, False, False\n",
    "    for geneIdx in range(nGenes):\n",
    "        geneAltCounts = [0, 0, 0]\n",
    "        geneProbs = [0, 0, 0]\n",
    "        rrs = [1, 1, 1]\n",
    "        # Each gene gets only 1 state: affects condition 1 only, condition 2 only, or both\n",
    "        # currently, in the both case, the increased in counts (rr) is. the same for both conditions\n",
    "        for conditionIdx in range(nConditions):\n",
    "            if geneIdx >= startIndices[conditionIdx] and geneIdx < endIndices[conditionIdx]:\n",
    "                if conditionIdx == 0:\n",
    "                    affectsCond1Only = True\n",
    "                elif conditionIdx == 1:\n",
    "                    affectsCond2Only = True\n",
    "                else:\n",
    "                    affectsBoth = True\n",
    "        \n",
    "        # gene affects one of 3 states\n",
    "        # based on which state it affects, sampleCase1, samplesCase2, samplesBoth get different rrs for this gene\n",
    "        # controls always get the same value, and that is based on 1 - sum(rrs)\n",
    "        if affectsCond1Only:\n",
    "            rrs[0] = rrs[geneIdx, conditionIdx]\n",
    "            rrs[1] = rrNulls[geneIdx, conditionIdx]\n",
    "            rrs[2] = rrs[geneIdx, conditionIdx] #both always gets a rr of non-1\n",
    "        elif affectsCond2Only:\n",
    "            rrs[0] = rrNulls[geneIdx, conditionIdx]\n",
    "            rrs[1] = rrs[geneIdx, conditionIdx]\n",
    "            rrs[2] = rrs[geneIdx, conditionIdx]\n",
    "        elif affectsBoth:\n",
    "            # q: should these really get the same value?\n",
    "            # where is the concept of covariance here?\n",
    "            rrs[0] = rrs[geneIdx, conditionIdx]\n",
    "            rrs[1] = rrs[geneIdx, conditionIdx]\n",
    "            rrs[2] = rrs[geneIdx, conditionIdx]\n",
    "            \n",
    "            probVgivenDs = pVgivenD(rr, afs[geneIdx])\n",
    "            altCountsCases = Binomial(total_count=nSamples[conditionIdx][1], probs=probVgivenD).sample()\n",
    "            \n",
    "            # we can use one simulation to study pooled an separate samples\n",
    "            # in the pooled model, we could sum control samples during inference\n",
    "            probVgivenNotD = pVgivenNotD(pDs[conditionIdx], afs[geneIdx], probVgivenD)\n",
    "            altCountsCtrls = Binomial(total_count=nSamples[conditionIdx][0], probs=probVgivenNotD).sample()\n",
    "            \n",
    "            geneAltCounts.append([altCountsCtrls, altCountsCases])\n",
    "            geneProbs.append([probVgivenNotD, probVgivenD])\n",
    "        altCounts.append(geneAltCounts)\n",
    "        probs.append(geneProbs)\n",
    "    altCounts = tensor(altCounts)\n",
    "    probs = tensor(probs)\n",
    "    \n",
    "    return altCounts, probs\n",
    "\n",
    "def genDataSequentialPooledCtrls(nCases, nCtrls, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "    # TODO: assert shapes match\n",
    "    print(\"TESTING POOLED WITH: nCases\", nCases, \"nCtrls\", nCtrls, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "    nConditions = len(nCases)\n",
    "    altCounts = []\n",
    "    probs = []\n",
    "    afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "    rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "    rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "    # shape == [nGenes, nConditions]\n",
    "    afs = afDist.sample([nGenes,])   \n",
    "    rrs = rrDist.sample([nGenes,])\n",
    "    rrNulls = rrNullDist.sample([nGenes,])\n",
    "    \n",
    "    endIndices = nGenes * diseaseFractions\n",
    "    startIndices = []\n",
    "    for i in range(len(diseaseFractions)):\n",
    "        if i == 0:\n",
    "            startIndices.append(0)\n",
    "            continue\n",
    "        endIndices[i] += endIndices[i-1]\n",
    "        startIndices.append(endIndices[i-1])\n",
    "    \n",
    "    print(\"startIndices\", startIndices, \"endIndices\", endIndices)\n",
    "    for geneIdx in range(nGenes):\n",
    "        geneAltCounts = []\n",
    "        geneProbs = []\n",
    "\n",
    "        probVgivenDs = []\n",
    "        for conditionIdx in range(nConditions):\n",
    "            # TODO: sample from uniform\n",
    "            if geneIdx >= startIndices[conditionIdx] and geneIdx < endIndices[conditionIdx]:\n",
    "                rr = rrs[geneIdx, conditionIdx]\n",
    "            else:\n",
    "                rr = rrNulls[geneIdx, conditionIdx]\n",
    "            probVgivenDs.append(pVgivenD(rr, afs[geneIdx]))\n",
    "\n",
    "        probVgivenDs = tensor(probVgivenDs)\n",
    "#         print(\"probVgivenDs\", probVgivenDs)\n",
    "        altCountsCases = Binomial(total_count=nCases, probs=probVgivenDs).sample()\n",
    "\n",
    "#         print(\"altCountsCases\", altCountsCases, \"altCountCases.shape\", altCountsCases.shape)\n",
    "#         print(\"0 index\", altCountsCases[0])\n",
    "        # we can use one simulation to study pooled an separate samples\n",
    "        # in the pooled model, we could sum control samples during inference\n",
    "        probVgivenNotD = pVgivenNotD(pDs, afs[geneIdx], probVgivenDs)\n",
    "#         print(\"probVgivenNotD\", probVgivenNotD)\n",
    "        \n",
    "        altCountsCtrls = Binomial(total_count=nCtrls, probs=probVgivenNotD).sample()\n",
    "#         print(\"altCountsCtrls\", altCountsCtrls)\n",
    "        \n",
    "        for conditionIdx in range(nConditions):\n",
    "            if conditionIdx == 0:\n",
    "                geneAltCounts.append([altCountsCtrls, altCountsCases[conditionIdx]])\n",
    "            else:\n",
    "                geneAltCounts.append([0, altCountsCases[conditionIdx]])\n",
    "            geneProbs.append([probVgivenNotD, probVgivenDs[conditionIdx]])\n",
    "\n",
    "        altCounts.append(geneAltCounts)\n",
    "        probs.append(geneProbs)\n",
    "    altCounts = tensor(altCounts)\n",
    "    probs = tensor(probs)\n",
    "    \n",
    "    return altCounts, probs\n",
    "\n",
    "## Another view on generative process\n",
    "# there is some contribution to disease 1 with probability P(V|D1)\n",
    "# there is some contribution to disease 2 with probability P(V|D2)\n",
    "# there is some contribution to both diseases with probability P(V|DBoth)\n",
    "# there is some contribution to no diseases with probability P(V|None)\n",
    "# The total P(V) = P(V|D1)*P(D1) + P(V|D2)*P(D2) + P(V|DBoth)*P(DBoth) + P(V|Ctrl)*P(Ctrl) = (say) 1e-4\n",
    "\n",
    "\n",
    "# P(V|D1) = (P(D1|V) * P(V)) / P(D1)\n",
    "\n",
    "# When do we see counts for diseases 1? When P(V|D1) + P(V|DBoth)\n",
    "# A person who is ascertained as having both diseases must be the contribution of 1 - P(V|Ctrl) (P(D1|V) + P(D2|V) + P(V|DBoth))\n",
    "# A person who has 1 : P(V|D1) + P(V|DBoth) and for person 2 : P(V|D2) + P(V|DBoth)\n",
    "\n",
    "# If we didn't people ascertained for both, we could use 1 - P(V|Ctrl1) + P(V|Ctrl2) ?\n",
    "\n",
    "# in our components, component 1 and 2 give no contribution whatsoever, so they are measuring singular effect\n",
    "# in our \n",
    "\n",
    "# def intersection(list1, list2):\n",
    "\n",
    "# TODO: this generates bivariate data, expand to multinomial\n",
    "\n",
    "# If i'm a sample with disease1 only, I get the effect1 component for the gene, null2 component for the gene, and the effectBoth component for the gene\n",
    "# If i'm a sample with disease2 only, I get the null1 component for the gene, effect2 component for the gene, and the effectBoth component for the gene\n",
    "# If I'm a sample with both, I always get the full contribution\n",
    "\n",
    "# Finally, genes are either in categories none, 1only, 2only, or both\n",
    "# For each gene, I think we should sample the state in each category only once\n",
    "\n",
    "# If I'm a case1only, and if the gene is a risk gene, my count should reflect P(V|D2)\n",
    "# If I'm a ctrl and gene is associated, the count should reflect P(!D|V)\n",
    "# If I'm a case2only, I should have P(V|D2)\n",
    "# If I'm a both case, I think my P(V|D) should reflect a relative risk that is the sum of rr1 + rrLatentBoth if \n",
    "\n",
    "# In Dave's picture, a gene that affects disease 1 only adds the same liability to all indviduals \n",
    "def genData2(nCases, nCtrls, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "    # TODO: assert shapes match\n",
    "    print(\"TESTING WITH: nSamples\", nSamples, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "    nConditions = len(nSamples)\n",
    "    assert(nConditions == 3)\n",
    "    altCounts = []\n",
    "    probs = []\n",
    "    afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "    rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "    print(\"rrDist mean\", rrDist.sample([10_000,]).mean())\n",
    "    rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "    # shape == [nGenes, nConditions]\n",
    "    afs = afDist.sample([nGenes,])   \n",
    "    rrs = rrDist.sample([nGenes,])\n",
    "#     print(\"rrs\", rrs);\n",
    "    rrNulls = rrNullDist.sample([nGenes,])\n",
    "    \n",
    "    endIndices = nGenes * diseaseFractions\n",
    "    startIndices = []\n",
    "    for i in range(len(diseaseFractions)):\n",
    "        if i == 0:\n",
    "            startIndices.append(0)\n",
    "            continue\n",
    "        endIndices[i] += endIndices[i-1]\n",
    "        startIndices.append(endIndices[i-1])\n",
    "    \n",
    "    print(\"startIndices\", startIndices, \"endIndices\", endIndices)\n",
    "#     print(\"rrs\", rrs[0:2000,0].mean())\n",
    "    for geneIdx in range(nGenes):\n",
    "        geneAltCounts = []\n",
    "        geneProbs = []\n",
    "        rrSamples = tensor([1., 1., 1.])\n",
    "        affects = 0\n",
    "        # Each gene gets only 1 state: affects condition 1 only, condition 2 only, or both\n",
    "        # currently, in the both case, the increased in counts (rr) is. the same for both conditions\n",
    "        for conditionIdx in range(nConditions):\n",
    "            if geneIdx >= startIndices[conditionIdx] and geneIdx < endIndices[conditionIdx]:\n",
    "                if conditionIdx == 0:\n",
    "                    affects = 1\n",
    "                elif conditionIdx == 1:\n",
    "                    affects = 2\n",
    "                elif conditionIdx == 2:\n",
    "                    affects = 3\n",
    "                else:\n",
    "                    assert(conditionIdx <= 2)\n",
    "                    \n",
    "        rrSamples = rrNulls[geneIdx, :]\n",
    "        \n",
    "        # gene affects one of 3 states\n",
    "        # based on which state it affects, sampleCase1, samplesCase2, samplesBoth get different rrs for this gene\n",
    "        # controls always get the same value, and that is based on 1 - sum(rrs)\n",
    "        if affects == 0:\n",
    "            rrSamples = rrNulls[geneIdx, :]\n",
    "        elif affects == 1:\n",
    "#             print(f\"affects1: {geneIdx}\")\n",
    "            rrSamples[0] = rrs[geneIdx, 0]\n",
    "            rrSamples[1] = rrNulls[geneIdx, 1]\n",
    "            rrSamples[2] = rrs[geneIdx, 0] #both always gets a rr of non-1\n",
    "        elif affects == 2:\n",
    "#             print(f\"affects2: {conditionIdx}\")\n",
    "            rrSamples[0] = rrNulls[geneIdx, 0]\n",
    "            rrSamples[1] = rrs[geneIdx, 1]\n",
    "            rrSamples[2] = rrs[geneIdx, 1]\n",
    "        elif affects == 3:\n",
    "#             print(f\"affectsBoth: {conditionIdx}\")\n",
    "            # q: should these really get the same value?\n",
    "            # where is the concept of covariance here?\n",
    "            rrSamples[0] = rrs[geneIdx, 2]\n",
    "            rrSamples[1] = rrs[geneIdx, 2]\n",
    "            rrSamples[2] = rrs[geneIdx, 2]\n",
    "        \n",
    "        probVgivenDs = pVgivenD(rrSamples, afs[geneIdx])\n",
    "#         print(\"rrs\", rrSamples, rrNulls[geneIdx, :], rrs[geneIdx, :])\n",
    "#         print(probVgivenDs)\n",
    "#         print(\"probVgivenDs\", probVgivenDs, \"for rrs\", rrSamples)\n",
    "        altCountsCases = Binomial(total_count=nCases, probs=probVgivenDs).sample()\n",
    "#         print(\"altCountsCases\", altCountsCases)\n",
    "        # we can use one simulation to study pooled an separate samples\n",
    "        # in the pooled model, we could sum control samples during inference\n",
    "        probVgivenNotD = pVgivenNotD(pDs, afs[geneIdx], probVgivenDs)\n",
    "#         print(\"nCases\", nCases, \"probVgivenDs/probVgivenNotD\", probVgivenDs / probVgivenNotD)\n",
    "        altCountsCtrls = Binomial(total_count=nCtrls, probs=probVgivenNotD).sample()\n",
    "#         print(\"altCountsCtrls\", altCountsCtrls)\n",
    "        \n",
    "        for conditionIdx in range(nConditions):\n",
    "            if conditionIdx == 0:\n",
    "                geneAltCounts.append([altCountsCtrls, altCountsCases[conditionIdx]])\n",
    "            else:\n",
    "                geneAltCounts.append([0, altCountsCases[conditionIdx]])\n",
    "            geneProbs.append([probVgivenNotD, probVgivenDs[conditionIdx]])\n",
    "#         print(f\"geneAltCoutns {geneAltCounts} \\n\")\n",
    "        altCounts.append(geneAltCounts)\n",
    "        probs.append(geneProbs)\n",
    "#     print(\"altCounts\", altCounts)\n",
    "    altCounts = tensor(altCounts)\n",
    "    probs = tensor(probs)\n",
    "    \n",
    "    return altCounts, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = Bernoulli(tensor(.1)).sample([20_000,]).nonzero()\n",
    "\n",
    "r2 = Bernoulli(tensor(.1)).sample([20_000,]).nonzero()\n",
    " \n",
    "r3 = Bernoulli(tensor(.1)).sample([20_000,]).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(r2) & set(r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cases tensor([5000., 5000., 2500.]) pDsGlobalSmall tensor([0.0099, 0.0099, 0.0050]) pDsGlobalLarge tensor([0.0098, 0.0098, 0.0049]) pDsConsideringBothLarge tensor([0.0146, 0.0146, 0.0049])\n"
     ]
    }
   ],
   "source": [
    "nGenes = 20_000\n",
    "disease1 = Samples(1e5, 1e3)\n",
    "disease2 = Samples(1e5, 1e3)\n",
    "diseaseBoth = Samples(1e5, 5e2)\n",
    "\n",
    "nSamples = [disease1, disease2, diseaseBoth]\n",
    "nSamples = tensor(nSamples)\n",
    "\n",
    "pDsGlobalSmall = nSamples[:, 1]/nSamples.sum(1)\n",
    "diseaseFractions = tensor([.1, .1, .05])\n",
    "rrShape = tensor(10.)\n",
    "rrMeans = tensor([10., 10., 10.])\n",
    "afMean = tensor(1e-4)\n",
    "afShape = tensor(10.)\n",
    "\n",
    "rrMeansLow = tensor([2., 2., 2.])\n",
    "rrMeans3 = tensor([3., 3., 3.])\n",
    "\n",
    "## For pooled version, want more samples for diseasesBoth\n",
    "pDsGlobalBothLarge = 5e-3\n",
    "nCtrlsLarge = tensor(5e5)\n",
    "nCasesBothLarge = nCtrlsLarge * pDsGlobalBothLarge\n",
    "nCases1onlyLarge = 5e3\n",
    "nCases2onlyLarge = 5e3\n",
    "nCasesLarge = tensor([nCases1onlyLarge, nCases2onlyLarge, nCasesBothLarge])\n",
    "\n",
    "pDsGlobalLarge = nCasesLarge / (nCasesLarge.sum() + nCtrlsLarge)\n",
    "pDsConsideringBothLarge = tensor([nCasesLarge[0] + nCasesBothLarge, nCasesLarge[1] + nCasesBothLarge, nCasesBothLarge]) / (nCasesLarge.sum() + nCtrlsLarge)\n",
    "\n",
    "print(\"cases\", nCasesLarge, \"pDsGlobalSmall\", pDsGlobalSmall, \"pDsGlobalLarge\", pDsGlobalLarge, \"pDsConsideringBothLarge\", pDsConsideringBothLarge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH: nSamples tensor([[100000.,   1000.],\n",
      "        [100000.,   1000.],\n",
      "        [100000.,    500.]]) rrMean tensor([10., 10., 15.]) rrShape tensor(10.) afMean tensor(1.0000e-04) afShape tensor(10.) diseaseFractions tensor([0.1000, 0.1000, 0.0500]) pDs tensor([0.0099, 0.0099, 0.0050])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7a1e977cf215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maltCountsByGene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafsByGene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenDataSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnSamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnSamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpDsGlobalSmall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiseaseFractions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiseaseFractions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrrShape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrrShape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrrMeans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrrMeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafMean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mafMean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafShape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mafShape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnGenes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnGenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-01ba1d17db71>\u001b[0m in \u001b[0;36mgenDataSequential\u001b[0;34m(nSamples, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mendIndices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnGenes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiseaseFractions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mstartIndices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mstartIndices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "altCountsByGene, afsByGene = genDataSequential(nSamples=nSamples, pDs=pDsGlobalSmall, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "altCountsByGeneRR2, afsByGeneRR2 = genDataSequential(nSamples=nSamples, pDs=pDsGlobalSmall, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansLow, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "altCountsByGeneRR3, afsByGeneRR3 = genDataSequential(nSamples=nSamples, pDs=pDsGlobalSmall, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans3, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING POOLED WITH: nCases tensor([5000., 5000., 2500.]) nCtrls tensor(500000.) rrMean tensor([10., 10., 10.]) rrShape tensor(10.) afMean tensor(1.0000e-04) afShape tensor(10.) diseaseFractions tensor([0.1000, 0.1000, 0.0500]) pDs tensor([0.0098, 0.0098, 0.0049])\n",
      "startIndices [0, tensor(2000.), tensor(4000.)] endIndices tensor([2000., 4000., 5000.])\n",
      "took 109.61700296401978\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "altCountsByGenePooledCtrls, afsByGenePooledCtrls = genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH: nSamples tensor([[100000.,   1000.],\n",
      "        [100000.,   1000.],\n",
      "        [100000.,    500.]]) rrMean tensor([10., 10., 15.]) rrShape tensor(10.) afMean tensor(1.0000e-04) afShape tensor(10.) diseaseFractions tensor([0.1000, 0.1000, 0.0500]) pDs tensor([0.0098, 0.0098, 0.0049])\n",
      "startIndices [0, tensor(2000.), tensor(4000.)] endIndices tensor([2000., 4000., 5000.])\n",
      "took 103.73266005516052\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "altCountsByGenePooledCtrls2, afsByGenePooledCtrls2 = genData2(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH: nSamples tensor([[100000.,   1000.],\n",
      "        [100000.,   1000.],\n",
      "        [100000.,    500.]]) rrMean tensor([10., 10., 10.]) rrShape tensor(10.) afMean tensor(1.0000e-04) afShape tensor(10.) diseaseFractions tensor([0.1000, 0.1000, 0.0500]) pDs tensor([0.0098, 0.0098, 0.0049])\n",
      "rrDist mean tensor(10.0317)\n",
      "rrs tensor([[ 6.4458,  7.9955, 10.1972],\n",
      "        [ 5.9341, 10.0282,  7.5199],\n",
      "        [10.4048,  8.8038,  6.0838],\n",
      "        ...,\n",
      "        [ 7.8593, 15.1697,  6.8376],\n",
      "        [11.2340,  6.2765,  7.5748],\n",
      "        [12.1510,  6.9209, 14.9180]])\n",
      "startIndices [0, tensor(2000.), tensor(4000.)] endIndices tensor([2000., 4000., 5000.])\n",
      "took 102.93743181228638\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "altCountsByGenePooledCtrls2a, afsByGenePooledCtrls2a = genData2(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH: nSamples tensor([[100000.,   1000.],\n",
      "        [100000.,   1000.],\n",
      "        [100000.,    500.]]) rrMean tensor([10., 10., 10.]) rrShape tensor(10.) afMean tensor(1.0000e-04) afShape tensor(10.) diseaseFractions tensor([0.1000, 0.1000, 0.0500]) pDs tensor([0.0098, 0.0098, 0.0049])\n",
      "rrDist mean tensor(10.0066)\n",
      "startIndices [0, tensor(2000.), tensor(4000.)] endIndices tensor([2000., 4000., 5000.])\n",
      "took 108.07282304763794\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "altCountsByGenePooledCtrls2b, afsByGenePooledCtrls2b = genData2(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 10., 15.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'altCountsByGenePooledCtrls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-073922bb5cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"altCountsByGenePooledCtrls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltCountsByGenePooledCtrls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"afsByGenePooledCtrls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafsByGenePooledCtrls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpDsGlobalLarge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'altCountsByGenePooledCtrls' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"altCountsByGenePooledCtrls\", altCountsByGenePooledCtrls)\n",
    "print(\"afsByGenePooledCtrls\", afsByGenePooledCtrls)\n",
    "pDsGlobalLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "altCountsByGenePooledCtrls2 tensor([[[57.,  5.],\n",
      "         [ 0.,  0.],\n",
      "         [ 0.,  3.]],\n",
      "\n",
      "        [[33.,  4.],\n",
      "         [ 0.,  1.],\n",
      "         [ 0.,  1.]],\n",
      "\n",
      "        [[32.,  8.],\n",
      "         [ 0.,  0.],\n",
      "         [ 0.,  4.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[79.,  2.],\n",
      "         [ 0.,  2.],\n",
      "         [ 0.,  1.]],\n",
      "\n",
      "        [[57.,  1.],\n",
      "         [ 0.,  1.],\n",
      "         [ 0.,  0.]],\n",
      "\n",
      "        [[62.,  0.],\n",
      "         [ 0.,  0.],\n",
      "         [ 0.,  0.]]])\n",
      "afsByGenePooledCtrls2 tensor([[[1.1584e-04, 1.8107e-03],\n",
      "         [1.1584e-04, 0.0000e+00],\n",
      "         [1.1584e-04, 1.8107e-03]],\n",
      "\n",
      "        [[6.6629e-05, 1.1572e-03],\n",
      "         [6.6629e-05, 8.2746e-05],\n",
      "         [6.6629e-05, 1.1572e-03]],\n",
      "\n",
      "        [[7.3478e-05, 2.6415e-03],\n",
      "         [7.3478e-05, 0.0000e+00],\n",
      "         [7.3478e-05, 2.6415e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.3780e-04, 1.3780e-04],\n",
      "         [1.3780e-04, 1.3780e-04],\n",
      "         [1.3780e-04, 1.3780e-04]],\n",
      "\n",
      "        [[1.2472e-04, 1.2472e-04],\n",
      "         [1.2472e-04, 1.2472e-04],\n",
      "         [1.2472e-04, 1.2472e-04]],\n",
      "\n",
      "        [[1.3106e-04, 0.0000e+00],\n",
      "         [1.3106e-04, 0.0000e+00],\n",
      "         [1.3106e-04, 0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"altCountsByGenePooledCtrls2\", altCountsByGenePooledCtrls2)\n",
    "print(\"afsByGenePooledCtrls2\", afsByGenePooledCtrls2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenAltCounts(altCounts, afs):\n",
    "    altCountsFlatPooled = []\n",
    "    afsFlatPooled = []\n",
    "    for geneIdx in range(nGenes):\n",
    "        altCountsFlatPooled.append([altCounts[geneIdx, 0, 0], *altCounts[geneIdx, :, 1].flatten()])\n",
    "        afsFlatPooled.append([afs[geneIdx, 0, 0], *afs[geneIdx, :, 1].flatten()])\n",
    "\n",
    "    altCountsFlatPooled = tensor(altCountsFlatPooled)\n",
    "    afsFlatPooled = tensor(afsFlatPooled)\n",
    "    print(\"altCountsFlatPooled\", altCountsFlatPooled)\n",
    "    print(\"afsFlatPooled\", afsFlatPooled)\n",
    "\n",
    "    flattenedData = []\n",
    "\n",
    "    for geneAfData in afs:\n",
    "        flattenedData.append([geneAfData[0][0],*geneAfData[:, 1]])\n",
    "    flattenedData = tensor(flattenedData)\n",
    "    \n",
    "    return altCountsFlatPooled, afsFlatPooled, flattenedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "altCountsFlatPooled tensor([[41.,  3.,  1.,  3.],\n",
      "        [20.,  3.,  1.,  0.],\n",
      "        [48.,  5.,  2.,  2.],\n",
      "        ...,\n",
      "        [50.,  0.,  0.,  0.],\n",
      "        [50.,  0.,  1.,  0.],\n",
      "        [72.,  2.,  0.,  1.]])\n",
      "afsFlatPooled tensor([[8.6933e-05, 7.6084e-04, 8.4495e-05, 7.6084e-04],\n",
      "        [5.3346e-05, 4.7881e-04, 1.0357e-04, 4.7881e-04],\n",
      "        [8.0309e-05, 1.2285e-03, 8.6144e-05, 1.2285e-03],\n",
      "        ...,\n",
      "        [9.7155e-05, 1.1197e-04, 1.4983e-04, 6.8495e-05],\n",
      "        [1.1968e-04, 9.2315e-05, 1.5075e-04, 1.9200e-04],\n",
      "        [1.4755e-04, 1.5299e-04, 1.6652e-04, 1.6753e-04]])\n"
     ]
    }
   ],
   "source": [
    "altCountsFlatPooled2, afsFlatPooled2, flattenedData2 = flattenAltCounts(altCountsByGenePooledCtrls2b, afsByGenePooledCtrls2b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6793e-05)\n"
     ]
    }
   ],
   "source": [
    "print(afsByGenePooledCtrls2[5000:, 2, 1].mean())\n",
    "# print(afsFlatPooled2[:, 1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.6933e-05, 7.6084e-04, 8.4495e-05, 7.6084e-04],\n",
      "        [5.3346e-05, 4.7881e-04, 1.0357e-04, 4.7881e-04],\n",
      "        [8.0309e-05, 1.2285e-03, 8.6144e-05, 1.2285e-03],\n",
      "        ...,\n",
      "        [9.7155e-05, 1.1197e-04, 1.4983e-04, 6.8495e-05],\n",
      "        [1.1968e-04, 9.2315e-05, 1.5075e-04, 1.9200e-04],\n",
      "        [1.4755e-04, 1.5299e-04, 1.6652e-04, 1.6753e-04]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb9ec8fb750>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(flattenedData2)\n",
    "pyplot.clf()\n",
    "pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(afsFlatPooled2[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0015)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.6793e-05)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(afsFlatPooled2[0:5000, 3].mean())\n",
    "afsFlatPooled2[5000:, 3].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical rr for both tensor(31.0443)\n",
      "empirical rr for 1 tensor(31.3405)\n",
      "empirical rr for 2 tensor(31.2599)\n"
     ]
    }
   ],
   "source": [
    "print(\"empirical rr for both\", afsFlatPooled2[0:5000, 3].mean()/ afsFlatPooled2[5000:, 3].mean())\n",
    "print(\"empirical rr for 1\", ((afsFlatPooled2[0:2000, 1].mean()))/ afsFlatPooled2[2000:4000, 1].mean())\n",
    "print(\"empirical rr for 2\", ((afsFlatPooled2[2000:4000, 2].mean() + afsFlatPooled2[4000:5000, 2].mean())/2)/ afsFlatPooled2[:2000, 2].mean())\n",
    "# print(\"nullLikelihoodGlobal 1\", (nullLikelihoodsGlobal[0:2000, 0] + nullLikelihoodsGlobal[4000:5000, 0]).mean(), nullLikelihoodsGlobal[2000:, 0].mean())\n",
    "# print(\"nullLikelihoodGlobal 2\", nullLikelihoodsGlobal[2000:4000, 1].mean(), nullLikelihoodsGlobal[4000:, 1].mean())\n",
    "# print(\"nullLikelihoodGlobal Both\", nullLikelihoodsGlobal[4000:5000, 2].mean(), nullLikelihoodsGlobal[0:4000, 2].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical rr for 1 tensor(9.7699)\n"
     ]
    }
   ],
   "source": [
    "# print(\"empirical rr for both\", afsFlatPooled2[0:5000, 3].mean()/ afsFlatPooled2[5000:, 3].mean())\n",
    "print(\"empirical rr for 1\", ((afsByGenePooledCtrls2b[0:2000, 0, 1].median()))/ afsByGenePooledCtrls2b[2000:4000, 0, 1].median())\n",
    "# print(\"empirical rr for 2\", ((afsFlatPooled2[2000:4000, 2].mean() + afsFlatPooled2[4000:5000, 2].mean())/2)/ afsFlatPooled2[:2000, 2].mean())\n",
    "# print(\"nullLikelihoodGlobal 1\", (nullLikelihoodsGlobal[0:2000, 0] + nullLikelihoodsGlobal[4000:5000, 0]).mean(), nullLikelihoodsGlobal[2000:, 0].mean())\n",
    "# print(\"nullLikelihoodGlobal 2\", nullLikelihoodsGlobal[2000:4000, 1].mean(), nullLikelihoodsGlobal[4000:, 1].mean())\n",
    "# print(\"nullLikelihoodGlobal Both\", nullLikelihoodsGlobal[4000:5000, 2].mean(), nullLikelihoodsGlobal[0:4000, 2].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(afsByGenePooledCtrls[2000:4000, 0, 1].nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altCountsByGenePooledCtrls[:, :, :].sum([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altCountsByGenePooledCtrls[:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomDist = Uniform(0, 1)\n",
    "randomDist2 = Uniform(1, 10000)\n",
    "fnArgs = []\n",
    "# pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "# P(V|D) * P(D) / P(V)\n",
    "nGenes = len(altCountsByGenePooledCtrls)\n",
    "\n",
    "probs = randomDist.sample([3,])\n",
    "probs = probs / probs.sum()\n",
    "print(probs)\n",
    "    #pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth\n",
    "fnArgs = [*probs, *randomDist2.sample([4,])]\n",
    "fnArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llPooledBivariateSingleGene(tensor([10.,1.,1.,20000.]), tensor([.01,.01,.05]), tensor(13.), tensor(10.), tensor(10.), tensor(100000.), tensor(.77), tensor(.1), tensor(.1), tensor(.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this gives -2.401 log(likelihoodUnivariateSingleGene(xCtrl = 10, xCase1 = 1, prevalence1 = .01, pi0 = .9, pi1 = .1, pDiseaseGivenVariant = .001))\n",
    "#tensor(-2.5290): llUnivariateSingleGeneJensen(xCtrl = tensor(10.), xCase = tensor(1.), pD = tensor(.01), pi0 = tensor(.9), pi1 = tensor(.1), pDgivenV = tensor(.001))\n",
    "r = llUnivariateSingleGeneNoJensen(xCtrl = tensor(10.), xCase = tensor(1.), pD = tensor(.01), pi0 = tensor(.9), pi1 = tensor(.1), pDgivenV = tensor(.001))\n",
    "assert(abs(-r + tensor(-2.4010)) < .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altCounts = tensor([10., 2., 3., 1.])\n",
    "n = altCounts.sum()\n",
    "\n",
    "testAlpha = tensor([16., 20., 30., 15.])\n",
    "print(f\"test data: testAlpha: {testAlpha}, n: {n}, altCounts: {altCounts}\")\n",
    "DirichletMultinomial(total_count=n, concentration=testAlpha).log_prob(altCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV(.01, afsByGene[0:2000, 0, 1], 1e-4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test functions\n",
    "pDgivenV(.01, afsByGeneRR2[0:2000, 0, 1], afsByGeneRR2Shape5[0:2000, 0, 0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance is wrong\n",
    "def betaVariance(alpha, beta):\n",
    "    return (alpha * beta) / ( ((alpha + beta)**2) + (alpha + beta + 1) )\n",
    "\n",
    "def betaMean(alpha, beta):\n",
    "    return alpha / (alpha + beta)\n",
    "\n",
    "print(\"variance\", betaVariance(6.47e1,5.39e3))\n",
    "print(\"mean\", betaMean(6.47e1,5.39e3))\n",
    "print(\"true varianc\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = afsByGene[0:2000, 0, 1].mean()\n",
    "m2 = afsByGeneRR2[0:2000, 0, 1].mean()/afsByGeneRR2[2000:, 0, 1].mean()\n",
    "m1 - m2\n",
    "print(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res = fitFnUniveriate(altCountsByGene, pDs, nEpochs=20, minLLThresholdCount=20, debug=True)\n",
    "print((time.time() - start) / 20, \"per iteration\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriate(altCountsByGeneRR2, pDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV(pDs[0], afsByGeneRR2Shape5[0:2000, 0, 1], afsByGeneRR2Shape5[0:2000, 0, 0]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriate(altCountsByGeneRR2, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR2, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR2Shape5, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(2.23307950e+02, 2.52700651e+04).sample([10_000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(2.20865706e+02, 1.73544747e+04).sample([10_000,]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR3, pDs, nEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(2.50432693e+02, 1.87756988e+04).sample([10_000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriate(altCountsByGeneRR3, pDs, nEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(3.84376856e+02, 2.37879954e+04).sample([10_000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsRR2Shape5 = []\n",
    "for i in range(1):\n",
    "    res = fitFnUniveriateBetaBinomial(altCountsByGeneRR2Shape5, pDs, nEpochs=50, minLLThresholdCount=50, debug=False)\n",
    "    resultsRR2Shape5.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsRR2Shape5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(1.96912591e+02, 1.61461738e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=50, minLLThresholdCount=50, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(3.30289057e+03, 2.94460355e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't really work resConstrained = fitFnUniveriateBetaBinomialConstrained(altCountsByGeneRR2Shape5, pDs, nEpochs=10, minLLThresholdCount=10, debug=True)\n",
    "#resConstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=10, minLLThresholdCount=10, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": []}\n",
    "cachedData = [[altCountsByGenePooledCtrls, afsByGenePooledCtrls, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean\n",
    "        }]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": [], \"costFnIdx\": []}\n",
    "cachedData2 = [[altCountsByGenePooledCtrls2, afsByGenePooledCtrls2, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean,\n",
    "        }]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i >= len(cachedData):\n",
    "        start = time.time()\n",
    "        altCountsByGenePooledCtrls, afsByGenePooledCtrls = genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData.append([altCountsByGenePooledCtrls, afsByGenePooledCtrls, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean\n",
    "        }])\n",
    "        \n",
    "    res = fitFnBivariate(cachedData[i][0], pDsGlobalLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=0)\n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3])\n",
    "    print(\"inferredPis\", inferredPis)\n",
    "    inferredAlphas = tensor(bestRes[3:])\n",
    "    print(\"inferredAlphas\", inferredAlphas)\n",
    "    \n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "    params[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params[\"inferredPis\"].append(inferredPis)\n",
    "    params[\"inferredPDVs\"].append(inferredPDs)\n",
    "\n",
    "    truth1 = pDgivenV(pDsGlobalLarge[0], afsByGenePooledCtrls[0:2000, 0, 1], afsByGenePooledCtrls[0:2000, 0, 0]).mean()\n",
    "    truth2 = pDgivenV(pDsGlobalLarge[1], afsByGenePooledCtrls[2000:4000, 1, 1], afsByGenePooledCtrls[2000:4000, 0, 0]).mean()\n",
    "    truth3 = pDgivenV(pDsGlobalLarge[2], afsByGenePooledCtrls[4000:5000, 2, 1], afsByGenePooledCtrls[4000:5000, 0, 0]).mean()\n",
    "    truth0 = 1 - (truth1 + truth2 + truth3)\n",
    "    print(\"truth0\", truth0, \"truth1\", truth1, \"truth2\", truth2, \"truthBoth\", truth3)\n",
    "\n",
    "    params[\"trueMeanPDVs\"].append(tensor([truth0, truth1, truth2, truth3]))\n",
    "    params[\"truePis\"].append(tensor(diseaseFractions))\n",
    "\n",
    "    print(f\"params on run {i}\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "altCountsFlat tensor([[58.,  6.,  1.,  1.],\n",
      "        [26.,  2.,  1.,  0.],\n",
      "        [19.,  2.,  0.,  0.],\n",
      "        ...,\n",
      "        [39.,  0.,  0.,  0.],\n",
      "        [71.,  1.,  0.,  0.],\n",
      "        [46.,  1.,  2.,  0.]])\n",
      "n tensor([66., 29., 21.,  ..., 39., 72., 49.])\n",
      "xCase1, xCase2, xCase12 tensor([6., 2., 2.,  ..., 0., 1., 1.])\n",
      "xCase1, xCase2, xCase12 tensor([1., 1., 0.,  ..., 0., 0., 2.])\n",
      "xCase1, xCase2, xCase12 tensor([1., 0., 0.,  ..., 0., 0., 0.])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2b at 0x7fb9ebe504d0>\n",
      "best ll: 87641.0625, bestParams: [tensor(0.0101), tensor(0.0519), tensor(0.0140), tensor(8648.6338), tensor(549.7957), tensor(7852.7959), tensor(8957.1025)]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.36035324e-02, 9.89241926e-03, 8.63437830e-04, 2.09364343e+04,\n",
      "        3.16306962e+02, 3.16358350e+02, 1.55009225e+04],\n",
      "       [1.36035323e-02, 9.89241940e-03, 8.63437613e-04, 2.09364343e+04,\n",
      "        3.16306959e+02, 3.16358348e+02, 1.55009226e+04],\n",
      "       [1.36035323e-02, 9.89241933e-03, 8.63437656e-04, 2.09364343e+04,\n",
      "        3.16306959e+02, 3.16358349e+02, 1.55009226e+04],\n",
      "       [1.36035323e-02, 9.89241923e-03, 8.63437640e-04, 2.09364343e+04,\n",
      "        3.16306959e+02, 3.16358344e+02, 1.55009226e+04],\n",
      "       [1.36035324e-02, 9.89241932e-03, 8.63437709e-04, 2.09364343e+04,\n",
      "        3.16306961e+02, 3.16358343e+02, 1.55009226e+04],\n",
      "       [1.36035323e-02, 9.89241927e-03, 8.63437733e-04, 2.09364343e+04,\n",
      "        3.16306961e+02, 3.16358338e+02, 1.55009226e+04],\n",
      "       [1.36035324e-02, 9.89241929e-03, 8.63437713e-04, 2.09364343e+04,\n",
      "        3.16306960e+02, 3.16358329e+02, 1.55009226e+04],\n",
      "       [1.36035324e-02, 9.89241928e-03, 8.63437719e-04, 2.09364343e+04,\n",
      "        3.16306960e+02, 3.16358323e+02, 1.55009226e+04]]), array([84499.65625, 84499.65625, 84499.65625, 84499.65625, 84499.65625,\n",
      "       84499.65625, 84499.65625, 84499.65625]))\n",
      "           fun: 84499.65625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1243\n",
      "           nit: 446\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.36035324e-02, 9.89241926e-03, 8.63437830e-04, 2.09364343e+04,\n",
      "       3.16306962e+02, 3.16358350e+02, 1.55009225e+04])\n",
      "best ll: 86645.8046875, bestParams: [tensor(0.0065), tensor(0.0041), tensor(0.0174), tensor(8369.1934), tensor(1268.1344), tensor(2157.6943), tensor(21195.2500)]\n",
      "epoch 1\n",
      " final_simplex: (array([[9.18337466e-03, 5.56977901e-03, 1.74260574e-03, 2.19191451e+04,\n",
      "        1.05773835e+02, 4.50651388e+02, 1.16092390e+04],\n",
      "       [9.18337466e-03, 5.56977901e-03, 1.74260578e-03, 2.19191451e+04,\n",
      "        1.05773837e+02, 4.50651392e+02, 1.16092390e+04],\n",
      "       [9.18337466e-03, 5.56977901e-03, 1.74260577e-03, 2.19191451e+04,\n",
      "        1.05773836e+02, 4.50651392e+02, 1.16092390e+04],\n",
      "       [9.18337466e-03, 5.56977901e-03, 1.74260574e-03, 2.19191451e+04,\n",
      "        1.05773835e+02, 4.50651391e+02, 1.16092390e+04],\n",
      "       [9.18337467e-03, 5.56977899e-03, 1.74260572e-03, 2.19191451e+04,\n",
      "        1.05773834e+02, 4.50651386e+02, 1.16092390e+04],\n",
      "       [9.18337467e-03, 5.56977901e-03, 1.74260577e-03, 2.19191451e+04,\n",
      "        1.05773834e+02, 4.50651395e+02, 1.16092389e+04],\n",
      "       [9.18337464e-03, 5.56977903e-03, 1.74260583e-03, 2.19191451e+04,\n",
      "        1.05773834e+02, 4.50651399e+02, 1.16092390e+04],\n",
      "       [9.18337467e-03, 5.56977900e-03, 1.74260579e-03, 2.19191451e+04,\n",
      "        1.05773836e+02, 4.50651397e+02, 1.16092390e+04]]), array([84487.453125, 84487.453125, 84487.453125, 84487.453125,\n",
      "       84487.453125, 84487.453125, 84487.453125, 84487.453125]))\n",
      "           fun: 84487.453125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1268\n",
      "           nit: 449\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.18337466e-03, 5.56977901e-03, 1.74260574e-03, 2.19191451e+04,\n",
      "       1.05773835e+02, 4.50651388e+02, 1.16092390e+04])\n",
      "minPrevious 84499.65625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.18337466e-03, 5.56977901e-03, 1.74260574e-03, 2.19191451e+04,\n",
      "        1.05773835e+02, 4.50651388e+02, 1.16092390e+04],\n",
      "       [9.18337466e-03, 5.56977901e-03, 1.74260578e-03, 2.19191451e+04,\n",
      "        1.05773837e+02, 4.50651392e+02, 1.16092390e+04],\n",
      "       [9.18337466e-03, 5.56977901e-03, 1.74260577e-03, 2.19191451e+04,\n",
      "        1.05773836e+02, 4.50651392e+02, 1.16092390e+04],\n",
      "       [9.18337466e-03, 5.56977901e-03, 1.74260574e-03, 2.19191451e+04,\n",
      "        1.05773835e+02, 4.50651391e+02, 1.16092390e+04],\n",
      "       [9.18337467e-03, 5.56977899e-03, 1.74260572e-03, 2.19191451e+04,\n",
      "        1.05773834e+02, 4.50651386e+02, 1.16092390e+04],\n",
      "       [9.18337467e-03, 5.56977901e-03, 1.74260577e-03, 2.19191451e+04,\n",
      "        1.05773834e+02, 4.50651395e+02, 1.16092389e+04],\n",
      "       [9.18337464e-03, 5.56977903e-03, 1.74260583e-03, 2.19191451e+04,\n",
      "        1.05773834e+02, 4.50651399e+02, 1.16092390e+04],\n",
      "       [9.18337467e-03, 5.56977900e-03, 1.74260579e-03, 2.19191451e+04,\n",
      "        1.05773836e+02, 4.50651397e+02, 1.16092390e+04]]), array([84487.453125, 84487.453125, 84487.453125, 84487.453125,\n",
      "       84487.453125, 84487.453125, 84487.453125, 84487.453125]))\n",
      "           fun: 84487.453125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1268\n",
      "           nit: 449\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.18337466e-03, 5.56977901e-03, 1.74260574e-03, 2.19191451e+04,\n",
      "       1.05773835e+02, 4.50651388e+02, 1.16092390e+04])\n",
      "best ll: 86811.9609375, bestParams: [tensor(0.0310), tensor(0.0068), tensor(0.0078), tensor(20018.9785), tensor(6030.6089), tensor(7122.2764), tensor(4522.1948)]\n",
      "epoch 2\n",
      " final_simplex: (array([[1.86601418e-02, 6.27489907e-03, 1.32430617e-02, 4.72664278e+04,\n",
      "        3.42196476e+03, 4.09517553e+03, 2.45988163e+02],\n",
      "       [1.86601415e-02, 6.27489919e-03, 1.32430615e-02, 4.72664279e+04,\n",
      "        3.42196478e+03, 4.09517552e+03, 2.45988163e+02],\n",
      "       [1.86601417e-02, 6.27489915e-03, 1.32430616e-02, 4.72664279e+04,\n",
      "        3.42196479e+03, 4.09517552e+03, 2.45988161e+02],\n",
      "       [1.86601417e-02, 6.27489912e-03, 1.32430616e-02, 4.72664279e+04,\n",
      "        3.42196480e+03, 4.09517553e+03, 2.45988160e+02],\n",
      "       [1.86601418e-02, 6.27489907e-03, 1.32430617e-02, 4.72664279e+04,\n",
      "        3.42196478e+03, 4.09517554e+03, 2.45988165e+02],\n",
      "       [1.86601416e-02, 6.27489910e-03, 1.32430617e-02, 4.72664279e+04,\n",
      "        3.42196477e+03, 4.09517554e+03, 2.45988164e+02],\n",
      "       [1.86601418e-02, 6.27489915e-03, 1.32430617e-02, 4.72664279e+04,\n",
      "        3.42196479e+03, 4.09517553e+03, 2.45988158e+02],\n",
      "       [1.86601416e-02, 6.27489923e-03, 1.32430616e-02, 4.72664279e+04,\n",
      "        3.42196480e+03, 4.09517552e+03, 2.45988155e+02]]), array([77191.46875, 77191.46875, 77191.46875, 77191.46875, 77191.46875,\n",
      "       77191.46875, 77191.46875, 77191.46875]))\n",
      "           fun: 77191.46875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1134\n",
      "           nit: 386\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.86601418e-02, 6.27489907e-03, 1.32430617e-02, 4.72664278e+04,\n",
      "       3.42196476e+03, 4.09517553e+03, 2.45988163e+02])\n",
      "minPrevious 84487.453125\n",
      "better by at >= 1; new ll:  final_simplex: (array([[1.86601418e-02, 6.27489907e-03, 1.32430617e-02, 4.72664278e+04,\n",
      "        3.42196476e+03, 4.09517553e+03, 2.45988163e+02],\n",
      "       [1.86601415e-02, 6.27489919e-03, 1.32430615e-02, 4.72664279e+04,\n",
      "        3.42196478e+03, 4.09517552e+03, 2.45988163e+02],\n",
      "       [1.86601417e-02, 6.27489915e-03, 1.32430616e-02, 4.72664279e+04,\n",
      "        3.42196479e+03, 4.09517552e+03, 2.45988161e+02],\n",
      "       [1.86601417e-02, 6.27489912e-03, 1.32430616e-02, 4.72664279e+04,\n",
      "        3.42196480e+03, 4.09517553e+03, 2.45988160e+02],\n",
      "       [1.86601418e-02, 6.27489907e-03, 1.32430617e-02, 4.72664279e+04,\n",
      "        3.42196478e+03, 4.09517554e+03, 2.45988165e+02],\n",
      "       [1.86601416e-02, 6.27489910e-03, 1.32430617e-02, 4.72664279e+04,\n",
      "        3.42196477e+03, 4.09517554e+03, 2.45988164e+02],\n",
      "       [1.86601418e-02, 6.27489915e-03, 1.32430617e-02, 4.72664279e+04,\n",
      "        3.42196479e+03, 4.09517553e+03, 2.45988158e+02],\n",
      "       [1.86601416e-02, 6.27489923e-03, 1.32430616e-02, 4.72664279e+04,\n",
      "        3.42196480e+03, 4.09517552e+03, 2.45988155e+02]]), array([77191.46875, 77191.46875, 77191.46875, 77191.46875, 77191.46875,\n",
      "       77191.46875, 77191.46875, 77191.46875]))\n",
      "           fun: 77191.46875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1134\n",
      "           nit: 386\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.86601418e-02, 6.27489907e-03, 1.32430617e-02, 4.72664278e+04,\n",
      "       3.42196476e+03, 4.09517553e+03, 2.45988163e+02])\n",
      "best ll: 82734.375, bestParams: [tensor(0.0043), tensor(0.0029), tensor(0.0024), tensor(22357.9219), tensor(6370.0039), tensor(2926.5269), tensor(591.1783)]\n",
      "epoch 3\n",
      " final_simplex: (array([[1.76691245e-03, 7.29933533e-05, 7.33696004e-03, 4.11546487e+04,\n",
      "        3.61045871e+03, 3.26342690e+03, 1.93296599e+02],\n",
      "       [1.76691249e-03, 7.29933173e-05, 7.33696003e-03, 4.11546486e+04,\n",
      "        3.61045869e+03, 3.26342689e+03, 1.93296601e+02],\n",
      "       [1.76691249e-03, 7.29933558e-05, 7.33696002e-03, 4.11546486e+04,\n",
      "        3.61045866e+03, 3.26342689e+03, 1.93296599e+02],\n",
      "       [1.76691249e-03, 7.29933555e-05, 7.33696002e-03, 4.11546486e+04,\n",
      "        3.61045866e+03, 3.26342689e+03, 1.93296600e+02],\n",
      "       [1.76691247e-03, 7.29933164e-05, 7.33696003e-03, 4.11546486e+04,\n",
      "        3.61045868e+03, 3.26342690e+03, 1.93296602e+02],\n",
      "       [1.76691246e-03, 7.29933220e-05, 7.33696003e-03, 4.11546486e+04,\n",
      "        3.61045868e+03, 3.26342689e+03, 1.93296602e+02],\n",
      "       [1.76691245e-03, 7.29933098e-05, 7.33696005e-03, 4.11546486e+04,\n",
      "        3.61045871e+03, 3.26342689e+03, 1.93296602e+02],\n",
      "       [1.76691243e-03, 7.29933419e-05, 7.33696003e-03, 4.11546487e+04,\n",
      "        3.61045865e+03, 3.26342689e+03, 1.93296605e+02]]), array([77864.046875, 77864.046875, 77864.046875, 77864.046875,\n",
      "       77864.046875, 77864.046875, 77864.046875, 77864.046875]))\n",
      "           fun: 77864.046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1269\n",
      "           nit: 460\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.76691245e-03, 7.29933533e-05, 7.33696004e-03, 4.11546487e+04,\n",
      "       3.61045871e+03, 3.26342690e+03, 1.93296599e+02])\n",
      "minPrevious 77191.46875\n",
      "best ll: 86750.40625, bestParams: [tensor(0.0349), tensor(0.0080), tensor(0.0065), tensor(24180.9023), tensor(13708.0469), tensor(1431.4775), tensor(17200.9277)]\n",
      "epoch 4\n",
      " final_simplex: (array([[7.68947866e-03, 1.24488442e-02, 6.25729552e-03, 5.84237074e+04,\n",
      "        7.35492656e+02, 5.89598107e+02, 1.99194990e+04],\n",
      "       [7.68947866e-03, 1.24488442e-02, 6.25729552e-03, 5.84237074e+04,\n",
      "        7.35492658e+02, 5.89598106e+02, 1.99194989e+04],\n",
      "       [7.68947873e-03, 1.24488442e-02, 6.25729551e-03, 5.84237073e+04,\n",
      "        7.35492677e+02, 5.89598110e+02, 1.99194990e+04],\n",
      "       [7.68947872e-03, 1.24488442e-02, 6.25729552e-03, 5.84237074e+04,\n",
      "        7.35492680e+02, 5.89598109e+02, 1.99194990e+04],\n",
      "       [7.68947870e-03, 1.24488442e-02, 6.25729551e-03, 5.84237074e+04,\n",
      "        7.35492656e+02, 5.89598108e+02, 1.99194990e+04],\n",
      "       [7.68947874e-03, 1.24488442e-02, 6.25729551e-03, 5.84237074e+04,\n",
      "        7.35492683e+02, 5.89598108e+02, 1.99194989e+04],\n",
      "       [7.68947862e-03, 1.24488442e-02, 6.25729552e-03, 5.84237075e+04,\n",
      "        7.35492656e+02, 5.89598107e+02, 1.99194990e+04],\n",
      "       [7.68947862e-03, 1.24488442e-02, 6.25729552e-03, 5.84237075e+04,\n",
      "        7.35492648e+02, 5.89598107e+02, 1.99194990e+04]]), array([84122.7421875, 84122.7421875, 84122.7421875, 84122.7421875,\n",
      "       84122.7421875, 84122.7421875, 84122.7421875, 84122.7421875]))\n",
      "           fun: 84122.7421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1288\n",
      "           nit: 441\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.68947866e-03, 1.24488442e-02, 6.25729552e-03, 5.84237074e+04,\n",
      "       7.35492656e+02, 5.89598107e+02, 1.99194990e+04])\n",
      "minPrevious 77191.46875\n",
      "best ll: 85221.8984375, bestParams: [tensor(0.0020), tensor(0.0149), tensor(0.0084), tensor(18130.9336), tensor(1669.8167), tensor(9519.0068), tensor(1731.1198)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if i >= len(cachedData2):\n",
    "        start = time.time()\n",
    "        altCountsByGenePooledCtrls2, afsByGenePooledCtrls2 = genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData2.append([altCountsByGenePooledCtrls2, afsByGenePooledCtrls2, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean,\n",
    "        }])\n",
    "    runCostFnIdx = 5\n",
    "    # todo append all entries to indciate failure\n",
    "    params2[\"costFnIdx\"].append(runCostFnIdx)\n",
    "\n",
    "    res = fitFnBivariate(cachedData2[i][0], pDsGlobalLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "    \n",
    "    \n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3])\n",
    "    print(\"inferredPis\", inferredPis)\n",
    "    inferredAlphas = tensor(bestRes[3:])\n",
    "    print(\"inferredAlphas\", inferredAlphas)\n",
    "    \n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "    params2[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params2[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params2[\"inferredPis\"].append(inferredPis)\n",
    "    params2[\"inferredPDVs\"].append(inferredPDs)\n",
    "\n",
    "    truth1 = pDgivenV(pDsGlobalLarge[0], cachedData2[i][1][0:2000, 0, 1], cachedData2[i][1][0:2000, 0, 0]).mean()\n",
    "    truth2 = pDgivenV(pDsGlobalLarge[1], cachedData2[i][1][2000:4000, 1, 1], cachedData2[i][1][2000:4000, 0, 0]).mean()\n",
    "    truth3 = pDgivenV(pDsGlobalLarge[2], cachedData2[i][1][4000:5000, 2, 1], cachedData2[i][1][4000:5000, 0, 0]).mean()\n",
    "    truth0 = 1 - (truth1 + truth2 + truth3)\n",
    "    print(\"truth0\", truth0, \"truth1\", truth1, \"truth2\", truth2, \"truthBoth\", truth3)\n",
    "\n",
    "    params2[\"trueMeanPDVs\"].append(tensor([truth0, truth1, truth2, truth3]))\n",
    "    params2[\"truePis\"].append(tensor(diseaseFractions))\n",
    "    \n",
    "    print(f\"params on run {i}\", params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(inputAltCounts, inputAfs, costFnIdx):\n",
    "    params = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": []}\n",
    "    cachedData = [[inputAltCounts, inputAfs, {\n",
    "                \"nCases\": nCasesLarge,\n",
    "                \"nCtrls\": nCtrlsLarge,\n",
    "                \"pDs\": pDsGlobalLarge,\n",
    "                \"diseaseFractions\": diseaseFractions,\n",
    "                \"rrShape\": rrShape,\n",
    "                \"rrMeans\": rrMeans,\n",
    "                \"afShape\": afShape,\n",
    "                \"afMean\": afMean\n",
    "            }]]\n",
    "    for i in range(10):\n",
    "        if i >= len(cachedData2):\n",
    "            start = time.time()\n",
    "            altCounts, afs = genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)\n",
    "            print(\"took\", time.time() - start)\n",
    "            cachedData2.append([altCounts, afs, {\n",
    "                \"nCases\": nCasesLarge,\n",
    "                \"nCtrls\": nCtrlsLarge,\n",
    "                \"pDs\": pDsGlobalLarge,\n",
    "                \"diseaseFractions\": diseaseFractions,\n",
    "                \"rrShape\": rrShape,\n",
    "                \"rrMeans\": rrMeans,\n",
    "                \"afShape\": afShape,\n",
    "                \"afMean\": afMean\n",
    "            }])\n",
    "\n",
    "        res = fitFnBivariate(cachedData[i][0], pDsGlobalLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=costFnIdx)\n",
    "        bestRes = res[\"params\"][-1]\n",
    "\n",
    "        inferredPis = tensor(bestRes[0:3])\n",
    "        print(\"inferredPis\", inferredPis)\n",
    "        inferredAlphas = tensor(bestRes[3:])\n",
    "        print(\"inferredAlphas\", inferredAlphas)\n",
    "\n",
    "        inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "        params[\"lls\"].append(res[\"lls\"][-1])\n",
    "        params[\"inferredAlphas\"].append(inferredAlphas)\n",
    "        params[\"inferredPis\"].append(inferredPis)\n",
    "        params[\"inferredPDVs\"].append(inferredPDs)\n",
    "\n",
    "        truth1 = pDgivenV(pDsGlobalLarge[0], cachedData[i][1][0:2000, 0, 1], cachedData[i][1][0:2000, 0, 0]).mean()\n",
    "        truth2 = pDgivenV(pDsGlobalLarge[1], cachedData[i][1][2000:4000, 1, 1], cachedData[i][1][2000:4000, 0, 0]).mean()\n",
    "        truth3 = pDgivenV(pDsGlobalLarge[2], cachedData[i][1][4000:5000, 2, 1], cachedData[i][1][4000:5000, 0, 0]).mean()\n",
    "        truth0 = 1 - (truth1 + truth2 + truth3)\n",
    "        print(\"truth0\", truth0, \"truth1\", truth1, \"truth2\", truth2, \"truthBoth\", truth3)\n",
    "\n",
    "        params[\"trueMeanPDVs\"].append(tensor([truth0, truth1, truth2, truth3]))\n",
    "        params[\"truePis\"].append(tensor(diseaseFractions))\n",
    "\n",
    "        print(f\"params on run {i}\", params)\n",
    "        \n",
    "        return params, cachedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "altCountsFlat tensor([[ 20.,   3.,   0.,   0.],\n",
      "        [ 38.,   2.,   0.,   0.],\n",
      "        [ 46.,   2.,   0.,   2.],\n",
      "        ...,\n",
      "        [ 35.,   0.,   0.,   0.],\n",
      "        [ 72.,   0.,   0.,   0.],\n",
      "        [101.,   1.,   0.,   0.]])\n",
      "n tensor([ 23.,  40.,  50.,  ...,  35.,  72., 102.])\n",
      "xCase1, xCase2, xCase12 tensor([3., 2., 2.,  ..., 0., 0., 1.])\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 2.,  ..., 0., 0., 0.])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2a at 0x7fb3f2ebae60>\n",
      "best ll: 96052.6953125, bestParams: [tensor(0.1795), tensor(0.1117), tensor(0.0489), tensor(18920.7910), tensor(1350.0138), tensor(1869.5825), tensor(3547.5586)]\n",
      "epoch 0\n",
      " final_simplex: (array([[6.97416370e-03, 5.88841374e-02, 8.69886373e-02, 2.01069605e+04,\n",
      "        2.11769505e+03, 2.66018193e+03, 2.05925312e+03],\n",
      "       [6.97416388e-03, 5.88841374e-02, 8.69886373e-02, 2.01069605e+04,\n",
      "        2.11769504e+03, 2.66018193e+03, 2.05925313e+03],\n",
      "       [6.97416397e-03, 5.88841373e-02, 8.69886372e-02, 2.01069606e+04,\n",
      "        2.11769504e+03, 2.66018193e+03, 2.05925311e+03],\n",
      "       [6.97416353e-03, 5.88841377e-02, 8.69886372e-02, 2.01069606e+04,\n",
      "        2.11769504e+03, 2.66018193e+03, 2.05925313e+03],\n",
      "       [6.97416396e-03, 5.88841376e-02, 8.69886373e-02, 2.01069606e+04,\n",
      "        2.11769504e+03, 2.66018193e+03, 2.05925314e+03],\n",
      "       [6.97416465e-03, 5.88841372e-02, 8.69886373e-02, 2.01069605e+04,\n",
      "        2.11769504e+03, 2.66018193e+03, 2.05925314e+03],\n",
      "       [6.97416515e-03, 5.88841366e-02, 8.69886372e-02, 2.01069605e+04,\n",
      "        2.11769505e+03, 2.66018192e+03, 2.05925315e+03],\n",
      "       [6.97416484e-03, 5.88841369e-02, 8.69886373e-02, 2.01069605e+04,\n",
      "        2.11769504e+03, 2.66018192e+03, 2.05925316e+03]]), array([86028.1171875, 86028.1171875, 86028.1171875, 86028.1171875,\n",
      "       86028.1171875, 86028.1171875, 86028.1171875, 86028.1171875]))\n",
      "           fun: 86028.1171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1257\n",
      "           nit: 489\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.97416370e-03, 5.88841374e-02, 8.69886373e-02, 2.01069605e+04,\n",
      "       2.11769505e+03, 2.66018193e+03, 2.05925312e+03])\n",
      "best ll: 96790.8203125, bestParams: [tensor(0.0607), tensor(0.0986), tensor(0.1927), tensor(24564.5605), tensor(1496.9585), tensor(5527.3882), tensor(5979.1455)]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.82459935e-02, 6.76853878e-03, 1.91636501e-01, 3.23145995e+04,\n",
      "        3.72088725e+03, 3.56653097e+03, 3.31881637e+03],\n",
      "       [3.82459934e-02, 6.76853868e-03, 1.91636502e-01, 3.23145995e+04,\n",
      "        3.72088724e+03, 3.56653097e+03, 3.31881638e+03],\n",
      "       [3.82459934e-02, 6.76853878e-03, 1.91636501e-01, 3.23145995e+04,\n",
      "        3.72088724e+03, 3.56653097e+03, 3.31881637e+03],\n",
      "       [3.82459933e-02, 6.76853875e-03, 1.91636501e-01, 3.23145995e+04,\n",
      "        3.72088725e+03, 3.56653097e+03, 3.31881639e+03],\n",
      "       [3.82459935e-02, 6.76853841e-03, 1.91636501e-01, 3.23145996e+04,\n",
      "        3.72088724e+03, 3.56653096e+03, 3.31881638e+03],\n",
      "       [3.82459939e-02, 6.76853904e-03, 1.91636502e-01, 3.23145996e+04,\n",
      "        3.72088722e+03, 3.56653098e+03, 3.31881636e+03],\n",
      "       [3.82459931e-02, 6.76853872e-03, 1.91636500e-01, 3.23145995e+04,\n",
      "        3.72088725e+03, 3.56653098e+03, 3.31881639e+03],\n",
      "       [3.82459933e-02, 6.76853853e-03, 1.91636501e-01, 3.23145995e+04,\n",
      "        3.72088725e+03, 3.56653096e+03, 3.31881638e+03]]), array([84428.9609375, 84428.9609375, 84428.9609375, 84428.9609375,\n",
      "       84428.9609375, 84428.9609375, 84428.9609375, 84428.9609375]))\n",
      "           fun: 84428.9609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1284\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.82459935e-02, 6.76853878e-03, 1.91636501e-01, 3.23145995e+04,\n",
      "       3.72088725e+03, 3.56653097e+03, 3.31881637e+03])\n",
      "minPrevious 86028.1171875\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.82459935e-02, 6.76853878e-03, 1.91636501e-01, 3.23145995e+04,\n",
      "        3.72088725e+03, 3.56653097e+03, 3.31881637e+03],\n",
      "       [3.82459934e-02, 6.76853868e-03, 1.91636502e-01, 3.23145995e+04,\n",
      "        3.72088724e+03, 3.56653097e+03, 3.31881638e+03],\n",
      "       [3.82459934e-02, 6.76853878e-03, 1.91636501e-01, 3.23145995e+04,\n",
      "        3.72088724e+03, 3.56653097e+03, 3.31881637e+03],\n",
      "       [3.82459933e-02, 6.76853875e-03, 1.91636501e-01, 3.23145995e+04,\n",
      "        3.72088725e+03, 3.56653097e+03, 3.31881639e+03],\n",
      "       [3.82459935e-02, 6.76853841e-03, 1.91636501e-01, 3.23145996e+04,\n",
      "        3.72088724e+03, 3.56653096e+03, 3.31881638e+03],\n",
      "       [3.82459939e-02, 6.76853904e-03, 1.91636502e-01, 3.23145996e+04,\n",
      "        3.72088722e+03, 3.56653098e+03, 3.31881636e+03],\n",
      "       [3.82459931e-02, 6.76853872e-03, 1.91636500e-01, 3.23145995e+04,\n",
      "        3.72088725e+03, 3.56653098e+03, 3.31881639e+03],\n",
      "       [3.82459933e-02, 6.76853853e-03, 1.91636501e-01, 3.23145995e+04,\n",
      "        3.72088725e+03, 3.56653096e+03, 3.31881638e+03]]), array([84428.9609375, 84428.9609375, 84428.9609375, 84428.9609375,\n",
      "       84428.9609375, 84428.9609375, 84428.9609375, 84428.9609375]))\n",
      "           fun: 84428.9609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1284\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.82459935e-02, 6.76853878e-03, 1.91636501e-01, 3.23145995e+04,\n",
      "       3.72088725e+03, 3.56653097e+03, 3.31881637e+03])\n",
      "best ll: 106202.2890625, bestParams: [tensor(0.2561), tensor(0.1584), tensor(0.2236), tensor(18548.7070), tensor(815.8840), tensor(754.5215), tensor(740.3597)]\n",
      "epoch 2\n",
      " final_simplex: (array([[6.68806514e-03, 7.17792756e-03, 2.16168886e-01, 1.14834561e+04,\n",
      "        1.33334915e+03, 1.34257792e+03, 1.14403277e+03],\n",
      "       [6.68806581e-03, 7.17792982e-03, 2.16168881e-01, 1.14834561e+04,\n",
      "        1.33334916e+03, 1.34257792e+03, 1.14403277e+03],\n",
      "       [6.68806423e-03, 7.17792966e-03, 2.16168879e-01, 1.14834561e+04,\n",
      "        1.33334916e+03, 1.34257793e+03, 1.14403277e+03],\n",
      "       [6.68806568e-03, 7.17792505e-03, 2.16168884e-01, 1.14834562e+04,\n",
      "        1.33334916e+03, 1.34257793e+03, 1.14403277e+03],\n",
      "       [6.68806592e-03, 7.17792837e-03, 2.16168884e-01, 1.14834560e+04,\n",
      "        1.33334916e+03, 1.34257792e+03, 1.14403277e+03],\n",
      "       [6.68806477e-03, 7.17793287e-03, 2.16168877e-01, 1.14834560e+04,\n",
      "        1.33334917e+03, 1.34257792e+03, 1.14403277e+03],\n",
      "       [6.68806566e-03, 7.17792623e-03, 2.16168883e-01, 1.14834560e+04,\n",
      "        1.33334917e+03, 1.34257793e+03, 1.14403277e+03],\n",
      "       [6.68806647e-03, 7.17792989e-03, 2.16168877e-01, 1.14834560e+04,\n",
      "        1.33334918e+03, 1.34257793e+03, 1.14403277e+03]]), array([84098.8828125, 84098.8828125, 84098.8828125, 84098.8828125,\n",
      "       84098.8828125, 84098.8828125, 84098.8828125, 84098.8828125]))\n",
      "           fun: 84098.8828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1199\n",
      "           nit: 459\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.68806514e-03, 7.17792756e-03, 2.16168886e-01, 1.14834561e+04,\n",
      "       1.33334915e+03, 1.34257792e+03, 1.14403277e+03])\n",
      "minPrevious 84428.9609375\n",
      "better by at >= 1; new ll:  final_simplex: (array([[6.68806514e-03, 7.17792756e-03, 2.16168886e-01, 1.14834561e+04,\n",
      "        1.33334915e+03, 1.34257792e+03, 1.14403277e+03],\n",
      "       [6.68806581e-03, 7.17792982e-03, 2.16168881e-01, 1.14834561e+04,\n",
      "        1.33334916e+03, 1.34257792e+03, 1.14403277e+03],\n",
      "       [6.68806423e-03, 7.17792966e-03, 2.16168879e-01, 1.14834561e+04,\n",
      "        1.33334916e+03, 1.34257793e+03, 1.14403277e+03],\n",
      "       [6.68806568e-03, 7.17792505e-03, 2.16168884e-01, 1.14834562e+04,\n",
      "        1.33334916e+03, 1.34257793e+03, 1.14403277e+03],\n",
      "       [6.68806592e-03, 7.17792837e-03, 2.16168884e-01, 1.14834560e+04,\n",
      "        1.33334916e+03, 1.34257792e+03, 1.14403277e+03],\n",
      "       [6.68806477e-03, 7.17793287e-03, 2.16168877e-01, 1.14834560e+04,\n",
      "        1.33334917e+03, 1.34257792e+03, 1.14403277e+03],\n",
      "       [6.68806566e-03, 7.17792623e-03, 2.16168883e-01, 1.14834560e+04,\n",
      "        1.33334917e+03, 1.34257793e+03, 1.14403277e+03],\n",
      "       [6.68806647e-03, 7.17792989e-03, 2.16168877e-01, 1.14834560e+04,\n",
      "        1.33334918e+03, 1.34257793e+03, 1.14403277e+03]]), array([84098.8828125, 84098.8828125, 84098.8828125, 84098.8828125,\n",
      "       84098.8828125, 84098.8828125, 84098.8828125, 84098.8828125]))\n",
      "           fun: 84098.8828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1199\n",
      "           nit: 459\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.68806514e-03, 7.17792756e-03, 2.16168886e-01, 1.14834561e+04,\n",
      "       1.33334915e+03, 1.34257792e+03, 1.14403277e+03])\n",
      "best ll: 95046.3046875, bestParams: [tensor(0.2367), tensor(0.1543), tensor(0.1178), tensor(22251.9902), tensor(2549.5603), tensor(4572.0430), tensor(2589.5850)]\n",
      "epoch 3\n",
      " final_simplex: (array([[1.23790756e-02, 8.61272002e-03, 2.00416338e-01, 3.52073125e+04,\n",
      "        4.13189686e+03, 4.29815333e+03, 3.12348166e+03],\n",
      "       [1.23790761e-02, 8.61272011e-03, 2.00416338e-01, 3.52073124e+04,\n",
      "        4.13189685e+03, 4.29815334e+03, 3.12348168e+03],\n",
      "       [1.23790754e-02, 8.61272065e-03, 2.00416337e-01, 3.52073124e+04,\n",
      "        4.13189685e+03, 4.29815333e+03, 3.12348169e+03],\n",
      "       [1.23790759e-02, 8.61272075e-03, 2.00416338e-01, 3.52073124e+04,\n",
      "        4.13189685e+03, 4.29815331e+03, 3.12348169e+03],\n",
      "       [1.23790747e-02, 8.61271963e-03, 2.00416338e-01, 3.52073124e+04,\n",
      "        4.13189690e+03, 4.29815332e+03, 3.12348167e+03],\n",
      "       [1.23790760e-02, 8.61272199e-03, 2.00416337e-01, 3.52073124e+04,\n",
      "        4.13189685e+03, 4.29815329e+03, 3.12348168e+03],\n",
      "       [1.23790753e-02, 8.61271949e-03, 2.00416338e-01, 3.52073124e+04,\n",
      "        4.13189688e+03, 4.29815331e+03, 3.12348170e+03],\n",
      "       [1.23790753e-02, 8.61271918e-03, 2.00416338e-01, 3.52073124e+04,\n",
      "        4.13189688e+03, 4.29815331e+03, 3.12348170e+03]]), array([84166.15625, 84166.15625, 84166.15625, 84166.15625, 84166.15625,\n",
      "       84166.15625, 84166.15625, 84166.15625]))\n",
      "           fun: 84166.15625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1243\n",
      "           nit: 450\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.23790756e-02, 8.61272002e-03, 2.00416338e-01, 3.52073125e+04,\n",
      "       4.13189686e+03, 4.29815333e+03, 3.12348166e+03])\n",
      "minPrevious 84098.8828125\n",
      "best ll: 106270.84375, bestParams: [tensor(0.0605), tensor(0.0640), tensor(0.0317), tensor(20255.5156), tensor(548.7508), tensor(7194.4438), tensor(6666.2563)]\n",
      "epoch 4\n",
      " final_simplex: (array([[3.60402760e-02, 2.16535598e-03, 7.25725497e-02, 1.18815864e+04,\n",
      "        1.45234680e+03, 1.34820355e+03, 1.15537646e+03],\n",
      "       [3.60402760e-02, 2.16535619e-03, 7.25725495e-02, 1.18815865e+04,\n",
      "        1.45234680e+03, 1.34820354e+03, 1.15537647e+03],\n",
      "       [3.60402760e-02, 2.16535639e-03, 7.25725494e-02, 1.18815865e+04,\n",
      "        1.45234680e+03, 1.34820355e+03, 1.15537647e+03],\n",
      "       [3.60402760e-02, 2.16535661e-03, 7.25725493e-02, 1.18815865e+04,\n",
      "        1.45234680e+03, 1.34820354e+03, 1.15537647e+03],\n",
      "       [3.60402761e-02, 2.16535694e-03, 7.25725489e-02, 1.18815865e+04,\n",
      "        1.45234680e+03, 1.34820353e+03, 1.15537648e+03],\n",
      "       [3.60402760e-02, 2.16535665e-03, 7.25725493e-02, 1.18815865e+04,\n",
      "        1.45234680e+03, 1.34820354e+03, 1.15537648e+03],\n",
      "       [3.60402761e-02, 2.16535664e-03, 7.25725491e-02, 1.18815865e+04,\n",
      "        1.45234680e+03, 1.34820355e+03, 1.15537647e+03],\n",
      "       [3.60402759e-02, 2.16535643e-03, 7.25725495e-02, 1.18815865e+04,\n",
      "        1.45234680e+03, 1.34820352e+03, 1.15537648e+03]]), array([86206.671875, 86206.671875, 86206.671875, 86206.671875,\n",
      "       86206.671875, 86206.671875, 86206.671875, 86206.671875]))\n",
      "           fun: 86206.671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1444\n",
      "           nit: 577\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.60402760e-02, 2.16535598e-03, 7.25725497e-02, 1.18815864e+04,\n",
      "       1.45234680e+03, 1.34820355e+03, 1.15537646e+03])\n",
      "minPrevious 84098.8828125\n",
      "best ll: 94346.171875, bestParams: [tensor(0.0467), tensor(0.0643), tensor(0.0228), tensor(6012.1294), tensor(255.6761), tensor(1155.1085), tensor(468.2769)]\n",
      "epoch 5\n",
      " final_simplex: (array([[8.88941121e-03, 8.00054093e-03, 1.74855468e-01, 9.46213301e+00,\n",
      "        9.24133398e-01, 9.28989324e-01, 1.14051279e+00],\n",
      "       [8.88941120e-03, 8.00054091e-03, 1.74855468e-01, 9.46213309e+00,\n",
      "        9.24133417e-01, 9.28989343e-01, 1.14051279e+00],\n",
      "       [8.88941124e-03, 8.00054099e-03, 1.74855468e-01, 9.46213303e+00,\n",
      "        9.24133399e-01, 9.28989344e-01, 1.14051284e+00],\n",
      "       [8.88941126e-03, 8.00054102e-03, 1.74855468e-01, 9.46213301e+00,\n",
      "        9.24133378e-01, 9.28989328e-01, 1.14051284e+00],\n",
      "       [8.88941124e-03, 8.00054099e-03, 1.74855468e-01, 9.46213294e+00,\n",
      "        9.24133358e-01, 9.28989318e-01, 1.14051281e+00],\n",
      "       [8.88941121e-03, 8.00054093e-03, 1.74855468e-01, 9.46213321e+00,\n",
      "        9.24133445e-01, 9.28989342e-01, 1.14051283e+00],\n",
      "       [8.88941122e-03, 8.00054095e-03, 1.74855468e-01, 9.46213341e+00,\n",
      "        9.24133455e-01, 9.28989360e-01, 1.14051286e+00],\n",
      "       [8.88941121e-03, 8.00054093e-03, 1.74855468e-01, 9.46213325e+00,\n",
      "        9.24133430e-01, 9.28989353e-01, 1.14051282e+00]]), array([74939.40625, 74939.40625, 74939.40625, 74939.40625, 74939.40625,\n",
      "       74939.40625, 74939.40625, 74939.40625]))\n",
      "           fun: 74939.40625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1505\n",
      "           nit: 668\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.88941121e-03, 8.00054093e-03, 1.74855468e-01, 9.46213301e+00,\n",
      "       9.24133398e-01, 9.28989324e-01, 1.14051279e+00])\n",
      "minPrevious 84098.8828125\n",
      "better by at >= 1; new ll:  final_simplex: (array([[8.88941121e-03, 8.00054093e-03, 1.74855468e-01, 9.46213301e+00,\n",
      "        9.24133398e-01, 9.28989324e-01, 1.14051279e+00],\n",
      "       [8.88941120e-03, 8.00054091e-03, 1.74855468e-01, 9.46213309e+00,\n",
      "        9.24133417e-01, 9.28989343e-01, 1.14051279e+00],\n",
      "       [8.88941124e-03, 8.00054099e-03, 1.74855468e-01, 9.46213303e+00,\n",
      "        9.24133399e-01, 9.28989344e-01, 1.14051284e+00],\n",
      "       [8.88941126e-03, 8.00054102e-03, 1.74855468e-01, 9.46213301e+00,\n",
      "        9.24133378e-01, 9.28989328e-01, 1.14051284e+00],\n",
      "       [8.88941124e-03, 8.00054099e-03, 1.74855468e-01, 9.46213294e+00,\n",
      "        9.24133358e-01, 9.28989318e-01, 1.14051281e+00],\n",
      "       [8.88941121e-03, 8.00054093e-03, 1.74855468e-01, 9.46213321e+00,\n",
      "        9.24133445e-01, 9.28989342e-01, 1.14051283e+00],\n",
      "       [8.88941122e-03, 8.00054095e-03, 1.74855468e-01, 9.46213341e+00,\n",
      "        9.24133455e-01, 9.28989360e-01, 1.14051286e+00],\n",
      "       [8.88941121e-03, 8.00054093e-03, 1.74855468e-01, 9.46213325e+00,\n",
      "        9.24133430e-01, 9.28989353e-01, 1.14051282e+00]]), array([74939.40625, 74939.40625, 74939.40625, 74939.40625, 74939.40625,\n",
      "       74939.40625, 74939.40625, 74939.40625]))\n",
      "           fun: 74939.40625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1505\n",
      "           nit: 668\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.88941121e-03, 8.00054093e-03, 1.74855468e-01, 9.46213301e+00,\n",
      "       9.24133398e-01, 9.28989324e-01, 1.14051279e+00])\n",
      "best ll: 108769.46875, bestParams: [tensor(0.2891), tensor(0.0331), tensor(0.1767), tensor(22159.5000), tensor(5644.6094), tensor(9148.4473), tensor(3599.4890)]\n",
      "epoch 6\n",
      " final_simplex: (array([[7.93414400e-03, 3.56952402e-02, 1.49651815e-01, 4.80594937e+04,\n",
      "        4.80099579e+03, 5.99907927e+03, 4.64867462e+03],\n",
      "       [7.93414377e-03, 3.56952404e-02, 1.49651814e-01, 4.80594936e+04,\n",
      "        4.80099579e+03, 5.99907927e+03, 4.64867462e+03],\n",
      "       [7.93414526e-03, 3.56952401e-02, 1.49651815e-01, 4.80594937e+04,\n",
      "        4.80099578e+03, 5.99907920e+03, 4.64867466e+03],\n",
      "       [7.93414720e-03, 3.56952401e-02, 1.49651815e-01, 4.80594937e+04,\n",
      "        4.80099578e+03, 5.99907924e+03, 4.64867461e+03],\n",
      "       [7.93414598e-03, 3.56952402e-02, 1.49651814e-01, 4.80594936e+04,\n",
      "        4.80099578e+03, 5.99907927e+03, 4.64867463e+03],\n",
      "       [7.93414556e-03, 3.56952403e-02, 1.49651815e-01, 4.80594937e+04,\n",
      "        4.80099576e+03, 5.99907923e+03, 4.64867461e+03],\n",
      "       [7.93414409e-03, 3.56952401e-02, 1.49651814e-01, 4.80594937e+04,\n",
      "        4.80099576e+03, 5.99907927e+03, 4.64867465e+03],\n",
      "       [7.93414570e-03, 3.56952401e-02, 1.49651815e-01, 4.80594937e+04,\n",
      "        4.80099578e+03, 5.99907919e+03, 4.64867463e+03]]), array([84550.5546875, 84550.5546875, 84550.5546875, 84550.5546875,\n",
      "       84550.5546875, 84550.5546875, 84550.5546875, 84550.5546875]))\n",
      "           fun: 84550.5546875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1158\n",
      "           nit: 390\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.93414400e-03, 3.56952402e-02, 1.49651815e-01, 4.80594937e+04,\n",
      "       4.80099579e+03, 5.99907927e+03, 4.64867462e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 99211.625, bestParams: [tensor(0.0498), tensor(0.2653), tensor(0.1634), tensor(11747.2764), tensor(3247.4846), tensor(841.6326), tensor(1829.3456)]\n",
      "epoch 7\n",
      " final_simplex: (array([[5.52598309e-02, 3.91831812e-03, 1.57322041e-01, 1.54767481e+04,\n",
      "        1.87308736e+03, 1.65449249e+03, 1.53439557e+03],\n",
      "       [5.52598311e-02, 3.91831897e-03, 1.57322041e-01, 1.54767481e+04,\n",
      "        1.87308737e+03, 1.65449249e+03, 1.53439557e+03],\n",
      "       [5.52598310e-02, 3.91831869e-03, 1.57322041e-01, 1.54767481e+04,\n",
      "        1.87308735e+03, 1.65449249e+03, 1.53439558e+03],\n",
      "       [5.52598309e-02, 3.91831917e-03, 1.57322041e-01, 1.54767480e+04,\n",
      "        1.87308737e+03, 1.65449249e+03, 1.53439558e+03],\n",
      "       [5.52598308e-02, 3.91831864e-03, 1.57322041e-01, 1.54767481e+04,\n",
      "        1.87308735e+03, 1.65449249e+03, 1.53439558e+03],\n",
      "       [5.52598310e-02, 3.91831903e-03, 1.57322041e-01, 1.54767480e+04,\n",
      "        1.87308735e+03, 1.65449249e+03, 1.53439558e+03],\n",
      "       [5.52598307e-02, 3.91831967e-03, 1.57322041e-01, 1.54767480e+04,\n",
      "        1.87308737e+03, 1.65449248e+03, 1.53439559e+03],\n",
      "       [5.52598312e-02, 3.91831843e-03, 1.57322041e-01, 1.54767480e+04,\n",
      "        1.87308735e+03, 1.65449249e+03, 1.53439558e+03]]), array([84848.2578125, 84848.2578125, 84848.2578125, 84848.2578125,\n",
      "       84848.2578125, 84848.2578125, 84848.2578125, 84848.2578125]))\n",
      "           fun: 84848.2578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 406\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.52598309e-02, 3.91831812e-03, 1.57322041e-01, 1.54767481e+04,\n",
      "       1.87308736e+03, 1.65449249e+03, 1.53439557e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 99761.6328125, bestParams: [tensor(0.1599), tensor(0.1614), tensor(0.1872), tensor(24509.1309), tensor(7541.6543), tensor(3351.3992), tensor(3709.6477)]\n",
      "epoch 8\n",
      " final_simplex: (array([[5.13682256e-02, 4.95959426e-03, 1.93649874e-01, 4.64640500e+04,\n",
      "        5.40013868e+03, 5.41325769e+03, 4.38681416e+03],\n",
      "       [5.13682253e-02, 4.95959517e-03, 1.93649873e-01, 4.64640499e+04,\n",
      "        5.40013870e+03, 5.41325772e+03, 4.38681414e+03],\n",
      "       [5.13682251e-02, 4.95959511e-03, 1.93649875e-01, 4.64640500e+04,\n",
      "        5.40013876e+03, 5.41325770e+03, 4.38681413e+03],\n",
      "       [5.13682252e-02, 4.95959447e-03, 1.93649875e-01, 4.64640500e+04,\n",
      "        5.40013876e+03, 5.41325768e+03, 4.38681415e+03],\n",
      "       [5.13682253e-02, 4.95959473e-03, 1.93649871e-01, 4.64640499e+04,\n",
      "        5.40013871e+03, 5.41325771e+03, 4.38681416e+03],\n",
      "       [5.13682257e-02, 4.95959479e-03, 1.93649874e-01, 4.64640499e+04,\n",
      "        5.40013870e+03, 5.41325769e+03, 4.38681415e+03],\n",
      "       [5.13682254e-02, 4.95959556e-03, 1.93649874e-01, 4.64640500e+04,\n",
      "        5.40013873e+03, 5.41325770e+03, 4.38681413e+03],\n",
      "       [5.13682258e-02, 4.95959441e-03, 1.93649876e-01, 4.64640500e+04,\n",
      "        5.40013867e+03, 5.41325768e+03, 4.38681414e+03]]), array([84543.3828125, 84543.3828125, 84543.3828125, 84543.3828125,\n",
      "       84543.3828125, 84543.3828125, 84543.3828125, 84543.3828125]))\n",
      "           fun: 84543.3828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1198\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.13682256e-02, 4.95959426e-03, 1.93649874e-01, 4.64640500e+04,\n",
      "       5.40013868e+03, 5.41325769e+03, 4.38681416e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 105765.046875, bestParams: [tensor(0.0133), tensor(0.0361), tensor(0.0607), tensor(17905.6074), tensor(2014.4242), tensor(8663.3320), tensor(3980.2078)]\n",
      "epoch 9\n",
      " final_simplex: (array([[1.35524220e-02, 3.51093932e-02, 8.48482858e-02, 2.42915916e+04,\n",
      "        2.84084280e+03, 2.87175515e+03, 2.32948765e+03],\n",
      "       [1.35524219e-02, 3.51093932e-02, 8.48482860e-02, 2.42915916e+04,\n",
      "        2.84084281e+03, 2.87175516e+03, 2.32948763e+03],\n",
      "       [1.35524220e-02, 3.51093933e-02, 8.48482860e-02, 2.42915916e+04,\n",
      "        2.84084280e+03, 2.87175513e+03, 2.32948763e+03],\n",
      "       [1.35524220e-02, 3.51093931e-02, 8.48482861e-02, 2.42915916e+04,\n",
      "        2.84084278e+03, 2.87175517e+03, 2.32948765e+03],\n",
      "       [1.35524220e-02, 3.51093933e-02, 8.48482861e-02, 2.42915915e+04,\n",
      "        2.84084281e+03, 2.87175518e+03, 2.32948761e+03],\n",
      "       [1.35524220e-02, 3.51093934e-02, 8.48482861e-02, 2.42915915e+04,\n",
      "        2.84084281e+03, 2.87175518e+03, 2.32948761e+03],\n",
      "       [1.35524219e-02, 3.51093935e-02, 8.48482855e-02, 2.42915915e+04,\n",
      "        2.84084281e+03, 2.87175519e+03, 2.32948764e+03],\n",
      "       [1.35524220e-02, 3.51093933e-02, 8.48482862e-02, 2.42915916e+04,\n",
      "        2.84084280e+03, 2.87175511e+03, 2.32948762e+03]]), array([85702.9375, 85702.9375, 85702.9375, 85702.9375, 85702.9375,\n",
      "       85702.9375, 85702.9375, 85702.9375]))\n",
      "           fun: 85702.9375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1201\n",
      "           nit: 439\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.35524220e-02, 3.51093932e-02, 8.48482858e-02, 2.42915916e+04,\n",
      "       2.84084280e+03, 2.87175515e+03, 2.32948765e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 104076.734375, bestParams: [tensor(0.0936), tensor(0.0306), tensor(0.1020), tensor(18111.7617), tensor(2399.4336), tensor(1993.5511), tensor(7930.8491)]\n",
      "epoch 10\n",
      " final_simplex: (array([[9.28355087e-02, 2.99864255e-02, 1.23561942e-01, 2.38075981e+04,\n",
      "        2.67776018e+03, 2.47065562e+03, 2.26440323e+03],\n",
      "       [9.28355079e-02, 2.99864255e-02, 1.23561942e-01, 2.38075982e+04,\n",
      "        2.67776019e+03, 2.47065562e+03, 2.26440325e+03],\n",
      "       [9.28355087e-02, 2.99864255e-02, 1.23561941e-01, 2.38075981e+04,\n",
      "        2.67776017e+03, 2.47065563e+03, 2.26440326e+03],\n",
      "       [9.28355086e-02, 2.99864255e-02, 1.23561942e-01, 2.38075981e+04,\n",
      "        2.67776019e+03, 2.47065563e+03, 2.26440323e+03],\n",
      "       [9.28355087e-02, 2.99864253e-02, 1.23561941e-01, 2.38075982e+04,\n",
      "        2.67776017e+03, 2.47065563e+03, 2.26440322e+03],\n",
      "       [9.28355082e-02, 2.99864254e-02, 1.23561942e-01, 2.38075981e+04,\n",
      "        2.67776018e+03, 2.47065563e+03, 2.26440325e+03],\n",
      "       [9.28355081e-02, 2.99864256e-02, 1.23561943e-01, 2.38075982e+04,\n",
      "        2.67776020e+03, 2.47065561e+03, 2.26440324e+03],\n",
      "       [9.28355087e-02, 2.99864257e-02, 1.23561942e-01, 2.38075981e+04,\n",
      "        2.67776019e+03, 2.47065561e+03, 2.26440324e+03]]), array([86013.4296875, 86013.4296875, 86013.4296875, 86013.4296875,\n",
      "       86013.4296875, 86013.4296875, 86013.4296875, 86013.4296875]))\n",
      "           fun: 86013.4296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1184\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.28355087e-02, 2.99864255e-02, 1.23561942e-01, 2.38075981e+04,\n",
      "       2.67776018e+03, 2.47065562e+03, 2.26440323e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 106897.6328125, bestParams: [tensor(0.0551), tensor(0.1252), tensor(0.0953), tensor(13852.7754), tensor(2989.7432), tensor(5398.6997), tensor(4424.8936)]\n",
      "epoch 11\n",
      " final_simplex: (array([[5.75384956e-02, 7.83384955e-03, 1.57962692e-01, 2.61180084e+04,\n",
      "        3.09383306e+03, 3.05180120e+03, 2.48177623e+03],\n",
      "       [5.75384956e-02, 7.83384943e-03, 1.57962692e-01, 2.61180083e+04,\n",
      "        3.09383305e+03, 3.05180120e+03, 2.48177623e+03],\n",
      "       [5.75384957e-02, 7.83384944e-03, 1.57962692e-01, 2.61180083e+04,\n",
      "        3.09383305e+03, 3.05180120e+03, 2.48177623e+03],\n",
      "       [5.75384956e-02, 7.83384944e-03, 1.57962692e-01, 2.61180084e+04,\n",
      "        3.09383306e+03, 3.05180119e+03, 2.48177623e+03],\n",
      "       [5.75384956e-02, 7.83384961e-03, 1.57962692e-01, 2.61180083e+04,\n",
      "        3.09383306e+03, 3.05180120e+03, 2.48177623e+03],\n",
      "       [5.75384956e-02, 7.83384979e-03, 1.57962692e-01, 2.61180083e+04,\n",
      "        3.09383306e+03, 3.05180119e+03, 2.48177622e+03],\n",
      "       [5.75384954e-02, 7.83385027e-03, 1.57962692e-01, 2.61180083e+04,\n",
      "        3.09383305e+03, 3.05180120e+03, 2.48177622e+03],\n",
      "       [5.75384954e-02, 7.83385061e-03, 1.57962692e-01, 2.61180083e+04,\n",
      "        3.09383305e+03, 3.05180121e+03, 2.48177622e+03]]), array([84847., 84847., 84847., 84847., 84847., 84847., 84847., 84847.]))\n",
      "           fun: 84847.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1252\n",
      "           nit: 406\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.75384956e-02, 7.83384955e-03, 1.57962692e-01, 2.61180084e+04,\n",
      "       3.09383306e+03, 3.05180120e+03, 2.48177623e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 98463.703125, bestParams: [tensor(0.0169), tensor(0.1995), tensor(0.0851), tensor(23116.7969), tensor(6128.9165), tensor(4050.8965), tensor(5318.6875)]\n",
      "epoch 12\n",
      " final_simplex: (array([[1.62023751e-02, 9.11260801e-03, 1.47144840e-01, 3.76379166e+04,\n",
      "        4.29209784e+03, 4.53826341e+03, 3.67629532e+03],\n",
      "       [1.62023751e-02, 9.11260821e-03, 1.47144840e-01, 3.76379167e+04,\n",
      "        4.29209783e+03, 4.53826340e+03, 3.67629533e+03],\n",
      "       [1.62023751e-02, 9.11260804e-03, 1.47144841e-01, 3.76379167e+04,\n",
      "        4.29209783e+03, 4.53826340e+03, 3.67629533e+03],\n",
      "       [1.62023751e-02, 9.11260803e-03, 1.47144841e-01, 3.76379167e+04,\n",
      "        4.29209783e+03, 4.53826340e+03, 3.67629534e+03],\n",
      "       [1.62023751e-02, 9.11260838e-03, 1.47144840e-01, 3.76379166e+04,\n",
      "        4.29209785e+03, 4.53826340e+03, 3.67629532e+03],\n",
      "       [1.62023751e-02, 9.11260944e-03, 1.47144841e-01, 3.76379167e+04,\n",
      "        4.29209784e+03, 4.53826340e+03, 3.67629529e+03],\n",
      "       [1.62023751e-02, 9.11260862e-03, 1.47144841e-01, 3.76379167e+04,\n",
      "        4.29209782e+03, 4.53826340e+03, 3.67629530e+03],\n",
      "       [1.62023752e-02, 9.11260751e-03, 1.47144841e-01, 3.76379167e+04,\n",
      "        4.29209780e+03, 4.53826341e+03, 3.67629532e+03]]), array([84387.59375, 84387.59375, 84387.59375, 84387.59375, 84387.59375,\n",
      "       84387.59375, 84387.59375, 84387.59375]))\n",
      "           fun: 84387.59375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1230\n",
      "           nit: 424\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.62023751e-02, 9.11260801e-03, 1.47144840e-01, 3.76379166e+04,\n",
      "       4.29209784e+03, 4.53826341e+03, 3.67629532e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 98637.0625, bestParams: [tensor(0.1080), tensor(0.0535), tensor(0.0079), tensor(24703.8301), tensor(6102.8604), tensor(1382.5287), tensor(2581.4192)]\n",
      "epoch 13\n",
      " final_simplex: (array([[2.88948748e-02, 4.81806187e-03, 5.07786264e-02, 9.00557532e+00,\n",
      "        1.00566185e+00, 8.62895433e-01, 1.16918999e+00],\n",
      "       [2.88948748e-02, 4.81806184e-03, 5.07786264e-02, 9.00557533e+00,\n",
      "        1.00566192e+00, 8.62895352e-01, 1.16918989e+00],\n",
      "       [2.88948748e-02, 4.81806187e-03, 5.07786264e-02, 9.00557524e+00,\n",
      "        1.00566183e+00, 8.62895369e-01, 1.16918991e+00],\n",
      "       [2.88948748e-02, 4.81806185e-03, 5.07786264e-02, 9.00557531e+00,\n",
      "        1.00566189e+00, 8.62895342e-01, 1.16918989e+00],\n",
      "       [2.88948748e-02, 4.81806184e-03, 5.07786264e-02, 9.00557515e+00,\n",
      "        1.00566191e+00, 8.62895281e-01, 1.16918986e+00],\n",
      "       [2.88948748e-02, 4.81806185e-03, 5.07786264e-02, 9.00557531e+00,\n",
      "        1.00566191e+00, 8.62895256e-01, 1.16918986e+00],\n",
      "       [2.88948748e-02, 4.81806185e-03, 5.07786264e-02, 9.00557478e+00,\n",
      "        1.00566186e+00, 8.62895277e-01, 1.16918986e+00],\n",
      "       [2.88948748e-02, 4.81806186e-03, 5.07786264e-02, 9.00557556e+00,\n",
      "        1.00566188e+00, 8.62895392e-01, 1.16918993e+00]]), array([78448.6640625, 78448.6640625, 78448.6640625, 78448.6640625,\n",
      "       78448.6640625, 78448.6640625, 78448.6640625, 78448.6640625]))\n",
      "           fun: 78448.6640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1644\n",
      "           nit: 769\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.88948748e-02, 4.81806187e-03, 5.07786264e-02, 9.00557532e+00,\n",
      "       1.00566185e+00, 8.62895433e-01, 1.16918999e+00])\n",
      "minPrevious 74939.40625\n",
      "best ll: 106671.1796875, bestParams: [tensor(0.1054), tensor(0.0436), tensor(0.0591), tensor(24284.5918), tensor(2769.6636), tensor(4240.3740), tensor(11719.7051)]\n",
      "epoch 14\n",
      " final_simplex: (array([[1.09897137e-02, 3.01856435e-02, 1.31439704e-01, 3.69815280e+04,\n",
      "        4.97334762e+03, 3.99275539e+03, 3.72567002e+03],\n",
      "       [1.09897137e-02, 3.01856436e-02, 1.31439705e-01, 3.69815280e+04,\n",
      "        4.97334762e+03, 3.99275540e+03, 3.72567002e+03],\n",
      "       [1.09897141e-02, 3.01856436e-02, 1.31439704e-01, 3.69815280e+04,\n",
      "        4.97334761e+03, 3.99275539e+03, 3.72567002e+03],\n",
      "       [1.09897141e-02, 3.01856435e-02, 1.31439704e-01, 3.69815280e+04,\n",
      "        4.97334762e+03, 3.99275538e+03, 3.72567001e+03],\n",
      "       [1.09897135e-02, 3.01856436e-02, 1.31439704e-01, 3.69815280e+04,\n",
      "        4.97334763e+03, 3.99275540e+03, 3.72567001e+03],\n",
      "       [1.09897137e-02, 3.01856436e-02, 1.31439704e-01, 3.69815280e+04,\n",
      "        4.97334762e+03, 3.99275539e+03, 3.72567001e+03],\n",
      "       [1.09897138e-02, 3.01856436e-02, 1.31439704e-01, 3.69815280e+04,\n",
      "        4.97334762e+03, 3.99275538e+03, 3.72567001e+03],\n",
      "       [1.09897134e-02, 3.01856435e-02, 1.31439705e-01, 3.69815280e+04,\n",
      "        4.97334763e+03, 3.99275540e+03, 3.72567001e+03]]), array([84918.078125, 84918.078125, 84918.078125, 84918.078125,\n",
      "       84918.078125, 84918.078125, 84918.078125, 84918.078125]))\n",
      "           fun: 84918.078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1288\n",
      "           nit: 462\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.09897137e-02, 3.01856435e-02, 1.31439704e-01, 3.69815280e+04,\n",
      "       4.97334762e+03, 3.99275539e+03, 3.72567002e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 113134.15625, bestParams: [tensor(0.0209), tensor(0.0262), tensor(0.0298), tensor(23718.7949), tensor(1005.2904), tensor(5143.6538), tensor(16830.6582)]\n",
      "epoch 15\n",
      " final_simplex: (array([[1.75641777e-02, 1.72848552e-02, 3.49783855e-02, 3.17813082e+04,\n",
      "        1.52722073e+03, 5.14038026e+03, 3.19206424e+03],\n",
      "       [1.75641777e-02, 1.72848548e-02, 3.49783859e-02, 3.17813083e+04,\n",
      "        1.52722074e+03, 5.14038024e+03, 3.19206421e+03],\n",
      "       [1.75641777e-02, 1.72848548e-02, 3.49783859e-02, 3.17813083e+04,\n",
      "        1.52722074e+03, 5.14038023e+03, 3.19206422e+03],\n",
      "       [1.75641777e-02, 1.72848548e-02, 3.49783859e-02, 3.17813082e+04,\n",
      "        1.52722074e+03, 5.14038025e+03, 3.19206421e+03],\n",
      "       [1.75641777e-02, 1.72848550e-02, 3.49783857e-02, 3.17813083e+04,\n",
      "        1.52722073e+03, 5.14038025e+03, 3.19206421e+03],\n",
      "       [1.75641777e-02, 1.72848551e-02, 3.49783856e-02, 3.17813082e+04,\n",
      "        1.52722073e+03, 5.14038025e+03, 3.19206426e+03],\n",
      "       [1.75641776e-02, 1.72848552e-02, 3.49783857e-02, 3.17813082e+04,\n",
      "        1.52722074e+03, 5.14038027e+03, 3.19206414e+03],\n",
      "       [1.75641779e-02, 1.72848547e-02, 3.49783861e-02, 3.17813082e+04,\n",
      "        1.52722073e+03, 5.14038025e+03, 3.19206414e+03]]), array([91585.46875, 91585.46875, 91585.46875, 91585.46875, 91585.46875,\n",
      "       91585.46875, 91585.46875, 91585.46875]))\n",
      "           fun: 91585.46875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1219\n",
      "           nit: 434\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.75641777e-02, 1.72848552e-02, 3.49783855e-02, 3.17813082e+04,\n",
      "       1.52722073e+03, 5.14038026e+03, 3.19206424e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 112311.4375, bestParams: [tensor(0.0081), tensor(0.0349), tensor(0.0220), tensor(19399.4043), tensor(5370.1772), tensor(9769.8496), tensor(6111.7505)]\n",
      "epoch 16\n",
      " final_simplex: (array([[8.40059865e-03, 3.35196490e-02, 3.35977707e-02, 3.61368116e+04,\n",
      "        3.87206562e+03, 4.30675716e+03, 3.46590873e+03],\n",
      "       [8.40059863e-03, 3.35196493e-02, 3.35977708e-02, 3.61368115e+04,\n",
      "        3.87206562e+03, 4.30675719e+03, 3.46590870e+03],\n",
      "       [8.40059858e-03, 3.35196492e-02, 3.35977705e-02, 3.61368116e+04,\n",
      "        3.87206568e+03, 4.30675723e+03, 3.46590876e+03],\n",
      "       [8.40059856e-03, 3.35196493e-02, 3.35977707e-02, 3.61368117e+04,\n",
      "        3.87206564e+03, 4.30675725e+03, 3.46590876e+03],\n",
      "       [8.40059865e-03, 3.35196490e-02, 3.35977707e-02, 3.61368117e+04,\n",
      "        3.87206564e+03, 4.30675715e+03, 3.46590870e+03],\n",
      "       [8.40059859e-03, 3.35196492e-02, 3.35977706e-02, 3.61368117e+04,\n",
      "        3.87206567e+03, 4.30675715e+03, 3.46590874e+03],\n",
      "       [8.40059857e-03, 3.35196495e-02, 3.35977707e-02, 3.61368115e+04,\n",
      "        3.87206561e+03, 4.30675724e+03, 3.46590875e+03],\n",
      "       [8.40059861e-03, 3.35196490e-02, 3.35977706e-02, 3.61368116e+04,\n",
      "        3.87206568e+03, 4.30675721e+03, 3.46590875e+03]]), array([88371.0703125, 88371.0703125, 88371.0703125, 88371.0703125,\n",
      "       88371.0703125, 88371.0703125, 88371.0703125, 88371.0703125]))\n",
      "           fun: 88371.0703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1178\n",
      "           nit: 427\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.40059865e-03, 3.35196490e-02, 3.35977707e-02, 3.61368116e+04,\n",
      "       3.87206562e+03, 4.30675716e+03, 3.46590873e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 95355.5546875, bestParams: [tensor(0.1303), tensor(0.0763), tensor(0.2145), tensor(15279.1143), tensor(750.2145), tensor(3826.3201), tensor(1558.2245)]\n",
      "epoch 17\n",
      " final_simplex: (array([[4.60785386e-03, 3.64690613e-02, 1.99394510e-01, 1.55828242e+04,\n",
      "        1.80644451e+03, 1.85369069e+03, 1.59052880e+03],\n",
      "       [4.60785456e-03, 3.64690631e-02, 1.99394513e-01, 1.55828242e+04,\n",
      "        1.80644452e+03, 1.85369065e+03, 1.59052879e+03],\n",
      "       [4.60785457e-03, 3.64690630e-02, 1.99394508e-01, 1.55828242e+04,\n",
      "        1.80644451e+03, 1.85369067e+03, 1.59052880e+03],\n",
      "       [4.60785490e-03, 3.64690638e-02, 1.99394510e-01, 1.55828242e+04,\n",
      "        1.80644452e+03, 1.85369065e+03, 1.59052879e+03],\n",
      "       [4.60785390e-03, 3.64690624e-02, 1.99394511e-01, 1.55828242e+04,\n",
      "        1.80644453e+03, 1.85369064e+03, 1.59052879e+03],\n",
      "       [4.60785496e-03, 3.64690638e-02, 1.99394512e-01, 1.55828243e+04,\n",
      "        1.80644452e+03, 1.85369062e+03, 1.59052879e+03],\n",
      "       [4.60785373e-03, 3.64690614e-02, 1.99394509e-01, 1.55828242e+04,\n",
      "        1.80644451e+03, 1.85369071e+03, 1.59052880e+03],\n",
      "       [4.60785419e-03, 3.64690618e-02, 1.99394510e-01, 1.55828243e+04,\n",
      "        1.80644450e+03, 1.85369071e+03, 1.59052880e+03]]), array([84419.40625, 84419.40625, 84419.40625, 84419.40625, 84419.40625,\n",
      "       84419.40625, 84419.40625, 84419.40625]))\n",
      "           fun: 84419.40625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1219\n",
      "           nit: 460\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.60785386e-03, 3.64690613e-02, 1.99394510e-01, 1.55828242e+04,\n",
      "       1.80644451e+03, 1.85369069e+03, 1.59052880e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 90905.421875, bestParams: [tensor(0.0655), tensor(0.0646), tensor(0.1709), tensor(19189.1133), tensor(3902.6858), tensor(3921.6992), tensor(2637.1685)]\n",
      "epoch 18\n",
      " final_simplex: (array([[6.00461719e-02, 5.22326440e-02, 1.87837582e-01, 2.83554159e+04,\n",
      "        3.16036368e+03, 3.18035731e+03, 2.69994256e+03],\n",
      "       [6.00461718e-02, 5.22326440e-02, 1.87837582e-01, 2.83554159e+04,\n",
      "        3.16036368e+03, 3.18035731e+03, 2.69994256e+03],\n",
      "       [6.00461717e-02, 5.22326438e-02, 1.87837582e-01, 2.83554159e+04,\n",
      "        3.16036367e+03, 3.18035731e+03, 2.69994256e+03],\n",
      "       [6.00461717e-02, 5.22326438e-02, 1.87837582e-01, 2.83554159e+04,\n",
      "        3.16036367e+03, 3.18035731e+03, 2.69994257e+03],\n",
      "       [6.00461715e-02, 5.22326437e-02, 1.87837582e-01, 2.83554159e+04,\n",
      "        3.16036367e+03, 3.18035732e+03, 2.69994257e+03],\n",
      "       [6.00461714e-02, 5.22326436e-02, 1.87837583e-01, 2.83554159e+04,\n",
      "        3.16036367e+03, 3.18035732e+03, 2.69994257e+03],\n",
      "       [6.00461716e-02, 5.22326437e-02, 1.87837582e-01, 2.83554160e+04,\n",
      "        3.16036367e+03, 3.18035731e+03, 2.69994257e+03],\n",
      "       [6.00461715e-02, 5.22326436e-02, 1.87837583e-01, 2.83554159e+04,\n",
      "        3.16036367e+03, 3.18035732e+03, 2.69994257e+03]]), array([85352.921875, 85352.921875, 85352.921875, 85352.921875,\n",
      "       85352.921875, 85352.921875, 85352.921875, 85352.921875]))\n",
      "           fun: 85352.921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1200\n",
      "           nit: 397\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.00461719e-02, 5.22326440e-02, 1.87837582e-01, 2.83554159e+04,\n",
      "       3.16036368e+03, 3.18035731e+03, 2.69994256e+03])\n",
      "minPrevious 74939.40625\n",
      "best ll: 102508.546875, bestParams: [tensor(0.2119), tensor(0.2322), tensor(0.2114), tensor(18241.8457), tensor(4440.9014), tensor(3570.5168), tensor(1761.8313)]\n",
      "epoch 19\n",
      " final_simplex: (array([[1.01795356e-02, 1.04041457e-02, 1.71918758e-01, 3.18118376e+04,\n",
      "        3.41436691e+03, 3.94565218e+03, 2.98131550e+03],\n",
      "       [1.01795358e-02, 1.04041482e-02, 1.71918756e-01, 3.18118377e+04,\n",
      "        3.41436693e+03, 3.94565214e+03, 2.98131549e+03],\n",
      "       [1.01795371e-02, 1.04041408e-02, 1.71918759e-01, 3.18118377e+04,\n",
      "        3.41436699e+03, 3.94565215e+03, 2.98131549e+03],\n",
      "       [1.01795394e-02, 1.04041389e-02, 1.71918759e-01, 3.18118376e+04,\n",
      "        3.41436700e+03, 3.94565215e+03, 2.98131548e+03],\n",
      "       [1.01795377e-02, 1.04041402e-02, 1.71918758e-01, 3.18118377e+04,\n",
      "        3.41436697e+03, 3.94565216e+03, 2.98131549e+03],\n",
      "       [1.01795376e-02, 1.04041408e-02, 1.71918759e-01, 3.18118377e+04,\n",
      "        3.41436696e+03, 3.94565216e+03, 2.98131549e+03],\n",
      "       [1.01795383e-02, 1.04041419e-02, 1.71918759e-01, 3.18118377e+04,\n",
      "        3.41436696e+03, 3.94565212e+03, 2.98131549e+03],\n",
      "       [1.01795370e-02, 1.04041392e-02, 1.71918759e-01, 3.18118377e+04,\n",
      "        3.41436697e+03, 3.94565218e+03, 2.98131549e+03]]), array([84248.3671875, 84248.3671875, 84248.3671875, 84248.3671875,\n",
      "       84248.3671875, 84248.3671875, 84248.3671875, 84248.3671875]))\n",
      "           fun: 84248.3671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1194\n",
      "           nit: 442\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.01795356e-02, 1.04041457e-02, 1.71918758e-01, 3.18118376e+04,\n",
      "       3.41436691e+03, 3.94565218e+03, 2.98131550e+03])\n",
      "minPrevious 74939.40625\n",
      "inferredPis tensor([0.0089, 0.0080, 0.1749], dtype=torch.float64)\n",
      "inferredAlphas tensor([9.4621, 0.9241, 0.9290, 1.1405], dtype=torch.float64)\n",
      "truth0 tensor(0.5174) truth1 tensor(0.1810) truth2 tensor(0.1825) truthBoth tensor(0.1192)\n",
      "params on run 0 {'lls': [], 'inferredAlphas': [], 'inferredPis': [], 'inferredPDVs': [], 'trueMeanPDVs': [], 'truePis': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "params4, cachedData2 = runModel(altCountsByGenePooledCtrls2, afsByGenePooledCtrls2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-408cb9ef4c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'params4' is not defined"
     ]
    }
   ],
   "source": [
    "params4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-84e613715e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inferredPis\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "tensor([*params[\"inferredPis\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fitFnBivariate(cachedData[0][0], pDsLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = fitFnBivariate(cachedData[0][0], pDsLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = fitFnBivariate(cachedData[0][0], pDsLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"res0\", res0)\n",
    "print(\"\\nres0\", \"pis\", res0[\"params\"][-1][0:3], \"mean P(D|V)'s\", Dirichlet(tensor(res0[\"params\"][-1][3:])).sample([10_000]).mean(0))\n",
    "\n",
    "print(\"\\n\\n\\nres1\", res1)\n",
    "print(\"\\nres1\", \"pis\", res1[\"params\"][-1][0:3], \"mean P(D|V)'s\", Dirichlet(tensor(res1[\"params\"][-1][3:])).sample([10_000]).mean(0))\n",
    "\n",
    "print(\"\\n\\n\\nres2\", res2)\n",
    "print(\"\\nres2\", \"pis\", res2[\"params\"][-1][0:3], \"mean P(D|V)'s\", Dirichlet(tensor(res2[\"params\"][-1][3:])).sample([10_000]).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb88903ef50>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(res0[\"llTrajectory\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb84a498610>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(res1[\"llTrajectory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb849d71f90>]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(res2[\"llTrajectory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(afsByGenePooledCtrls[2000:4000, 1, 1]/afsByGenePooledCtrls[2000:4000, 0, 0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pDgivenV(pD., afsByGenePooledCtrls[0:2000, :, 1], afsByGenePooledCtrls[0:2000, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dirichlet(tensor(1/4.0).expand(4)).sample()\n",
    "test = test[0:3]\n",
    "r = [0,1,2,3]\n",
    "r[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnBivariate(altCountsByGenePooledCtrls, pDs, nEpochs=100, minLLThresholdCount=100, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dirichlet(concentration=tensor([1.40625703e+04,\n",
    "         5.56195520e+03, 1.57978682e+02, 2.33518936e+04]))\n",
    "d.sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(7.74788652e+02, 2.58170768e+04 + 9.72956833e+02 + 5.18278100e+03).sample([10000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(3.05871723e+04, 3.25256694e+02 + 3.75135881e+03 +4.52942294e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res = fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=100, minLLThresholdCount=100, debug=False)\n",
    "print(\"fitFnUniveriateBetaBinomial took for 100 epochs: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(res[\"llTrajectory\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomH0 = Binomial(total_count=tensor([1.,1]), probs=pDs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomH0.log_prob(tensor(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn2 = likelihoodUnivariateFast(altCountsByGene, pDs)\n",
    "# print(costFn2([1e-9, .999999]))\n",
    "print(costFn2([1e-9, 1e-9]))\n",
    "print(costFn2([0.08845797,0.11094360])) #gives ~12067 using jensen's method, and ~9887 using exponentiation of the log\n",
    "\n",
    "# best result from R\n",
    "#  0.08845797           0.11094360 , ll -10127.23, and with jensen's version, \"example -12037.4347455843\"\n",
    "# pDgivenV, pi1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn = likelihoodUnivariate(altCountsByGene, pDs)\n",
    "print(\"costFn1:\", costFn([.001, .01]),\"costFn2:\",costFn2([.001, .01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn([0.0001,0.11094360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(costFn2([0.0001,0.11094360]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Binomial(total_count=tensor([14., 0., 9.]), probs=tensor(.0099))\n",
    "d.log_prob(tensor([0.,0.,0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn2([1e-9, .999999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomH0 = Binomial(total_count=geneSums, probs=.001)\n",
    "binomH1 = Binomial(total_count=geneSums, probs=.01)\n",
    "caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "print(caseAltCounts)\n",
    "component0 = binomH0.log_prob(caseAltCounts)\n",
    "print(\"component0\", component0, .5*component0)\n",
    "component1 = binomH1.log_prob(caseAltCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV(pDs[0], afsByGene2[0:2000, 0, 1].mean(), afMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition1 = altCountsByGene2[:, 0, :]\n",
    "condition1\n",
    "pDs[0]\n",
    "\n",
    "afsByGene2[0:2000,:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(afsByGene2[:, 0, 1:2].flatten())\n",
    "pyplot.plot(afsByGene2[:, 0, 0:1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 0, 0:1].flatten())\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 0, 1:2].flatten())\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 1, 1:2].flatten())\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 2, 1:2].flatten())\n",
    "# pyplot.plot(afsByGeneRR2[:, 0, 1:2].flatten())\n",
    "# pyplot.plot(afsByGeneRR2[:, 0, 0:1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrlCounts = altCountsByGene[:, 0, 0]\n",
    "altCountsCases = altCountsByGene[:, :, 1]\n",
    "\n",
    "altCountsFlat = []\n",
    "for geneIdx in range(nGenes):\n",
    "    altCountsFlat.append([ctrlCounts[geneIdx], *altCountsByGene[geneIdx, :, 1].flatten()])\n",
    "altCountsFlat = tensor(altCountsFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altCountsFlat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DirichletMultinomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "K = 4  # Fixed number of components.\n",
    "\n",
    "@config_enumerate\n",
    "def model(data):\n",
    "    # Global variables.\n",
    "    weights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(K)))\n",
    "    alpha0 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "    alpha1 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "    alpha2 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "    alpha3 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "\n",
    "    with pyro.plate('components', K):\n",
    "        concentrations = pyro.sample('concentrations', dist.Dirichlet(0.5 * torch.ones(K)))\n",
    "\n",
    "    with pyro.plate('data', len(data)):\n",
    "        # Local variables.\n",
    "        component = pyro.sample('assignment', dist.Categorical(weights))\n",
    "        print(f\"concentrations: {concentrations[component]}\")\n",
    "        pyro.sample('obs', DirichletMultinomial(concentration=concentrations[component], total_count=data.sum(1)), obs=data)\n",
    "\n",
    "optim = pyro.optim.Adam({'lr': 0.1, 'betas': [0.8, 0.99]})\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_loc_fn(site):\n",
    "    if site[\"name\"] == \"weights\":\n",
    "        # Initialize weights to uniform.\n",
    "        return torch.ones(K) / K\n",
    "    if site[\"name\"] == \"concentrations\":\n",
    "        return torch.ones(K) / K\n",
    "    raise ValueError(site[\"name\"])\n",
    "\n",
    "def initialize(seed):\n",
    "    global global_guide, svi\n",
    "    pyro.set_rng_seed(seed)\n",
    "    pyro.clear_param_store()\n",
    "    global_guide = AutoDelta(poutine.block(model, expose=['weights', 'concentrations']),\n",
    "                             init_loc_fn=init_loc_fn)\n",
    "    svi = SVI(model, global_guide, optim, loss=elbo)\n",
    "    return svi.loss(model, global_guide, altCountsFlat)\n",
    "\n",
    "# Choose the best among 100 random initializations.\n",
    "loss, seed = min((initialize(seed), seed) for seed in range(2))\n",
    "initialize(seed)\n",
    "print('seed = {}, initial_loss = {}'.format(seed, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register hooks to monitor gradient norms.\n",
    "gradient_norms = defaultdict(list)\n",
    "for name, value in pyro.get_param_store().named_parameters():\n",
    "    value.register_hook(lambda g, name=name: gradient_norms[name].append(g.norm().item()))\n",
    "\n",
    "losses = []\n",
    "for i in range(200 if not smoke_test else 2):\n",
    "    loss = svi.step(altCountsFlat)\n",
    "    losses.append(loss)\n",
    "    print('.' if i % 100 else '\\n', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-b35e8b608158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(figsize=(10,3), dpi=100).set_facecolor('white')\n",
    "pyplot.plot(losses)\n",
    "pyplot.xlabel('iters')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.yscale('log')\n",
    "pyplot.title('Convergence of SVI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, grad_norms in gradient_norms.items():\n",
    "    pyplot.plot(grad_norms, label=name)\n",
    "pyplot.xlabel('iters')\n",
    "pyplot.ylabel('gradient norm')\n",
    "pyplot.yscale('log')\n",
    "pyplot.legend(loc='best')\n",
    "pyplot.title('Gradient norms during SVI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimates = global_guide(altCountsFlat)\n",
    "weights = map_estimates['weights']\n",
    "locs = map_estimates['concentrations']\n",
    "print('weights = {}'.format(weights.data.numpy()))\n",
    "print('concentrations = {}'.format(locs.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([0.8973397  , 0.0494441,  0.04917945, 0.00403667])).sample([10_000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
