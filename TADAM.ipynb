{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "!pip install --upgrade torch\n",
    "!pip install --upgrade pyro-ppl\n",
    "!pip install --upgrade scipy\n",
    "!pip install --upgrade matplotlib\n",
    "!pip install --upgrade scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import torch.tensor as tensor\n",
    "import pyro.distributions as dist\n",
    "# from torch.distributions import Binomial, Gamma, Uniform\n",
    "from pyro.distributions import Binomial, Bernoulli, Categorical, Dirichlet, DirichletMultinomial, Beta, BetaBinomial, Uniform, Gamma, Multinomial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from skopt import gp_minimize \n",
    "from scipy.stats import binom as ScipyBinom\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from collections import namedtuple\n",
    "import time\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN\n"
     ]
    }
   ],
   "source": [
    "from mvl import genData, likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "r5 = genData.v5(**genData.genParams(rrMeans=tensor([5., 5., 2.]), pis=tensor([.05, .05, .05]))[0])\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r5afs = r5[\"afs\"]\n",
    "r5afs[0:1000].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "r6 = genData.v6(**genData.genParams(rrMeans=tensor([5., 5., 2.]), pis=tensor([.05, .05, .05]))[0])\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r6afs = r6[\"afs\"]\n",
    "r6afs[0:1000].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "r7 = genData.v7(**genData.genParams(rrMeans=tensor([5., 5., 2.]), pis=tensor([.05, .05, .05]))[0])\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "r6normal = genData.v6normal(**genData.genParams(rrMeans=tensor([5., 5., 2.]), pis=tensor([.05, .05, .05]))[0])\n",
    "print(\"took\", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "r7run2 = genData.v7(**genData.genParams(rrMeans=tensor([5., 5., 2.]), pis=tensor([.05, .05, .05]))[0])\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r7afs = r7[\"afs\"]\n",
    "cBothgenes = r7[\"affectedGenes\"][2]\n",
    "\n",
    "diff57 = (abs(r7afs[cBothgenes] - r5afs[cBothgenes])/r7afs[cBothgenes])\n",
    "print(\"mean vs 5\", diff57.mean(0))\n",
    "\n",
    "r7run2afs = r7run2[\"afs\"]\n",
    "diffrun2 = (abs(r7afs[cBothgenes] - r7run2afs[cBothgenes])/r7afs[cBothgenes])\n",
    "print(\"mean vs 7run2\", diffrun2.mean(0))\n",
    "print(\"std vs 5\", diff57.std(0))\n",
    "print(\"std vs 7run2\", diffrun2.std(0))\n",
    "\n",
    "print(\"difference in means\",  diff57.mean(0) - diffrun2.mean(0))\n",
    "\n",
    "print(\"difference in std\",  diff57.std(0) - diffrun2.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r7afs = r7[\"afs\"]\n",
    "cBothgenes = r7[\"affectedGenes\"][2]\n",
    "\n",
    "diff67 = (abs(r7afs[cBothgenes] - r6afs[cBothgenes])/r7afs[cBothgenes])\n",
    "print(\"mean vs 6\", diff67.mean(0))\n",
    "\n",
    "r7run2afs = r7run2[\"afs\"]\n",
    "diffrun2 = (abs(r7afs[cBothgenes] - r7run2afs[cBothgenes])/r7afs[cBothgenes])\n",
    "print(\"mean vs 7run2\", diffrun2.mean(0))\n",
    "print(\"std vs 5\", diff67.std(0))\n",
    "print(\"std vs 7run2\", diffrun2.std(0))\n",
    "\n",
    "print(\"difference in means\",  abs(diff67.mean(0) - diffrun2.mean(0)))\n",
    "\n",
    "print(\"difference in std\",  abs(diff67.std(0) - diffrun2.std(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(r7[\"afs\"][2000:3000, 1], r7[\"afs\"][2000:3000, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flattenedData4)\n",
    "pyplot.clf()\n",
    "pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(cachedData4b[-1][0][\"afsPooled\"][:, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"corr for 1 & both in both\", np.corrcoef(afsFlatPooled4[4000:5000, 2], afsFlatPooled4[4000:5000, 3]))\n",
    "print(\"corr for 1 & both in 1only\", np.corrcoef(afsFlatPooled4[0:2000, 1], afsFlatPooled4[0:2000, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(afsFlatPooled2[0:5000, 3].mean())\n",
    "afsFlatPooled2[5000:, 3].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"empirical rr for both\", afsFlatPooled4[0:5000, 3].mean()/ afsFlatPooled4[5000:, 3].mean())\n",
    "print(\"empirical rr for 1\", ((afsFlatPooled4[0:2000, 1].mean()))/ afsFlatPooled4[2000:4000, 1].mean())\n",
    "print(\"empirical rr for 2\", ((afsFlatPooled4[2000:4000, 2].mean() + afsFlatPooled4[4000:5000, 2].mean())/2)/ afsFlatPooled4[:2000, 2].mean())\n",
    "# print(\"nullLikelihoodGlobal 1\", (nullLikelihoodsGlobal[0:2000, 0] + nullLikelihoodsGlobal[4000:5000, 0]).mean(), nullLikelihoodsGlobal[2000:, 0].mean())\n",
    "# print(\"nullLikelihoodGlobal 2\", nullLikelihoodsGlobal[2000:4000, 1].mean(), nullLikelihoodsGlobal[4000:, 1].mean())\n",
    "# print(\"nullLikelihoodGlobal Both\", nullLikelihoodsGlobal[4000:5000, 2].mean(), nullLikelihoodsGlobal[0:4000, 2].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llPooledBivariateSingleGene(tensor([10.,1.,1.,20000.]), tensor([.01,.01,.05]), tensor(13.), tensor(10.), tensor(10.), tensor(100000.), tensor(.77), tensor(.1), tensor(.1), tensor(.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this gives -2.401 log(likelihoodUnivariateSingleGene(xCtrl = 10, xCase1 = 1, prevalence1 = .01, pi0 = .9, pi1 = .1, pDiseaseGivenVariant = .001))\n",
    "#tensor(-2.5290): llUnivariateSingleGeneJensen(xCtrl = tensor(10.), xCase = tensor(1.), pD = tensor(.01), pi0 = tensor(.9), pi1 = tensor(.1), pDgivenV = tensor(.001))\n",
    "r = llUnivariateSingleGeneNoJensen(xCtrl = tensor(10.), xCase = tensor(1.), pD = tensor(.01), pi0 = tensor(.9), pi1 = tensor(.1), pDgivenV = tensor(.001))\n",
    "assert(abs(-r + tensor(-2.4010)) < .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altCounts = tensor([10., 2., 3., 1.])\n",
    "n = altCounts.sum()\n",
    "\n",
    "testAlpha = tensor([16., 20., 30., 15.])\n",
    "print(f\"test data: testAlpha: {testAlpha}, n: {n}, altCounts: {altCounts}\")\n",
    "DirichletMultinomial(total_count=n, concentration=testAlpha).log_prob(altCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV(.01, afsByGene[0:2000, 0, 1], 1e-4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test functions\n",
    "pDgivenV(.01, afsByGeneRR2[0:2000, 0, 1], afsByGeneRR2Shape5[0:2000, 0, 0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance is wrong\n",
    "def betaVariance(alpha, beta):\n",
    "    return (alpha * beta) / ( ((alpha + beta)**2) + (alpha + beta + 1) )\n",
    "\n",
    "def betaMean(alpha, beta):\n",
    "    return alpha / (alpha + beta)\n",
    "\n",
    "print(\"variance\", betaVariance(6.47e1,5.39e3))\n",
    "print(\"mean\", betaMean(6.47e1,5.39e3))\n",
    "print(\"true varianc\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = afsByGene[0:2000, 0, 1].mean()\n",
    "m2 = afsByGeneRR2[0:2000, 0, 1].mean()/afsByGeneRR2[2000:, 0, 1].mean()\n",
    "m1 - m2\n",
    "print(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res = fitFnUniveriate(altCountsByGene, pDs, nEpochs=20, minLLThresholdCount=20, debug=True)\n",
    "print((time.time() - start) / 20, \"per iteration\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriate(altCountsByGeneRR2, pDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV(pDs[0], afsByGeneRR2Shape5[0:2000, 0, 1], afsByGeneRR2Shape5[0:2000, 0, 0]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriate(altCounts, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR2, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR2Shape5, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(2.23307950e+02, 2.52700651e+04).sample([10_000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(2.20865706e+02, 1.73544747e+04).sample([10_000,]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR3, pDs, nEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(2.50432693e+02, 1.87756988e+04).sample([10_000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriate(altCountsByGeneRR3, pDs, nEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(3.84376856e+02, 2.37879954e+04).sample([10_000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsRR2Shape5 = []\n",
    "for i in range(1):\n",
    "    res = fitFnUniveriateBetaBinomial(altCountsByGeneRR2Shape5, pDs, nEpochs=50, minLLThresholdCount=50, debug=False)\n",
    "    resultsRR2Shape5.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsRR2Shape5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(1.96912591e+02, 1.61461738e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=50, minLLThresholdCount=50, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(3.30289057e+03, 2.94460355e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't really work resConstrained = fitFnUniveriateBetaBinomialConstrained(altCountsByGeneRR2Shape5, pDs, nEpochs=10, minLLThresholdCount=10, debug=True)\n",
    "#resConstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=10, minLLThresholdCount=10, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": []}\n",
    "cachedData = [[altCountsByGenePooledCtrls, afsByGenePooledCtrls, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean\n",
    "        }]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": [], \"costFnIdx\": []}\n",
    "cachedData2 = [[altCountsByGenePooledCtrls2, afsByGenePooledCtrls2, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean,\n",
    "        }]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i >= len(cachedData):\n",
    "        start = time.time()\n",
    "        altCountsByGenePooledCtrls, afsByGenePooledCtrls = genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData.append([altCountsByGenePooledCtrls, afsByGenePooledCtrls, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean\n",
    "        }])\n",
    "        \n",
    "    res = fitFnBivariate(cachedData[i][0], pDsGlobalLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=0)\n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3])\n",
    "    print(\"inferredPis\", inferredPis)\n",
    "    inferredAlphas = tensor(bestRes[3:])\n",
    "    print(\"inferredAlphas\", inferredAlphas)\n",
    "    \n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "    params[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params[\"inferredPis\"].append(inferredPis)\n",
    "    params[\"inferredPDVs\"].append(inferredPDs)\n",
    "\n",
    "    truth1 = pDgivenV(pDsGlobalLarge[0], afsByGenePooledCtrls[0:2000, 0, 1], afsByGenePooledCtrls[0:2000, 0, 0]).mean()\n",
    "    truth2 = pDgivenV(pDsGlobalLarge[1], afsByGenePooledCtrls[2000:4000, 1, 1], afsByGenePooledCtrls[2000:4000, 0, 0]).mean()\n",
    "    truth3 = pDgivenV(pDsGlobalLarge[2], afsByGenePooledCtrls[4000:5000, 2, 1], afsByGenePooledCtrls[4000:5000, 0, 0]).mean()\n",
    "    truth0 = 1 - (truth1 + truth2 + truth3)\n",
    "    print(\"truth0\", truth0, \"truth1\", truth1, \"truth2\", truth2, \"truthBoth\", truth3)\n",
    "\n",
    "    params[\"trueMeanPDVs\"].append(tensor([truth0, truth1, truth2, truth3]))\n",
    "    params[\"truePis\"].append(tensor(diseaseFractions))\n",
    "\n",
    "    print(f\"params on run {i}\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i >= len(cachedData2):\n",
    "        start = time.time()\n",
    "        altCountsByGenePooledCtrls2, afsByGenePooledCtrls2 = genDataSequentialPooledCtrls(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData2.append([altCountsByGenePooledCtrls2, afsByGenePooledCtrls2, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean,\n",
    "        }])\n",
    "    runCostFnIdx = 6\n",
    "    # todo append all entries to indciate failure\n",
    "    params2[\"costFnIdx\"].append(runCostFnIdx)\n",
    "\n",
    "    res = fitFnBivariate(cachedData2[i][0], pDsGlobalLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "    \n",
    "    \n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3])\n",
    "    print(\"inferredPis\", inferredPis)\n",
    "    inferredAlphas = tensor(bestRes[3:])\n",
    "    print(\"inferredAlphas\", inferredAlphas)\n",
    "    \n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "    params2[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params2[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params2[\"inferredPis\"].append(inferredPis)\n",
    "    params2[\"inferredPDVs\"].append(inferredPDs)\n",
    "\n",
    "    truth1 = pDgivenV(pDsGlobalLarge[0], cachedData2[i][1][0:2000, 0, 1], cachedData2[i][1][0:2000, 0, 0]).mean()\n",
    "    truth2 = pDgivenV(pDsGlobalLarge[1], cachedData2[i][1][2000:4000, 1, 1], cachedData2[i][1][2000:4000, 0, 0]).mean()\n",
    "    truth3 = pDgivenV(pDsGlobalLarge[2], cachedData2[i][1][4000:5000, 2, 1], cachedData2[i][1][4000:5000, 0, 0]).mean()\n",
    "    truth0 = 1 - (truth1 + truth2 + truth3)\n",
    "    print(\"truth0\", truth0, \"truth1\", truth1, \"truth2\", truth2, \"truthBoth\", truth3)\n",
    "\n",
    "    params2[\"trueMeanPDVs\"].append(tensor([truth0, truth1, truth2, truth3]))\n",
    "    params2[\"truePis\"].append(tensor(diseaseFractions))\n",
    "    \n",
    "    print(f\"params on run {i}\", params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": [], \"costFnIdx\": []}\n",
    "cachedData3 = [[altCountsByGenePooledCtrls3, afsByGenePooledCtrls3, {\n",
    "            \"nCases\": nCasesLarge,\n",
    "            \"nCtrls\": nCtrlsLarge,\n",
    "            \"pDs\": pDsGlobalLarge,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean,\n",
    "        }]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4 = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"truePDVs\": [], \"truePis\": [], \"costFnIdx\": []}\n",
    "# altCountsByGenePooledCtrls4, afsByGenePooledCtrls4, affectedGenes4 = genData4(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedData4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 5):\n",
    "    if i >= len(cachedData4):\n",
    "        \n",
    "        params = genParams()[0]\n",
    "        start = time.time()\n",
    "        xsPooledRun, afsPooledRun, affectedGenesRun, unaffectedGenesRun = genData4(**params)\n",
    "\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData4.append({\n",
    "            \"xsPooled\": xsPooledRun,\n",
    "            \"afsPooled\": afsPooledRun,\n",
    "            \"affectedGenes\": affectedGenesRun,\n",
    "            \"unaffectedGenes\": unaffectedGenesRun,\n",
    "            \"params\": params,\n",
    "        })\n",
    "    cd = cachedData4[i]\n",
    "    xsPooledRun = cd[\"xsPooled\"]\n",
    "    afsPooledRun = cd[\"afsPooled\"]\n",
    "    affectedGenesRun = cd[\"affectedGenes\"]\n",
    "    unaffectedGenesRun = cd[\"unaffectedGenes\"]\n",
    "\n",
    "    pDsRun = cd[\"params\"][\"pDs\"]\n",
    "    pisRun = cd[\"params\"][\"diseaseFractions\"]\n",
    "\n",
    "    runCostFnIdx = 15\n",
    "    res = fitFnBivariate(xsPooledRun, pDsRun, nEpochs=3, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "    \n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "    inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "    # index 0 is the P(!D|V), aka probability of being a control given variant present\n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "    \n",
    "    inferredPiProp1 = inferredPis[0] / (inferredPis[0] + inferredPis[2])\n",
    "    inferredPiProp2 = inferredPis[1] / (inferredPis[1] + inferredPis[2])\n",
    "    \n",
    "    PDctrlV = inferredPDs[0]\n",
    "    PD1V = inferredPDs[1]\n",
    "    PD2V = inferredPDs[2]\n",
    "    PDBothV = inferredPDs[1]\n",
    "    \n",
    "    inferredC1PDgivenV = inferredPiProp1 * PD1V + (1 - inferredPiProp1) * (PD1V + PDBothV * pDsRun[0]/pDsRun[2])\n",
    "    inferredC2PDgivenV = inferredPiProp2 * PD2V + (1 - inferredPiProp2) * (PD2V + PDBothV * pDsRun[1]/pDsRun[2])\n",
    "    inferredCBothPDgivenV = (inferredPis[0] / inferredPis.sum()) * PD1V * pDsRun[2]/pDsRun[0] + (inferredPis[1] / inferredPis.sum()) * PD2V * pDsRun[2]/pDsRun[1] + (inferredPis[2] / inferredPis.sum()) * PDBothV\n",
    "    \n",
    "    inferredPDGivenVs = tensor([inferredC1PDgivenV, inferredC2PDgivenV, inferredCBothPDgivenV])\n",
    "    \n",
    "    piProp1 = pisRun[0] / (pisRun[0] + pisRun[2])\n",
    "    piProp2 = pisRun[1] / (pisRun[1] + pisRun[2])\n",
    "    \n",
    "    PV_hat = afsPooledRun[unaffectedGenesRun].mean()\n",
    "    \n",
    "    trueC1PVgivenD = piProp1 * afsPooledRun[affectedGenesRun[0], 0, 1].mean() + (1-piProp1) * afsPooledRun[affectedGenesRun[2], 0, 1].mean()\n",
    "    trueC2PVgivenD = piProp2 * afsPooledRun[affectedGenesRun[1], 1, 1].mean() + (1-piProp2) * afsPooledRun[affectedGenesRun[2], 1, 1].mean()\n",
    "    trueCBothPVgivenD = (pisRun[0] / pisRun.sum()) * afsPooledRun[affectedGenesRun[0], 2, 1].mean() + (pisRun[1] / pisRun.sum()) * afsPooledRun[affectedGenesRun[1], 2, 1].mean() + (pisRun[2] / pisRun.sum()) * afsPooledRun[affectedGenesRun[2], 2, 1].mean()\n",
    "    \n",
    "    trueC1PDgivenV = pDgivenV(pD=pDsRun[0], pVgivenD=trueC1PVgivenD, pV=PV_hat)\n",
    "    trueC2PDgivenV = pDgivenV(pD=pDsRun[1], pVgivenD=trueC2PVgivenD, pV=PV_hat)\n",
    "    trueCBothPDgivenV = pDgivenV(pD=pDsRun[2], pVgivenD=trueCBothPVgivenD, pV=PV_hat)\n",
    "    \n",
    "    \n",
    "    truePDGivenVs = tensor([trueC1PDgivenV, trueC2PDgivenV, trueCBothPDgivenV])\n",
    "    print(\"\\ninferredPis\", inferredPis)\n",
    "    print(\"\\ninferredPDVs raw\", inferredPDs)\n",
    "    print(\"\\ninferredPDVs scaled\", inferredPDGivenVs)\n",
    "    print(\"\\ntruePDGivenVs\", truePDGivenVs)\n",
    "    \n",
    "    params4[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params4[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params4[\"inferredPis\"].append(inferredPis)\n",
    "    params4[\"inferredPDVs\"].append(inferredPDGivenVs)\n",
    "    params4[\"truePDVs\"].append(truePDGivenVs)\n",
    "    params4[\"truePis\"].append(pisRun)\n",
    "    \n",
    "    params4[\"costFnIdx\"].append(runCostFnIdx)\n",
    "\n",
    "    print(f\"\\n\\nparams on run {i}\\n\", params4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piProp1 = pisRun[0] / (pisRun[0] + pisRun[2])\n",
    "piProp2 = pisRun[1] / (pisRun[1] + pisRun[2])\n",
    "\n",
    "PV_hat = afsPooledRun[unaffectedGenesRun].mean()\n",
    "\n",
    "afs1 = afsPooledRun[affectedGenesRun[0], 0, 1].mean()\n",
    "piProp1 * afsPooledRun[affectedGenesRun[0], 0, 1].mean() + (1-piProp1) * ( afsPooledRun[affectedGenesRun[2], 0, 1].mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferredPiProp1 = inferredPis[0] / inferredPis.sum()\n",
    "inferredPiProp2 = inferredPis[1] / inferredPis.sum()\n",
    "inferredPiProp3 = inferredPis[2] / inferredPis.sum()\n",
    "inferredPis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferredPiProp1 = inferredPis[0] / (inferredPis[0] + inferredPis[2])\n",
    "PDctrlV = inferredPDs[0]\n",
    "PD1V = inferredPDs[1]\n",
    "PD2V = inferredPDs[2]\n",
    "PDBothV = inferredPDs[1]\n",
    "\n",
    "inferredC1PDgivenV = inferredPiProp1 * PD1V + (1 - inferredPiProp1) * (PD1V + PDBothV * pDsRun[0]/pDsRun[2])\n",
    "inferredC2PDgivenV = inferredPiProp2 * PD2V + (1 - inferredPiProp2) * (PD2V + PDBothV * pDsRun[1]/pDsRun[2])\n",
    "inferredCBothPDgivenV = inferredPiProp1 * PD1V * pDsRun[2]/pDsRun[0] + inferredPiProp2 * PD2V * pDsRun[2]/pDsRun[1] + inferredPiProp3 * PDBothV\n",
    "\n",
    "inferredC1PDgivenV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piProp2 * afsPooledRun[affectedGenesRun[1], 1, 1].mean() + (1-piProp2) * afsPooledRun[affectedGenesRun[2], 1, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afsPooledRun[affectedGenesRun[2], 0, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afsPooledRun[1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piProp1 * afsPooledRun[affectedGenesRun[0], 0, 1].mean() + (1-piProp1) * afsPooledRun[affectedGenesRun[2], 0, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "inferredPiProp1 = inferredPis[0] / inferredPis.sum()\n",
    "inferredPiProp2 = inferredPis[1] / inferredPis.sum()\n",
    "\n",
    "inferredC1PDgivenV = inferredPiProp1 * inferredPDs[1] + (1 - inferredPiProp1) * (inferredPDs[1] + inferredPDs[3] * pDsRun[0]/pDsRun[2])\n",
    "inferredC2PDgivenV = inferredPiProp2 * inferredPDs[2] + (1 - inferredPiProp2) * (inferredPDs[2] + inferredPDs[3] * pDsRun[1]/pDsRun[2])\n",
    "inferredCBothPDgivenV = inferredPiProp1 * inferredPDs[1] * pDsRun[2]/pDsRun[0] + inferredPiProp2 * inferredPDs[2] * pDsRun[2]/pDsRun[1] + (1 - inferredPiProp1 - inferredPiProp2) * inferredPDs[3]\n",
    "inferredCBothPDgivenV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4b = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"truePDVs\": [], \"truePis\": [], \"costFnIdx\": []}\n",
    "# altCountsByGenePooledCtrls4, afsByGenePooledCtrls4, affectedGenes4 = genData4(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedData4b = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    if i >= len(cachedData4b):\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        params = genParams(rrMeans=tensor([5., 5., 2.]), pis=tensor([.05, .05, .05]))[0]\n",
    "        start = time.time()\n",
    "        xsPooledRun, afsPooledRun, affectedGenesRun, unaffectedGenesRun = genData4(**params)\n",
    "\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData4b.append({\n",
    "            \"xsPooled\": xsPooledRun,\n",
    "            \"afsPooled\": afsPooledRun,\n",
    "            \"affectedGenes\": affectedGenesRun,\n",
    "            \"unaffectedGenes\": unaffectedGenesRun,\n",
    "            \"params\": params,\n",
    "        })\n",
    "    xsPooledRun = cachedData4b[i][\"xsPooled\"]\n",
    "    afsPooledRun = cachedData4b[i][\"afsPooled\"]\n",
    "    affectedGenesRun = cachedData4b[i][\"affectedGenes\"]\n",
    "    unaffectedGenesRun = cachedData4b[i][\"unaffectedGenes\"]\n",
    "    pDsRun = cachedData4b[i][\"params\"][\"pDs\"]\n",
    "    pisRun = cachedData4b[i][\"params\"][\"diseaseFractions\"]\n",
    "\n",
    "    print(\"i is\", i)\n",
    "    print(\"params are:\", cachedData4b[i][\"params\"])\n",
    "    runCostFnIdx = 15\n",
    "    res = fitFnBivariate(xsPooledRun, pDsRun, nEpochs=10, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "    \n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "    inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "    # index 0 is the P(!D|V), aka probability of being a control given variant present\n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "    \n",
    "    inferredPiProp1 = inferredPis[0] / inferredPis.sum()\n",
    "    inferredPiProp2 = inferredPis[1] / inferredPis.sum()\n",
    "    \n",
    "    inferredC1PDgivenV = inferredPiProp1 * inferredPDs[1] + (1 - inferredPiProp1) * (inferredPDs[1] + inferredPDs[3] * pDsRun[0]/pDsRun[2])\n",
    "    inferredC2PDgivenV = inferredPiProp2 * inferredPDs[2] + (1 - inferredPiProp2) * (inferredPDs[2] + inferredPDs[3] * pDsRun[1]/pDsRun[2])\n",
    "    inferredCBothPDgivenV = (inferredPis[0] / inferredPis.sum()) * inferredPDs[1] * pDsRun[2]/pDsRun[0] + (inferredPis[1] / inferredPis.sum()) * inferredPDs[2] * pDsRun[2]/pDsRun[1] + (inferredPis[2] / inferredPis.sum()) * inferredPDs[3]\n",
    "\n",
    "    piProp1 = pisRun[0] / (pisRun[0] + pisRun[2])\n",
    "    piProp2 = pisRun[1] / (pisRun[1] + pisRun[2])\n",
    "    \n",
    "    PV_hat = afsPooledRun[unaffectedGenesRun].mean()\n",
    "    \n",
    "    trueC1PVgivenD = piProp1 * afsPooledRun[affectedGenesRun[0], 0, 1].mean() + (1-piProp1) * afsPooledRun[affectedGenesRun[2], 0, 1].mean()\n",
    "    trueC2PVgivenD = piProp2 * afsPooledRun[affectedGenesRun[1], 1, 1].mean() + (1-piProp2) * afsPooledRun[affectedGenesRun[2], 1, 1].mean()\n",
    "    trueCBothPVgivenD = (pisRun[0] / pisRun.sum()) * afsPooledRun[affectedGenesRun[0], 2, 1].mean() + (pisRun[1] / pisRun.sum()) * afsPooledRun[affectedGenesRun[1], 2, 1].mean() + (pisRun[2] / pisRun.sum()) * afsPooledRun[affectedGenesRun[2], 2, 1].mean()\n",
    "    \n",
    "    trueC1PDgivenV = pDgivenV(pD=pDsRun[0], pVgivenD=trueC1PVgivenD, pV=PV_hat)\n",
    "    trueC2PDgivenV = pDgivenV(pD=pDsRun[1], pVgivenD=trueC2PVgivenD, pV=PV_hat)\n",
    "    trueCBothPDgivenV = pDgivenV(pD=pDsRun[2], pVgivenD=trueCBothPVgivenD, pV=PV_hat)\n",
    "    \n",
    "    inferredPDGivenVs = tensor([inferredC1PDgivenV, inferredC2PDgivenV, inferredCBothPDgivenV])\n",
    "    truePDGivenVs = tensor([trueC1PDgivenV, trueC2PDgivenV, trueCBothPDgivenV])\n",
    "    print(\"\\ninferredPis\", inferredPis)\n",
    "    print(\"\\ninferredPDVs\", inferredPDGivenVs)\n",
    "    print(\"\\ntruePDGivenVs\", truePDGivenVs)\n",
    "    \n",
    "    params4b[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params4b[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params4b[\"inferredPis\"].append(inferredPis)\n",
    "    params4b[\"inferredPDVs\"].append(inferredPDGivenVs)\n",
    "    params4b[\"truePDVs\"].append(truePDGivenVs)\n",
    "    params4b[\"truePis\"].append(pisRun)\n",
    "    \n",
    "    params4b[\"costFnIdx\"].append(runCostFnIdx)\n",
    "\n",
    "    print(f\"\\n\\nparams on run {i}\\n\", params4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4c = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"truePDVs\": [], \"truePis\": [], \"costFnIdx\": []}\n",
    "# altCountsByGenePooledCtrls4, afsByGenePooledCtrls4, affectedGenes4 = genData4(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "cachedData4c = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pafor i in range(2):\n",
    "    if i >= len(cachedData4c):\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        params = genParams(rrMeans=tensor([5., 5., 2.]), pis=tensor([.05, .05, .05]))[0]\n",
    "        start = time.time()\n",
    "        xsPooledRun, afsPooledRun, affectedGenesRun, unaffectedGenesRun = genData4c(**params)\n",
    "\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData4c.append({\n",
    "            \"xsPooled\": xsPooledRun,\n",
    "            \"afsPooled\": afsPooledRun,\n",
    "            \"affectedGenes\": affectedGenesRun,\n",
    "            \"unaffectedGenes\": unaffectedGenesRun,\n",
    "            \"params\": params,\n",
    "        })\n",
    "    xsPooledRun = cachedData4c[i][\"xsPooled\"]\n",
    "    afsPooledRun = cachedData4c[i][\"afsPooled\"]\n",
    "    affectedGenesRun = cachedData4c[i][\"affectedGenes\"]\n",
    "    unaffectedGenesRun = cachedData4c[i][\"unaffectedGenes\"]\n",
    "    pDsRun = cachedData4c[i][\"params\"][\"pDs\"]\n",
    "    pisRun = cachedData4c[i][\"params\"][\"diseaseFractions\"]\n",
    "\n",
    "    print(\"i is\", i)\n",
    "    print(\"params are:\", cachedData4c[i][\"params\"])\n",
    "    runCostFnIdx = 15\n",
    "    res = fitFnBivariate(xsPooledRun, pDsRun, nEpochs=10, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)pa\n",
    "    \n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "    inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "    # index 0 is the P(!D|V), aka probability of being a control given variant present\n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "    \n",
    "    inferredPiProp1 = inferredPis[0] / inferredPis.sum()\n",
    "    inferredPiProp2 = inferredPis[1] / inferredPis.sum()\n",
    "    \n",
    "    inferredC1PDgivenV = inferredPiProp1 * inferredPDs[1] + (1 - inferredPiProp1) * (inferredPDs[1] + inferredPDs[3] * pDsRun[0]/pDsRun[2])\n",
    "    inferredC2PDgivenV = inferredPiProp2 * inferredPDs[2] + (1 - inferredPiProp2) * (inferredPDs[2] + inferredPDs[3] * pDsRun[1]/pDsRun[2])\n",
    "    inferredCBothPDgivenV = (inferredPis[0] / inferredPis.sum()) * inferredPDs[1] * pDsRun[2]/pDsRun[0] + (inferredPis[1] / inferredPis.sum()) * inferredPDs[2] * pDsRun[2]/pDsRun[1] + (inferredPis[2] / inferredPis.sum()) * inferredPDs[3]\n",
    "\n",
    "    piProp1 = pisRun[0] / (pisRun[0] + pisRun[2])\n",
    "    piProp2 = pisRun[1] / (pisRun[1] + pisRun[2])\n",
    "    \n",
    "    PV_hat = afsPooledRun[unaffectedGenesRun].mean()\n",
    "    \n",
    "    trueC1PVgivenD = piProp1 * afsPooledRun[affectedGenesRun[0], 0, 1].mean() + (1-piProp1) * afsPooledRun[affectedGenesRun[2], 0, 1].mean()\n",
    "    trueC2PVgivenD = piProp2 * afsPooledRun[affectedGenesRun[1], 1, 1].mean() + (1-piProp2) * afsPooledRun[affectedGenesRun[2], 1, 1].mean()\n",
    "    trueCBothPVgivenD = (pisRun[0] / pisRun.sum()) * afsPooledRun[affectedGenesRun[0], 2, 1].mean() + (pisRun[1] / pisRun.sum()) * afsPooledRun[affectedGenesRun[1], 2, 1].mean() + (pisRun[2] / pisRun.sum()) * afsPooledRun[affectedGenesRun[2], 2, 1].mean()\n",
    "    \n",
    "    trueC1PDgivenV = pDgivenV(pD=pDsRun[0], pVgivenD=trueC1PVgivenD, pV=PV_hat)\n",
    "    trueC2PDgivenV = pDgivenV(pD=pDsRun[1], pVgivenD=trueC2PVgivenD, pV=PV_hat)\n",
    "    trueCBothPDgivenV = pDgivenV(pD=pDsRun[2], pVgivenD=trueCBothPVgivenD, pV=PV_hat)\n",
    "    \n",
    "    inferredPDGivenVs = tensor([inferredC1PDgivenV, inferredC2PDgivenV, inferredCBothPDgivenV])\n",
    "    truePDGivenVs = tensor([trueC1PDgivenV, trueC2PDgivenV, trueCBothPDgivenV])\n",
    "    print(\"\\ninferredPis\", inferredPis)\n",
    "    print(\"\\ninferredPDVs\", inferredPDGivenVs)\n",
    "    print(\"\\ntruePDGivenVs\", truePDGivenVs)\n",
    "    \n",
    "    params4c[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params4c[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params4c[\"inferredPis\"].append(inferredPis)\n",
    "    params4c[\"inferredPDVs\"].append(inferredPDGivenVs)\n",
    "    params4c[\"truePDVs\"].append(truePDGivenVs)\n",
    "    params4c[\"truePis\"].append(pisRun)\n",
    "    \n",
    "    params4c[\"costFnIdx\"].append(runCostFnIdx)\n",
    "\n",
    "    print(f\"\\n\\nparams on run {i}\\n\", params4c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params5 = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"truePDVs\": [], \"params\": [], \"costFnIdx\": [], \"generatingFn\": []}\n",
    "# altCountsByGenePooledCtrls4, afsByGenePooledCtrls4, affectedGenes4 = genData4(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "\n",
    "cachedData5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    if i >= len(cachedData5):\n",
    "        generatingFn = genData5\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        params = genParams(rrMeans=tensor([5, 5, 2]), pis=tensor([.1, .1, .05]))\n",
    "        start = time.time()\n",
    "        r = generatingFn(**params[0])\n",
    "\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData5.append({**r, \"params\": params[0], \"generatingFn\": generatingFn})\n",
    "    print(\"params are:\", cachedData5[i][\"params\"])\n",
    "    xsRun = cachedData5[i][\"altCounts\"]\n",
    "    afsRun = cachedData5[i][\"afs\"]\n",
    "    affectedGenesRun = cachedData5[i][\"affectedGenes\"]\n",
    "    unaffectedGenesRun = cachedData5[i][\"unaffectedGenes\"]\n",
    "    pDsRun = cachedData5[i][\"params\"][\"pDs\"]\n",
    "    pisRun = cachedData5[i][\"params\"][\"diseaseFractions\"]\n",
    "    paramsRun = cachedData5[i][\"params\"]\n",
    "\n",
    "    print(\"i is\", i)\n",
    "    print(\"pis are\", pisRun)\n",
    "    runCostFnIdx = 16\n",
    "    res = fitFnBivariate(xsRun, pDsRun, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "    \n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "    inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "    # index 0 is the P(!D|V), aka probability of being a control given variant present\n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "    \n",
    "    inferredPiProp1 = inferredPis[0] / inferredPis.sum()\n",
    "    inferredPiProp2 = inferredPis[1] / inferredPis.sum()\n",
    "    \n",
    "    inferredC1PDgivenV = inferredPiProp1 * inferredPDs[1] + (1 - inferredPiProp1) * (inferredPDs[1] + inferredPDs[3] * pDsRun[0]/pDsRun[2])\n",
    "    inferredC2PDgivenV = inferredPiProp2 * inferredPDs[2] + (1 - inferredPiProp2) * (inferredPDs[2] + inferredPDs[3] * pDsRun[1]/pDsRun[2])\n",
    "    inferredCBothPDgivenV = (inferredPis[0] / inferredPis.sum()) * inferredPDs[1] * pDsRun[2]/pDsRun[0] + (inferredPis[1] / inferredPis.sum()) * inferredPDs[2] * pDsRun[2]/pDsRun[1] + (inferredPis[2] / inferredPis.sum()) * inferredPDs[3]\n",
    "\n",
    "    \n",
    "    piProp1 = pisRun[0] / (pisRun[0] + pisRun[2])\n",
    "    piProp2 = pisRun[1] / (pisRun[1] + pisRun[2])\n",
    "    \n",
    "    PV_hat = afsRun[unaffectedGenesRun].mean()\n",
    "    \n",
    "    trueC1PVgivenD = piProp1 * afsRun[affectedGenesRun[0], 1].mean() + (1-piProp1) * afsRun[affectedGenesRun[2], 1].mean()\n",
    "    trueC2PVgivenD = piProp2 * afsRun[affectedGenesRun[1], 2].mean() + (1-piProp2) * afsRun[affectedGenesRun[2], 2].mean()\n",
    "    trueCBothPVgivenD = (pisRun[0] / pisRun.sum()) * afsRun[affectedGenesRun[0], 3].mean() + (pisRun[1] / pisRun.sum()) * afsRun[affectedGenesRun[1], 3].mean() + (pisRun[2] / pisRun.sum()) * afsRun[affectedGenesRun[2], 3].mean()\n",
    "    \n",
    "    trueC1PDgivenV = pDgivenV(pD=pDsRun[0], pVgivenD=trueC1PVgivenD, pV=PV_hat)\n",
    "    trueC2PDgivenV = pDgivenV(pD=pDsRun[1], pVgivenD=trueC2PVgivenD, pV=PV_hat)\n",
    "    trueCBothPDgivenV = pDgivenV(pD=pDsRun[2], pVgivenD=trueCBothPVgivenD, pV=PV_hat)\n",
    "    \n",
    "    inferredPDGivenVs = tensor([inferredC1PDgivenV, inferredC2PDgivenV, inferredCBothPDgivenV])\n",
    "    truePDGivenVs = tensor([trueC1PDgivenV, trueC2PDgivenV, trueCBothPDgivenV])\n",
    "    print(\"\\ninferredPis\", inferredPis)\n",
    "    print(\"\\ninferredPDVs\", inferredPDGivenVs)\n",
    "    print(\"\\ntruePDGivenVs\", truePDGivenVs)\n",
    "    \n",
    "    params5[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params5[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params5[\"inferredPis\"].append(inferredPis)\n",
    "    params5[\"inferredPDVs\"].append(inferredPDGivenVs)\n",
    "    params5[\"truePDVs\"].append(truePDGivenVs)\n",
    "    params5[\"params\"].append(paramsRun)\n",
    "    \n",
    "    params5[\"costFnIdx\"].append(runCostFnIdx)\n",
    "    params5[\"generatingFn\"].append(generatingFn)\n",
    "\n",
    "    print(f\"\\n\\nparams on run {i}\\n\", params5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params6 = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"truePDVs\": [], \"params\": [], \"costFnIdx\": [], \"generatingFn\": []}\n",
    "# altCountsByGenePooledCtrls4, afsByGenePooledCtrls4, affectedGenes4 = genData4(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "\n",
    "cachedData6 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedData6 = [cachedData6[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cachedData6), len(cachedData6) + 1):\n",
    "    if i >= len(cachedData6):\n",
    "        generatingFn = genData.v6normal\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        params = genData.genParams(rrMeans=tensor([5, 5, 2]), pis=tensor([.1, .1, .1]))\n",
    "        start = time.time()\n",
    "        r = generatingFn(**params[0])\n",
    "\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData6.append({**r, \"params\": params[0], \"generatingFn\": generatingFn})\n",
    "    print(\"params are:\", cachedData6[i][\"params\"])\n",
    "    xsRun = cachedData6[i][\"altCounts\"]\n",
    "    afsRun = cachedData6[i][\"afs\"]\n",
    "    affectedGenesRun = cachedData6[i][\"affectedGenes\"]\n",
    "    unaffectedGenesRun = cachedData6[i][\"unaffectedGenes\"]\n",
    "    pDsRun = cachedData6[i][\"params\"][\"pDs\"]\n",
    "    pisRun = cachedData6[i][\"params\"][\"diseaseFractions\"]\n",
    "    paramsRun = cachedData6[i][\"params\"]\n",
    "\n",
    "    print(\"i is\", i)\n",
    "    print(\"pis are\", pisRun)\n",
    "    runCostFnIdx = 16\n",
    "    res = likelihoods.fitFnBivariate(xsRun, pDsRun, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "    \n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "    inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "    # index 0 is the P(!D|V), aka probability of being a control given variant present\n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "    \n",
    "    inferredPiProp1 = inferredPis[0] / inferredPis.sum()\n",
    "    inferredPiProp2 = inferredPis[1] / inferredPis.sum()\n",
    "    \n",
    "    inferredC1PDgivenV = inferredPiProp1 * inferredPDs[1] + (1 - inferredPiProp1) * (inferredPDs[1] + inferredPDs[3] * pDsRun[0]/pDsRun[2])\n",
    "    inferredC2PDgivenV = inferredPiProp2 * inferredPDs[2] + (1 - inferredPiProp2) * (inferredPDs[2] + inferredPDs[3] * pDsRun[1]/pDsRun[2])\n",
    "    inferredCBothPDgivenV = (inferredPis[0] / inferredPis.sum()) * inferredPDs[1] * pDsRun[2]/pDsRun[0] + (inferredPis[1] / inferredPis.sum()) * inferredPDs[2] * pDsRun[2]/pDsRun[1] + (inferredPis[2] / inferredPis.sum()) * inferredPDs[3]\n",
    "\n",
    "    \n",
    "    piProp1 = pisRun[0] / (pisRun[0] + pisRun[2])\n",
    "    piProp2 = pisRun[1] / (pisRun[1] + pisRun[2])\n",
    "    \n",
    "    PV_hat = afsRun[unaffectedGenesRun].mean()\n",
    "    \n",
    "    trueC1PVgivenD = piProp1 * afsRun[affectedGenesRun[0], 1].mean() + (1-piProp1) * afsRun[affectedGenesRun[2], 1].mean()\n",
    "    trueC2PVgivenD = piProp2 * afsRun[affectedGenesRun[1], 2].mean() + (1-piProp2) * afsRun[affectedGenesRun[2], 2].mean()\n",
    "    trueCBothPVgivenD = (pisRun[0] / pisRun.sum()) * afsRun[affectedGenesRun[0], 3].mean() + (pisRun[1] / pisRun.sum()) * afsRun[affectedGenesRun[1], 3].mean() + (pisRun[2] / pisRun.sum()) * afsRun[affectedGenesRun[2], 3].mean()\n",
    "    \n",
    "    trueC1PDgivenV = pDgivenV(pD=pDsRun[0], pVgivenD=trueC1PVgivenD, pV=PV_hat)\n",
    "    trueC2PDgivenV = pDgivenV(pD=pDsRun[1], pVgivenD=trueC2PVgivenD, pV=PV_hat)\n",
    "    trueCBothPDgivenV = pDgivenV(pD=pDsRun[2], pVgivenD=trueCBothPVgivenD, pV=PV_hat)\n",
    "    \n",
    "    inferredPDGivenVs = tensor([inferredC1PDgivenV, inferredC2PDgivenV, inferredCBothPDgivenV])\n",
    "    truePDGivenVs = tensor([trueC1PDgivenV, trueC2PDgivenV, trueCBothPDgivenV])\n",
    "    print(\"\\ninferredPis\", inferredPis)\n",
    "    print(\"\\ninferredPDVs\", inferredPDGivenVs)\n",
    "    print(\"\\ntruePDGivenVs\", truePDGivenVs)\n",
    "    \n",
    "    params6[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params6[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params6[\"inferredPis\"].append(inferredPis)\n",
    "    params6[\"inferredPDVs\"].append(inferredPDGivenVs)\n",
    "    params6[\"truePDVs\"].append(truePDGivenVs)\n",
    "    params6[\"params\"].append(paramsRun)\n",
    "    \n",
    "    params6[\"costFnIdx\"].append(runCostFnIdx)\n",
    "    params6[\"generatingFn\"].append(generatingFn)\n",
    "\n",
    "    print(f\"\\n\\nparams on run {i}\\n\", params6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n",
      " final_simplex: (array([[2.45967352e-01, 2.48706016e-01, 2.53089505e-01, 3.01056976e+02,\n",
      "        3.39704477e+03, 3.39149081e+03, 7.68600219e+03],\n",
      "       [2.45967351e-01, 2.48706015e-01, 2.53089504e-01, 3.01056976e+02,\n",
      "        3.39704478e+03, 3.39149078e+03, 7.68600221e+03],\n",
      "       [2.45967354e-01, 2.48706010e-01, 2.53089504e-01, 3.01056976e+02,\n",
      "        3.39704475e+03, 3.39149081e+03, 7.68600222e+03],\n",
      "       [2.45967352e-01, 2.48706012e-01, 2.53089503e-01, 3.01056977e+02,\n",
      "        3.39704478e+03, 3.39149082e+03, 7.68600227e+03],\n",
      "       [2.45967351e-01, 2.48706013e-01, 2.53089503e-01, 3.01056975e+02,\n",
      "        3.39704475e+03, 3.39149078e+03, 7.68600227e+03],\n",
      "       [2.45967353e-01, 2.48706011e-01, 2.53089503e-01, 3.01056977e+02,\n",
      "        3.39704479e+03, 3.39149082e+03, 7.68600224e+03],\n",
      "       [2.45967353e-01, 2.48706013e-01, 2.53089502e-01, 3.01056976e+02,\n",
      "        3.39704477e+03, 3.39149082e+03, 7.68600218e+03],\n",
      "       [2.45967354e-01, 2.48706012e-01, 2.53089502e-01, 3.01056976e+02,\n",
      "        3.39704474e+03, 3.39149083e+03, 7.68600216e+03]]), array([114397.60567515, 114397.60568238, 114397.60569788, 114397.60570335,\n",
      "       114397.60570741, 114397.60571043, 114397.60572265, 114397.60573074]))\n",
      "           fun: 114397.60567515067\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1227\n",
      "           nit: 499\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.45967352e-01, 2.48706016e-01, 2.53089505e-01, 3.01056976e+02,\n",
      "       3.39704477e+03, 3.39149081e+03, 7.68600219e+03])\n",
      "minPrevious 114353.84712578746\n",
      "best ll: 121220.25, bestParams: [tensor(0.0733), tensor(0.3422), tensor(0.1972), tensor(1046.5663), tensor(16260.1797), tensor(7225.0308), tensor(22039.6191)]\n",
      "epoch 7\n",
      " final_simplex: (array([[2.46886842e-01, 2.49333667e-01, 2.51423035e-01, 5.31594302e+02,\n",
      "        6.01822273e+03, 5.98804701e+03, 1.36105497e+04],\n",
      "       [2.46886844e-01, 2.49333666e-01, 2.51423034e-01, 5.31594303e+02,\n",
      "        6.01822271e+03, 5.98804698e+03, 1.36105497e+04],\n",
      "       [2.46886843e-01, 2.49333663e-01, 2.51423036e-01, 5.31594303e+02,\n",
      "        6.01822270e+03, 5.98804704e+03, 1.36105497e+04],\n",
      "       [2.46886843e-01, 2.49333661e-01, 2.51423036e-01, 5.31594302e+02,\n",
      "        6.01822273e+03, 5.98804706e+03, 1.36105497e+04],\n",
      "       [2.46886844e-01, 2.49333661e-01, 2.51423035e-01, 5.31594300e+02,\n",
      "        6.01822267e+03, 5.98804704e+03, 1.36105497e+04],\n",
      "       [2.46886843e-01, 2.49333663e-01, 2.51423035e-01, 5.31594303e+02,\n",
      "        6.01822272e+03, 5.98804705e+03, 1.36105497e+04],\n",
      "       [2.46886844e-01, 2.49333665e-01, 2.51423037e-01, 5.31594299e+02,\n",
      "        6.01822265e+03, 5.98804697e+03, 1.36105496e+04],\n",
      "       [2.46886845e-01, 2.49333662e-01, 2.51423030e-01, 5.31594302e+02,\n",
      "        6.01822274e+03, 5.98804703e+03, 1.36105496e+04]]), array([114355.14789345, 114355.14792166, 114355.14794953, 114355.14795696,\n",
      "       114355.14797381, 114355.14797647, 114355.14798236, 114355.14798381]))\n",
      "           fun: 114355.14789344775\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1227\n",
      "           nit: 496\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.46886842e-01, 2.49333667e-01, 2.51423035e-01, 5.31594302e+02,\n",
      "       6.01822273e+03, 5.98804701e+03, 1.36105497e+04])\n",
      "minPrevious 114353.84712578746\n",
      "best ll: 134082.4375, bestParams: [tensor(0.0781), tensor(0.0666), tensor(0.1119), tensor(794.3400), tensor(16634.5508), tensor(21140.1348), tensor(17151.2871)]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.45463275e-01, 2.49672689e-01, 2.51225421e-01, 5.76951162e+02,\n",
      "        6.51823636e+03, 6.49594962e+03, 1.47984773e+04],\n",
      "       [2.45463275e-01, 2.49672689e-01, 2.51225421e-01, 5.76951163e+02,\n",
      "        6.51823637e+03, 6.49594962e+03, 1.47984773e+04],\n",
      "       [2.45463274e-01, 2.49672690e-01, 2.51225421e-01, 5.76951159e+02,\n",
      "        6.51823633e+03, 6.49594959e+03, 1.47984772e+04],\n",
      "       [2.45463274e-01, 2.49672689e-01, 2.51225421e-01, 5.76951162e+02,\n",
      "        6.51823637e+03, 6.49594962e+03, 1.47984773e+04],\n",
      "       [2.45463275e-01, 2.49672689e-01, 2.51225421e-01, 5.76951162e+02,\n",
      "        6.51823636e+03, 6.49594962e+03, 1.47984773e+04],\n",
      "       [2.45463275e-01, 2.49672689e-01, 2.51225421e-01, 5.76951162e+02,\n",
      "        6.51823637e+03, 6.49594962e+03, 1.47984773e+04],\n",
      "       [2.45463275e-01, 2.49672689e-01, 2.51225421e-01, 5.76951165e+02,\n",
      "        6.51823641e+03, 6.49594966e+03, 1.47984774e+04],\n",
      "       [2.45463275e-01, 2.49672689e-01, 2.51225421e-01, 5.76951162e+02,\n",
      "        6.51823637e+03, 6.49594962e+03, 1.47984773e+04]]), array([114353.65371477, 114353.6537159 , 114353.65371606, 114353.65371694,\n",
      "       114353.65371938, 114353.65372083, 114353.65372095, 114353.65372188]))\n",
      "           fun: 114353.65371476611\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1698\n",
      "           nit: 781\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.45463275e-01, 2.49672689e-01, 2.51225421e-01, 5.76951162e+02,\n",
      "       6.51823636e+03, 6.49594962e+03, 1.47984773e+04])\n",
      "minPrevious 114353.84712578746\n",
      "best ll: 120490.5, bestParams: [tensor(0.1449), tensor(0.0758), tensor(0.2111), tensor(1000.3541), tensor(14912.9482), tensor(13539.6992), tensor(15614.2148)]\n",
      "epoch 9\n",
      " final_simplex: (array([[2.47641482e-01, 2.43381844e-01, 2.51545125e-01, 3.33989367e+02,\n",
      "        3.78574070e+03, 3.75967489e+03, 8.54805699e+03],\n",
      "       [2.47641488e-01, 2.43381842e-01, 2.51545125e-01, 3.33989365e+02,\n",
      "        3.78574069e+03, 3.75967492e+03, 8.54805698e+03],\n",
      "       [2.47641485e-01, 2.43381844e-01, 2.51545124e-01, 3.33989365e+02,\n",
      "        3.78574068e+03, 3.75967490e+03, 8.54805694e+03],\n",
      "       [2.47641487e-01, 2.43381843e-01, 2.51545124e-01, 3.33989365e+02,\n",
      "        3.78574069e+03, 3.75967492e+03, 8.54805693e+03],\n",
      "       [2.47641486e-01, 2.43381843e-01, 2.51545124e-01, 3.33989365e+02,\n",
      "        3.78574069e+03, 3.75967491e+03, 8.54805690e+03],\n",
      "       [2.47641483e-01, 2.43381845e-01, 2.51545124e-01, 3.33989365e+02,\n",
      "        3.78574068e+03, 3.75967488e+03, 8.54805690e+03],\n",
      "       [2.47641485e-01, 2.43381844e-01, 2.51545124e-01, 3.33989367e+02,\n",
      "        3.78574071e+03, 3.75967491e+03, 8.54805694e+03],\n",
      "       [2.47641483e-01, 2.43381845e-01, 2.51545123e-01, 3.33989365e+02,\n",
      "        3.78574067e+03, 3.75967486e+03, 8.54805692e+03]]), array([114387.10737571, 114387.1073846 , 114387.10738749, 114387.10738837,\n",
      "       114387.1074047 , 114387.10740574, 114387.10740626, 114387.10740731]))\n",
      "           fun: 114387.10737571177\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1357\n",
      "           nit: 590\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.47641482e-01, 2.43381844e-01, 2.51545125e-01, 3.33989367e+02,\n",
      "       3.78574070e+03, 3.75967489e+03, 8.54805699e+03])\n",
      "minPrevious 114353.84712578746\n",
      "\n",
      "\n",
      "run 47 results for rrs: tensor([10, 10, 10]), pis: tensor([0.2500, 0.2500, 0.2500])\n",
      "Inferred pis: tensor([0.2461, 0.2495, 0.2507], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8695, 0.0973, 0.0097, 0.0195])\n",
      "P(D|V) inferred in component 1: tensor([0.8731, 0.0985, 0.0087, 0.0197], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8716, 0.0098, 0.0974, 0.0195])\n",
      "P(D|V) inferred in component both: tensor([0.8727, 0.0087, 0.0988, 0.0198], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.5514, 0.1957, 0.1959, 0.0587])\n",
      "P(D|V) inferred in component both: tensor([0.5456, 0.2008, 0.2009, 0.0526], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([5000., 5000., 1000.]) nCtrls tensor(500000.) rrMeans tensor([10, 10, 10]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.2500, 0.2500, 0.2500]) pDs tensor([0.0098, 0.0098, 0.0020])\n",
      "rrDist mean tensor([10.0212, 10.0073, 10.0051])\n",
      "startIndices [0, tensor(5000.), tensor(10000.)] endIndices tensor([ 5000., 10000., 15000.])\n",
      "totalSamples 511000\n",
      "took 31.585857152938843\n",
      "Run: 47, 2\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[41.,  6.,  0.,  1.],\n",
      "        [42.,  7.,  0.,  2.],\n",
      "        [42.,  6.,  2.,  1.],\n",
      "        ...,\n",
      "        [40.,  1.,  2.,  0.],\n",
      "        [63.,  0.,  0.,  0.],\n",
      "        [56.,  0.,  0.,  0.]])\n",
      "n tensor([48., 51., 51.,  ..., 43., 63., 56.])\n",
      "xCase1, xCase2, xCase12 tensor([6., 7., 6.,  ..., 1., 0., 0.])\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 2.,  ..., 2., 0., 0.])\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 1.,  ..., 0., 0., 0.])\n",
      "altCountsFlat tensor([[41.,  6.,  0.,  1.],\n",
      "        [42.,  7.,  0.,  2.],\n",
      "        [42.,  6.,  2.,  1.],\n",
      "        ...,\n",
      "        [40.,  1.,  2.,  0.],\n",
      "        [63.,  0.,  0.,  0.],\n",
      "        [56.,  0.,  0.,  0.]])\n",
      "allNull2 tensor([3.6269e-07, 1.4440e-09, 5.0540e-08,  ..., 1.4524e-02, 2.5386e-01,\n",
      "        2.9563e-01])\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0098) tensor(0.0098) tensor(0.0020) tensor(0.9785)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe3626d5050>\n",
      "best ll: 134777.890625, bestParams: [tensor(0.0668), tensor(0.1421), tensor(0.0700), tensor(429.1887), tensor(4876.9819), tensor(9733.0625), tensor(18569.9492)]\n",
      "epoch 0\n",
      " final_simplex: (array([[2.48852277e-01, 2.46477174e-01, 2.51477393e-01, 4.98834387e+02,\n",
      "        5.64661407e+03, 5.68594071e+03, 1.26624455e+04],\n",
      "       [2.48852278e-01, 2.46477174e-01, 2.51477393e-01, 4.98834385e+02,\n",
      "        5.64661407e+03, 5.68594071e+03, 1.26624455e+04],\n",
      "       [2.48852277e-01, 2.46477174e-01, 2.51477392e-01, 4.98834386e+02,\n",
      "        5.64661408e+03, 5.68594072e+03, 1.26624455e+04],\n",
      "       [2.48852276e-01, 2.46477175e-01, 2.51477392e-01, 4.98834385e+02,\n",
      "        5.64661405e+03, 5.68594069e+03, 1.26624454e+04],\n",
      "       [2.48852275e-01, 2.46477174e-01, 2.51477391e-01, 4.98834384e+02,\n",
      "        5.64661406e+03, 5.68594069e+03, 1.26624454e+04],\n",
      "       [2.48852277e-01, 2.46477175e-01, 2.51477392e-01, 4.98834389e+02,\n",
      "        5.64661410e+03, 5.68594074e+03, 1.26624455e+04],\n",
      "       [2.48852276e-01, 2.46477175e-01, 2.51477392e-01, 4.98834388e+02,\n",
      "        5.64661409e+03, 5.68594073e+03, 1.26624455e+04],\n",
      "       [2.48852276e-01, 2.46477174e-01, 2.51477392e-01, 4.98834388e+02,\n",
      "        5.64661409e+03, 5.68594073e+03, 1.26624455e+04]]), array([114677.39401102, 114677.39401609, 114677.39403477, 114677.39403639,\n",
      "       114677.39405823, 114677.39409853, 114677.39410116, 114677.39410323]))\n",
      "           fun: 114677.39401101884\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1697\n",
      "           nit: 789\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.48852277e-01, 2.46477174e-01, 2.51477393e-01, 4.98834387e+02,\n",
      "       5.64661407e+03, 5.68594071e+03, 1.26624455e+04])\n",
      "best ll: 120214.7265625, bestParams: [tensor(0.1018), tensor(0.1416), tensor(0.2168), tensor(1384.8973), tensor(18019.0820), tensor(21786.3613), tensor(20637.4863)]\n",
      "epoch 1\n",
      " final_simplex: (array([[2.45441659e-01, 2.48048569e-01, 2.49721086e-01, 6.62010055e+02,\n",
      "        7.53163903e+03, 7.48293082e+03, 1.68242148e+04],\n",
      "       [2.45441658e-01, 2.48048568e-01, 2.49721086e-01, 6.62010060e+02,\n",
      "        7.53163911e+03, 7.48293090e+03, 1.68242149e+04],\n",
      "       [2.45441660e-01, 2.48048569e-01, 2.49721085e-01, 6.62010056e+02,\n",
      "        7.53163905e+03, 7.48293083e+03, 1.68242148e+04],\n",
      "       [2.45441661e-01, 2.48048566e-01, 2.49721084e-01, 6.62010054e+02,\n",
      "        7.53163903e+03, 7.48293082e+03, 1.68242148e+04],\n",
      "       [2.45441661e-01, 2.48048567e-01, 2.49721083e-01, 6.62010055e+02,\n",
      "        7.53163904e+03, 7.48293084e+03, 1.68242148e+04],\n",
      "       [2.45441660e-01, 2.48048571e-01, 2.49721083e-01, 6.62010059e+02,\n",
      "        7.53163905e+03, 7.48293080e+03, 1.68242148e+04],\n",
      "       [2.45441660e-01, 2.48048568e-01, 2.49721083e-01, 6.62010057e+02,\n",
      "        7.53163909e+03, 7.48293086e+03, 1.68242148e+04],\n",
      "       [2.45441660e-01, 2.48048570e-01, 2.49721083e-01, 6.62010055e+02,\n",
      "        7.53163908e+03, 7.48293083e+03, 1.68242147e+04]]), array([114678.40748531, 114678.40748979, 114678.40749825, 114678.40752871,\n",
      "       114678.4075451 , 114678.40754773, 114678.40755086, 114678.40755266]))\n",
      "           fun: 114678.40748531322\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1309\n",
      "           nit: 559\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.45441659e-01, 2.48048569e-01, 2.49721086e-01, 6.62010055e+02,\n",
      "       7.53163903e+03, 7.48293082e+03, 1.68242148e+04])\n",
      "minPrevious 114677.39401101884\n",
      "best ll: 134409.515625, bestParams: [tensor(0.1401), tensor(0.1856), tensor(0.0163), tensor(1816.8683), tensor(17099.1660), tensor(19361.4766), tensor(23211.8203)]\n",
      "epoch 2\n",
      " final_simplex: (array([[2.47798126e-01, 2.49594403e-01, 2.47599355e-01, 6.08347537e+02,\n",
      "        6.92173211e+03, 6.91571265e+03, 1.54178192e+04],\n",
      "       [2.47798126e-01, 2.49594403e-01, 2.47599355e-01, 6.08347537e+02,\n",
      "        6.92173212e+03, 6.91571266e+03, 1.54178193e+04],\n",
      "       [2.47798127e-01, 2.49594402e-01, 2.47599354e-01, 6.08347537e+02,\n",
      "        6.92173211e+03, 6.91571265e+03, 1.54178192e+04],\n",
      "       [2.47798123e-01, 2.49594406e-01, 2.47599354e-01, 6.08347536e+02,\n",
      "        6.92173211e+03, 6.91571268e+03, 1.54178193e+04],\n",
      "       [2.47798128e-01, 2.49594401e-01, 2.47599354e-01, 6.08347538e+02,\n",
      "        6.92173211e+03, 6.91571267e+03, 1.54178192e+04],\n",
      "       [2.47798127e-01, 2.49594402e-01, 2.47599354e-01, 6.08347536e+02,\n",
      "        6.92173210e+03, 6.91571268e+03, 1.54178192e+04],\n",
      "       [2.47798128e-01, 2.49594402e-01, 2.47599354e-01, 6.08347537e+02,\n",
      "        6.92173211e+03, 6.91571269e+03, 1.54178192e+04],\n",
      "       [2.47798126e-01, 2.49594404e-01, 2.47599354e-01, 6.08347537e+02,\n",
      "        6.92173211e+03, 6.91571268e+03, 1.54178193e+04]]), array([114678.61634458, 114678.61634746, 114678.61635206, 114678.61635354,\n",
      "       114678.61635681, 114678.61635889, 114678.61636118, 114678.61636317]))\n",
      "           fun: 114678.61634457948\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1758\n",
      "           nit: 822\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.47798126e-01, 2.49594403e-01, 2.47599355e-01, 6.08347537e+02,\n",
      "       6.92173211e+03, 6.91571265e+03, 1.54178192e+04])\n",
      "minPrevious 114677.39401101884\n",
      "best ll: 124748.1796875, bestParams: [tensor(0.1760), tensor(0.0873), tensor(0.2009), tensor(1224.5032), tensor(22494.5820), tensor(19101.0801), tensor(9808.5361)]\n",
      "epoch 3\n",
      " final_simplex: (array([[2.46219599e-01, 2.46627102e-01, 2.49318518e-01, 4.64568980e+02,\n",
      "        5.29836191e+03, 5.29136518e+03, 1.17393898e+04],\n",
      "       [2.46219600e-01, 2.46627103e-01, 2.49318518e-01, 4.64568980e+02,\n",
      "        5.29836189e+03, 5.29136515e+03, 1.17393898e+04],\n",
      "       [2.46219599e-01, 2.46627103e-01, 2.49318517e-01, 4.64568979e+02,\n",
      "        5.29836191e+03, 5.29136515e+03, 1.17393898e+04],\n",
      "       [2.46219600e-01, 2.46627103e-01, 2.49318517e-01, 4.64568979e+02,\n",
      "        5.29836189e+03, 5.29136515e+03, 1.17393898e+04],\n",
      "       [2.46219599e-01, 2.46627103e-01, 2.49318517e-01, 4.64568980e+02,\n",
      "        5.29836191e+03, 5.29136518e+03, 1.17393898e+04],\n",
      "       [2.46219600e-01, 2.46627103e-01, 2.49318516e-01, 4.64568980e+02,\n",
      "        5.29836191e+03, 5.29136517e+03, 1.17393898e+04],\n",
      "       [2.46219601e-01, 2.46627103e-01, 2.49318515e-01, 4.64568980e+02,\n",
      "        5.29836190e+03, 5.29136518e+03, 1.17393898e+04],\n",
      "       [2.46219603e-01, 2.46627103e-01, 2.49318514e-01, 4.64568979e+02,\n",
      "        5.29836190e+03, 5.29136518e+03, 1.17393897e+04]]), array([114680.28639742, 114680.28641182, 114680.28641556, 114680.28641691,\n",
      "       114680.28642148, 114680.28644031, 114680.28645841, 114680.28648855]))\n",
      "           fun: 114680.28639742492\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1361\n",
      "           nit: 570\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.46219599e-01, 2.46627102e-01, 2.49318518e-01, 4.64568980e+02,\n",
      "       5.29836191e+03, 5.29136518e+03, 1.17393898e+04])\n",
      "minPrevious 114677.39401101884\n",
      "best ll: 130784.1328125, bestParams: [tensor(0.1227), tensor(0.1223), tensor(0.0863), tensor(1327.6965), tensor(9198.6133), tensor(9695.9404), tensor(23886.8379)]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.51957302e-01, 2.45459934e-01, 2.48394447e-01, 5.11318091e+02,\n",
      "        5.82629614e+03, 5.80467158e+03, 1.28846320e+04],\n",
      "       [2.51957303e-01, 2.45459933e-01, 2.48394446e-01, 5.11318091e+02,\n",
      "        5.82629614e+03, 5.80467160e+03, 1.28846320e+04],\n",
      "       [2.51957303e-01, 2.45459933e-01, 2.48394446e-01, 5.11318092e+02,\n",
      "        5.82629615e+03, 5.80467160e+03, 1.28846320e+04],\n",
      "       [2.51957303e-01, 2.45459933e-01, 2.48394446e-01, 5.11318092e+02,\n",
      "        5.82629616e+03, 5.80467161e+03, 1.28846320e+04],\n",
      "       [2.51957304e-01, 2.45459933e-01, 2.48394446e-01, 5.11318091e+02,\n",
      "        5.82629615e+03, 5.80467160e+03, 1.28846320e+04],\n",
      "       [2.51957304e-01, 2.45459933e-01, 2.48394445e-01, 5.11318092e+02,\n",
      "        5.82629616e+03, 5.80467161e+03, 1.28846320e+04],\n",
      "       [2.51957303e-01, 2.45459932e-01, 2.48394445e-01, 5.11318091e+02,\n",
      "        5.82629616e+03, 5.80467160e+03, 1.28846320e+04],\n",
      "       [2.51957304e-01, 2.45459933e-01, 2.48394445e-01, 5.11318093e+02,\n",
      "        5.82629617e+03, 5.80467162e+03, 1.28846321e+04]]), array([114677.96234147, 114677.962358  , 114677.9623598 , 114677.96236215,\n",
      "       114677.96236939, 114677.96237885, 114677.96238149, 114677.96238252]))\n",
      "           fun: 114677.96234147299\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1612\n",
      "           nit: 719\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.51957302e-01, 2.45459934e-01, 2.48394447e-01, 5.11318091e+02,\n",
      "       5.82629614e+03, 5.80467158e+03, 1.28846320e+04])\n",
      "minPrevious 114677.39401101884\n",
      "best ll: 139439.859375, bestParams: [tensor(0.1581), tensor(0.0520), tensor(0.0283), tensor(1789.9680), tensor(17933.4336), tensor(14935.3330), tensor(20982.1758)]\n",
      "epoch 5\n",
      " final_simplex: (array([[2.50443715e-01, 2.46269949e-01, 2.48495446e-01, 4.37948111e+02,\n",
      "        4.96018336e+03, 4.97147555e+03, 1.11197624e+04],\n",
      "       [2.50443714e-01, 2.46269951e-01, 2.48495446e-01, 4.37948111e+02,\n",
      "        4.96018336e+03, 4.97147554e+03, 1.11197624e+04],\n",
      "       [2.50443713e-01, 2.46269949e-01, 2.48495445e-01, 4.37948111e+02,\n",
      "        4.96018335e+03, 4.97147556e+03, 1.11197624e+04],\n",
      "       [2.50443712e-01, 2.46269949e-01, 2.48495445e-01, 4.37948111e+02,\n",
      "        4.96018335e+03, 4.97147556e+03, 1.11197624e+04],\n",
      "       [2.50443713e-01, 2.46269949e-01, 2.48495445e-01, 4.37948109e+02,\n",
      "        4.96018333e+03, 4.97147553e+03, 1.11197624e+04],\n",
      "       [2.50443713e-01, 2.46269950e-01, 2.48495444e-01, 4.37948109e+02,\n",
      "        4.96018334e+03, 4.97147554e+03, 1.11197624e+04],\n",
      "       [2.50443715e-01, 2.46269950e-01, 2.48495447e-01, 4.37948111e+02,\n",
      "        4.96018336e+03, 4.97147553e+03, 1.11197625e+04],\n",
      "       [2.50443715e-01, 2.46269949e-01, 2.48495447e-01, 4.37948111e+02,\n",
      "        4.96018336e+03, 4.97147554e+03, 1.11197625e+04]]), array([114680.25121397, 114680.25122061, 114680.25122578, 114680.25123344,\n",
      "       114680.25124253, 114680.25127357, 114680.25127359, 114680.2512739 ]))\n",
      "           fun: 114680.25121397484\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2001\n",
      "           nit: 948\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.50443715e-01, 2.46269949e-01, 2.48495446e-01, 4.37948111e+02,\n",
      "       4.96018336e+03, 4.97147555e+03, 1.11197624e+04])\n",
      "minPrevious 114677.39401101884\n",
      "best ll: 139105.171875, bestParams: [tensor(0.0570), tensor(0.0383), tensor(0.0298), tensor(807.4124), tensor(11114.9121), tensor(20434.7793), tensor(10874.2217)]\n",
      "epoch 6\n",
      " final_simplex: (array([[2.46060770e-01, 2.48446503e-01, 2.49435479e-01, 6.13624524e+02,\n",
      "        6.97396351e+03, 6.96738632e+03, 1.55997835e+04],\n",
      "       [2.46060769e-01, 2.48446503e-01, 2.49435479e-01, 6.13624523e+02,\n",
      "        6.97396351e+03, 6.96738632e+03, 1.55997834e+04],\n",
      "       [2.46060769e-01, 2.48446502e-01, 2.49435479e-01, 6.13624523e+02,\n",
      "        6.97396351e+03, 6.96738633e+03, 1.55997834e+04],\n",
      "       [2.46060768e-01, 2.48446504e-01, 2.49435479e-01, 6.13624526e+02,\n",
      "        6.97396355e+03, 6.96738636e+03, 1.55997835e+04],\n",
      "       [2.46060767e-01, 2.48446505e-01, 2.49435479e-01, 6.13624524e+02,\n",
      "        6.97396352e+03, 6.96738634e+03, 1.55997834e+04],\n",
      "       [2.46060767e-01, 2.48446506e-01, 2.49435478e-01, 6.13624523e+02,\n",
      "        6.97396351e+03, 6.96738633e+03, 1.55997834e+04],\n",
      "       [2.46060769e-01, 2.48446503e-01, 2.49435478e-01, 6.13624520e+02,\n",
      "        6.97396348e+03, 6.96738628e+03, 1.55997834e+04],\n",
      "       [2.46060768e-01, 2.48446506e-01, 2.49435478e-01, 6.13624524e+02,\n",
      "        6.97396352e+03, 6.96738634e+03, 1.55997834e+04]]), array([114678.19782462, 114678.19782665, 114678.197832  , 114678.19783734,\n",
      "       114678.19784006, 114678.19784843, 114678.19785022, 114678.19785656]))\n",
      "           fun: 114678.19782462435\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1965\n",
      "           nit: 928\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.46060770e-01, 2.48446503e-01, 2.49435479e-01, 6.13624524e+02,\n",
      "       6.97396351e+03, 6.96738632e+03, 1.55997835e+04])\n",
      "minPrevious 114677.39401101884\n",
      "best ll: 130750.625, bestParams: [tensor(0.2263), tensor(0.1587), tensor(0.0750), tensor(644.5486), tensor(12388.0938), tensor(5736.6274), tensor(5741.2847)]\n",
      "epoch 7\n",
      " final_simplex: (array([[2.45856204e-01, 2.51103961e-01, 2.50732703e-01, 3.26888999e+02,\n",
      "        3.72133904e+03, 3.71371854e+03, 8.29335001e+03],\n",
      "       [2.45856204e-01, 2.51103961e-01, 2.50732703e-01, 3.26888999e+02,\n",
      "        3.72133904e+03, 3.71371854e+03, 8.29335001e+03],\n",
      "       [2.45856205e-01, 2.51103961e-01, 2.50732703e-01, 3.26888999e+02,\n",
      "        3.72133904e+03, 3.71371854e+03, 8.29335001e+03],\n",
      "       [2.45856204e-01, 2.51103961e-01, 2.50732703e-01, 3.26888999e+02,\n",
      "        3.72133904e+03, 3.71371854e+03, 8.29335001e+03],\n",
      "       [2.45856204e-01, 2.51103961e-01, 2.50732703e-01, 3.26888999e+02,\n",
      "        3.72133904e+03, 3.71371854e+03, 8.29335000e+03],\n",
      "       [2.45856204e-01, 2.51103961e-01, 2.50732703e-01, 3.26888999e+02,\n",
      "        3.72133904e+03, 3.71371854e+03, 8.29335000e+03],\n",
      "       [2.45856204e-01, 2.51103961e-01, 2.50732703e-01, 3.26888999e+02,\n",
      "        3.72133904e+03, 3.71371854e+03, 8.29335000e+03],\n",
      "       [2.45856205e-01, 2.51103960e-01, 2.50732703e-01, 3.26888999e+02,\n",
      "        3.72133904e+03, 3.71371854e+03, 8.29335001e+03]]), array([114697.73684132, 114697.73684148, 114697.73684169, 114697.73684201,\n",
      "       114697.73684255, 114697.73684353, 114697.73684569, 114697.73684645]))\n",
      "           fun: 114697.73684131991\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1579\n",
      "           nit: 660\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.45856204e-01, 2.51103961e-01, 2.50732703e-01, 3.26888999e+02,\n",
      "       3.72133904e+03, 3.71371854e+03, 8.29335001e+03])\n",
      "minPrevious 114677.39401101884\n",
      "best ll: 131314.34375, bestParams: [tensor(0.2515), tensor(0.0411), tensor(0.2158), tensor(827.0760), tensor(5172.0249), tensor(19050.5234), tensor(12560.5703)]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.47054302e-01, 2.49583878e-01, 2.47359705e-01, 4.76329556e+02,\n",
      "        5.40630293e+03, 5.42474651e+03, 1.20667446e+04],\n",
      "       [2.47054302e-01, 2.49583878e-01, 2.47359703e-01, 4.76329556e+02,\n",
      "        5.40630292e+03, 5.42474651e+03, 1.20667446e+04],\n",
      "       [2.47054303e-01, 2.49583879e-01, 2.47359703e-01, 4.76329556e+02,\n",
      "        5.40630292e+03, 5.42474650e+03, 1.20667446e+04],\n",
      "       [2.47054303e-01, 2.49583879e-01, 2.47359701e-01, 4.76329557e+02,\n",
      "        5.40630292e+03, 5.42474651e+03, 1.20667446e+04],\n",
      "       [2.47054303e-01, 2.49583880e-01, 2.47359701e-01, 4.76329556e+02,\n",
      "        5.40630291e+03, 5.42474649e+03, 1.20667446e+04],\n",
      "       [2.47054303e-01, 2.49583880e-01, 2.47359701e-01, 4.76329559e+02,\n",
      "        5.40630295e+03, 5.42474653e+03, 1.20667447e+04],\n",
      "       [2.47054304e-01, 2.49583880e-01, 2.47359701e-01, 4.76329557e+02,\n",
      "        5.40630292e+03, 5.42474652e+03, 1.20667446e+04],\n",
      "       [2.47054303e-01, 2.49583880e-01, 2.47359700e-01, 4.76329557e+02,\n",
      "        5.40630292e+03, 5.42474651e+03, 1.20667446e+04]]), array([114678.95275267, 114678.9527892 , 114678.95279033, 114678.95282574,\n",
      "       114678.95283499, 114678.95283649, 114678.95283972, 114678.95284602]))\n",
      "           fun: 114678.95275267384\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1646\n",
      "           nit: 787\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.47054302e-01, 2.49583878e-01, 2.47359705e-01, 4.76329556e+02,\n",
      "       5.40630293e+03, 5.42474651e+03, 1.20667446e+04])\n",
      "minPrevious 114677.39401101884\n",
      "best ll: 128172.3671875, bestParams: [tensor(0.2420), tensor(0.1333), tensor(0.0183), tensor(1114.1859), tensor(18152.9219), tensor(18945.4570), tensor(24602.7441)]\n",
      "epoch 9\n",
      " final_simplex: (array([[2.48148464e-01, 2.49205125e-01, 2.50215596e-01, 4.39013517e+02,\n",
      "        4.96800072e+03, 4.98900025e+03, 1.11019259e+04],\n",
      "       [2.48148467e-01, 2.49205120e-01, 2.50215596e-01, 4.39013520e+02,\n",
      "        4.96800076e+03, 4.98900031e+03, 1.11019258e+04],\n",
      "       [2.48148465e-01, 2.49205124e-01, 2.50215595e-01, 4.39013518e+02,\n",
      "        4.96800073e+03, 4.98900027e+03, 1.11019259e+04],\n",
      "       [2.48148464e-01, 2.49205124e-01, 2.50215596e-01, 4.39013523e+02,\n",
      "        4.96800078e+03, 4.98900032e+03, 1.11019260e+04],\n",
      "       [2.48148467e-01, 2.49205124e-01, 2.50215594e-01, 4.39013518e+02,\n",
      "        4.96800072e+03, 4.98900027e+03, 1.11019259e+04],\n",
      "       [2.48148464e-01, 2.49205125e-01, 2.50215594e-01, 4.39013521e+02,\n",
      "        4.96800074e+03, 4.98900027e+03, 1.11019259e+04],\n",
      "       [2.48148467e-01, 2.49205124e-01, 2.50215594e-01, 4.39013521e+02,\n",
      "        4.96800074e+03, 4.98900029e+03, 1.11019259e+04],\n",
      "       [2.48148467e-01, 2.49205122e-01, 2.50215595e-01, 4.39013524e+02,\n",
      "        4.96800078e+03, 4.98900033e+03, 1.11019260e+04]]), array([114679.85110919, 114679.85112099, 114679.85112332, 114679.85114196,\n",
      "       114679.85115571, 114679.85115844, 114679.85116599, 114679.85117974]))\n",
      "           fun: 114679.85110919169\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1633\n",
      "           nit: 758\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.48148464e-01, 2.49205125e-01, 2.50215596e-01, 4.39013517e+02,\n",
      "       4.96800072e+03, 4.98900025e+03, 1.11019259e+04])\n",
      "minPrevious 114677.39401101884\n",
      "\n",
      "\n",
      "run 47 results for rrs: tensor([10, 10, 10]), pis: tensor([0.2500, 0.2500, 0.2500])\n",
      "Inferred pis: tensor([0.2489, 0.2465, 0.2515], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8684, 0.0973, 0.0097, 0.0195])\n",
      "P(D|V) inferred in component 1: tensor([0.8725, 0.0988, 0.0087, 0.0199], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8721, 0.0098, 0.0975, 0.0195])\n",
      "P(D|V) inferred in component both: tensor([0.8719, 0.0087, 0.0995, 0.0199], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.5491, 0.1955, 0.1954, 0.0586])\n",
      "P(D|V) inferred in component both: tensor([0.5461, 0.2004, 0.2010, 0.0526], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([5000., 5000., 1000.]) nCtrls tensor(500000.) rrMeans tensor([10, 10, 10]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.2500, 0.2500, 0.2500]) pDs tensor([0.0098, 0.0098, 0.0020])\n",
      "rrDist mean tensor([10.0083,  9.9855, 10.0182])\n",
      "startIndices [0, tensor(5000.), tensor(10000.)] endIndices tensor([ 5000., 10000., 15000.])\n",
      "totalSamples 511000\n",
      "took 13.497199058532715\n",
      "Run: 47, 3\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[52.,  3.,  1.,  1.],\n",
      "        [46.,  4.,  0.,  2.],\n",
      "        [35., 10.,  0.,  1.],\n",
      "        ...,\n",
      "        [54.,  0.,  1.,  0.],\n",
      "        [35.,  0.,  0.,  0.],\n",
      "        [37.,  1.,  1.,  0.]])\n",
      "n tensor([57., 52., 46.,  ..., 55., 35., 39.])\n",
      "xCase1, xCase2, xCase12 tensor([ 3.,  4., 10.,  ...,  0.,  0.,  1.])\n",
      "xCase1, xCase2, xCase12 tensor([1., 0., 0.,  ..., 1., 0., 1.])\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 1.,  ..., 0., 0., 0.])\n",
      "altCountsFlat tensor([[52.,  3.,  1.,  1.],\n",
      "        [46.,  4.,  0.,  2.],\n",
      "        [35., 10.,  0.,  1.],\n",
      "        ...,\n",
      "        [54.,  0.,  1.,  0.],\n",
      "        [35.,  0.,  0.,  0.],\n",
      "        [37.,  1.,  1.,  0.]])\n",
      "allNull2 tensor([4.8447e-04, 3.9396e-06, 1.0786e-12,  ..., 1.6617e-01, 4.6689e-01,\n",
      "        6.3425e-02])\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0098) tensor(0.0098) tensor(0.0020) tensor(0.9785)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe3626d5e60>\n",
      "best ll: 125635.6953125, bestParams: [tensor(0.2987), tensor(0.1621), tensor(0.0323), tensor(856.0081), tensor(8890.6084), tensor(16770.7715), tensor(19793.5977)]\n",
      "epoch 0\n",
      " final_simplex: (array([[2.49610406e-01, 2.47330108e-01, 2.51063605e-01, 4.91157421e+02,\n",
      "        5.57789168e+03, 5.56915910e+03, 1.25023487e+04],\n",
      "       [2.49610407e-01, 2.47330107e-01, 2.51063604e-01, 4.91157420e+02,\n",
      "        5.57789166e+03, 5.56915912e+03, 1.25023486e+04],\n",
      "       [2.49610406e-01, 2.47330108e-01, 2.51063604e-01, 4.91157423e+02,\n",
      "        5.57789170e+03, 5.56915915e+03, 1.25023488e+04],\n",
      "       [2.49610406e-01, 2.47330108e-01, 2.51063603e-01, 4.91157424e+02,\n",
      "        5.57789173e+03, 5.56915918e+03, 1.25023487e+04],\n",
      "       [2.49610406e-01, 2.47330108e-01, 2.51063603e-01, 4.91157421e+02,\n",
      "        5.57789170e+03, 5.56915915e+03, 1.25023486e+04],\n",
      "       [2.49610406e-01, 2.47330108e-01, 2.51063603e-01, 4.91157420e+02,\n",
      "        5.57789169e+03, 5.56915914e+03, 1.25023486e+04],\n",
      "       [2.49610406e-01, 2.47330108e-01, 2.51063603e-01, 4.91157421e+02,\n",
      "        5.57789170e+03, 5.56915917e+03, 1.25023486e+04],\n",
      "       [2.49610406e-01, 2.47330108e-01, 2.51063603e-01, 4.91157424e+02,\n",
      "        5.57789173e+03, 5.56915918e+03, 1.25023487e+04]]), array([114654.88168403, 114654.88169155, 114654.88169479, 114654.88171143,\n",
      "       114654.88171622, 114654.88171666, 114654.88171708, 114654.88171971]))\n",
      "           fun: 114654.88168403094\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1635\n",
      "           nit: 730\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.49610406e-01, 2.47330108e-01, 2.51063605e-01, 4.91157421e+02,\n",
      "       5.57789168e+03, 5.56915910e+03, 1.25023487e+04])\n",
      "best ll: 126517.890625, bestParams: [tensor(0.1345), tensor(0.2364), tensor(0.1896), tensor(1307.2137), tensor(9714.8252), tensor(12852.9365), tensor(17099.9531)]\n",
      "epoch 1\n",
      " final_simplex: (array([[2.57158176e-01, 2.43996435e-01, 2.41674578e-01, 6.38402163e+02,\n",
      "        7.25689062e+03, 7.23720365e+03, 1.62990971e+04],\n",
      "       [2.57158175e-01, 2.43996436e-01, 2.41674577e-01, 6.38402162e+02,\n",
      "        7.25689062e+03, 7.23720364e+03, 1.62990971e+04],\n",
      "       [2.57158176e-01, 2.43996435e-01, 2.41674577e-01, 6.38402164e+02,\n",
      "        7.25689060e+03, 7.23720363e+03, 1.62990971e+04],\n",
      "       [2.57158175e-01, 2.43996436e-01, 2.41674577e-01, 6.38402163e+02,\n",
      "        7.25689060e+03, 7.23720365e+03, 1.62990971e+04],\n",
      "       [2.57158176e-01, 2.43996435e-01, 2.41674577e-01, 6.38402164e+02,\n",
      "        7.25689060e+03, 7.23720365e+03, 1.62990971e+04],\n",
      "       [2.57158175e-01, 2.43996435e-01, 2.41674577e-01, 6.38402165e+02,\n",
      "        7.25689062e+03, 7.23720367e+03, 1.62990971e+04],\n",
      "       [2.57158177e-01, 2.43996436e-01, 2.41674576e-01, 6.38402163e+02,\n",
      "        7.25689054e+03, 7.23720363e+03, 1.62990970e+04],\n",
      "       [2.57158176e-01, 2.43996436e-01, 2.41674576e-01, 6.38402164e+02,\n",
      "        7.25689058e+03, 7.23720364e+03, 1.62990970e+04]]), array([114660.61084898, 114660.61085398, 114660.61085773, 114660.61086329,\n",
      "       114660.6108655 , 114660.61086652, 114660.61087426, 114660.61087442]))\n",
      "           fun: 114660.61084898049\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1301\n",
      "           nit: 532\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.57158176e-01, 2.43996435e-01, 2.41674578e-01, 6.38402163e+02,\n",
      "       7.25689062e+03, 7.23720365e+03, 1.62990971e+04])\n",
      "minPrevious 114654.88168403094\n",
      "best ll: 124136.3828125, bestParams: [tensor(0.1735), tensor(0.3736), tensor(0.0396), tensor(1362.2224), tensor(18702.9961), tensor(21706.5820), tensor(19206.4121)]\n",
      "epoch 2\n",
      " final_simplex: (array([[2.52496408e-01, 2.45698043e-01, 2.49563650e-01, 4.95615209e+02,\n",
      "        5.59314153e+03, 5.60357290e+03, 1.26564463e+04],\n",
      "       [2.52496408e-01, 2.45698043e-01, 2.49563650e-01, 4.95615209e+02,\n",
      "        5.59314156e+03, 5.60357288e+03, 1.26564464e+04],\n",
      "       [2.52496408e-01, 2.45698043e-01, 2.49563650e-01, 4.95615208e+02,\n",
      "        5.59314155e+03, 5.60357289e+03, 1.26564463e+04],\n",
      "       [2.52496408e-01, 2.45698045e-01, 2.49563649e-01, 4.95615209e+02,\n",
      "        5.59314158e+03, 5.60357292e+03, 1.26564464e+04],\n",
      "       [2.52496408e-01, 2.45698043e-01, 2.49563649e-01, 4.95615209e+02,\n",
      "        5.59314160e+03, 5.60357292e+03, 1.26564463e+04],\n",
      "       [2.52496407e-01, 2.45698044e-01, 2.49563649e-01, 4.95615209e+02,\n",
      "        5.59314157e+03, 5.60357293e+03, 1.26564464e+04],\n",
      "       [2.52496406e-01, 2.45698045e-01, 2.49563648e-01, 4.95615210e+02,\n",
      "        5.59314157e+03, 5.60357294e+03, 1.26564464e+04],\n",
      "       [2.52496409e-01, 2.45698043e-01, 2.49563648e-01, 4.95615207e+02,\n",
      "        5.59314158e+03, 5.60357292e+03, 1.26564463e+04]]), array([114655.17754006, 114655.17754195, 114655.17754423, 114655.17755189,\n",
      "       114655.17755812, 114655.17756545, 114655.17757434, 114655.17758382]))\n",
      "           fun: 114655.17754006179\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1329\n",
      "           nit: 557\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.52496408e-01, 2.45698043e-01, 2.49563650e-01, 4.95615209e+02,\n",
      "       5.59314153e+03, 5.60357290e+03, 1.26564463e+04])\n",
      "minPrevious 114654.88168403094\n",
      "best ll: 121953.578125, bestParams: [tensor(0.1739), tensor(0.2174), tensor(0.1611), tensor(1573.6953), tensor(24945.2520), tensor(13641.9023), tensor(22082.3223)]\n",
      "epoch 3\n",
      " final_simplex: (array([[2.59320102e-01, 2.43809067e-01, 2.40571493e-01, 1.09817982e+03,\n",
      "        1.24716734e+04, 1.24701241e+04, 2.78983294e+04],\n",
      "       [2.59320104e-01, 2.43809067e-01, 2.40571492e-01, 1.09817981e+03,\n",
      "        1.24716735e+04, 1.24701240e+04, 2.78983295e+04],\n",
      "       [2.59320103e-01, 2.43809067e-01, 2.40571492e-01, 1.09817982e+03,\n",
      "        1.24716734e+04, 1.24701241e+04, 2.78983294e+04],\n",
      "       [2.59320104e-01, 2.43809067e-01, 2.40571492e-01, 1.09817981e+03,\n",
      "        1.24716735e+04, 1.24701240e+04, 2.78983295e+04],\n",
      "       [2.59320101e-01, 2.43809067e-01, 2.40571492e-01, 1.09817982e+03,\n",
      "        1.24716735e+04, 1.24701241e+04, 2.78983295e+04],\n",
      "       [2.59320105e-01, 2.43809068e-01, 2.40571492e-01, 1.09817981e+03,\n",
      "        1.24716735e+04, 1.24701240e+04, 2.78983295e+04],\n",
      "       [2.59320104e-01, 2.43809067e-01, 2.40571492e-01, 1.09817982e+03,\n",
      "        1.24716734e+04, 1.24701242e+04, 2.78983294e+04],\n",
      "       [2.59320104e-01, 2.43809067e-01, 2.40571492e-01, 1.09817981e+03,\n",
      "        1.24716735e+04, 1.24701240e+04, 2.78983295e+04]]), array([114669.47983782, 114669.47983918, 114669.47983981, 114669.47983983,\n",
      "       114669.47984182, 114669.47984573, 114669.47984577, 114669.47984626]))\n",
      "           fun: 114669.47983782474\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1243\n",
      "           nit: 505\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.59320102e-01, 2.43809067e-01, 2.40571493e-01, 1.09817982e+03,\n",
      "       1.24716734e+04, 1.24701241e+04, 2.78983294e+04])\n",
      "minPrevious 114654.88168403094\n",
      "best ll: 118489.0625, bestParams: [tensor(0.2730), tensor(0.1372), tensor(0.1701), tensor(752.5580), tensor(8114.6958), tensor(7213.7334), tensor(13978.4023)]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.51639861e-01, 2.46060111e-01, 2.50162978e-01, 4.62032144e+02,\n",
      "        5.23027188e+03, 5.25526252e+03, 1.17754717e+04],\n",
      "       [2.51639861e-01, 2.46060111e-01, 2.50162978e-01, 4.62032144e+02,\n",
      "        5.23027188e+03, 5.25526254e+03, 1.17754717e+04],\n",
      "       [2.51639861e-01, 2.46060111e-01, 2.50162978e-01, 4.62032143e+02,\n",
      "        5.23027184e+03, 5.25526254e+03, 1.17754718e+04],\n",
      "       [2.51639861e-01, 2.46060111e-01, 2.50162978e-01, 4.62032144e+02,\n",
      "        5.23027185e+03, 5.25526256e+03, 1.17754717e+04],\n",
      "       [2.51639861e-01, 2.46060111e-01, 2.50162978e-01, 4.62032144e+02,\n",
      "        5.23027185e+03, 5.25526255e+03, 1.17754717e+04],\n",
      "       [2.51639861e-01, 2.46060111e-01, 2.50162978e-01, 4.62032144e+02,\n",
      "        5.23027186e+03, 5.25526255e+03, 1.17754718e+04],\n",
      "       [2.51639861e-01, 2.46060111e-01, 2.50162977e-01, 4.62032144e+02,\n",
      "        5.23027184e+03, 5.25526256e+03, 1.17754718e+04],\n",
      "       [2.51639861e-01, 2.46060112e-01, 2.50162977e-01, 4.62032144e+02,\n",
      "        5.23027184e+03, 5.25526255e+03, 1.17754718e+04]]), array([114657.73035075, 114657.7303539 , 114657.73035667, 114657.73036065,\n",
      "       114657.730362  , 114657.73036341, 114657.73037201, 114657.73037447]))\n",
      "           fun: 114657.73035075158\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1205\n",
      "           nit: 453\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.51639861e-01, 2.46060111e-01, 2.50162978e-01, 4.62032144e+02,\n",
      "       5.23027188e+03, 5.25526252e+03, 1.17754717e+04])\n",
      "minPrevious 114654.88168403094\n",
      "best ll: 138119.453125, bestParams: [tensor(0.0252), tensor(0.0200), tensor(0.0318), tensor(522.2734), tensor(7566.8511), tensor(7418.5435), tensor(11807.3809)]\n",
      "epoch 5\n",
      " final_simplex: (array([[2.50876463e-01, 2.53624647e-01, 2.43632593e-01, 5.04718273e+02,\n",
      "        5.71788947e+03, 5.67580041e+03, 1.29519852e+04],\n",
      "       [2.50876467e-01, 2.53624644e-01, 2.43632592e-01, 5.04718269e+02,\n",
      "        5.71788941e+03, 5.67580034e+03, 1.29519852e+04],\n",
      "       [2.50876467e-01, 2.53624645e-01, 2.43632592e-01, 5.04718273e+02,\n",
      "        5.71788946e+03, 5.67580039e+03, 1.29519853e+04],\n",
      "       [2.50876466e-01, 2.53624645e-01, 2.43632592e-01, 5.04718273e+02,\n",
      "        5.71788946e+03, 5.67580040e+03, 1.29519852e+04],\n",
      "       [2.50876469e-01, 2.53624643e-01, 2.43632591e-01, 5.04718270e+02,\n",
      "        5.71788942e+03, 5.67580034e+03, 1.29519852e+04],\n",
      "       [2.50876466e-01, 2.53624645e-01, 2.43632591e-01, 5.04718274e+02,\n",
      "        5.71788947e+03, 5.67580040e+03, 1.29519853e+04],\n",
      "       [2.50876467e-01, 2.53624644e-01, 2.43632590e-01, 5.04718272e+02,\n",
      "        5.71788945e+03, 5.67580039e+03, 1.29519852e+04],\n",
      "       [2.50876465e-01, 2.53624643e-01, 2.43632590e-01, 5.04718272e+02,\n",
      "        5.71788945e+03, 5.67580038e+03, 1.29519852e+04]]), array([114658.09376122, 114658.09379341, 114658.0937945 , 114658.09379606,\n",
      "       114658.09380466, 114658.0938048 , 114658.09381783, 114658.09382443]))\n",
      "           fun: 114658.09376121794\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1568\n",
      "           nit: 692\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.50876463e-01, 2.53624647e-01, 2.43632593e-01, 5.04718273e+02,\n",
      "       5.71788947e+03, 5.67580041e+03, 1.29519852e+04])\n",
      "minPrevious 114654.88168403094\n",
      "best ll: 134102.859375, bestParams: [tensor(0.1853), tensor(0.0915), tensor(0.2350), tensor(1393.2190), tensor(15791.2891), tensor(15046.8711), tensor(7604.2607)]\n",
      "epoch 6\n",
      " final_simplex: (array([[2.54609511e-01, 2.43856216e-01, 2.50291407e-01, 4.36286194e+02,\n",
      "        4.94960540e+03, 4.93820998e+03, 1.11321798e+04],\n",
      "       [2.54609510e-01, 2.43856216e-01, 2.50291405e-01, 4.36286198e+02,\n",
      "        4.94960545e+03, 4.93821002e+03, 1.11321798e+04],\n",
      "       [2.54609511e-01, 2.43856216e-01, 2.50291405e-01, 4.36286199e+02,\n",
      "        4.94960546e+03, 4.93821002e+03, 1.11321798e+04],\n",
      "       [2.54609511e-01, 2.43856217e-01, 2.50291403e-01, 4.36286199e+02,\n",
      "        4.94960545e+03, 4.93821002e+03, 1.11321798e+04],\n",
      "       [2.54609512e-01, 2.43856217e-01, 2.50291403e-01, 4.36286196e+02,\n",
      "        4.94960542e+03, 4.93821000e+03, 1.11321797e+04],\n",
      "       [2.54609512e-01, 2.43856215e-01, 2.50291403e-01, 4.36286199e+02,\n",
      "        4.94960542e+03, 4.93821003e+03, 1.11321799e+04],\n",
      "       [2.54609512e-01, 2.43856216e-01, 2.50291403e-01, 4.36286197e+02,\n",
      "        4.94960543e+03, 4.93821001e+03, 1.11321798e+04],\n",
      "       [2.54609512e-01, 2.43856215e-01, 2.50291403e-01, 4.36286201e+02,\n",
      "        4.94960545e+03, 4.93821005e+03, 1.11321799e+04]]), array([114658.8812344 , 114658.88127872, 114658.88128784, 114658.88131463,\n",
      "       114658.88131858, 114658.88132239, 114658.88132343, 114658.88133034]))\n",
      "           fun: 114658.88123440312\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1338\n",
      "           nit: 572\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.54609511e-01, 2.43856216e-01, 2.50291407e-01, 4.36286194e+02,\n",
      "       4.94960540e+03, 4.93820998e+03, 1.11321798e+04])\n",
      "minPrevious 114654.88168403094\n",
      "best ll: 123080.078125, bestParams: [tensor(0.0854), tensor(0.0873), tensor(0.1528), tensor(571.8457), tensor(4760.9360), tensor(7557.0615), tensor(14724.2188)]\n",
      "epoch 7\n",
      " final_simplex: (array([[2.48834245e-01, 2.51464041e-01, 2.48115256e-01, 2.53366027e+02,\n",
      "        2.86820655e+03, 2.86541723e+03, 6.46507594e+03],\n",
      "       [2.48834245e-01, 2.51464041e-01, 2.48115256e-01, 2.53366028e+02,\n",
      "        2.86820656e+03, 2.86541728e+03, 6.46507590e+03],\n",
      "       [2.48834245e-01, 2.51464041e-01, 2.48115255e-01, 2.53366028e+02,\n",
      "        2.86820656e+03, 2.86541727e+03, 6.46507592e+03],\n",
      "       [2.48834246e-01, 2.51464040e-01, 2.48115254e-01, 2.53366029e+02,\n",
      "        2.86820656e+03, 2.86541728e+03, 6.46507588e+03],\n",
      "       [2.48834246e-01, 2.51464043e-01, 2.48115253e-01, 2.53366028e+02,\n",
      "        2.86820655e+03, 2.86541728e+03, 6.46507589e+03],\n",
      "       [2.48834246e-01, 2.51464041e-01, 2.48115252e-01, 2.53366029e+02,\n",
      "        2.86820657e+03, 2.86541726e+03, 6.46507594e+03],\n",
      "       [2.48834246e-01, 2.51464041e-01, 2.48115252e-01, 2.53366029e+02,\n",
      "        2.86820657e+03, 2.86541726e+03, 6.46507595e+03],\n",
      "       [2.48834246e-01, 2.51464041e-01, 2.48115252e-01, 2.53366029e+02,\n",
      "        2.86820658e+03, 2.86541727e+03, 6.46507593e+03]]), array([114710.32693136, 114710.32694743, 114710.32696425, 114710.32697995,\n",
      "       114710.3269933 , 114710.32701561, 114710.32701699, 114710.32702926]))\n",
      "           fun: 114710.3269313625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1326\n",
      "           nit: 597\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.48834245e-01, 2.51464041e-01, 2.48115256e-01, 2.53366027e+02,\n",
      "       2.86820655e+03, 2.86541723e+03, 6.46507594e+03])\n",
      "minPrevious 114654.88168403094\n",
      "best ll: 127118.71875, bestParams: [tensor(0.2159), tensor(0.2781), tensor(0.0663), tensor(1952.6284), tensor(20105.4023), tensor(21884.8574), tensor(20629.8730)]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.50804648e-01, 2.46021368e-01, 2.47094555e-01, 1.01044555e+03,\n",
      "        1.14092730e+04, 1.14115725e+04, 2.55711896e+04],\n",
      "       [2.50804648e-01, 2.46021369e-01, 2.47094555e-01, 1.01044555e+03,\n",
      "        1.14092730e+04, 1.14115725e+04, 2.55711897e+04],\n",
      "       [2.50804648e-01, 2.46021368e-01, 2.47094555e-01, 1.01044555e+03,\n",
      "        1.14092730e+04, 1.14115725e+04, 2.55711897e+04],\n",
      "       [2.50804648e-01, 2.46021368e-01, 2.47094554e-01, 1.01044555e+03,\n",
      "        1.14092730e+04, 1.14115725e+04, 2.55711896e+04],\n",
      "       [2.50804648e-01, 2.46021369e-01, 2.47094554e-01, 1.01044555e+03,\n",
      "        1.14092730e+04, 1.14115725e+04, 2.55711897e+04],\n",
      "       [2.50804648e-01, 2.46021368e-01, 2.47094554e-01, 1.01044555e+03,\n",
      "        1.14092730e+04, 1.14115725e+04, 2.55711896e+04],\n",
      "       [2.50804648e-01, 2.46021368e-01, 2.47094554e-01, 1.01044555e+03,\n",
      "        1.14092730e+04, 1.14115725e+04, 2.55711896e+04],\n",
      "       [2.50804649e-01, 2.46021368e-01, 2.47094554e-01, 1.01044555e+03,\n",
      "        1.14092730e+04, 1.14115725e+04, 2.55711896e+04]]), array([114659.11878924, 114659.11879189, 114659.1187923 , 114659.11879345,\n",
      "       114659.1187938 , 114659.11879596, 114659.11879845, 114659.11879945]))\n",
      "           fun: 114659.11878924232\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1418\n",
      "           nit: 596\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.50804648e-01, 2.46021368e-01, 2.47094555e-01, 1.01044555e+03,\n",
      "       1.14092730e+04, 1.14115725e+04, 2.55711896e+04])\n",
      "minPrevious 114654.88168403094\n",
      "best ll: 132205.0, bestParams: [tensor(0.1075), tensor(0.1951), tensor(0.2460), tensor(531.8789), tensor(5737.9839), tensor(14946.0537), tensor(20566.4004)]\n",
      "epoch 9\n",
      " final_simplex: (array([[2.49762096e-01, 2.49685628e-01, 2.48809360e-01, 6.15323658e+02,\n",
      "        7.01172892e+03, 6.98162266e+03, 1.56811221e+04],\n",
      "       [2.49762096e-01, 2.49685630e-01, 2.48809359e-01, 6.15323659e+02,\n",
      "        7.01172891e+03, 6.98162272e+03, 1.56811221e+04],\n",
      "       [2.49762096e-01, 2.49685628e-01, 2.48809359e-01, 6.15323658e+02,\n",
      "        7.01172892e+03, 6.98162270e+03, 1.56811220e+04],\n",
      "       [2.49762096e-01, 2.49685628e-01, 2.48809359e-01, 6.15323659e+02,\n",
      "        7.01172892e+03, 6.98162271e+03, 1.56811221e+04],\n",
      "       [2.49762097e-01, 2.49685628e-01, 2.48809358e-01, 6.15323659e+02,\n",
      "        7.01172892e+03, 6.98162267e+03, 1.56811221e+04],\n",
      "       [2.49762097e-01, 2.49685629e-01, 2.48809358e-01, 6.15323659e+02,\n",
      "        7.01172891e+03, 6.98162270e+03, 1.56811221e+04],\n",
      "       [2.49762096e-01, 2.49685629e-01, 2.48809358e-01, 6.15323658e+02,\n",
      "        7.01172892e+03, 6.98162273e+03, 1.56811221e+04],\n",
      "       [2.49762098e-01, 2.49685628e-01, 2.48809357e-01, 6.15323658e+02,\n",
      "        7.01172892e+03, 6.98162270e+03, 1.56811221e+04]]), array([114655.41830211, 114655.41831565, 114655.41832601, 114655.41832931,\n",
      "       114655.41833588, 114655.41833604, 114655.41833804, 114655.4183577 ]))\n",
      "           fun: 114655.41830210996\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1267\n",
      "           nit: 499\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.49762096e-01, 2.49685628e-01, 2.48809360e-01, 6.15323658e+02,\n",
      "       7.01172892e+03, 6.98162266e+03, 1.56811221e+04])\n",
      "minPrevious 114654.88168403094\n",
      "\n",
      "\n",
      "run 47 results for rrs: tensor([10, 10, 10]), pis: tensor([0.2500, 0.2500, 0.2500])\n",
      "Inferred pis: tensor([0.2496, 0.2473, 0.2511], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8750, 0.0979, 0.0098, 0.0196])\n",
      "P(D|V) inferred in component 1: tensor([0.8725, 0.0989, 0.0087, 0.0198], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8697, 0.0098, 0.0976, 0.0195])\n",
      "P(D|V) inferred in component both: tensor([0.8727, 0.0087, 0.0988, 0.0198], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.5539, 0.1973, 0.1967, 0.0591])\n",
      "P(D|V) inferred in component both: tensor([0.5456, 0.2010, 0.2008, 0.0526], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([5000., 5000., 1000.]) nCtrls tensor(500000.) rrMeans tensor([10, 10, 10]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.2500, 0.2500, 0.2500]) pDs tensor([0.0098, 0.0098, 0.0020])\n",
      "rrDist mean tensor([9.9900, 9.9909, 9.9546])\n",
      "startIndices [0, tensor(5000.), tensor(10000.)] endIndices tensor([ 5000., 10000., 15000.])\n",
      "totalSamples 511000\n",
      "took 19.168979167938232\n",
      "Run: 47, 4\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[57.,  1.,  0.,  0.],\n",
      "        [48., 11.,  0.,  2.],\n",
      "        [32.,  7.,  0.,  0.],\n",
      "        ...,\n",
      "        [42.,  1.,  0.,  0.],\n",
      "        [48.,  0.,  0.,  0.],\n",
      "        [52.,  2.,  1.,  0.]])\n",
      "n tensor([58., 61., 39.,  ..., 43., 48., 55.])\n",
      "xCase1, xCase2, xCase12 tensor([ 1., 11.,  7.,  ...,  1.,  0.,  2.])\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 0.,  ..., 0., 0., 1.])\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 0.,  ..., 0., 0., 0.])\n",
      "altCountsFlat tensor([[57.,  1.,  0.,  0.],\n",
      "        [48., 11.,  0.,  2.],\n",
      "        [32.,  7.,  0.,  0.],\n",
      "        ...,\n",
      "        [42.,  1.,  0.,  0.],\n",
      "        [48.,  0.,  0.,  0.],\n",
      "        [52.,  2.,  1.,  0.]])\n",
      "allNull2 tensor([1.6416e-01, 5.4321e-14, 6.5826e-08,  ..., 1.6869e-01, 3.5185e-01,\n",
      "        2.3779e-02])\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0098) tensor(0.0098) tensor(0.0020) tensor(0.9785)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe3626d5e60>\n",
      "best ll: 126170.7578125, bestParams: [tensor(0.0529), tensor(0.1265), tensor(0.2348), tensor(950.6364), tensor(10534.4883), tensor(6090.2051), tensor(19335.7910)]\n",
      "epoch 0\n",
      " final_simplex: (array([[2.47879830e-01, 2.46412170e-01, 2.49602652e-01, 4.48905955e+02,\n",
      "        5.10766188e+03, 5.13367243e+03, 1.13980967e+04],\n",
      "       [2.47879830e-01, 2.46412168e-01, 2.49602652e-01, 4.48905956e+02,\n",
      "        5.10766189e+03, 5.13367245e+03, 1.13980967e+04],\n",
      "       [2.47879830e-01, 2.46412169e-01, 2.49602652e-01, 4.48905956e+02,\n",
      "        5.10766189e+03, 5.13367244e+03, 1.13980968e+04],\n",
      "       [2.47879829e-01, 2.46412167e-01, 2.49602652e-01, 4.48905957e+02,\n",
      "        5.10766188e+03, 5.13367246e+03, 1.13980967e+04],\n",
      "       [2.47879830e-01, 2.46412167e-01, 2.49602652e-01, 4.48905955e+02,\n",
      "        5.10766187e+03, 5.13367244e+03, 1.13980967e+04],\n",
      "       [2.47879830e-01, 2.46412170e-01, 2.49602652e-01, 4.48905955e+02,\n",
      "        5.10766188e+03, 5.13367245e+03, 1.13980967e+04],\n",
      "       [2.47879830e-01, 2.46412169e-01, 2.49602652e-01, 4.48905959e+02,\n",
      "        5.10766192e+03, 5.13367248e+03, 1.13980968e+04],\n",
      "       [2.47879829e-01, 2.46412169e-01, 2.49602652e-01, 4.48905957e+02,\n",
      "        5.10766190e+03, 5.13367247e+03, 1.13980967e+04]]), array([114864.59024393, 114864.59024572, 114864.5902498 , 114864.59025078,\n",
      "       114864.59025177, 114864.59025315, 114864.59025395, 114864.59025419]))\n",
      "           fun: 114864.59024392633\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1673\n",
      "           nit: 754\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.47879830e-01, 2.46412170e-01, 2.49602652e-01, 4.48905955e+02,\n",
      "       5.10766188e+03, 5.13367243e+03, 1.13980967e+04])\n",
      "best ll: 175478.125, bestParams: [tensor(0.0409), tensor(0.0103), tensor(0.0243), tensor(3031.2563), tensor(21487.8262), tensor(16840.2324), tensor(21346.3555)]\n",
      "epoch 1\n",
      " final_simplex: (array([[2.34061174e-01, 2.20248866e-01, 2.70287399e-01, 3.60503470e+03,\n",
      "        4.42591075e+04, 4.37512865e+04, 8.69103226e+04],\n",
      "       [2.34061174e-01, 2.20248866e-01, 2.70287399e-01, 3.60503470e+03,\n",
      "        4.42591075e+04, 4.37512865e+04, 8.69103227e+04],\n",
      "       [2.34061174e-01, 2.20248866e-01, 2.70287399e-01, 3.60503470e+03,\n",
      "        4.42591075e+04, 4.37512865e+04, 8.69103227e+04],\n",
      "       [2.34061174e-01, 2.20248866e-01, 2.70287398e-01, 3.60503470e+03,\n",
      "        4.42591075e+04, 4.37512865e+04, 8.69103225e+04],\n",
      "       [2.34061175e-01, 2.20248866e-01, 2.70287398e-01, 3.60503470e+03,\n",
      "        4.42591075e+04, 4.37512865e+04, 8.69103225e+04],\n",
      "       [2.34061175e-01, 2.20248866e-01, 2.70287398e-01, 3.60503470e+03,\n",
      "        4.42591075e+04, 4.37512865e+04, 8.69103226e+04],\n",
      "       [2.34061175e-01, 2.20248866e-01, 2.70287398e-01, 3.60503470e+03,\n",
      "        4.42591075e+04, 4.37512865e+04, 8.69103226e+04],\n",
      "       [2.34061175e-01, 2.20248865e-01, 2.70287398e-01, 3.60503470e+03,\n",
      "        4.42591075e+04, 4.37512865e+04, 8.69103225e+04]]), array([114996.03069142, 114996.03069177, 114996.03069228, 114996.03069495,\n",
      "       114996.03069635, 114996.03069768, 114996.03069867, 114996.03070037]))\n",
      "           fun: 114996.03069142032\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2094\n",
      "           nit: 1028\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.34061174e-01, 2.20248866e-01, 2.70287399e-01, 3.60503470e+03,\n",
      "       4.42591075e+04, 4.37512865e+04, 8.69103226e+04])\n",
      "minPrevious 114864.59024392633\n",
      "best ll: 136817.5, bestParams: [tensor(0.2342), tensor(0.0465), tensor(0.1209), tensor(634.1966), tensor(4522.8730), tensor(11828.6807), tensor(5026.1323)]\n",
      "epoch 2\n",
      " final_simplex: (array([[2.50603810e-01, 2.48032624e-01, 2.48982197e-01, 4.42678473e+02,\n",
      "        4.99746442e+03, 5.05678483e+03, 1.12249454e+04],\n",
      "       [2.50603810e-01, 2.48032622e-01, 2.48982196e-01, 4.42678472e+02,\n",
      "        4.99746445e+03, 5.05678482e+03, 1.12249453e+04],\n",
      "       [2.50603810e-01, 2.48032623e-01, 2.48982196e-01, 4.42678473e+02,\n",
      "        4.99746442e+03, 5.05678484e+03, 1.12249454e+04],\n",
      "       [2.50603810e-01, 2.48032623e-01, 2.48982196e-01, 4.42678473e+02,\n",
      "        4.99746440e+03, 5.05678483e+03, 1.12249454e+04],\n",
      "       [2.50603810e-01, 2.48032624e-01, 2.48982196e-01, 4.42678473e+02,\n",
      "        4.99746438e+03, 5.05678484e+03, 1.12249454e+04],\n",
      "       [2.50603810e-01, 2.48032623e-01, 2.48982196e-01, 4.42678474e+02,\n",
      "        4.99746441e+03, 5.05678485e+03, 1.12249454e+04],\n",
      "       [2.50603810e-01, 2.48032623e-01, 2.48982196e-01, 4.42678473e+02,\n",
      "        4.99746441e+03, 5.05678484e+03, 1.12249454e+04],\n",
      "       [2.50603810e-01, 2.48032623e-01, 2.48982196e-01, 4.42678473e+02,\n",
      "        4.99746441e+03, 5.05678484e+03, 1.12249454e+04]]), array([114865.11057891, 114865.11058034, 114865.11058221, 114865.11058742,\n",
      "       114865.11058855, 114865.11058914, 114865.11059518, 114865.110596  ]))\n",
      "           fun: 114865.11057891152\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1690\n",
      "           nit: 787\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.50603810e-01, 2.48032624e-01, 2.48982197e-01, 4.42678473e+02,\n",
      "       4.99746442e+03, 5.05678483e+03, 1.12249454e+04])\n",
      "minPrevious 114864.59024392633\n",
      "best ll: 123764.765625, bestParams: [tensor(0.2083), tensor(0.0569), tensor(0.1485), tensor(1349.1322), tensor(23850.8086), tensor(15120.6230), tensor(20901.1484)]\n",
      "epoch 3\n",
      " final_simplex: (array([[2.46206171e-01, 2.30769062e-01, 2.60706619e-01, 3.14419362e+02,\n",
      "        3.56956355e+03, 3.61968958e+03, 7.92346878e+03],\n",
      "       [2.46206171e-01, 2.30769062e-01, 2.60706619e-01, 3.14419362e+02,\n",
      "        3.56956355e+03, 3.61968958e+03, 7.92346878e+03],\n",
      "       [2.46206171e-01, 2.30769062e-01, 2.60706619e-01, 3.14419362e+02,\n",
      "        3.56956355e+03, 3.61968958e+03, 7.92346878e+03],\n",
      "       [2.46206171e-01, 2.30769062e-01, 2.60706619e-01, 3.14419362e+02,\n",
      "        3.56956355e+03, 3.61968958e+03, 7.92346878e+03],\n",
      "       [2.46206171e-01, 2.30769062e-01, 2.60706619e-01, 3.14419361e+02,\n",
      "        3.56956355e+03, 3.61968958e+03, 7.92346878e+03],\n",
      "       [2.46206171e-01, 2.30769062e-01, 2.60706619e-01, 3.14419361e+02,\n",
      "        3.56956355e+03, 3.61968958e+03, 7.92346878e+03],\n",
      "       [2.46206171e-01, 2.30769062e-01, 2.60706619e-01, 3.14419361e+02,\n",
      "        3.56956355e+03, 3.61968958e+03, 7.92346878e+03],\n",
      "       [2.46206171e-01, 2.30769062e-01, 2.60706619e-01, 3.14419362e+02,\n",
      "        3.56956355e+03, 3.61968958e+03, 7.92346878e+03]]), array([114901.91559913, 114901.91559915, 114901.91559916, 114901.91559917,\n",
      "       114901.91559919, 114901.91559922, 114901.91559924, 114901.91559926]))\n",
      "           fun: 114901.91559912659\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1690\n",
      "           nit: 660\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.46206171e-01, 2.30769062e-01, 2.60706619e-01, 3.14419362e+02,\n",
      "       3.56956355e+03, 3.61968958e+03, 7.92346878e+03])\n",
      "minPrevious 114864.59024392633\n",
      "best ll: 132430.28125, bestParams: [tensor(0.1245), tensor(0.1211), tensor(0.0654), tensor(1242.2180), tensor(19280.9375), tensor(17928.9980), tensor(6773.6514)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-1b51f491e757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[0;31m#         fnArgs = [probs[0], probs[1], probs[2], *alphas]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m         \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Nelder-Mead'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adaptive\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mxbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxbar\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mfxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mdoshrink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0maBothBoth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malphaBoth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mh3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBoth1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBoth2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBothBoth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mh0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "resSim = {\n",
    "        \"allRes\": None,\n",
    "        \"nEpochs\": None,\n",
    "        \"bestRes\": {\n",
    "            \"pis\": None,\n",
    "            \"alphas\": None,\n",
    "            \"PDV_c1true\": None,\n",
    "            \"PDV_c2true\": None,\n",
    "            \"PDV_cBothTrue\": None,\n",
    "            \"PDV_c1inferred\": None,\n",
    "            \"PDV_c2inferred\": None,\n",
    "            \"PDV_cBothInferred\": None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cachedData6SimResults = []\n",
    "\n",
    "rrsSim = tensor([[2, 2, 2], [5, 5, 2], [10, 10, 2], [5, 5, 5], [10, 10, 10], [20, 20, 20]])\n",
    "pisSim = tensor([[.01, .01, .01], [.05, .05, .05], [.1, .1, .1], [.25, .25, .25], [.05, .05, .01], [.1, .1, .01], [.1, .1, .05], [.25, .25, .01], [.25, .25, .05], [.25, .25, .1], [.25, .25, .25]])\n",
    "\n",
    "i = 0\n",
    "for rrsSimRun in rrsSim:\n",
    "    for pisSimRun in pisSim:\n",
    "        afMeanRun = 1e-4\n",
    "        generatingFn = genData.v6 #can't use normal until we truncate distribution with lower rr values\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        # needs tensor for shapes, otherwise \"gamma_cpu not implemente for long\", e.g rrShape=50.0 doesn't work...\n",
    "        paramsRun = genData.genParams(rrMeans=rrsSimRun, pis=pisSimRun, afMean=afMeanRun, rrShape=tensor(50.), afShape=tensor(50.))[0]\n",
    "        \n",
    "        pDsRun = paramsRun[\"pDs\"]\n",
    "        pisRun = paramsRun[\"diseaseFractions\"]\n",
    "        print(\"params are:\", paramsRun)\n",
    "        \n",
    "        cachedData6SimResults.append({\"params\": paramsRun, \"runs\": []})\n",
    "        for y in range(0, 10):\n",
    "            start = time.time()\n",
    "            r = generatingFn(**paramsRun)\n",
    "            print(\"took\", time.time() - start)\n",
    "            \n",
    "            resPointer = {\n",
    "                **r,\n",
    "                \"generatingFn\": generatingFn,\n",
    "                \"results\": None,\n",
    "            }\n",
    "\n",
    "            cachedData6SimResults[i][\"runs\"].append(resPointer)\n",
    "            \n",
    "            print(f\"Run: {i}, {y}\")\n",
    "            \n",
    "            xsRun = resPointer[\"altCounts\"]\n",
    "            afsRun = resPointer[\"afs\"]\n",
    "            affectedGenesRun = resPointer[\"affectedGenes\"]\n",
    "            unaffectedGenesRun = resPointer[\"unaffectedGenes\"]\n",
    "\n",
    "            runCostFnIdx = 16\n",
    "\n",
    "            nEpochsRun = 10\n",
    "            if(rrsSimRun.max() < 5):\n",
    "                nEpochsRun = 20\n",
    "            print(\"nEpochsRun\", nEpochsRun)\n",
    "            \n",
    "            res = likelihoods.fitFnBivariate(xsRun, pDsRun, nEpochs=nEpochsRun, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "            bestRes = res[\"params\"][-1]\n",
    "\n",
    "            inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "            inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "            #### Calculate actual ###\n",
    "            component1Afs = afsRun[affectedGenesRun[0]]\n",
    "            c1true = (component1Afs / afMeanRun).mean(0)\n",
    "\n",
    "            component2Afs = afsRun[affectedGenesRun[1]]\n",
    "            c2true = (component2Afs / afMeanRun).mean(0)\n",
    "\n",
    "            componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "            cBothTrue = (componentBothAfs / afMeanRun).mean(0)\n",
    "\n",
    "            ### calculate inferred values\n",
    "            pds = tensor([1-pDsRun.sum(), *pDsRun])\n",
    "            alphas = inferredAlphas.numpy()\n",
    "            c1inferred = Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            c2inferred = Dirichlet(tensor([alphas[0], alphas[0], alphas[2], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            cBothInferred = Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0)\n",
    "\n",
    "            print(f\"\\n\\nrun {i} results for rrs: {rrsSimRun}, pis: {pisSimRun}\")\n",
    "            print(\"Inferred pis:\", inferredPis)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c1true)\n",
    "            print(\"P(D|V) inferred in component 1:\", c1inferred)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c2true)\n",
    "            print(\"P(D|V) inferred in component both:\", c2inferred)\n",
    "            print(\"\\nP(D|V) true ans in component both:\", cBothTrue)\n",
    "            print(\"P(D|V) inferred in component both:\", cBothInferred,\"\\n\\n\")\n",
    "\n",
    "            resToStore = copy.deepcopy(resSim)\n",
    "            resToStore[\"allRes\"] = res\n",
    "            resToStore[\"nEpochs\"] = nEpochsRun\n",
    "            br = resToStore[\"bestRes\"]\n",
    "            br[\"pis\"] = inferredPis\n",
    "            br[\"alphas\"] = inferredAlphas\n",
    "            br[\"PDV_c1true\"] = c1true\n",
    "            br[\"PDV_c2true\"] = c2true\n",
    "            br[\"PDV_cBothTrue\"] = cBothTrue\n",
    "            br[\"PDV_c1inferred\"] = c1inferred\n",
    "            br[\"PDV_c2inferred\"] = c2inferred\n",
    "            br[\"PDV_cBothInferred\"] = cBothInferred\n",
    "\n",
    "            resPointer[\"results\"] = resToStore\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in cachedData6SimResults:\n",
    "    for res in obj[\"runs\"]:\n",
    "        del res[\"generatingFn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"tadm-sim-large\", cachedData6SimResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e87475a9288e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tadm-sim-large.npy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf_should_read_directly\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "t = np.load(\"tadm-sim-large.npy\",allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4a68cb4573be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresByParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrunSet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrunSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"diseaseFractions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rrMeans\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rrShape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     print(\"param\", params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "# resByParams = []\n",
    "# for runSet in t:\n",
    "#     params = (runSet[\"params\"][\"diseaseFractions\"], runSet[\"params\"][\"rrMeans\"], runSet[\"params\"][\"rrShape\"])\n",
    "# #     print(\"param\", params)\n",
    "#     res = []\n",
    "# #     if params not in resByParam:\n",
    "# #         resByParams[params] = []\n",
    "    \n",
    "#     for run in runSet[\"runs\"]:\n",
    "#         if run is None or \"results\" not in run or run[\"results\"] is None:\n",
    "#             print(f\"no results found for {params}\")\n",
    "#             continue\n",
    "#         res.append(run[\"results\"])\n",
    "#     resByParams.append([params, res])\n",
    "\n",
    "# np.save(\"tadm-sim-large-results\", resByParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resByParams = np.load(\"tadm-sim-large-results.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "nRuns = len(resByParams)\n",
    "print(nRuns)\n",
    "params = [x[0] for x in resByParams]\n",
    "results = [x[1] for x in resByParams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.subplot([1,len(resByParams)])\n",
    "i = 0\n",
    "with open(\"tadam-res.tsv\", \"w\") as file:\n",
    "    file.write(f\"Notes: 5000 samples1, 5000 samples2, 2000 samplesBoth; rrs generated from gamma distribution, and individual effect rr summed with shared-effect rr in genes affecting both conditions\\n\")\n",
    "    file.write(f\"\\tmean\\tstd\\n\")\n",
    "    for res in resByParams:\n",
    "        i += 1\n",
    "\n",
    "        paramsRun = res[0]\n",
    "        resRun = res[1]\n",
    "\n",
    "        pis = tensor([x[\"bestRes\"][\"pis\"].numpy() for x in resRun])\n",
    "        PDV_c1true = tensor([x[\"bestRes\"][\"PDV_c1true\"].numpy() for x in resRun])\n",
    "        PDV_c2true = tensor([x[\"bestRes\"][\"PDV_c2true\"].numpy() for x in resRun])\n",
    "        PDV_c3true = tensor([x[\"bestRes\"][\"PDV_cBothTrue\"].numpy() for x in resRun])\n",
    "        PDV_c1inferred = tensor([x[\"bestRes\"][\"PDV_c1inferred\"].numpy() for x in resRun])\n",
    "        PDV_c2inferred = tensor([x[\"bestRes\"][\"PDV_c2inferred\"].numpy() for x in resRun])\n",
    "        PDV_c3inferred = tensor([x[\"bestRes\"][\"PDV_cBothInferred\"].numpy() for x in resRun])\n",
    "\n",
    "        file.write(f\"\\n\\ntrue params: \\t{paramsRun} \\n\\n\")\n",
    "\n",
    "        file.write(f\"pi\\t {pis.mean(0).numpy()} \\t  {pis.std(0).numpy()} \\n\")\n",
    "\n",
    "        file.write(f\"PDV_c1inferred \\t {PDV_c1inferred.mean(0).numpy()}\\t {PDV_c1inferred.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c1true \\t {PDV_c1true.mean(0).numpy()} \\t {PDV_c1true.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c2inferred \\t {PDV_c2inferred.mean(0).numpy()} \\t {PDV_c2inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c2true \\t {PDV_c2true.mean(0).numpy()} \\t {PDV_c2true.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3inferred \\t {PDV_c3inferred.mean(0).numpy()} \\t {PDV_c3inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3true \\t {PDV_c3true.mean(0).numpy()} \\t {PDV_c3true.std(0).numpy()}\\n\")\n",
    "\n",
    "    #     plt.figure(i)\n",
    "    #     plt.plot(t, s1)\n",
    "    #     plt.plot(t, 2*s1)\n",
    "        # plt.subplot(222)\n",
    "        # plt.plot(t, 2*s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99999993, 0.99999992, 0.99999981, 0.99999796,\n",
       "        0.99999778, 0.999998  , 0.99999775],\n",
       "       [0.99999993, 1.        , 0.9999999 , 0.99999984, 0.99999847,\n",
       "        0.9999983 , 0.99999851, 0.99999827],\n",
       "       [0.99999992, 0.9999999 , 1.        , 0.99999998, 0.9999976 ,\n",
       "        0.99999738, 0.99999766, 0.99999735],\n",
       "       [0.99999981, 0.99999984, 0.99999998, 1.        , 0.99999749,\n",
       "        0.99999726, 0.99999755, 0.99999722],\n",
       "       [0.99999796, 0.99999847, 0.9999976 , 0.99999749, 1.        ,\n",
       "        0.99999999, 1.        , 0.99999999],\n",
       "       [0.99999778, 0.9999983 , 0.99999738, 0.99999726, 0.99999999,\n",
       "        1.        , 0.99999999, 1.        ],\n",
       "       [0.999998  , 0.99999851, 0.99999766, 0.99999755, 1.        ,\n",
       "        0.99999999, 1.        , 0.99999999],\n",
       "       [0.99999775, 0.99999827, 0.99999735, 0.99999722, 0.99999999,\n",
       "        1.        , 0.99999999, 1.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.figure(1)\n",
    "# plt.scatter(PDV_c1inferred, PDV_c1true)\n",
    "import numpy as np\n",
    "# len(PDV_c1inferred)\n",
    "np.corrcoef(PDV_c1inferred, PDV_c1true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "runIdx = 30\n",
    "\n",
    "# print(resRun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true params (tensor([0.2500, 0.2500, 0.0500]), tensor([10, 10,  2]), tensor(50.)) \n",
      "\n",
      "pi inf. mean tensor([0.2439, 0.2468, 0.0513], dtype=torch.float64) std tensor([0.0028, 0.0022, 0.0009], dtype=torch.float64) \n",
      "\n",
      "PDV_c1inferred mean tensor([0.8724, 0.0992, 0.0087, 0.0198], dtype=torch.float64) std tensor([6.4146e-04, 6.2730e-04, 1.6878e-05, 1.9582e-04], dtype=torch.float64)\n",
      "PDV_c1true mean tensor([0.8724, 0.0978, 0.0098, 0.0196]) std tensor([2.1619e-03, 3.3423e-04, 2.3977e-05, 6.6854e-05]) \n",
      "\n",
      "PDV_c2inferred mean tensor([0.8727, 0.0087, 0.0988, 0.0198], dtype=torch.float64) std tensor([1.1060e-03, 1.8489e-05, 9.1835e-04, 1.9054e-04], dtype=torch.float64)\n",
      "PDV_c2true mean tensor([0.8725, 0.0098, 0.0978, 0.0196]) std tensor([1.6640e-03, 1.8167e-05, 3.0733e-04, 6.1479e-05]) \n",
      "\n",
      "PDV_c3inferred mean tensor([0.7223, 0.1189, 0.1187, 0.0401], dtype=torch.float64) std tensor([0.0048, 0.0022, 0.0023, 0.0004], dtype=torch.float64)\n",
      "PDV_c3true mean tensor([0.7221, 0.1176, 0.1175, 0.0431]) std tensor([0.0009, 0.0006, 0.0008, 0.0002])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     \n",
    "#     'bestRes': {'pis': tensor([0.2802, 0.2084, 0.0922], dtype=torch.float64),\n",
    "#      'alphas': tensor([22917.1452, 19728.8451, 18864.1235, 24970.0287], dtype=torch.float64),\n",
    "#      'PDV_c1true': tensor([0.9499, 0.0193, 0.0096, 0.0039]),\n",
    "#      'PDV_c2true': tensor([0.9459, 0.0096, 0.0191, 0.0038]),\n",
    "#      'PDV_cBothTrue': tensor([0.9024, 0.0392, 0.0391, 0.0117]),\n",
    "#      'PDV_c1inferred': tensor([0.9801, 0.0084, 0.0098, 0.0016], dtype=torch.float64),\n",
    "#      'PDV_c2inferred': tensor([0.9805, 0.0098, 0.0081, 0.0016], dtype=torch.float64),\n",
    "#      'PDV_cBothInferred': tensor([0.9577, 0.0187, 0.0183, 0.0053], dtype=torch.float64)}}},\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best for rr = 10, 10, 2  pis = .1, .1, .1 using ll 2L i get, with 2 epochs:\n",
    "# ll:75336.61691385253\n",
    "# x: array([9.82810535e-02, 9.95955936e-02, 9.92386489e-02, 2.63195506e+03,\n",
    "#       2.99568070e+02, 3.03870925e+02, 2.64435039e+01])\n",
    "# ratio between alpha3/alpha2 is .08\n",
    "# Corresponding probabilities, calculated by:\n",
    "# Dirichlet(tensor([2.63195506e+03,2.99568070e+02, 3.03870925e+02, 2.64435039e+01])).sample([10_000]).mean(0)\n",
    "# are: tensor([0.8070, 0.0918, 0.0931, 0.0081])\n",
    "# true PD1|V in first component is .0964\n",
    "\n",
    "# and with ll 2m (simplified model, scaling everything by prevalence): in 1 epoch:\n",
    "# ll: 75353.11707923887\n",
    "# x: array([9.89051723e-02, 9.89630191e-02, 1.01472643e-01, 1.04537269e+03,\n",
    "#       1.18222798e+04, 1.19419991e+04, 5.66127181e+03])\n",
    "# ratio alpha3/alpha2 is \n",
    "# 4th epoch give sbetter resutl:\n",
    "# ll:75350.36999357422\n",
    "# x: array([9.73252252e-02, 9.97021162e-02, 9.99173056e-02, 1.84813348e+03,\n",
    "#       2.09636601e+04, 2.13425518e+04, 9.79171130e+03])\n",
    "# ratio is: 9.79171130e+03/2.13425518e+04 == .45\n",
    "# corresponding probs, calculated by:\n",
    "# pds = tensor([0.9785, 0.0098, 0.0098, 0.0020])\n",
    "# Dirichlet(tensor([1.84813348e+03, 2.09636601e+04, 2.13425518e+04, 9.79171130e+03]) * pds).sample([10_000]).mean(0)\n",
    "# are:\n",
    "# tensor([0.8065, 0.0914, 0.0933, 0.0087])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afsRun = cachedData6[0][\"afs\"]\n",
    "affectedGenesRun = cachedData6[0][\"affectedGenes\"]\n",
    "\n",
    "component1Afs = afsRun[affectedGenesRun[0]]\n",
    "b = (component1Afs / 1e-4).mean(0)\n",
    "print(\"P(D|V) true ans in component 1:\", b)\n",
    "\n",
    "componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "a = (componentBothAfs / 1e-4).mean(0)\n",
    "print(\"P(D|V) true ans in component both:\", a)\n",
    "\n",
    "print(\"their weighted average\", .66 * a[1] + .33 * b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = tensor([0.9785, 0.0098, 0.0098, 0.0020])\n",
    "alphas = tensor([1.54050827e+03,\n",
    "       1.72596651e+04, 1.73096601e+04, 8.14625381e+03])\n",
    "print(\"P(D|V) inferred in component 1:\", Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0))\n",
    "print(\"P(D|V) inferred in component both:\", Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afsRun = cachedData6[1][\"afs\"]\n",
    "affectedGenesRun = cachedData6[1][\"affectedGenes\"]\n",
    "\n",
    "component1Afs = afsRun[affectedGenesRun[0]]\n",
    "b = (component1Afs / 1e-4).mean(0)\n",
    "print(\"P(D|V) true ans in component 1:\", b)\n",
    "\n",
    "componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "a = (componentBothAfs / 1e-4).mean(0)\n",
    "print(\"P(D|V) true ans in component both:\", a)\n",
    "\n",
    "print(\"their weighted average\", .66 * a[1] + .33 * b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = tensor([0.9785, 0.0098, 0.0098, 0.0020])\n",
    "alphas = tensor([3.46447340e+03,\n",
    "       1.82738687e+04, 1.80604772e+04, 1.26368803e+04])\n",
    "print(\"P(D|V) inferred in component 1:\", Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0))\n",
    "print(\"P(D|V) inferred in component both:\", Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pis6 = tensor([9.93066320e-02, 8.98661230e-02, 5.06311231e-02])\n",
    "alphas6 = tensor([1.40389464e+03,\n",
    "       7.41484840e+03, 7.66827878e+03, 4.15453746e+03])\n",
    "\n",
    "\n",
    "pisDenom = pis6.sum()\n",
    "pi1frac = pis6[0]/pisDenom\n",
    "pi3frac = pis6[2]/pisDenom\n",
    "print(\"pi1frac\", pi1frac, \"pi3frac\",pi3frac)\n",
    "pNotD = 1 - pDsRun.sum()\n",
    "pDstest = tensor([pNotD, *pDsRun])\n",
    "print(\"pDstest\", pDstest)\n",
    "d = Dirichlet(alphas6).sample([100_000]).mean(0)\n",
    "print(\"d\", d)\n",
    "\n",
    "weightedAveragePDStest = \n",
    "inferredPD1V = pi1frac*(alphas6[1]/alphas6.sum())*pDsRun[0] + .33*( (alphas6[1] + alphas6[3])/ alphas6.sum() )*pDsRun[0]\n",
    "print(\"expected mixed\", (alphas6[1] + alphas6[3])/ alphas6.sum())\n",
    "print(\"inferred\", inferredPD1V, pis6[0], pis6[2])\n",
    "actualPD1V = .66 * likelihoods.pDgivenV(.01, (5 * 1e-4), 1e-4) + .33 * likelihoods.pDgivenV(.01, ((5 + 2) * 1e-4), 1e-4)\n",
    "print(\"actualPD1V\", actualPD1V)\n",
    "\n",
    "# alphas6[1]/alphas6.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvd = likelihoods.pVgivenD(10, 1e-4)\n",
    "print(\"pvd\", pvd)\n",
    "likelihoods.pDgivenV(.01, pvd, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params7 = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"truePDVs\": [], \"params\": [], \"costFnIdx\": []}\n",
    "# altCountsByGenePooledCtrls4, afsByGenePooledCtrls4, affectedGenes4 = genData4(nCases=nCasesLarge, nCtrls=nCtrlsLarge, pDs=pDsGlobalLarge, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansCovary, afMean=afMean, afShape=afShape, nGenes=nGenes)\n",
    "\n",
    "cachedData7 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 50):\n",
    "    if i >= len(cachedData7):\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        params = genParams(rrMeans=tensor([5., 5., 2]), pis=tensor([.1, .1, .05]))\n",
    "        start = time.time()\n",
    "        r = genData7(**params[0])\n",
    "\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData7.append({**r, \"params\": params[0]})\n",
    "    cd = cachedData7[i]\n",
    "    print(f\"I is {i}\")\n",
    "    print(\"params are:\", cd[\"params\"], \"pis are\", pisRun)\n",
    "    xsRun = cd[\"altCounts\"]\n",
    "    afsRun = cd[\"afs\"]\n",
    "    affectedGenesRun = cd[\"affectedGenes\"]\n",
    "    unaffectedGenesRun = cd[\"unaffectedGenes\"]\n",
    "    pDsRun = cd[\"params\"][\"pDs\"]\n",
    "    pisRun = cd[\"params\"][\"diseaseFractions\"]\n",
    "\n",
    "    print(\"i is\", i)\n",
    "    print(\"pis are\", pisRun)\n",
    "    runCostFnIdx = 16\n",
    "    res = fitFnBivariate(xsRun, pDsRun, nEpochs=10, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "    \n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "    inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "    # index 0 is the P(!D|V), aka probability of being a control given variant present\n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "    \n",
    "    inferredPiProp1 = inferredPis[0] / inferredPis.sum()\n",
    "    inferredPiProp2 = inferredPis[1] / inferredPis.sum()\n",
    "    \n",
    "    inferredC1PDgivenV = inferredPiProp1 * inferredPDs[1] + (1 - inferredPiProp1) * (inferredPDs[1] + inferredPDs[3] * pDsRun[0]/pDsRun[2])\n",
    "    inferredC2PDgivenV = inferredPiProp2 * inferredPDs[2] + (1 - inferredPiProp2) * (inferredPDs[2] + inferredPDs[3] * pDsRun[1]/pDsRun[2])\n",
    "    inferredCBothPDgivenV = (inferredPis[0] / inferredPis.sum()) * inferredPDs[1] * pDsRun[2]/pDsRun[0] + (inferredPis[1] / inferredPis.sum()) * inferredPDs[2] * pDsRun[2]/pDsRun[1] + (inferredPis[2] / inferredPis.sum()) * inferredPDs[3]\n",
    "    \n",
    "    piProp1 = pisRun[0] / (pisRun[0] + pisRun[2])\n",
    "    piProp2 = pisRun[1] / (pisRun[1] + pisRun[2])\n",
    "    \n",
    "    PV_hat = afsRun[unaffectedGenesRun].mean()\n",
    "    \n",
    "    trueC1PVgivenD = piProp1 * afsPooledRun[affectedGenesRun[0], 1].mean() + (1-piProp1) * afsPooledRun[affectedGenesRun[2], 1].mean()\n",
    "    trueC2PVgivenD = piProp2 * afsPooledRun[affectedGenesRun[1], 2].mean() + (1-piProp2) * afsPooledRun[affectedGenesRun[2], 2].mean()\n",
    "    trueCBothPVgivenD = (pisRun[0] / pisRun.sum()) * afsPooledRun[affectedGenesRun[0], 3].mean() + (pisRun[1] / pisRun.sum()) * afsPooledRun[affectedGenesRun[1], 3].mean() + (pisRun[2] / pisRun.sum()) * afsPooledRun[affectedGenesRun[2], 3].mean()\n",
    "    \n",
    "    trueC1PDgivenV = pDgivenV(pD=pDsRun[0], pVgivenD=trueC1PVgivenD, pV=PV_hat)\n",
    "    trueC2PDgivenV = pDgivenV(pD=pDsRun[1], pVgivenD=trueC2PVgivenD, pV=PV_hat)\n",
    "    trueCBothPDgivenV = pDgivenV(pD=pDsRun[2], pVgivenD=trueCBothPVgivenD, pV=PV_hat)\n",
    "    \n",
    "    inferredPDGivenVs = tensor([inferredC1PDgivenV, inferredC2PDgivenV, inferredCBothPDgivenV])\n",
    "    truePDGivenVs = tensor([trueC1PDgivenV, trueC2PDgivenV, trueCBothPDgivenV])\n",
    "    print(\"\\ninferredPis\", inferredPis)\n",
    "    print(\"\\ninferredPDVs\", inferredPDGivenVs)\n",
    "    print(\"\\ntruePDGivenVs\", truePDGivenVs)\n",
    "    \n",
    "    params7[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params7[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params7[\"inferredPis\"].append(inferredPis)\n",
    "    params7[\"inferredPDVs\"].append(inferredPDGivenVs)\n",
    "    params7[\"truePDVs\"].append(truePDGivenVs)\n",
    "    params7[\"params\"].append(cd[\"params\"])\n",
    "    \n",
    "    params7[\"costFnIdx\"].append(runCostFnIdx)\n",
    "\n",
    "    print(f\"\\n\\nparams on run {i}\\n\", params7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res50runs = {'lls': [58650.980808793975, 58663.01401779418, 58569.64432617293, 58783.93053623588, 58682.33104454364, 58670.7864442745, 58767.07466917903, 58782.95043266173, 58606.908820588906, 59304.74890821583, 58911.15021697714, 58777.76354377231, 58886.570525058676, 58979.60372626227, 58614.46769251791, 58575.018502609695, 58626.15989734368, 58342.02048699708, 58829.85280470915, 58523.63671041844, 59007.470544101496, 58665.29306683903, 58648.988256305376, 58598.11571418069, 58663.155895392454, 58532.66995278367, 58745.85232303206, 58644.916042740035, 58709.34026003936, 58809.63451601051, 58977.55303030012, 58892.08514286647, 58877.93190469771, 58620.8791816608, 58482.08335511814, 58771.290054508005, 58647.06512581756, 58771.13322666185, 59108.46648654986, 58352.932648069494, 58575.05496089697, 58791.550182731444, 58369.87373441178, 58822.57336510841, 58547.54381986277, 58687.756211119966, 58837.32699975922, 58466.909804709016, 58817.619849630566, 59005.57744894046, 58835.565050908466], 'inferredAlphas': [tensor([285.8449,  16.3664,  14.0267,   2.0217], dtype=torch.float64), tensor([ 741.8330, 4306.4346, 3780.8586, 2703.1299], dtype=torch.float64), tensor([ 827.7676, 4815.6097, 4234.2331, 2795.9735], dtype=torch.float64), tensor([ 262.6893, 1468.7320, 1280.2859,  960.5048], dtype=torch.float64), tensor([1070.0174, 6370.6853, 5331.2606, 3840.4440], dtype=torch.float64), tensor([1059.2849, 6294.1272, 5878.8562, 3665.3299], dtype=torch.float64), tensor([ 2058.0929, 12130.9712, 10666.2817,  6925.0974], dtype=torch.float64), tensor([ 244.4174, 1308.6004, 1285.9113,  996.4851], dtype=torch.float64), tensor([ 244.8058, 1382.5232, 1175.4547,  951.0711], dtype=torch.float64), tensor([ 253.0269, 1375.9456, 1155.1913,  971.0471], dtype=torch.float64), tensor([ 243.6885, 1279.8120, 1228.5845,  904.9808], dtype=torch.float64), tensor([ 227.2277, 1332.9335, 1045.9575,  837.2653], dtype=torch.float64), tensor([ 4491.7193, 25390.3203, 23260.1949, 16825.4658], dtype=torch.float64), tensor([ 210.3162, 1030.6505,  942.5924,  899.7928], dtype=torch.float64), tensor([ 951.5742, 5679.4705, 4692.2591, 3427.2280], dtype=torch.float64), tensor([ 2090.3471, 12572.5728, 11265.6956,  6863.4594], dtype=torch.float64), tensor([ 258.4622, 1358.8527, 1195.5652, 1029.1043], dtype=torch.float64), tensor([ 240.7183, 1422.7796, 1213.0808,  822.0767], dtype=torch.float64), tensor([ 218.6876, 1173.6052, 1008.0436,  913.3256], dtype=torch.float64), tensor([ 210.1855, 1198.3421,  950.7173,  774.5709], dtype=torch.float64), tensor([ 3885.8629, 22739.5771, 19526.8962, 14821.5338], dtype=torch.float64), tensor([ 327.3761, 1764.3421, 1621.4323, 1173.8440], dtype=torch.float64), tensor([ 347.1718, 1859.6708, 1685.6409, 1200.0646], dtype=torch.float64), tensor([ 299.7725, 1606.8455, 1396.6842, 1035.4529], dtype=torch.float64), tensor([ 257.2449, 1394.8654, 1207.4923, 1128.7950], dtype=torch.float64), tensor([ 2250.3099, 12833.0054, 12132.0743,  8453.1434], dtype=torch.float64), tensor([ 3716.1046, 22287.1198, 19425.6479, 12787.6191], dtype=torch.float64), tensor([1283.7207, 7219.4065, 6604.0128, 4735.5723], dtype=torch.float64), tensor([ 935.3248, 5416.2586, 4710.4235, 3779.6145], dtype=torch.float64), tensor([1033.9795, 5918.5535, 5207.8239, 3790.4872], dtype=torch.float64), tensor([ 321.1685, 1725.5269, 1467.2492, 1160.3267], dtype=torch.float64), tensor([ 286.3987, 1578.7462, 1465.8942, 1054.8159], dtype=torch.float64), tensor([ 5350.6208, 31668.0002, 29205.9696, 18821.1926], dtype=torch.float64), tensor([ 235.1930, 1262.0046, 1097.4198,  940.1415], dtype=torch.float64), tensor([ 259.1587, 1503.3844, 1281.0662,  846.0275], dtype=torch.float64), tensor([ 303.7221, 1760.4908, 1517.8713, 1049.1027], dtype=torch.float64), tensor([1076.3718, 6178.6256, 5626.6585, 3700.2391], dtype=torch.float64), tensor([ 254.6358, 1436.3133, 1255.2412,  939.2954], dtype=torch.float64), tensor([ 279.3273, 1441.6041, 1347.6220, 1101.8724], dtype=torch.float64), tensor([ 2272.5879, 13162.9147, 12073.3307,  8428.0081], dtype=torch.float64), tensor([ 305.1653, 1723.3509, 1518.7186, 1095.0070], dtype=torch.float64), tensor([ 226.5479, 1287.4487, 1058.2461,  626.2429], dtype=torch.float64), tensor([1503.1435, 8640.1354, 7890.9421, 4690.5015], dtype=torch.float64), tensor([ 242.4476, 1379.2745, 1170.9628,  842.5328], dtype=torch.float64), tensor([1696.1485, 9752.0705, 9307.7056, 5566.2307], dtype=torch.float64), tensor([ 4350.0141, 24539.3574, 22032.2995, 16896.9732], dtype=torch.float64), tensor([ 269.7695, 1583.3619, 1264.4152,  922.0513], dtype=torch.float64), tensor([ 235.7259, 1334.1986, 1223.2905,  735.6499], dtype=torch.float64), tensor([ 281.1943, 1628.7886, 1303.0426,  853.6718], dtype=torch.float64), tensor([ 2974.3975, 17608.0967, 15149.8580, 10894.3071], dtype=torch.float64), tensor([1663.6231, 9815.7876, 8915.7372, 5856.1519], dtype=torch.float64)], 'inferredPis': [tensor([0.0883, 0.0976, 0.0431], dtype=torch.float64), tensor([0.0888, 0.0960, 0.0436], dtype=torch.float64), tensor([0.0817, 0.0888, 0.0459], dtype=torch.float64), tensor([0.0864, 0.1012, 0.0461], dtype=torch.float64), tensor([0.0838, 0.0950, 0.0445], dtype=torch.float64), tensor([0.0848, 0.0805, 0.0429], dtype=torch.float64), tensor([0.0832, 0.0868, 0.0462], dtype=torch.float64), tensor([0.1021, 0.0883, 0.0335], dtype=torch.float64), tensor([0.0887, 0.0972, 0.0405], dtype=torch.float64), tensor([0.0907, 0.1154, 0.0468], dtype=torch.float64), tensor([0.1088, 0.0880, 0.0399], dtype=torch.float64), tensor([0.0661, 0.1068, 0.0480], dtype=torch.float64), tensor([0.0842, 0.0948, 0.0428], dtype=torch.float64), tensor([0.1099, 0.1108, 0.0452], dtype=torch.float64), tensor([0.0797, 0.0908, 0.0470], dtype=torch.float64), tensor([0.0871, 0.0829, 0.0440], dtype=torch.float64), tensor([0.0943, 0.1079, 0.0443], dtype=torch.float64), tensor([0.0714, 0.0921, 0.0434], dtype=torch.float64), tensor([0.0944, 0.1081, 0.0437], dtype=torch.float64), tensor([0.0857, 0.1092, 0.0421], dtype=torch.float64), tensor([0.0925, 0.1004, 0.0421], dtype=torch.float64), tensor([0.0965, 0.1002, 0.0434], dtype=torch.float64), tensor([0.0886, 0.0990, 0.0500], dtype=torch.float64), tensor([0.0849, 0.1075, 0.0473], dtype=torch.float64), tensor([0.1032, 0.1038, 0.0400], dtype=torch.float64), tensor([0.0894, 0.0908, 0.0398], dtype=torch.float64), tensor([0.0793, 0.0905, 0.0447], dtype=torch.float64), tensor([0.0841, 0.0890, 0.0463], dtype=torch.float64), tensor([0.0871, 0.0929, 0.0442], dtype=torch.float64), tensor([0.0857, 0.0859, 0.0455], dtype=torch.float64), tensor([0.0845, 0.1058, 0.0500], dtype=torch.float64), tensor([0.0891, 0.0930, 0.0436], dtype=torch.float64), tensor([0.0879, 0.0780, 0.0437], dtype=torch.float64), tensor([0.0943, 0.0986, 0.0446], dtype=torch.float64), tensor([0.0832, 0.0964, 0.0448], dtype=torch.float64), tensor([0.0853, 0.0872, 0.0450], dtype=torch.float64), tensor([0.0872, 0.0876, 0.0463], dtype=torch.float64), tensor([0.0913, 0.0833, 0.0422], dtype=torch.float64), tensor([0.1056, 0.0961, 0.0478], dtype=torch.float64), tensor([0.0817, 0.0893, 0.0398], dtype=torch.float64), tensor([0.0860, 0.0868, 0.0465], dtype=torch.float64), tensor([0.0682, 0.0968, 0.0603], dtype=torch.float64), tensor([0.0866, 0.0812, 0.0451], dtype=torch.float64), tensor([0.0847, 0.1019, 0.0477], dtype=torch.float64), tensor([0.0886, 0.0802, 0.0427], dtype=torch.float64), tensor([0.0909, 0.0928, 0.0422], dtype=torch.float64), tensor([0.0737, 0.1014, 0.0497], dtype=torch.float64), tensor([0.0824, 0.0799, 0.0473], dtype=torch.float64), tensor([0.0704, 0.1052, 0.0497], dtype=torch.float64), tensor([0.0821, 0.0994, 0.0440], dtype=torch.float64), tensor([0.0885, 0.0844, 0.0428], dtype=torch.float64)], 'inferredPDVs': [tensor([0.0708, 0.0619, 0.0089], dtype=torch.float64), tensor([1.0899, 1.0074, 0.1014], dtype=torch.float64), tensor([1.0667, 0.9848, 0.1029], dtype=torch.float64), tensor([1.1318, 1.0077, 0.1029], dtype=torch.float64), tensor([1.1056, 0.9851, 0.1022], dtype=torch.float64), tensor([1.0153, 1.0133, 0.1020], dtype=torch.float64), tensor([1.0521, 0.9876, 0.1029], dtype=torch.float64), tensor([1.0482, 1.1222, 0.0965], dtype=torch.float64), tensor([1.1388, 1.0359, 0.1011], dtype=torch.float64), tensor([1.1952, 1.0104, 0.1022], dtype=torch.float64), tensor([1.0185, 1.1137, 0.0989], dtype=torch.float64), tensor([1.2393, 0.9314, 0.1054], dtype=torch.float64), tensor([1.1085, 1.0210, 0.1023], dtype=torch.float64), tensor([1.1904, 1.1569, 0.1027], dtype=torch.float64), tensor([1.1210, 0.9949, 0.1050], dtype=torch.float64), tensor([1.0040, 0.9848, 0.1009], dtype=torch.float64), tensor([1.1806, 1.0640, 0.1024], dtype=torch.float64), tensor([1.1127, 0.9445, 0.1024], dtype=torch.float64), tensor([1.2040, 1.0772, 0.1028], dtype=torch.float64), tensor([1.1715, 0.9701, 0.0995], dtype=torch.float64), tensor([1.1101, 1.0163, 0.1003], dtype=torch.float64), tensor([1.0790, 1.0315, 0.1001], dtype=torch.float64), tensor([1.1042, 1.0182, 0.1044], dtype=torch.float64), tensor([1.1412, 0.9801, 0.1022], dtype=torch.float64), tensor([1.1735, 1.1224, 0.1005], dtype=torch.float64), tensor([1.0633, 1.0358, 0.1002], dtype=torch.float64), tensor([1.0750, 0.9687, 0.1022], dtype=torch.float64), tensor([1.0996, 1.0419, 0.1052], dtype=torch.float64), tensor([1.1437, 1.0632, 0.1049], dtype=torch.float64), tensor([1.0902, 1.0446, 0.1049], dtype=torch.float64), tensor([1.1739, 1.0088, 0.1053], dtype=torch.float64), tensor([1.0874, 1.0412, 0.1024], dtype=torch.float64), tensor([1.0148, 1.0381, 0.1029], dtype=torch.float64), tensor([1.1585, 1.0881, 0.1041], dtype=torch.float64), tensor([1.0711, 0.9495, 0.1004], dtype=torch.float64), tensor([1.0685, 1.0061, 0.1029], dtype=torch.float64), tensor([1.0485, 1.0132, 0.1030], dtype=torch.float64), tensor([1.0689, 1.0671, 0.1030], dtype=torch.float64), tensor([1.1077, 1.1350, 0.1048], dtype=torch.float64), tensor([1.0844, 1.0117, 0.1011], dtype=torch.float64), tensor([1.0880, 1.0398, 0.1050], dtype=torch.float64), tensor([1.0852, 0.8890, 0.1052], dtype=torch.float64), tensor([0.9926, 0.9855, 0.1011], dtype=torch.float64), tensor([1.1193, 0.9772, 0.1027], dtype=torch.float64), tensor([0.9850, 1.0100, 0.1006], dtype=torch.float64), tensor([1.1063, 1.0590, 0.1024], dtype=torch.float64), tensor([1.1593, 0.9396, 0.1044], dtype=torch.float64), tensor([1.0107, 0.9919, 0.1032], dtype=torch.float64), tensor([1.1219, 0.8802, 0.1013], dtype=torch.float64), tensor([1.1205, 0.9784, 0.1017], dtype=torch.float64), tensor([1.0317, 1.0187, 0.1015], dtype=torch.float64)], 'truePDVs': [tensor([6.3481e-04, 8.3878e-04, 4.1462e-05]), tensor([6.3481e-04, 8.3878e-04, 4.1462e-05]), tensor([6.3808e-04, 8.4310e-04, 4.1676e-05]), tensor([6.3467e-04, 8.3859e-04, 4.1453e-05]), tensor([6.3585e-04, 8.4015e-04, 4.1530e-05]), tensor([6.3759e-04, 8.4245e-04, 4.1644e-05]), tensor([6.3618e-04, 8.4059e-04, 4.1552e-05]), tensor([6.3485e-04, 8.3882e-04, 4.1464e-05]), tensor([6.3768e-04, 8.4256e-04, 4.1649e-05]), tensor([6.3740e-04, 8.4219e-04, 4.1631e-05]), tensor([6.3179e-04, 8.3479e-04, 4.1265e-05]), tensor([6.3569e-04, 8.3994e-04, 4.1520e-05]), tensor([6.3702e-04, 8.4170e-04, 4.1606e-05]), tensor([6.3582e-04, 8.4011e-04, 4.1528e-05]), tensor([6.3487e-04, 8.3886e-04, 4.1466e-05]), tensor([6.3620e-04, 8.4062e-04, 4.1553e-05]), tensor([6.3820e-04, 8.4325e-04, 4.1683e-05]), tensor([6.3967e-04, 8.4520e-04, 4.1779e-05]), tensor([6.3799e-04, 8.4298e-04, 4.1670e-05]), tensor([6.3464e-04, 8.3855e-04, 4.1451e-05]), tensor([6.3531e-04, 8.3944e-04, 4.1495e-05]), tensor([6.3777e-04, 8.4269e-04, 4.1655e-05]), tensor([6.3644e-04, 8.4093e-04, 4.1569e-05]), tensor([6.3583e-04, 8.4012e-04, 4.1529e-05]), tensor([6.3549e-04, 8.3967e-04, 4.1506e-05]), tensor([6.3602e-04, 8.4038e-04, 4.1541e-05]), tensor([6.3228e-04, 8.3544e-04, 4.1297e-05]), tensor([6.3543e-04, 8.3960e-04, 4.1503e-05]), tensor([6.3494e-04, 8.3895e-04, 4.1470e-05]), tensor([6.3507e-04, 8.3912e-04, 4.1479e-05]), tensor([6.3449e-04, 8.3835e-04, 4.1441e-05]), tensor([6.3523e-04, 8.3933e-04, 4.1490e-05]), tensor([6.3498e-04, 8.3900e-04, 4.1473e-05]), tensor([6.3650e-04, 8.4101e-04, 4.1572e-05]), tensor([6.3526e-04, 8.3937e-04, 4.1491e-05]), tensor([6.3655e-04, 8.4108e-04, 4.1576e-05]), tensor([6.3606e-04, 8.4043e-04, 4.1544e-05]), tensor([6.3609e-04, 8.4047e-04, 4.1546e-05]), tensor([6.3596e-04, 8.4030e-04, 4.1537e-05]), tensor([6.3583e-04, 8.4013e-04, 4.1529e-05]), tensor([6.3649e-04, 8.4100e-04, 4.1572e-05]), tensor([6.3450e-04, 8.3837e-04, 4.1442e-05]), tensor([6.3596e-04, 8.4030e-04, 4.1537e-05]), tensor([6.3761e-04, 8.4247e-04, 4.1645e-05]), tensor([6.3420e-04, 8.3797e-04, 4.1422e-05]), tensor([6.3418e-04, 8.3795e-04, 4.1421e-05]), tensor([6.3593e-04, 8.4026e-04, 4.1535e-05]), tensor([6.3837e-04, 8.4349e-04, 4.1695e-05]), tensor([6.3636e-04, 8.4082e-04, 4.1563e-05]), tensor([6.3534e-04, 8.3947e-04, 4.1497e-05]), tensor([6.3583e-04, 8.4013e-04, 4.1529e-05])], 'params': [{'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}, {'nGenes': 20000, 'nCases': tensor([5000., 5000., 1000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0098, 0.0098, 0.0020]), 'diseaseFractions': tensor([0.1000, 0.1000, 0.0500]), 'rrShape': tensor(10.), 'rrMeans': tensor([5., 5., 2.]), 'afShape': tensor(10.), 'afMean': tensor(1.0000e-04)}], 'costFnIdx': [15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res50runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastIdx = len(cachedData7) - 1\n",
    "cd = cachedData7[lastIdx]\n",
    "alphas = params7[\"inferredAlphas\"][lastIdx + 1]\n",
    "pds = tensor([1 - cd[\"params\"][\"pDs\"].sum(), *cd[\"params\"][\"pDs\"]])\n",
    "print('pds', pds)\n",
    "individualProbabilities = Dirichlet(alphas*pds).sample([10_000]).mean(0)\n",
    "print(\"alphas\", alphas)\n",
    "print(\"P(D|V)'s'\", individualProbabilities)\n",
    "pis = params7[\"inferredPis\"][lastIdx + 1]\n",
    "print(\"pis\", pis)\n",
    "params = params7[\"params\"][0]\n",
    "alphas\n",
    "print(params.__repr__())\n",
    "print(cd[\"params\"])\n",
    "\n",
    "inferredAlphas = tensor([x.numpy() for x in params7[\"inferredAlphas\"][1:]])\n",
    "avg = inferredAlphas.mean(0)\n",
    "std = inferredAlphas.std(0)\n",
    "minimum = inferredAlphas.min(0)\n",
    "maximum = inferredAlphas.max(0)\n",
    "\n",
    "print(\"avg\", avg, \"std\", std, \"min\", minimum, \"max\", maximum)\n",
    "\n",
    "inferredPDVs = tensor([Dirichlet(x*pds).sample([10_000]).mean(0).numpy() for x in params7[\"inferredAlphas\"][1:]])\n",
    "avg = inferredPDVs.mean(0)\n",
    "std = inferredPDVs.std(0)\n",
    "minimum = inferredPDVs.min(0)\n",
    "maximum = inferredPDVs.max(0)\n",
    "\n",
    "print(\"avg P(D|V)\", avg, \"std P(D|V)\", std, \"min P(D|V)\", minimum, \"max P(D|V)\", maximum)\n",
    "\n",
    "\n",
    "params7[\"params\"]\n",
    "\n",
    "params7[\"params\"][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latentAlphas = tensor([10., 10., 5.])\n",
    "oneA = tensor([1000., latentAlphas[0] +latentAlphas[2] , latentAlphas[1] +latentAlphas[2],latentAlphas.sum()])#inferredAlphas[0]\n",
    "oneAsum = oneA.sum()\n",
    "print(oneA, \"before\", inferredAlphas[0], \"sim\",oneAsum)\n",
    "CovX1X3 = (-oneA[1]*oneA[3] ) / ((oneAsum**2)*(oneAsum+1))\n",
    "CovX1X3\n",
    "Dirichlet(oneA).sample([10_00000]).mean(0)\n",
    "\n",
    "# P(V|D) = P(D|V)P(V) / P(D)\n",
    "# P(D|V) = rr * P(D|!V) * P(V)  / P(D)\n",
    "# = rr * P(D|!V) * P(V) / (P(D|V)PV + P(D|!V)P(!V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = cachedData7[1]\n",
    "np.corrcoef(cd[\"afs\"][0:1000, 0], cd[\"afs\"][0:1000, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd = cachedData4b[0][\"xsPooled\"]\n",
    "# print(cd[:, 0, 0][0])\n",
    "\n",
    "# cdCtrl = cd[:, 0, 0]\n",
    "# cdCases = cd[:, :, 1]\n",
    "\n",
    "# cdFlat = []\n",
    "# for geneIdx in range(20_000):\n",
    "#     cdFlat.append([cdCtrl[geneIdx], *cdCases[geneIdx].flatten()])\n",
    "# cdFlat = tensor(cdFlat)\n",
    "# cdFlat.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdFlat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Multinomial(probs=tensor([.5, .5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.log_prob(tensor([5., 0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedData4b[-1][\"xsPooled\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCtrlsRun = tensor(5e5)\n",
    "nCases12 = tensor([5e3, 5e3])\n",
    "nCasesBoth = nCases12.sum() * .1\n",
    "nCasesRun = tensor([*nCases12, nCasesBoth])\n",
    "\n",
    "pDsRun = nCasesRun / ( nCasesRun.sum() + nCtrlsRun )\n",
    "pDsRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unaffectedGenesRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(cachedData4[0][0][4000:5000, 0, 0], cachedData4[0][0][4000:5000, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdAlts = cachedData4[0][0]\n",
    "cdAfs = cachedData4[0][1]\n",
    "cdGenes = cachedData4[0][2]\n",
    "cdPDs = cachedData4[0][3][\"pDs\"]\n",
    "cdPDs\n",
    "# pDgivenV(cdPDs[0], cdAfs[cdGenes[0], 0, 1], cdAfs[genesRun[0], 0, 0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdAlts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating P(D|V) for sample 1:\n",
    "# First, we know which genes are affected, the first pi1*nGenes, and then some genes that affect both diseases\n",
    "cdAfs[0:2000, 0, 1].mean()/cdAfs[0:2000, 0, 0].mean()\n",
    "s1PVgivenD = (2/3.0) * cdAfs[0:2000, 0, 1].mean() + (1/3.0) * cdAfs[4000:5000, 0, 1].mean()\n",
    "s1pD = cdPDs[0]\n",
    "s1PVhat = cdAfs[5000:, 0, 0].mean() # estimate allele frequency\n",
    "print(\"s1PVgivenD\", s1PVgivenD, \"s1pD\", s1pD, \"s1PVhat\", s1PVhat)\n",
    "# Note, we don't use 0:2000 for the estimate, because control allele frequency is P(V|!D)\n",
    "# and is depressed by the the presence of controls, e.g our P(V|!D) is proportional to P(V) - (P(V|D)*P(D)).sum()\n",
    "print(\"True P(D1|V)\", pDgivenV(pD=s1pD,pVgivenD=s1PVgivenD,pV=s1PVhat))\n",
    "\n",
    "# Now the estimated one\n",
    "pisInferred = params4[\"inferredPis\"][0]\n",
    "pi1inferred = pisInferred[0]\n",
    "piBothinferred = pisInferred[2]\n",
    "pi1ratio = (pi1inferred / (pi1inferred + piBothinferred))\n",
    "print(\"pi1inferred\", pi1inferred, \"piBothinferred\", piBothinferred, \"pi1ratio\", pi1ratio)\n",
    "pDsInferred = params4[\"inferredPDVs\"][0]\n",
    "pD1onlyInferred = pDsInferred[1]\n",
    "pDsharedInferred = pDsInferred[3]\n",
    "print(\"pD1onlyInferred inferred\", pD1onlyInferred, \"pDsharedInferred\", pDsharedInferred)\n",
    "print(\"Inferred P(D1|V)\", pD1onlyInferred * pi1ratio + (pD1onlyInferred + pDsharedInferred) * (1 - pi1ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cdGenes[)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The P(D|V) for condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdAfs[cdGenes[0], 0, 1].mean() / cdAfs[cdGenes[0], 0, 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params4, cachedData2 = runModel(altCountsByGenePooledCtrls2, afsByGenePooledCtrls2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = altCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fitFnBivariate(cachedData[0][0], pDsLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = fitFnBivariate(cachedData[0][0], pDsLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = fitFnBivariate(cachedData[0][0], pDsLarge, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"res0\", res0)\n",
    "print(\"\\nres0\", \"pis\", res0[\"params\"][-1][0:3], \"mean P(D|V)'s\", Dirichlet(tensor(res0[\"params\"][-1][3:])).sample([10_000]).mean(0))\n",
    "\n",
    "print(\"\\n\\n\\nres1\", res1)\n",
    "print(\"\\nres1\", \"pis\", res1[\"params\"][-1][0:3], \"mean P(D|V)'s\", Dirichlet(tensor(res1[\"params\"][-1][3:])).sample([10_000]).mean(0))\n",
    "\n",
    "print(\"\\n\\n\\nres2\", res2)\n",
    "print(\"\\nres2\", \"pis\", res2[\"params\"][-1][0:3], \"mean P(D|V)'s\", Dirichlet(tensor(res2[\"params\"][-1][3:])).sample([10_000]).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(res0[\"llTrajectory\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(res1[\"llTrajectory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(res2[\"llTrajectory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(afsByGenePooledCtrls[2000:4000, 1, 1]/afsByGenePooledCtrls[2000:4000, 0, 0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pDgivenV(pD., afsByGenePooledCtrls[0:2000, :, 1], afsByGenePooledCtrls[0:2000, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dirichlet(tensor(1/4.0).expand(4)).sample()\n",
    "test = test[0:3]\n",
    "r = [0,1,2,3]\n",
    "r[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnBivariate(altCountsByGenePooledCtrls, pDs, nEpochs=100, minLLThresholdCount=100, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dirichlet(concentration=tensor([1.40625703e+04,\n",
    "         5.56195520e+03, 1.57978682e+02, 2.33518936e+04]))\n",
    "d.sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(7.74788652e+02, 2.58170768e+04 + 9.72956833e+02 + 5.18278100e+03).sample([10000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(3.05871723e+04, 3.25256694e+02 + 3.75135881e+03 +4.52942294e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res = fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=100, minLLThresholdCount=100, debug=False)\n",
    "print(\"fitFnUniveriateBetaBinomial took for 100 epochs: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(res[\"llTrajectory\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomH0 = Binomial(total_count=tensor([1.,1]), probs=pDs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomH0.log_prob(tensor(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn2 = likelihoodUnivariateFast(altCountsByGene, pDs)\n",
    "# print(costFn2([1e-9, .999999]))\n",
    "print(costFn2([1e-9, 1e-9]))\n",
    "print(costFn2([0.08845797,0.11094360])) #gives ~12067 using jensen's method, and ~9887 using exponentiation of the log\n",
    "\n",
    "# best result from R\n",
    "#  0.08845797           0.11094360 , ll -10127.23, and with jensen's version, \"example -12037.4347455843\"\n",
    "# pDgivenV, pi1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn = likelihoodUnivariate(altCountsByGene, pDs)\n",
    "print(\"costFn1:\", costFn([.001, .01]),\"costFn2:\",costFn2([.001, .01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn([0.0001,0.11094360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(costFn2([0.0001,0.11094360]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Binomial(total_count=tensor([14., 0., 9.]), probs=tensor(.0099))\n",
    "d.log_prob(tensor([0.,0.,0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn2([1e-9, .999999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomH0 = Binomial(total_count=geneSums, probs=.001)\n",
    "binomH1 = Binomial(total_count=geneSums, probs=.01)\n",
    "caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "print(caseAltCounts)\n",
    "component0 = binomH0.log_prob(caseAltCounts)\n",
    "print(\"component0\", component0, .5*component0)\n",
    "component1 = binomH1.log_prob(caseAltCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDgivenV(pDs[0], afsByGene2[0:2000, 0, 1].mean(), afMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition1 = altCountsByGene2[:, 0, :]\n",
    "condition1\n",
    "pDs[0]\n",
    "\n",
    "afsByGene2[0:2000,:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(afsByGene2[:, 0, 1:2].flatten())\n",
    "pyplot.plot(afsByGene2[:, 0, 0:1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(cachedData6[1][\"altCounts\"][:, 1])\n",
    "# pyplot.plot(afsByGenePooledCtrls[:, 0, 1:2].flatten())\n",
    "# pyplot.plot(afsByGenePooledCtrls[:, 1, 1:2].flatten())\n",
    "# pyplot.plot(afsByGenePooledCtrls[:, 2, 1:2].flatten())\n",
    "# pyplot.plot(afsByGeneRR2[:, 0, 1:2].flatten())\n",
    "# pyplot.plot(afsByGeneRR2[:, 0, 0:1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedData5[0][\"altCounts\"][0:5000].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrlCounts = altCountsByGene[:, 0, 0]\n",
    "altCountsCases = altCountsByGene[:, :, 1]\n",
    "\n",
    "altCountsFlat = []\n",
    "for geneIdx in range(nGenes):\n",
    "    altCountsFlat.append([ctrlCounts[geneIdx], *altCountsByGene[geneIdx, :, 1].flatten()])\n",
    "altCountsFlat = tensor(altCountsFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altCountsFlat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DirichletMultinomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "K = 4  # Fixed number of components.\n",
    "\n",
    "@config_enumerate\n",
    "def model(data):\n",
    "    # Global variables.\n",
    "    weights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(K)))\n",
    "    alpha0 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "    alpha1 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "    alpha2 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "    alpha3 = pyro.sample('alpha0', Uniform(1, 2.5e4))\n",
    "\n",
    "    with pyro.plate('components', K):\n",
    "        concentrations = pyro.sample('concentrations', dist.Dirichlet(0.5 * torch.ones(K)))\n",
    "\n",
    "    with pyro.plate('data', len(data)):\n",
    "        # Local variables.\n",
    "        component = pyro.sample('assignment', dist.Categorical(weights))\n",
    "        print(f\"concentrations: {concentrations[component]}\")\n",
    "        pyro.sample('obs', DirichletMultinomial(concentration=concentrations[component], total_count=data.sum(1)), obs=data)\n",
    "\n",
    "optim = pyro.optim.Adam({'lr': 0.1, 'betas': [0.8, 0.99]})\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_loc_fn(site):\n",
    "    if site[\"name\"] == \"weights\":\n",
    "        # Initialize weights to uniform.\n",
    "        return torch.ones(K) / K\n",
    "    if site[\"name\"] == \"concentrations\":\n",
    "        return torch.ones(K) / K\n",
    "    raise ValueError(site[\"name\"])\n",
    "\n",
    "def initialize(seed):\n",
    "    global global_guide, svi\n",
    "    pyro.set_rng_seed(seed)\n",
    "    pyro.clear_param_store()\n",
    "    global_guide = AutoDelta(poutine.block(model, expose=['weights', 'concentrations']),\n",
    "                             init_loc_fn=init_loc_fn)\n",
    "    svi = SVI(model, global_guide, optim, loss=elbo)\n",
    "    return svi.loss(model, global_guide, altCountsFlat)\n",
    "\n",
    "# Choose the best among 100 random initializations.\n",
    "loss, seed = min((initialize(seed), seed) for seed in range(2))\n",
    "initialize(seed)\n",
    "print('seed = {}, initial_loss = {}'.format(seed, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register hooks to monitor gradient norms.\n",
    "gradient_norms = defaultdict(list)\n",
    "for name, value in pyro.get_param_store().named_parameters():\n",
    "    value.register_hook(lambda g, name=name: gradient_norms[name].append(g.norm().item()))\n",
    "\n",
    "losses = []\n",
    "for i in range(200 if not smoke_test else 2):\n",
    "    loss = svi.step(altCountsFlat)\n",
    "    losses.append(loss)\n",
    "    print('.' if i % 100 else '\\n', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(10,3), dpi=100).set_facecolor('white')\n",
    "pyplot.plot(losses)\n",
    "pyplot.xlabel('iters')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.yscale('log')\n",
    "pyplot.title('Convergence of SVI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, grad_norms in gradient_norms.items():\n",
    "    pyplot.plot(grad_norms, label=name)\n",
    "\n",
    "pyplot.xlabel('iters')\n",
    "pyplot.ylabel('gradient norm')\n",
    "pyplot.yscale('log')\n",
    "pyplot.legend(loc='best')\n",
    "pyplot.title('Gradient norms during SVI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimates = global_guide(altCountsFlat)\n",
    "weights = map_estimates['weights']\n",
    "locs = map_estimates['concentrations']\n",
    "print('weights = {}'.format(weights.data.numpy()))\n",
    "print('concentrations = {}'.format(locs.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dirichlet(tensor([0.8973397  , 0.0494441,  0.04917945, 0.00403667])).sample([10_000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.3.1')\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2  # Fixed number of components.\n",
    "\n",
    "@config_enumerate\n",
    "def model(data):\n",
    "    # Global variables.\n",
    "    weights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(K)))\n",
    "    scale = pyro.sample('scale', dist.LogNormal(0., 2.))\n",
    "    with pyro.plate('components', K):\n",
    "        locs = pyro.sample('locs', dist.Normal(0., 10.))\n",
    "\n",
    "    with pyro.plate('data', len(data)):\n",
    "        # Local variables.\n",
    "        assignment = pyro.sample('assignment', dist.Categorical(weights))\n",
    "        pyro.sample('obs', dist.Normal(locs[assignment], scale), obs=data)\n",
    "        \n",
    "optim = pyro.optim.Adam({'lr': 0.1, 'betas': [0.8, 0.99]})\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "\n",
    "\n",
    "def init_loc_fn(site):\n",
    "    if site[\"name\"] == \"weights\":\n",
    "        # Initialize weights to uniform.\n",
    "        return torch.ones(K) / K\n",
    "    if site[\"name\"] == \"scale\":\n",
    "        return (data.var() / 2).sqrt()\n",
    "    if site[\"name\"] == \"locs\":\n",
    "        return data[torch.multinomial(torch.ones(len(data)) / len(data), K)]\n",
    "    raise ValueError(site[\"name\"])\n",
    "\n",
    "def initialize(seed):\n",
    "    global global_guide, svi\n",
    "    pyro.set_rng_seed(seed)\n",
    "    pyro.clear_param_store()\n",
    "    global_guide = AutoDelta(poutine.block(model, expose=['weights', 'locs', 'scale']),\n",
    "                             init_loc_fn=init_loc_fn)\n",
    "    svi = SVI(model, global_guide, optim, loss=elbo)\n",
    "    return svi.loss(model, global_guide, data)\n",
    "\n",
    "# Choose the best among 100 random initializations.\n",
    "loss, seed = min((initialize(seed), seed) for seed in range(100))\n",
    "initialize(seed)\n",
    "print('seed = {}, initial_loss = {}'.format(seed, loss))\n",
    "\n",
    "# Register hooks to monitor gradient norms.\n",
    "gradient_norms = defaultdict(list)\n",
    "for name, value in pyro.get_param_store().named_parameters():\n",
    "    value.register_hook(lambda g, name=name: gradient_norms[name].append(g.norm().item()))\n",
    "\n",
    "losses = []\n",
    "for i in range(200 if not smoke_test else 2):\n",
    "    loss = svi.step(data)\n",
    "    losses.append(loss)\n",
    "    print('.' if i % 100 else '\\n', end='')\n",
    "    \n",
    "\n",
    "pyplot.figure(figsize=(10,3), dpi=100).set_facecolor('white')\n",
    "pyplot.plot(losses)\n",
    "pyplot.xlabel('iters')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.yscale('log')\n",
    "pyplot.title('Convergence of SVI');\n",
    "\n",
    "\n",
    "pyplot.figure(figsize=(10,4), dpi=100).set_facecolor('white')\n",
    "for name, grad_norms in gradient_norms.items():\n",
    "    pyplot.plot(grad_norms, label=name)\n",
    "pyplot.xlabel('iters')\n",
    "pyplot.ylabel('gradient norm')\n",
    "pyplot.yscale('log')\n",
    "pyplot.legend(loc='best')\n",
    "pyplot.title('Gradient norms during SVI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_estimates = global_guide(data)\n",
    "weights = map_estimates['weights']\n",
    "locs = map_estimates['locs']\n",
    "scale = map_estimates['scale']\n",
    "print('weights = {}'.format(weights.data.numpy()))\n",
    "print('locs = {}'.format(locs.data.numpy()))\n",
    "print('scale = {}'.format(scale.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import constraints\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "from pyro.ops.indexing import Vindex\n",
    "import pyro.distributions as pdist\n",
    "\n",
    "@config_enumerate\n",
    "def model(obs, n):\n",
    "\n",
    "    p_A = pyro.sample('p_A', pdist.D(1, 1))\n",
    "    \n",
    "    p_B = pyro.sample('p_B', dist.Beta(torch.ones(2), torch.ones(2)).to_event(1))\n",
    "    \n",
    "    p_C = pyro.sample('p_C', dist.Beta(torch.ones(2), torch.ones(2)).to_event(1))\n",
    "    \n",
    "    with pyro.plate('data_plate', n):\n",
    "        A = pyro.sample('A', dist.Bernoulli(p_A.expand(n)), obs=obs['A'])\n",
    "    \n",
    "        B = pyro.sample('B', dist.Bernoulli(Vindex(p_B)[A.type(torch.long)]), infer={\"enumerate\": \"parallel\"})\n",
    "        \n",
    "        pyro.sample('C', dist.Bernoulli(Vindex(p_C)[B.type(torch.long)]), obs=obs['C'])\n",
    "\n",
    "def guide(obs, n):\n",
    "    \n",
    "    a = pyro.param('a', prior['A'], constraint=constraints.positive)\n",
    "    p_A = pyro.sample('p_A', dist.Beta(a[0], a[1]))\n",
    "    \n",
    "    b = pyro.param('b', prior['B'], constraint=constraints.positive)\n",
    "    pyro.sample('p_B', dist.Beta(b[:, 0], b[:, 1]).to_event(1))\n",
    "    \n",
    "    c = pyro.param('c', prior['C'], constraint=constraints.positive)\n",
    "    pyro.sample('p_C', dist.Beta(c[:, 0], c[:, 1]).to_event(1))\n",
    "\n",
    "import pyro.optim\n",
    "import pyro.infer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pyro.enable_validation(True)\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# setup svi object\n",
    "loss_func = pyro.infer.TraceEnum_ELBO(max_plate_nesting=1)\n",
    "optim = pyro.optim.Adam({\"lr\": .001})\n",
    "svi = pyro.infer.SVI(model, guide, optim, loss=loss_func)\n",
    "\n",
    "# perform svi\n",
    "num_steps = 30000\n",
    "losses = []\n",
    "start = time.time()\n",
    "for step in range(num_steps):\n",
    "    loss = svi.step(data, n)\n",
    "    losses.append(loss)\n",
    "\n",
    "    if step % (num_steps*.33) == 0:\n",
    "        print(step, f'({(time.time() - start)/60:.1f} min.)')\n",
    "print(step+1, f'({(time.time() - start)/60:.1f} min.)\\n\\n')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "\n",
    "posterior_params = {k: np.array(v.data) for k, v in pyro.get_param_store().items()}\n",
    "posterior_params['a'] = posterior_params['a'][None, :]\n",
    "for key, val in posterior_params.items():\n",
    "    true_p = p[f'p_{key.upper()}'].numpy()\n",
    "    print(f'p_{key.upper()}  (true/pred): ')\n",
    "    print('\\t', np.round(true_p, 2))\n",
    "    print('\\t', np.round(val[:, 0]/(np.sum(val, axis=1)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "t = np.arange(0.0, 2.0, 0.01)\n",
    "s1 = np.sin(2*np.pi*t)\n",
    "s2 = np.sin(4*np.pi*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7b8fa03365b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# plt.subplot(222)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0mbyebye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1417\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_axes_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                     \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot([1,2])\n",
    "plt.plot(t, s1)\n",
    "plt.plot(t, 2*s1)\n",
    "# plt.subplot(222)\n",
    "# plt.plot(t, 2*s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
