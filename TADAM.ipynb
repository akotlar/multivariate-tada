{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: torch in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (1.4.0)\n",
      "Requirement already up-to-date: pyro-ppl in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.36 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (4.42.1)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.4.0 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyro-api>=0.1.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (0.1.1)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyro-ppl) (3.2.0)\n",
      "Requirement already up-to-date: scipy in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scipy) (1.18.2)\n",
      "Requirement already up-to-date: matplotlib in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "Requirement already up-to-date: scikit-optimize in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.19.1 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.0 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: pyaml>=16.9 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (20.3.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from scikit-optimize) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /Users/alexkotlar/miniconda3/lib/python3.7/site-packages (from pyaml>=16.9->scikit-optimize) (5.3.1)\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "!pip install --upgrade torch\n",
    "!pip install --upgrade pyro-ppl\n",
    "!pip install --upgrade scipy\n",
    "!pip install --upgrade matplotlib\n",
    "!pip install --upgrade scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import torch.tensor as tensor\n",
    "import pyro.distributions as dist\n",
    "# from torch.distributions import Binomial, Gamma, Uniform\n",
    "from pyro.distributions import Binomial, Categorical, Dirichlet, DirichletMultinomial, Beta, BetaBinomial, Uniform, Gamma\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from skopt import gp_minimize \n",
    "from scipy.stats import binom as ScipyBinom\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from collections import namedtuple\n",
    "import time\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Scalar version took: 0.1151268482208252\n",
      "Done\n",
      "Tensor version took: 3.2699129581451416\n",
      "Done\n",
      "Tensor convert array version took: 0.12297391891479492\n"
     ]
    }
   ],
   "source": [
    "# Measuring overhead\n",
    "import time\n",
    "\n",
    "# .1s\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(i)\n",
    "\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Scalar version took: {time.time() - start}\")\n",
    "\n",
    "# 30x slower, 3.2s\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(tensor(i))\n",
    "\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Tensor version took: {time.time() - start}\")\n",
    "\n",
    "# do it in one pass\n",
    "# this wraps the array in tensor, aka tensor([]),\n",
    "# but accessing a single element gives back a tensor\n",
    "l = []\n",
    "start = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    l.append(i)\n",
    "\n",
    "# .13s \n",
    "l = torch.tensor(l)\n",
    "if len(l) > 5:\n",
    "    print(\"Done\")\n",
    "print(f\"Tensor convert array version took: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood functions\n",
    "# These assume univariate currently\n",
    "\n",
    "# TODO:\n",
    "# 1) Explore constraining alphas using prevalence estimate, namely E(P(D)) = alpha0 / (alpha0 + alpha1 + alpha2 + alphaBoth) (as long as all case counts are mutually exclusive)\n",
    "# 2) Can DM approximate NB + Multinomial? If so do we need mixture at all? But if we don't have that how do we model % disease-afffecting genes in each hypothesis(maybe proportion of alphas?)\n",
    "# rr: relative risk\n",
    "def pVgivenD(rr, pV):\n",
    "    return (rr * pV) / (rr * pV + (1 - pV))\n",
    "\n",
    "# pD: prevalence, tensor of mConditions x 1\n",
    "# pVgivenD: tensor of mConditions x 1\n",
    "# pV: allele frequency\n",
    "def pVgivenNotD(pD, pV, pVgivenD):\n",
    "    p = (pV - (pD*pVgivenD).sum()) / (1 - pD.sum())\n",
    "    assert(p >= 0)\n",
    "    return p\n",
    "\n",
    "# def pVgivenNotD(pD, pV, pVgivenD):\n",
    "#     p = (pV - (pD*pVgivenD)) / (1 - pD)\n",
    "#     assert(p >= 0)\n",
    "#     return p\n",
    "\n",
    "def pDgivenV(pD, pVgivenD, pV):\n",
    "    return pVgivenD * pD / pV\n",
    "\n",
    "# works like shit\n",
    "def llUnivariateSingleGeneJensen(xCtrl, xCase, pD, pi0, pi1, pDgivenV):\n",
    "    n = xCtrl + xCase\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    return pi0 * Binomial(total_count=n, probs=pD).log_prob(xCase) + pi1*Binomial(total_count=n, probs=pDgivenV).log_prob(xCase)\n",
    "\n",
    "def llUnivariateSingleGene(xCtrl, xCase, pD, pi0, pi1, pDgivenV):\n",
    "    n = xCtrl + xCase\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    return torch.log(pi0 * torch.exp(Binomial(total_count=n, probs=pD).log_prob(xCase)) + pi1*torch.exp(Binomial(total_count=n, probs=pDgivenV).log_prob(xCase)))\n",
    "\n",
    "# alphas shape: [2] #corresponding to cases and controls\n",
    "def llUnivariateSingleGeneBetaBinomial(xCtrl, xCase, pD, alphas, pi0, pi1):\n",
    "    n = xCtrl + xCase\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    # what is the \n",
    "    h0 = pi0 * torch.exp( Binomial(total_count=n, probs=pD).log_prob(xCase) )\n",
    "    h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alphas[1], concentration0=alphas[0]).log_prob(xCase) )\n",
    "    return torch.log( h0 + h1 )\n",
    "\n",
    "# TODO: support pooled and non-pooled controls\n",
    "# TODO: think about whether we need overlapping cases (both disease1 + disease2) or whether that can be inferred\n",
    "# altCounts.shape = [1 control + nConditions cases, 1]\n",
    "# alphas shape: [nConditions + 2] #1 ctrl + nCondition cases; for now the last condition in nCondition cases is for individuals who has all of the previous nConditions\n",
    "# in a more multivariate setting we will need more information, aka mapping to which combinations of conditions these people have\n",
    "# xCases: we have nConditions cases\n",
    "# pDs shape: [nConditions]\n",
    "# TODO: make this more effificent by taking alphas tensor of shape (1 + nConditions)\n",
    "def llPooledBivariateSingleGene(altCounts, pDs, alpha0, alpha1, alpha2, alphaBoth, pi0, pi1, pi2, piBoth):\n",
    "    # currently assume altCounts are all independent (in simulation), or 0 for everything but first condition\n",
    "    n = altCounts.sum()\n",
    "    alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "    print(\"n is \", n)\n",
    "    #convex function, so by jensen's sum of logs is fine (always <= the log of sum)\n",
    "    # what is the \n",
    "    case1nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[0]).log_prob(altCounts[1]) )\n",
    "    case2nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[1]).log_prob(altCounts[2]) )\n",
    "    h0 = pi0 * case1nullLikelihood * case2nullLikelihood\n",
    "    h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCounts[1]) ) * case2nullLikelihood\n",
    "    h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCounts[2]) ) * case1nullLikelihood\n",
    "    h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCounts))\n",
    "    print(f\"h0: {h0}, h1: {h1}, h2: {h2}, h3: {h3}\")\n",
    "    return torch.log( h0 + h1 + h2 + h3 )\n",
    "\n",
    "# shape of altCountsByGene: [nGenes, nConditions, 2]\n",
    "# last dimension is \n",
    "# 2nd dimension altCountsCasesByGene must match controls, or the control nConditions must be 1 (pooled controls)\n",
    "def likelihoodUnivariate(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    \n",
    "    # passed to optimization function, we optimize pDgivenV and pi1 by maximizing likelihood\n",
    "    def likelihood(params):\n",
    "        pDgivenV = params[0]\n",
    "        pi1 = params[1]\n",
    "        pi0 = 1 - pi1\n",
    "        \n",
    "        if(pDgivenV >= 1 or pDgivenV < 0 or pi1 < 0 or pi1 > 1):\n",
    "            print(\"returning inf\")\n",
    "            return float(\"-inf\")\n",
    "    \n",
    "        logLikelihood = 0\n",
    "        penaltyCount = float(nGenes)\n",
    "        \n",
    "        # \n",
    "        for geneIdx in range(nGenes):\n",
    "            ctrlAltCount = altCountsByGene[geneIdx, 0, 0]\n",
    "            caseAltCount = altCountsByGene[geneIdx, 0, 1]\n",
    "            pd = pDs[0]\n",
    "            \n",
    "            if ctrlAltCount == 0 and caseAltCount == 0:\n",
    "                print(\"skipping\", geneIdx)\n",
    "                continue\n",
    "\n",
    "            # this is insanely slow\n",
    "            ll = llUnivariateSingleGene(ctrlAltCount, caseAltCount, pd, pi0, pi1, pDgivenV)\n",
    "\n",
    "            if torch.isnan(ll) or torch.isinf(ll):\n",
    "                print(f\"nan or 0 likelihood: like: {like}, p1: {pi1}, pDgivenV: {pDgivenV}, gene: {geneIdx}, ctrlCount: {ctrlAltCount}, caseCount: {caseAltCount}\")\n",
    "                penaltyCount -= 1\n",
    "                continue\n",
    "                \n",
    "            logLikelihood += ll\n",
    "        \n",
    "    \n",
    "        if penaltyCount == 0:\n",
    "            penaltyCount = 1\n",
    "    \n",
    "        return -logLikelihood * (nGenes / penaltyCount)\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "def likelihoodUnivariateFast(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    geneSums = altCountsByGene[:, 0, :].sum(1)\n",
    "        \n",
    "    caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "    pD = pDs[0]\n",
    "    def likelihood(params):\n",
    "        pi1, pDgivenV = params\n",
    "\n",
    "        pi0 = 1.0 - pi1\n",
    "\n",
    "        if(pDgivenV > 1 or pDgivenV < 0 or pi1 < 0 or pi1 > 1):\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        binomH0 = Binomial(total_count=geneSums, probs=pD)\n",
    "        binomH1 = Binomial(total_count=geneSums, probs=pDgivenV)\n",
    "        \n",
    "        component0 = pi0 * torch.exp(binomH0.log_prob(caseAltCounts))\n",
    "        component1 = pi1 * torch.exp(binomH1.log_prob(caseAltCounts))\n",
    "        \n",
    "        return - torch.log(component0 + component1).sum()\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "def likelihoodUnivariateBetaBinomialFast(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    geneSums = altCountsByGene[:, 0, :].sum(1)\n",
    "        \n",
    "    caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "    pD = pDs[0]\n",
    "    def likelihood(params):\n",
    "        pi1, alpha1, alpha0 = params\n",
    "\n",
    "        if alpha1 < 0 or alpha0 < 0 or pi1 < 0 or pi1 > 1:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - pi1\n",
    "\n",
    "        binomH0 = Binomial(total_count=geneSums, probs=pD)\n",
    "        binomH1 = BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alpha0)\n",
    "        \n",
    "        component0 = pi0 * torch.exp(binomH0.log_prob(caseAltCounts))\n",
    "        component1 = pi1 * torch.exp(binomH1.log_prob(caseAltCounts))\n",
    "\n",
    "        return - torch.log(component0 + component1).sum()\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "def getUnivariateAlpha0(alpha1, pD):\n",
    "    return ((1-pD) / pD)*alpha1\n",
    "\n",
    "# doesn't really work constraint looks wrong\n",
    "def likelihoodUnivariateBetaBinomialConstrainedFast(altCountsByGene, pDs):\n",
    "    nGenes = len(altCountsByGene)\n",
    "    geneSums = altCountsByGene[:, 0, :].sum(1)\n",
    "        \n",
    "    caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "    pD = pDs[0]\n",
    "    pNotDRatio = (1 - pD)/pD\n",
    "    def likelihood(params):\n",
    "        pi1, alpha1 = params\n",
    "        \n",
    "        if alpha1 < 0 or pi1 < 0 or pi1 > 1:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - pi1\n",
    "        \n",
    "        alpha0 = pNotDRatio*alpha1\n",
    "        \n",
    "        assert(alpha0 > 0)\n",
    "        \n",
    "        print(\"alpha0\",alpha0)\n",
    "        \n",
    "        binomH0 = Binomial(total_count=geneSums, probs=pD)\n",
    "        binomH1 = BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alpha0)\n",
    "        \n",
    "        component0 = pi0 * torch.exp(binomH0.log_prob(caseAltCounts))\n",
    "        component1 = pi1 * torch.exp(binomH1.log_prob(caseAltCounts))\n",
    "\n",
    "        return - torch.log(component0 + component1).sum()\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "# Bivariate likelihood function modeled on:\n",
    "#def llPooledBivariateSingleGene(altCounts, pDs, alpha0, alpha1, alpha2, alphaBoth, pi0, pi1, pi2, piBoth):\n",
    "# # currently assume altCounts are all independent (in simulation), or 0 for everything but first condition\n",
    "# n = altCounts.sum()\n",
    "# alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "# case1nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[0]).log_prob(altCounts[1]) )\n",
    "# case2nullLikelihood = torch.exp( Binomial(total_count=n, probs=pDs[1]).log_prob(altCounts[2]) )\n",
    "# h0 = pi0 * case1nullLikelihood * case2nullLikelihood\n",
    "# h1 = pi1 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCounts[1]) ) * case2nullLikelihood\n",
    "# h2 = pi2 * torch.exp( BetaBinomial(total_count=n, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCounts[2]) ) * case1nullLikelihood\n",
    "# h3 = piBoth * torch.exp( DirichletMultinomial(total_count=n, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCounts))\n",
    "# print(f\"h0: {h0}, h1: {h1}, h2: {h2}, h3: {h3}\")\n",
    "# return torch.log( h0 + h1 + h2 + h3 )\n",
    "def likelihoodBivariateFast(altCountsByGene, pDs):\n",
    "    nGenes = altCountsByGene.shape[0]\n",
    "\n",
    "    geneSums = altCountsByGene[:, :, :].sum([1,2])\n",
    "\n",
    "    ctrlCounts = altCountsByGene[:, 0, 0]\n",
    "    altCountsCases = altCountsByGene[:, :, 1]\n",
    "    \n",
    "    altCountsFlat = []\n",
    "    for geneIdx in range(nGenes):\n",
    "        altCountsFlat.append([ctrlCounts[geneIdx], *altCountsByGene[geneIdx, :, 1].flatten()])\n",
    "\n",
    "    altCountsFlat = tensor(altCountsFlat)\n",
    "    print(altCountsFlat)\n",
    "    nullLikelihoods = torch.exp(Binomial(total_count=geneSums.expand([3, 20_000]).T, probs=pDs).log_prob(altCountsCases))\n",
    "\n",
    "    allNull = nullLikelihoods.prod(1)\n",
    "    case1null = nullLikelihoods[:, 0]\n",
    "    case2null = nullLikelihoods[:, 1]\n",
    "    caseBothNull = nullLikelihoods[:, 2]\n",
    "\n",
    "    case1and2Null = case1null * case2null\n",
    "    \n",
    "    case1andBothNull = nullLikelihoods[:, 0] * caseBothNull\n",
    "    case2andBothNull = nullLikelihoods[:, 1] * caseBothNull\n",
    "    def likelihood1(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1]) ) * case2andBothNull\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2]) ) * case1andBothNull\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood1a(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1]) ) * case2Null\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2]) ) * case1Null\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood1b(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1]) )\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2]) )\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood2(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1] + altCountsFlat[:, 3]) ) * case2andBothNull\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2] + altCountsFlat[:, 3]) ) * case1andBothNull\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood2a(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1] + altCountsFlat[:, 3]) ) * case2null\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2] + altCountsFlat[:, 3]) ) * case1null\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "\n",
    "    def likelihood2b(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1] + altCountsFlat[:, 3]) )\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2] + altCountsFlat[:, 3]) )\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood3(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha1, concentration0=alphasSum - alpha1).log_prob(altCountsFlat[:, 1] + altCountsFlat[:, 2] + altCountsFlat[:, 3]) )\n",
    "        h2 = pi2 * torch.exp( BetaBinomial(total_count=geneSums, concentration1=alpha2, concentration0=alphasSum - alpha2).log_prob(altCountsFlat[:, 2] + altCountsFlat[:, 1] + altCountsFlat[:, 3]) )\n",
    "        h3 = piBoth * torch.exp( DirichletMultinomial(total_count=geneSums, concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 + h3 ).sum()\n",
    "    \n",
    "    def likelihood4(params):\n",
    "        # TODO: better to do constrained or unconstrained alpha1?\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "        \n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        alphasSum = alpha0 + alpha1 + alpha2 + alphaBoth\n",
    "        \n",
    "        h0 = pi0 * allNull\n",
    "\n",
    "        h1 = pi1 * torch.exp( DirichletMultinomial(total_count=geneSums - altCountsFlat[:, 3], concentration=tensor([alpha1, alpha2])).log_prob(altCountsFlat[:, 1:3]))\n",
    "        h2 = pi2 * torch.exp( DirichletMultinomial(total_count=geneSums , concentration=tensor([alpha0, alpha1, alpha2, alphaBoth])).log_prob(altCountsFlat))\n",
    "\n",
    "        return -torch.log( h0 + h1 + h2 ).sum()\n",
    "\n",
    "    return likelihood1, likelihood1a, likelihood1b, likelihood2, likelihood2a, likelihood2b, likelihood3, likelihood4\n",
    "\n",
    "def cb(f, context):\n",
    "    print(\"got callback\", f, context)\n",
    "\n",
    "# TODO: update for multivariate\n",
    "def fitFnUniveriate(altCountsByGene, pDs, nEpochs = 100, minLLThresholdCount = 100, debug = False):\n",
    "    costFn = likelihoodUnivariateFast(altCountsByGene, pDs)\n",
    "    \n",
    "    lls = []\n",
    "    params = []\n",
    "\n",
    "    minLLDiff = 1\n",
    "    thresholdHitCount = 0\n",
    "    \n",
    "    nGenes = len(altCountsByGene)\n",
    "\n",
    "    randomDist = Uniform(1/nGenes, .5)\n",
    "    randomDist2 = Uniform(0, 1)\n",
    "    \n",
    "        # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "    # P(V|D) * P(D) / P(V)\n",
    "#     pDgivenVbounds = ( pVgivenD(2, 1e-6) * .001 / 1e-6, pVgivenD(100, 1e-2) * .1 / 1e-2 )\n",
    "#     pi1Bounds = ( 1/nGenes,  1 )\n",
    "#     bounds = [pDgivenVbounds, pi1Bounds]\n",
    "    for i in range(nEpochs):\n",
    "        best = float(\"inf\")\n",
    "        bestParams = []\n",
    "        for y in range(100):\n",
    "            # pi1, p(D|V)\n",
    "            fnArgs = [randomDist.sample(), randomDist2.sample()]\n",
    "            ll = costFn(fnArgs)\n",
    "            if ll < best:\n",
    "                best = ll\n",
    "                bestParams = fnArgs\n",
    "                \n",
    "        if debug:\n",
    "            print(f\"best ll: {best}, params: {bestParams}\")\n",
    "\n",
    "        fit = scipy.optimize.minimize(costFn, x0 = bestParams, method='Nelder-Mead', options={\"maxiter\": 10000, \"adaptive\": True})#gp_minimize(costFn, [(1e-7, .9),(1/nGenes, .99)])#scipy.optimize.minimize(costFn, x0 = fnArgs, method=\"Nelder-Mead\", options={\"maxiter\": 10000})\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"epoch {i}\")\n",
    "            print(fit)\n",
    "\n",
    "        if not fit[\"success\"] is True:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        pi1, pDgivenV= fit[\"x\"]\n",
    "        if pDgivenV < 0 or pDgivenV > 1 or pi1 < 1/nGenes or pi1 > 1:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        ll = fit[\"fun\"]\n",
    "        if len(lls) == 0:\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            continue\n",
    "\n",
    "        minPrevious = min(lls)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"minPrevious\", minPrevious)\n",
    "            \n",
    "        # TODO: take mode of some pc-based cluster of parameters, or some auto-encoded cluster\n",
    "        if ll < minPrevious and (minPrevious - ll) >= minLLDiff:\n",
    "            if debug:\n",
    "                print(f\"better by at >= {minLLDiff}; new ll: {fit}\")\n",
    "\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            \n",
    "            thresholdHitCount = 0\n",
    "            continue\n",
    "\n",
    "        thresholdHitCount += 1\n",
    "        \n",
    "        if thresholdHitCount == minLLThresholdCount:\n",
    "            break\n",
    "            \n",
    "    return {\"lls\": lls, \"params\": params}\n",
    "\n",
    "\n",
    "# TODO: maybe beta distribution should be constrained such that variance is that of the data?\n",
    "# or maybe there's an analog to 0 mean liability variance?\n",
    "def fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs = 100, minLLThresholdCount = 100, debug = False):\n",
    "    costFn = likelihoodUnivariateBetaBinomialFast(altCountsByGene, pDs)\n",
    "    \n",
    "    llsAll = []\n",
    "    lls = []\n",
    "    params = []\n",
    "\n",
    "    minLLDiff = 1\n",
    "    thresholdHitCount = 0\n",
    "    \n",
    "    nGenes = len(altCountsByGene)\n",
    "    remainingEpochs = nEpochs\n",
    "    \n",
    "    randomDist = Uniform(1/nGenes, .5)\n",
    "    randomDist2 = Uniform(100, 25000)\n",
    "    # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "    # P(V|D) * P(D) / P(V)\n",
    "    while remainingEpochs > 0:\n",
    "        best = float(\"inf\")\n",
    "        bestParams = []\n",
    "        for i in range(50):\n",
    "            # pi1, alpha1, alpha0\n",
    "            fnArgs = [randomDist.sample(), randomDist2.sample(), randomDist2.sample()]\n",
    "            ll = costFn(fnArgs)\n",
    "            if ll < best:\n",
    "                best = ll\n",
    "                bestParams = fnArgs\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"best ll: {best}, bestParams: {bestParams}\")\n",
    "\n",
    "        fit = scipy.optimize.minimize(costFn, x0 = bestParams, method='Nelder-Mead', options={\"maxiter\": 10000, \"adaptive\": True})#gp_minimize(costFn, [(1e-7, .9),(1/nGenes, .99)])#scipy.optimize.minimize(costFn, x0 = fnArgs, method=\"Nelder-Mead\", options={\"maxiter\": 10000})\n",
    "        #fit = scipy.optimize.basinhopping(costFn, x0 = bestParams)\n",
    "        if debug:\n",
    "            print(f\"epoch {remainingEpochs}\")\n",
    "            print(fit)\n",
    "\n",
    "        if not fit[\"success\"] is True:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        pi1, alpha1, alpha0 = fit[\"x\"]\n",
    "        # TODO: is pi1 > .5 restriction sound?\n",
    "        if pi1 < 1/nGenes or pi1 > .5 or alpha1 <= 0 or alpha0 <= 0:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "            \n",
    "        remainingEpochs -= 1\n",
    "        \n",
    "        ll = fit[\"fun\"]\n",
    "        llsAll.append(ll)\n",
    "        if len(lls) == 0:\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            continue\n",
    "\n",
    "        minPrevious = min(lls)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"minPrevious\", minPrevious)\n",
    "            \n",
    "        # TODO: take mode of some pc-based cluster of parameters, or some auto-encoded cluster\n",
    "        if ll < minPrevious and (minPrevious - ll) >= minLLDiff:\n",
    "            if debug:\n",
    "                print(f\"better by at >= {minLLDiff}; new ll: {fit}\")\n",
    "\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            \n",
    "            thresholdHitCount = 0\n",
    "            continue\n",
    "\n",
    "        thresholdHitCount += 1\n",
    "        \n",
    "        if thresholdHitCount == minLLThresholdCount:\n",
    "            break\n",
    "            \n",
    "    return {\"lls\": lls, \"params\": params, \"llTrajectory\": llsAll}\n",
    "\n",
    "# Constrain alpha0 by using 1-P(D)\n",
    "# def fitFnUniveriateBetaBinomialConstrained(altCountsByGene, pDs, nEpochs = 100, minLLThresholdCount = 100, debug = False):\n",
    "#     costFn = likelihoodUnivariateBetaBinomialConstrainedFast(altCountsByGene, pDs)\n",
    "    \n",
    "#     llsAll = []\n",
    "#     lls = []\n",
    "#     params = []\n",
    "\n",
    "#     minLLDiff = 1\n",
    "#     thresholdHitCount = 0\n",
    "    \n",
    "#     randomDist = Uniform(0, 1)\n",
    "#     randomDist2 = Uniform(1, 10000)\n",
    "#     fnArgs = [0, 0]\n",
    "#     # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "#     # P(V|D) * P(D) / P(V)\n",
    "#     nGenes = len(altCountsByGene)\n",
    "#     remainingEpochs = nEpochs\n",
    "#     while remainingEpochs > 0:\n",
    "#         # pi1\n",
    "#         fnArgs[0] = randomDist.sample()\n",
    "#         # alpha1\n",
    "#         fnArgs[1] = randomDist2.sample()\n",
    "#         fit = scipy.optimize.minimize(costFn, x0 = fnArgs, method='Nelder-Mead', options={\"maxiter\": 10000})#gp_minimize(costFn, [(1e-7, .9),(1/nGenes, .99)])#scipy.optimize.minimize(costFn, x0 = fnArgs, method=\"Nelder-Mead\", options={\"maxiter\": 10000})\n",
    "        \n",
    "#         if debug:\n",
    "#             print(f\"epoch {remainingEpochs}\")\n",
    "#             print(fit)\n",
    "\n",
    "#         if not fit[\"success\"] is True:\n",
    "#             if debug:\n",
    "#                 print(\"Failed to converge\")\n",
    "#                 print(fit)\n",
    "#             continue\n",
    "        \n",
    "        \n",
    "#         pi1, alpha1 = fit[\"x\"]\n",
    "#         # TODO: is pi1 > .5 restriction sound?\n",
    "#         if pi1 < 1/nGenes or pi1 > .5 or alpha1 <= 0:\n",
    "#             if debug:\n",
    "#                 print(\"Failed to converge\")\n",
    "#                 print(fit)\n",
    "#             continue\n",
    "            \n",
    "#         remainingEpochs -= 1\n",
    "        \n",
    "#         ll = fit[\"fun\"]\n",
    "#         llsAll.append(ll)\n",
    "#         if len(lls) == 0:\n",
    "#             lls.append(ll)\n",
    "#             params.append(fit[\"x\"])\n",
    "#             continue\n",
    "\n",
    "#         minPrevious = min(lls)\n",
    "        \n",
    "#         if debug:\n",
    "#             print(\"minPrevious\", minPrevious)\n",
    "            \n",
    "#         # TODO: take mode of some pc-based cluster of parameters, or some auto-encoded cluster\n",
    "#         if ll < minPrevious and (minPrevious - ll) >= minLLDiff:\n",
    "#             if debug:\n",
    "#                 print(f\"better by at >= {minLLDiff}; new ll: {fit}\")\n",
    "\n",
    "#             lls.append(ll)\n",
    "#             params.append(fit[\"x\"])\n",
    "            \n",
    "#             thresholdHitCount = 0\n",
    "#             continue\n",
    "\n",
    "#         thresholdHitCount += 1\n",
    "        \n",
    "#         if thresholdHitCount == minLLThresholdCount:\n",
    "#             break\n",
    "            \n",
    "#     return {\"lls\": lls, \"params\": params, \"llTrajectory\": llsAll}\n",
    "\n",
    "# TODO: maybe beta distribution should be constrained such that variance is that of the data?\n",
    "# or maybe there's an analog to 0 mean liability variance\n",
    "def fitFnBivariate(altCountsByGene, pDs, nEpochs = 100, minLLThresholdCount = 100, K = 4, debug = False, costFnIdx = 0):\n",
    "    costFunctions = likelihoodBivariateFast(altCountsByGene, pDs)\n",
    "\n",
    "    costFn = costFunctions[costFnIdx]\n",
    "    print(\"past\", costFn)\n",
    "    llsAll = []\n",
    "    lls = []\n",
    "    params = []\n",
    "\n",
    "    minLLDiff = 1\n",
    "    thresholdHitCount = 0\n",
    "    \n",
    "    nGenes = len(altCountsByGene)\n",
    "    \n",
    "    # pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "    # P(V|D) * P(D) / P(V)\n",
    "    pi0Dist = Uniform(.5, 1)\n",
    "    alphasDist = Uniform(100, 25000)    \n",
    "    for i in range(nEpochs):\n",
    "        # TODO: should we constrain alpha0 to the pD, i.e\n",
    "        # E[P(D)] = alpha1 / sum(alphasRes)\n",
    "        # P(D) * (alphasRes) = alpha1\n",
    "        best = float(\"inf\")\n",
    "        bestParams = []\n",
    "        for y in range(100):\n",
    "            pi0 = pi0Dist.sample()\n",
    "            pis = Uniform(1/nGenes, 1-pi0).sample([K-1])\n",
    "            pis = pis/(pis.sum() + pi0)\n",
    "#             print(\"pi0\", pi0, \"pis\", pis, \"sum\", pis.sum())\n",
    "            fnArgs = [*pis, *alphasDist.sample([K,])]\n",
    "\n",
    "            ll = costFn(fnArgs)\n",
    "            if ll < best:\n",
    "                best = ll\n",
    "                bestParams = fnArgs\n",
    "        \n",
    "        print(f\"best ll: {best}, bestParams: {bestParams}\")\n",
    "\n",
    "#         fnArgs = [probs[0], probs[1], probs[2], *alphas]\n",
    "        fit = scipy.optimize.minimize(costFn, x0 = bestParams, method='Nelder-Mead', options={\"maxiter\": 10000, \"adaptive\": True})\n",
    "\n",
    "        if debug:\n",
    "            print(f\"epoch {i}\")\n",
    "            print(fit)\n",
    "\n",
    "        if not fit[\"success\"] is True:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = fit[\"x\"]\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi1 > 1 or pi2 < 0 or pi2 > 1 or piBoth < 0 or piBoth > 1:\n",
    "            if debug:\n",
    "                print(\"Failed to converge\")\n",
    "                print(fit)\n",
    "            continue\n",
    "        \n",
    "        ll = fit[\"fun\"]\n",
    "        llsAll.append(ll)\n",
    "        if len(lls) == 0:\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            continue\n",
    "\n",
    "        minPrevious = min(lls)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"minPrevious\", minPrevious)\n",
    "            \n",
    "        # TODO: take mode of some pc-based cluster of parameters, or some auto-encoded cluster\n",
    "        if ll < minPrevious and (minPrevious - ll) >= minLLDiff:\n",
    "            if debug:\n",
    "                print(f\"better by at >= {minLLDiff}; new ll: {fit}\")\n",
    "\n",
    "            lls.append(ll)\n",
    "            params.append(fit[\"x\"])\n",
    "            \n",
    "            thresholdHitCount = 0\n",
    "            continue\n",
    "\n",
    "        thresholdHitCount += 1\n",
    "        \n",
    "        if thresholdHitCount == minLLThresholdCount:\n",
    "            break\n",
    "            \n",
    "    return {\"lls\": lls, \"params\": params, \"llTrajectory\": llsAll}\n",
    "\n",
    "def initBetaParams(mu, variance):\n",
    "    alpha = ((1 - mu) / variance - 1 / variance) * mu**2\n",
    "    beta = alpha * (1/mu -1)\n",
    "    \n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'altCountsByGenePooledCtrls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-442dfe97a2ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnGenes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20_000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mctrlCounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maltCountsByGenePooledCtrls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maltCountsCases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maltCountsByGenePooledCtrls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maltCountsFlat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'altCountsByGenePooledCtrls' is not defined"
     ]
    }
   ],
   "source": [
    "nGenes = 20_000\n",
    "ctrlCounts = altCountsByGenePooledCtrls[:, 0, 0]\n",
    "altCountsCases = altCountsByGenePooledCtrls[:, :, 1]\n",
    "\n",
    "altCountsFlat = []\n",
    "for geneIdx in range(nGenes):\n",
    "    altCountsFlat.append([ctrlCounts[geneIdx], *altCountsByGenePooledCtrls[geneIdx, :, 1].flatten()])\n",
    "\n",
    "altCountsFlat = tensor(altCountsFlat)\n",
    "print(altCountsFlat)\n",
    "nullLikelihoods = torch.exp(Binomial(total_count=geneSums.expand([3, 20_000]).T, probs=pDs).log_prob(altCountsCases))\n",
    "\n",
    "allNull = nullLikelihoods.prod(1)\n",
    "case1null = nullLikelihoods[:, 0]\n",
    "case2null = nullLikelihoods[:, 1]\n",
    "caseBothNull = nullLikelihoods[:, 2]\n",
    "\n",
    "case1and2Null = case1null * case2null\n",
    "\n",
    "case1andBothNull = nullLikelihoods[:, 0] * caseBothNull\n",
    "case2andBothNull = nullLikelihoods[:, 1] * caseBothNull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(altCountsFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12.,  5.,  3.,  ...,  8., 12., 10.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altCountsByGenePooledCtrls[:, :, :].sum([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[12.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.]],\n",
       "\n",
       "        [[ 4.,  0.],\n",
       "         [ 0.,  1.],\n",
       "         [ 0.,  0.]],\n",
       "\n",
       "        [[ 3.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 8.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.]],\n",
       "\n",
       "        [[12.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.]],\n",
       "\n",
       "        [[10.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altCountsByGenePooledCtrls[:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geneSums = altCountsByGenePooledCtrls[:, :, :].sum([1,2])\n",
    "# # print(\"geneSums\", geneSums)\n",
    "# # print(\"alt counts\", altCountsByGenePooledCtrls)\n",
    "    \n",
    "# altCountsCases = altCountsByGenePooledCtrls[:, :, 1]\n",
    "# print(\"case counts\", altCountsCases)\n",
    "# # precomputed since params never change\n",
    "# print(\"pDS\", pDs.T)\n",
    "# # print('pdS expande', pDs.expand([2000, 3]))\n",
    "# print(geneSums.expand([3, 20_000]).T)\n",
    "nullLikelihoods = Binomial(total_count=geneSums.expand([3, 20_000]).T, probs=pDs)\n",
    "\n",
    "# print(geneSums)\n",
    "# pDs.expand([20_000,3]).T\n",
    "\n",
    "r = torch.exp(nullLikelihoods.log_prob(altCountsCases))\n",
    "\n",
    "r.prod(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2383, -2.2383, -0.0640],\n",
       "        [-1.0011, -1.1144, -0.1119],\n",
       "        [-1.0058, -1.0058, -0.1159],\n",
       "        ...,\n",
       "        [-1.5821, -2.0016, -0.1589],\n",
       "        [-1.8899, -2.5023, -3.5536],\n",
       "        [-0.9851, -0.9851, -2.4116]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 60.,   2.,   0.,   2.,   0.,   0.],\n",
       "        [111.,   1.,   0.,   0.,   0.,   0.],\n",
       "        [114.,   1.,   0.,   1.,   0.,   0.],\n",
       "        ...,\n",
       "        [156.,   0.,   0.,   3.,   0.,   0.],\n",
       "        [264.,   4.,   0.,   5.,   0.,   2.],\n",
       "        [ 98.,   0.,   0.,   0.,   0.,   1.]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altCountsByGenePooledCtrls.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### all named tuples used\n",
    "\n",
    "Samples = namedtuple(\"Samples\", [\"ctrls\", \"cases\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nSamples shape: [nConditions, 2] , last dim is ctrls, cases\n",
    "\n",
    "# this is insanely slow for some reason, and almost all time is in the expanded binomial sampling\n",
    "# def genData(nSamples, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "#     # TODO: assert shapes match\n",
    "#     print(\"TESTING WITH: nSamples\", nSamples, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "#     nConditions = len(nSamples)\n",
    "#     probs = []\n",
    "#     afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "#     rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "#     rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "#     # shape == [nGenes, nConditions]\n",
    "#     afs = afDist.sample([nGenes,])   \n",
    "#     rrs = rrDist.sample([nGenes,])\n",
    "#     rrNulls = rrNullDist.sample([nGenes,])\n",
    "#     for geneIdx in range(nGenes):\n",
    "#         geneProbs = []\n",
    "#         for conditionIdx in range(nConditions):\n",
    "#             # TODO: sample from uniform\n",
    "#             if geneIdx < nGenes * diseaseFractions[conditionIdx]:\n",
    "#                 rr = rrs[geneIdx, conditionIdx]\n",
    "#             else:\n",
    "#                 rr = rrNulls[geneIdx, conditionIdx]\n",
    "            \n",
    "#             probVgivenD = pVgivenD(rr, afs[geneIdx])\n",
    "#             probVgivenNotD = pVgivenNotD(pDs[conditionIdx], afs[geneIdx], probVgivenD)\n",
    "            \n",
    "#             geneProbs.append([probVgivenNotD, probVgivenD])\n",
    "#         probs.append(geneProbs)\n",
    "#     probs = tensor(probs)\n",
    "\n",
    "#     # This should not be slow but is\n",
    "#     # https://github.com/pytorch/pytorch/issues/11389\n",
    "#     start = time.time()\n",
    "#     altCounts = Binomial(total_count=nSamples.expand([nGenes, *nSamples.shape]), probs=probs).sample()\n",
    "#     print(\"final sampling took\", time.time() - start)\n",
    "    \n",
    "#     return altCounts, probs\n",
    "\n",
    "def genDataSequential(nSamples, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "    # TODO: assert shapes match\n",
    "    print(\"TESTING WITH: nSamples\", nSamples, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "    nConditions = len(nSamples)\n",
    "    altCounts = []\n",
    "    probs = []\n",
    "    afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "    rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "    rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "    # shape == [nGenes, nConditions]\n",
    "    afs = afDist.sample([nGenes,])   \n",
    "    rrs = rrDist.sample([nGenes,])\n",
    "    rrNulls = rrNullDist.sample([nGenes,])\n",
    "    \n",
    "    endIndices = nGenes * diseaseFractions\n",
    "    startIndices = []\n",
    "    for i in range(len(t)):\n",
    "        if i == 0:\n",
    "            startIndices.append(0)\n",
    "            continue\n",
    "        endIndices[i] += endIndices[i-1]\n",
    "        startIndices.append(endIndices[i-1])\n",
    "    \n",
    "    print(\"startIndices\", startIndices, \"endIndices\", endIndices)\n",
    "    for geneIdx in range(nGenes):\n",
    "        geneAltCounts = []\n",
    "        geneProbs = []\n",
    "        for conditionIdx in range(nConditions):\n",
    "            # TODO: sample from uniform\n",
    "            if geneIdx >= startIndices[conditionIdx] and geneIdx < endIndices[conditionIdx]:\n",
    "                rr = rrs[geneIdx, conditionIdx]\n",
    "            else:\n",
    "                rr = rrNulls[geneIdx, conditionIdx]\n",
    "            \n",
    "            probVgivenD = pVgivenD(rr, afs[geneIdx])\n",
    "            altCountsCases = Binomial(total_count=nSamples[conditionIdx][1], probs=probVgivenD).sample()\n",
    "            \n",
    "            # we can use one simulation to study pooled an separate samples\n",
    "            # in the pooled model, we could sum control samples during inference\n",
    "            probVgivenNotD = pVgivenNotD(pDs[conditionIdx], afs[geneIdx], probVgivenD)\n",
    "            altCountsCtrls = Binomial(total_count=nSamples[conditionIdx][0], probs=probVgivenNotD).sample()\n",
    "            \n",
    "            geneAltCounts.append([altCountsCtrls, altCountsCases])\n",
    "            geneProbs.append([probVgivenNotD, probVgivenD])\n",
    "        altCounts.append(geneAltCounts)\n",
    "        probs.append(geneProbs)\n",
    "    altCounts = tensor(altCounts)\n",
    "    probs = tensor(probs)\n",
    "    \n",
    "    return altCounts, probs\n",
    "\n",
    "def genDataSequentialPooledCtrls(nCases, nCtrls, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes = 20000):\n",
    "    # TODO: assert shapes match\n",
    "    print(\"TESTING POOLED WITH: nCases\", nCases, \"nCtrls\", nCtrls, \"rrMean\", rrMeans, \"rrShape\", rrShape, \"afMean\", afMean, \"afShape\", afShape, \"diseaseFractions\", diseaseFractions, \"pDs\", pDs)\n",
    "    \n",
    "    nConditions = len(nCases)\n",
    "    altCounts = []\n",
    "    probs = []\n",
    "    afDist = Gamma(concentration=afShape,rate=afShape/afMean)\n",
    "    rrDist = Gamma(concentration=rrShape,rate=rrShape/rrMeans)\n",
    "    rrNullDist = Gamma(concentration=rrShape,rate=rrShape.expand(nConditions))\n",
    "    \n",
    "    # shape == [nGenes, nConditions]\n",
    "    afs = afDist.sample([nGenes,])   \n",
    "    rrs = rrDist.sample([nGenes,])\n",
    "    rrNulls = rrNullDist.sample([nGenes,])\n",
    "    \n",
    "    endIndices = nGenes * diseaseFractions\n",
    "    startIndices = []\n",
    "    for i in range(len(t)):\n",
    "        if i == 0:\n",
    "            startIndices.append(0)\n",
    "            continue\n",
    "        endIndices[i] += endIndices[i-1]\n",
    "        startIndices.append(endIndices[i-1])\n",
    "    \n",
    "    print(\"startIndices\", startIndices, \"endIndices\", endIndices)\n",
    "    for geneIdx in range(nGenes):\n",
    "        geneAltCounts = []\n",
    "        geneProbs = []\n",
    "\n",
    "        probVgivenDs = []\n",
    "        for conditionIdx in range(nConditions):\n",
    "            # TODO: sample from uniform\n",
    "            if geneIdx >= startIndices[conditionIdx] and geneIdx < endIndices[conditionIdx]:\n",
    "                rr = rrs[geneIdx, conditionIdx]\n",
    "            else:\n",
    "                rr = rrNulls[geneIdx, conditionIdx]\n",
    "            probVgivenDs.append(pVgivenD(rr, afs[geneIdx]))\n",
    "\n",
    "        probVgivenDs = tensor(probVgivenDs)\n",
    "#         print(\"probVgivenDs\", probVgivenDs)\n",
    "        altCountsCases = Binomial(total_count=nCases, probs=probVgivenDs).sample()\n",
    "\n",
    "#         print(\"altCountsCases\", altCountsCases, \"altCountCases.shape\", altCountsCases.shape)\n",
    "#         print(\"0 index\", altCountsCases[0])\n",
    "        # we can use one simulation to study pooled an separate samples\n",
    "        # in the pooled model, we could sum control samples during inference\n",
    "        probVgivenNotD = pVgivenNotD(pDs, afs[geneIdx], probVgivenDs)\n",
    "#         print(\"probVgivenNotD\", probVgivenNotD)\n",
    "        \n",
    "        altCountsCtrls = Binomial(total_count=nCtrls, probs=probVgivenNotD).sample()\n",
    "#         print(\"altCountsCtrls\", altCountsCtrls)\n",
    "        \n",
    "        for conditionIdx in range(nConditions):\n",
    "            if conditionIdx == 0:\n",
    "                geneAltCounts.append([altCountsCtrls, altCountsCases[conditionIdx]])\n",
    "            else:\n",
    "                geneAltCounts.append([0, altCountsCases[conditionIdx]])\n",
    "            geneProbs.append([probVgivenNotD, probVgivenDs[conditionIdx]])\n",
    "\n",
    "        altCounts.append(geneAltCounts)\n",
    "        probs.append(geneProbs)\n",
    "    altCounts = tensor(altCounts)\n",
    "    probs = tensor(probs)\n",
    "    \n",
    "    return altCounts, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0099, 0.0099, 0.0010])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease1 = Samples(1e5, 1e3)\n",
    "disease2 = Samples(1e5, 1e3)\n",
    "diseaseBoth = Samples(1e5, 1e2)\n",
    "\n",
    "nSamples = [disease1, disease2, diseaseBoth]\n",
    "nSamples = tensor(nSamples)\n",
    "\n",
    "pDs = nSamples[:, 1]/nSamples.sum(1)\n",
    "diseaseFractions = tensor([.1, .1, .05])\n",
    "rrShape = tensor(10.)\n",
    "rrMeans = tensor([10., 10., 5.])\n",
    "afMean = tensor(1e-4)\n",
    "afShape = tensor(10.)\n",
    "pooledControls = True\n",
    "pDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH: nSamples tensor([[100000.,   1000.],\n",
      "        [100000.,   1000.],\n",
      "        [100000.,    100.]]) rrMean tensor([10., 10.,  5.]) rrShape tensor(10.) afMean tensor(1.0000e-04) afShape tensor(10.) diseaseFractions tensor([0.1000, 0.1000, 0.0500]) pDs tensor([0.0099, 0.0099, 0.0010])\n",
      "startIndices [0, tensor(2000.), tensor(4000.)] endIndices tensor([2000., 4000., 5000.])\n",
      "took 73.88606190681458\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "altCountsByGene, afsByGene = genDataSequential(nSamples=nSamples, pDs=pDs, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH: nSamples tensor([[100000.,   1000.],\n",
      "        [100000.,   1000.],\n",
      "        [100000.,    100.]]) rrMean tensor([2., 2., 2.]) rrShape tensor(10.) afMean tensor(1.0000e-04) afShape tensor(10.) diseaseFractions tensor([0.1000, 0.1000, 0.0500]) pDs tensor([0.0099, 0.0099, 0.0010])\n",
      "startIndices [0, tensor(2000.), tensor(4000.)] endIndices tensor([2000., 4000., 5000.])\n",
      "took 77.93965601921082\n"
     ]
    }
   ],
   "source": [
    "rrMeansLow = tensor([2., 2., 2.])\n",
    "\n",
    "start = time.time()\n",
    "altCountsByGeneRR2, afsByGeneRR2 = genDataSequential(nSamples=nSamples, pDs=pDs, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeansLow, afMean=afMean, afShape=afShape)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING WITH: nSamples tensor([[100000.,   1000.],\n",
      "        [100000.,   1000.],\n",
      "        [100000.,    100.]]) rrMean tensor([3., 3., 3.]) rrShape tensor(10.) afMean tensor(1.0000e-04) afShape tensor(10.) diseaseFractions tensor([0.1000, 0.1000, 0.0500]) pDs tensor([0.0099, 0.0099, 0.0010])\n",
      "startIndices [0, tensor(2000.), tensor(4000.)] endIndices tensor([2000., 4000., 5000.])\n",
      "took 142.18190717697144\n"
     ]
    }
   ],
   "source": [
    "rrMeans3 = tensor([3., 3., 3.])\n",
    "\n",
    "start = time.time()\n",
    "altCountsByGeneRR3, afsByGeneRR3 = genDataSequential(nSamples=nSamples, pDs=pDs, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans3, afMean=afMean, afShape=afShape)\n",
    "print(\"took\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nCases\n"
     ]
    }
   ],
   "source": [
    "print(\"nCases\")\n",
    "r = Binomial(total_count=nCases, probs=tensor([1.4566e-04, 8.7859e-05, 2.5974e-04])).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(170000.)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1-pDs[0]) / pD[0])*1.7e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([43., 32., 22.,  ..., 52., 47., 55.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 4])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geneSums = altCountsByGene.sum([1,2])\n",
    "print(geneSums)\n",
    "altCountsByGenePooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[41.,  1.,  1.,  0.],\n",
      "        [32.,  0.,  0.,  0.],\n",
      "        [22.,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [52.,  0.,  0.,  0.],\n",
      "        [47.,  0.,  0.,  0.],\n",
      "        [55.,  0.,  0.,  0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.2718, -0.3184, -0.2189,  ..., -0.5174, -0.4677, -0.5473])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(altCountsByGenePooled)\n",
    "d = Binomial(total_count=geneSums, probs=pDs[0])\n",
    "d.log_prob(altCountsByGenePooled[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2., -1.,  1.,  ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = altCountsByGenePooled[:, 2] - altCountsByGenePooled[:, 1]\n",
    "r[r != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3368, 0.3300, 0.3332])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.3368),\n",
       " tensor(0.3300),\n",
       " tensor(0.3332),\n",
       " tensor(206.3920),\n",
       " tensor(1597.2917),\n",
       " tensor(903.7043),\n",
       " tensor(122.3799)]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomDist = Uniform(0, 1)\n",
    "randomDist2 = Uniform(1, 10000)\n",
    "fnArgs = []\n",
    "# pDgivenV can't be smaller than this assuming allele freq > 1e-6 and rr < 100\n",
    "# P(V|D) * P(D) / P(V)\n",
    "nGenes = len(altCountsByGene)\n",
    "\n",
    "probs = randomDist.sample([3,])\n",
    "probs = probs / probs.sum()\n",
    "print(probs)\n",
    "    #pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth\n",
    "fnArgs = [*probs, *randomDist2.sample([4,])]\n",
    "fnArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0: tensor([0., 0., 0.,  ..., 0., 0., 0.]), h1: tensor([2.2024e-15, 8.3472e-13, 3.3618e-09,  ..., 5.8654e-20, 3.5449e-18,\n",
      "        5.0277e-21]), h2: tensor([1.3259e-07, 1.1344e-06, 5.6730e-05,  ..., 4.7533e-10, 3.3060e-09,\n",
      "        1.4845e-10]), h3: tensor([7.9874e-44, 1.1356e-36, 8.7359e-26,  ..., 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(254699.7969)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llFn(fnArgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is  tensor(20012.)\n",
      "h0: 0.0, h1: 0.0, h2: 0.0, h3: 7.369135346380062e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-14.1208)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llPooledBivariateSingleGene(tensor([10.,1.,1.,20000.]), tensor([.01,.01,.05]), tensor(13.), tensor(10.), tensor(10.), tensor(100000.), tensor(.77), tensor(.1), tensor(.1), tensor(.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this gives -2.401 log(likelihoodUnivariateSingleGene(xCtrl = 10, xCase1 = 1, prevalence1 = .01, pi0 = .9, pi1 = .1, pDiseaseGivenVariant = .001))\n",
    "#tensor(-2.5290): llUnivariateSingleGeneJensen(xCtrl = tensor(10.), xCase = tensor(1.), pD = tensor(.01), pi0 = tensor(.9), pi1 = tensor(.1), pDgivenV = tensor(.001))\n",
    "r = llUnivariateSingleGeneNoJensen(xCtrl = tensor(10.), xCase = tensor(1.), pD = tensor(.01), pi0 = tensor(.9), pi1 = tensor(.1), pDgivenV = tensor(.001))\n",
    "assert(abs(-r + tensor(-2.4010)) < .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: testAlpha: tensor([16., 20., 30., 15.]), n: 16.0, altCounts: tensor([10.,  2.,  3.,  1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-9.4702)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altCounts = tensor([10., 2., 3., 1.])\n",
    "n = altCounts.sum()\n",
    "\n",
    "testAlpha = tensor([16., 20., 30., 15.])\n",
    "print(f\"test data: testAlpha: {testAlpha}, n: {n}, altCounts: {altCounts}\")\n",
    "DirichletMultinomial(total_count=n, concentration=testAlpha).log_prob(altCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1005)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pDgivenV(.01, afsByGene[0:2000, 0, 1], 1e-4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0255)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test functions\n",
    "pDgivenV(.01, afsByGeneRR2[0:2000, 0, 1], afsByGeneRR2Shape5[0:2000, 0, 0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance 0.01171849070919102\n",
      "mean 0.011861330595633124\n",
      "true varianc\n"
     ]
    }
   ],
   "source": [
    "# variance is wrong\n",
    "def betaVariance(alpha, beta):\n",
    "    return (alpha * beta) / ( ((alpha + beta)**2) + (alpha + beta + 1) )\n",
    "\n",
    "def betaMean(alpha, beta):\n",
    "    return alpha / (alpha + beta)\n",
    "\n",
    "print(\"variance\", betaVariance(6.47e1,5.39e3))\n",
    "print(\"mean\", betaMean(6.47e1,5.39e3))\n",
    "print(\"true varianc\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0010) tensor(0.0002)\n"
     ]
    }
   ],
   "source": [
    "m1 = afsByGene[0:2000, 0, 1].mean()\n",
    "m2 = afsByGeneRR2[0:2000, 0, 1].mean()/afsByGeneRR2[2000:, 0, 1].mean()\n",
    "m1 - m2\n",
    "print(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6571210503578186 per iteration\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lls': [10080.6748046875], 'params': [array([0.08972293, 0.10678517])]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "res = fitFnUniveriate(altCountsByGene, pDs, nEpochs=20, minLLThresholdCount=20, debug=True)\n",
    "print((time.time() - start) / 20, \"per iteration\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lls': [6853.025390625], 'params': [array([0.08424001, 0.01998017])]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitFnUniveriate(altCountsByGeneRR2, pDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0094)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pDgivenV(pDs[0], afsByGeneRR2Shape5[0:2000, 0, 1], afsByGeneRR2Shape5[0:2000, 0, 0]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mpDgivenV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpVgivenD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/projects/tada/<ipython-input-411-fa0e75662af6>\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pDgivenV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 6733.791015625, params: [tensor(0.0445), tensor(0.0212)]\n",
      "epoch 0\n",
      " final_simplex: (array([[0.05863696, 0.01835999],\n",
      "       [0.05862671, 0.01836145],\n",
      "       [0.05863561, 0.01835996]]), array([6733.71728516, 6733.71728516, 6733.71728516]))\n",
      "           fun: 6733.71728515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 57\n",
      "           nit: 23\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.05863696, 0.01835999])\n",
      "best ll: 6795.6962890625, params: [tensor(0.0577), tensor(0.0596)]\n",
      "epoch 1\n",
      " final_simplex: (array([[0.06383722, 0.01817908],\n",
      "       [0.06383722, 0.01817908],\n",
      "       [0.06383723, 0.01817908]]), array([6733.69628906, 6733.69628906, 6733.69628906]))\n",
      "           fun: 6733.6962890625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 100\n",
      "           nit: 36\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.06383722, 0.01817908])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6737.7705078125, params: [tensor(0.0222), tensor(0.0062)]\n",
      "epoch 2\n",
      " final_simplex: (array([[0.10395577, 0.01493198],\n",
      "       [0.10395591, 0.01493197],\n",
      "       [0.10395594, 0.01493197]]), array([6733.64599609, 6733.64599609, 6733.64599609]))\n",
      "           fun: 6733.64599609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 132\n",
      "           nit: 56\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.10395577, 0.01493198])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.6689453125, params: [tensor(0.1464), tensor(0.0134)]\n",
      "epoch 3\n",
      " final_simplex: (array([[0.15309711, 0.0135569 ],\n",
      "       [0.15309854, 0.01355686],\n",
      "       [0.15309717, 0.01355691]]), array([6733.62207031, 6733.62207031, 6733.62207031]))\n",
      "           fun: 6733.6220703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 68\n",
      "           nit: 30\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.15309711, 0.0135569 ])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.76806640625, params: [tensor(0.0102), tensor(0.0339)]\n",
      "epoch 4\n",
      " final_simplex: (array([[0.08865971, 0.01605534],\n",
      "       [0.08865971, 0.01605534],\n",
      "       [0.08865972, 0.01605534]]), array([6733.64990234, 6733.64990234, 6733.64990234]))\n",
      "           fun: 6733.64990234375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 146\n",
      "           nit: 61\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.08865971, 0.01605534])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.7080078125, params: [tensor(0.3790), tensor(0.0111)]\n",
      "epoch 5\n",
      " final_simplex: (array([[0.38950399, 0.01130413],\n",
      "       [0.38950407, 0.01130413],\n",
      "       [0.38950486, 0.01130412]]), array([6733.59960938, 6733.59960938, 6733.59960938]))\n",
      "           fun: 6733.599609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 87\n",
      "           nit: 36\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.38950399, 0.01130413])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.39794921875, params: [tensor(0.0789), tensor(0.0200)]\n",
      "epoch 6\n",
      " final_simplex: (array([[0.08612494, 0.01608673],\n",
      "       [0.08611551, 0.01608738],\n",
      "       [0.08612204, 0.01608683]]), array([6733.65478516, 6733.65478516, 6733.65478516]))\n",
      "           fun: 6733.65478515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 60\n",
      "           nit: 25\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.08612494, 0.01608673])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6749.12451171875, params: [tensor(0.0703), tensor(0.0007)]\n",
      "epoch 7\n",
      " final_simplex: (array([[0.00012354, 0.00125192],\n",
      "       [0.00012354, 0.0012498 ],\n",
      "       [0.00012397, 0.00125086]]), array([6736.73193359, 6736.73193359, 6736.73193359]))\n",
      "           fun: 6736.73193359375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 69\n",
      "           nit: 33\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.00012354, 0.00125192])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6738.705078125, params: [tensor(0.3786), tensor(0.0133)]\n",
      "epoch 8\n",
      " final_simplex: (array([[0.3991278 , 0.01127854],\n",
      "       [0.39912646, 0.01127855],\n",
      "       [0.39912614, 0.01127855]]), array([6733.61621094, 6733.61621094, 6733.61621094]))\n",
      "           fun: 6733.6162109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 81\n",
      "           nit: 33\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.3991278 , 0.01127854])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6736.408203125, params: [tensor(0.0008), tensor(0.0532)]\n",
      "epoch 9\n",
      " final_simplex: (array([[0.04674537, 0.02076651],\n",
      "       [0.04674538, 0.02076648],\n",
      "       [0.04674537, 0.02076651]]), array([6733.75927734, 6733.75927734, 6733.75927734]))\n",
      "           fun: 6733.75927734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 161\n",
      "           nit: 78\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.04674537, 0.02076651])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.84130859375, params: [tensor(0.2342), tensor(0.0103)]\n",
      "epoch 10\n",
      " final_simplex: (array([[0.24416334, 0.01221661],\n",
      "       [0.24416329, 0.01221661],\n",
      "       [0.24416321, 0.01221661]]), array([6733.61132812, 6733.61132812, 6733.61132812]))\n",
      "           fun: 6733.611328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 89\n",
      "           nit: 34\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.24416334, 0.01221661])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6736.3330078125, params: [tensor(0.0895), tensor(0.0103)]\n",
      "epoch 11\n",
      " final_simplex: (array([[0.09727151, 0.01525237],\n",
      "       [0.09727119, 0.01525239],\n",
      "       [0.09727099, 0.01525239]]), array([6733.64892578, 6733.64892578, 6733.64892578]))\n",
      "           fun: 6733.64892578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 91\n",
      "           nit: 39\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.09727151, 0.01525237])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6754.55615234375, params: [tensor(0.0095), tensor(0.1194)]\n",
      "epoch 12\n",
      " final_simplex: (array([[0.05960592, 0.01888818],\n",
      "       [0.05960531, 0.01888828],\n",
      "       [0.05960531, 0.01888825]]), array([6733.70898438, 6733.70898438, 6733.70898438]))\n",
      "           fun: 6733.708984375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 129\n",
      "           nit: 62\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.05960592, 0.01888818])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.6982421875, params: [tensor(0.1253), tensor(0.0148)]\n",
      "epoch 13\n",
      " final_simplex: (array([[0.13284602, 0.01390173],\n",
      "       [0.1328382 , 0.01390201],\n",
      "       [0.13284307, 0.01390182]]), array([6733.62451172, 6733.62451172, 6733.62451172]))\n",
      "           fun: 6733.62451171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 68\n",
      "           nit: 27\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.13284602, 0.01390173])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6737.1318359375, params: [tensor(0.0163), tensor(0.0536)]\n",
      "epoch 14\n",
      " final_simplex: (array([[0.078901  , 0.01635978],\n",
      "       [0.07889136, 0.01636073],\n",
      "       [0.07889566, 0.01636033]]), array([6733.67285156, 6733.67285156, 6733.67285156]))\n",
      "           fun: 6733.6728515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 107\n",
      "           nit: 48\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.078901  , 0.01635978])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.791015625, params: [tensor(0.2994), tensor(0.0122)]\n",
      "epoch 15\n",
      " final_simplex: (array([[0.31471995, 0.01168041],\n",
      "       [0.31471672, 0.01168041],\n",
      "       [0.31471801, 0.0116804 ]]), array([6733.60888672, 6733.60888672, 6733.60888672]))\n",
      "           fun: 6733.60888671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 69\n",
      "           nit: 32\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.31471995, 0.01168041])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.62646484375, params: [tensor(0.1970), tensor(0.0127)]\n",
      "epoch 16\n",
      " final_simplex: (array([[0.19694256, 0.01267178],\n",
      "       [0.1969428 , 0.01267178],\n",
      "       [0.19694251, 0.01267178]]), array([6733.62060547, 6733.62060547, 6733.62060547]))\n",
      "           fun: 6733.62060546875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 82\n",
      "           nit: 32\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.19694256, 0.01267178])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.39306640625, params: [tensor(0.0476), tensor(0.0158)]\n",
      "epoch 17\n",
      " final_simplex: (array([[0.05471225, 0.01961583],\n",
      "       [0.05471225, 0.01961582],\n",
      "       [0.05471216, 0.01961585]]), array([6733.7265625, 6733.7265625, 6733.7265625]))\n",
      "           fun: 6733.7265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 83\n",
      "           nit: 31\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.05471225, 0.01961583])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6748.24755859375, params: [tensor(0.2817), tensor(0.0164)]\n",
      "epoch 18\n",
      " final_simplex: (array([[0.3045249 , 0.01170738],\n",
      "       [0.3045308 , 0.01170739],\n",
      "       [0.30452757, 0.01170735]]), array([6733.61230469, 6733.61230469, 6733.61230469]))\n",
      "           fun: 6733.6123046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 77\n",
      "           nit: 35\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.3045249 , 0.01170738])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6741.22607421875, params: [tensor(0.3398), tensor(0.0142)]\n",
      "epoch 19\n",
      " final_simplex: (array([[0.35769458, 0.01146627],\n",
      "       [0.35769459, 0.01146627],\n",
      "       [0.35769459, 0.01146627]]), array([6733.60791016, 6733.60791016, 6733.60791016]))\n",
      "           fun: 6733.60791015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 111\n",
      "           nit: 41\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.35769458, 0.01146627])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.94921875, params: [tensor(0.0115), tensor(0.0273)]\n",
      "epoch 20\n",
      " final_simplex: (array([[0.07669939, 0.01650311],\n",
      "       [0.07669966, 0.01650309],\n",
      "       [0.07669957, 0.0165031 ]]), array([6733.67480469, 6733.67480469, 6733.67480469]))\n",
      "           fun: 6733.6748046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 134\n",
      "           nit: 62\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.07669939, 0.01650311])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.67626953125, params: [tensor(0.1062), tensor(0.0148)]\n",
      "epoch 21\n",
      " final_simplex: (array([[0.11709392, 0.01447531],\n",
      "       [0.11709392, 0.01447531],\n",
      "       [0.11709393, 0.01447531]]), array([6733.63183594, 6733.63183594, 6733.63183594]))\n",
      "           fun: 6733.6318359375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 102\n",
      "           nit: 41\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.11709392, 0.01447531])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.45947265625, params: [tensor(0.0218), tensor(0.0157)]\n",
      "epoch 22\n",
      " final_simplex: (array([[0.06145066, 0.01828966],\n",
      "       [0.0614595 , 0.01828837],\n",
      "       [0.06147012, 0.01828687]]), array([6733.69238281, 6733.69238281, 6733.69238281]))\n",
      "           fun: 6733.6923828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 94\n",
      "           nit: 45\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.06145066, 0.01828966])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.8583984375, params: [tensor(0.1122), tensor(0.0189)]\n",
      "epoch 23\n",
      " final_simplex: (array([[0.1191856 , 0.01441573],\n",
      "       [0.11918439, 0.01441577],\n",
      "       [0.11918514, 0.01441575]]), array([6733.62890625, 6733.62890625, 6733.62890625]))\n",
      "           fun: 6733.62890625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 78\n",
      "           nit: 32\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.1191856 , 0.01441573])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6771.14306640625, params: [tensor(0.0020), tensor(0.5609)]\n",
      "epoch 24\n",
      " final_simplex: (array([[5.00437140e-07, 6.16527574e-01],\n",
      "       [4.99692442e-07, 6.16603849e-01],\n",
      "       [5.01158567e-07, 6.16563228e-01]]), array([6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 93\n",
      "           nit: 39\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.00437140e-07, 6.16527574e-01])\n",
      "Failed to converge\n",
      " final_simplex: (array([[5.00437140e-07, 6.16527574e-01],\n",
      "       [4.99692442e-07, 6.16603849e-01],\n",
      "       [5.01158567e-07, 6.16563228e-01]]), array([6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 93\n",
      "           nit: 39\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.00437140e-07, 6.16527574e-01])\n",
      "best ll: 6734.41796875, params: [tensor(0.0655), tensor(0.0141)]\n",
      "epoch 25\n",
      " final_simplex: (array([[0.07167346, 0.01732983],\n",
      "       [0.07167347, 0.01732971],\n",
      "       [0.07167362, 0.01732971]]), array([6733.67578125, 6733.67578125, 6733.67578125]))\n",
      "           fun: 6733.67578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 82\n",
      "           nit: 35\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.07167346, 0.01732983])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.3779296875, params: [tensor(0.1170), tensor(0.0169)]\n",
      "epoch 26\n",
      " final_simplex: (array([[0.12214214, 0.01441   ],\n",
      "       [0.12214224, 0.01441   ],\n",
      "       [0.1221422 , 0.01441   ]]), array([6733.62841797, 6733.62841797, 6733.62841797]))\n",
      "           fun: 6733.62841796875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 96\n",
      "           nit: 40\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.12214214, 0.01441   ])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6736.66748046875, params: [tensor(0.0406), tensor(0.0101)]\n",
      "epoch 27\n",
      " final_simplex: (array([[0.05168508, 0.01972107],\n",
      "       [0.05165718, 0.01972689],\n",
      "       [0.05167352, 0.01972572]]), array([6733.74023438, 6733.74023438, 6733.74023438]))\n",
      "           fun: 6733.740234375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 58\n",
      "           nit: 26\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.05168508, 0.01972107])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.572265625, params: [tensor(0.1190), tensor(0.0182)]\n",
      "epoch 28\n",
      " final_simplex: (array([[0.12470127, 0.01433763],\n",
      "       [0.1247012 , 0.01433763],\n",
      "       [0.12470123, 0.01433763]]), array([6733.625, 6733.625, 6733.625]))\n",
      "           fun: 6733.625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 96\n",
      "           nit: 38\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.12470127, 0.01433763])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.0810546875, params: [tensor(0.0767), tensor(0.0144)]\n",
      "epoch 29\n",
      " final_simplex: (array([[0.08298859, 0.01637415],\n",
      "       [0.08298859, 0.01637415],\n",
      "       [0.08298859, 0.01637415]]), array([6733.65136719, 6733.65136719, 6733.65136719]))\n",
      "           fun: 6733.6513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 119\n",
      "           nit: 48\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.08298859, 0.01637415])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.8994140625, params: [tensor(0.0524), tensor(0.0114)]\n",
      "epoch 30\n",
      " final_simplex: (array([[0.05958318, 0.01875345],\n",
      "       [0.0595814 , 0.01875368],\n",
      "       [0.05958099, 0.01875375]]), array([6733.70410156, 6733.70410156, 6733.70410156]))\n",
      "           fun: 6733.7041015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 77\n",
      "           nit: 34\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.05958318, 0.01875345])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.7841796875, params: [tensor(0.0926), tensor(0.0146)]\n",
      "epoch 31\n",
      " final_simplex: (array([[0.09794008, 0.01546479],\n",
      "       [0.09794005, 0.01546479],\n",
      "       [0.0979401 , 0.01546478]]), array([6733.64257812, 6733.64257812, 6733.64257812]))\n",
      "           fun: 6733.642578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 85\n",
      "           nit: 34\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.09794008, 0.01546479])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6816.91552734375, params: [tensor(0.1561), tensor(0.0335)]\n",
      "epoch 32\n",
      " final_simplex: (array([[0.16768868, 0.01341876],\n",
      "       [0.16768608, 0.0134188 ],\n",
      "       [0.16768738, 0.01341879]]), array([6733.63427734, 6733.63427734, 6733.63427734]))\n",
      "           fun: 6733.63427734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 83\n",
      "           nit: 33\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.16768868, 0.01341876])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6749.57080078125, params: [tensor(0.0159), tensor(0.0820)]\n",
      "epoch 33\n",
      " final_simplex: (array([[0.07897927, 0.01625785],\n",
      "       [0.07897121, 0.01625854],\n",
      "       [0.07897073, 0.01625855]]), array([6733.67724609, 6733.67724609, 6733.67724609]))\n",
      "           fun: 6733.67724609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 118\n",
      "           nit: 55\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.07897927, 0.01625785])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.2568359375, params: [tensor(0.0059), tensor(0.0553)]\n",
      "epoch 34\n",
      " final_simplex: (array([[0.07901963, 0.01638829],\n",
      "       [0.07901965, 0.0163883 ],\n",
      "       [0.0790195 , 0.0163883 ]]), array([6733.67285156, 6733.67285156, 6733.67285156]))\n",
      "           fun: 6733.6728515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 123\n",
      "           nit: 58\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.07901963, 0.01638829])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.8173828125, params: [tensor(0.0405), tensor(0.0151)]\n",
      "epoch 35\n",
      " final_simplex: (array([[0.08224773, 0.01651627],\n",
      "       [0.08224923, 0.01651614],\n",
      "       [0.08224656, 0.01651636]]), array([6733.65771484, 6733.65771484, 6733.65771484]))\n",
      "           fun: 6733.65771484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 97\n",
      "           nit: 42\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.08224773, 0.01651627])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.99169921875, params: [tensor(0.0262), tensor(0.0275)]\n",
      "epoch 36\n",
      " final_simplex: (array([[0.02918399, 0.02478844],\n",
      "       [0.02918395, 0.02478848],\n",
      "       [0.02918393, 0.02478851]]), array([6733.92919922, 6733.92919922, 6733.92919922]))\n",
      "           fun: 6733.92919921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 86\n",
      "           nit: 36\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.02918399, 0.02478844])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.951171875, params: [tensor(0.2509), tensor(0.0128)]\n",
      "epoch 37\n",
      " final_simplex: (array([[0.25243403, 0.01207195],\n",
      "       [0.25243514, 0.01207194],\n",
      "       [0.25243224, 0.01207197]]), array([6733.60693359, 6733.60693359, 6733.60693359]))\n",
      "           fun: 6733.60693359375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 79\n",
      "           nit: 31\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.25243403, 0.01207195])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.6875, params: [tensor(0.1458), tensor(0.0168)]\n",
      "epoch 38\n",
      " final_simplex: (array([[0.15696111, 0.01351836],\n",
      "       [0.15696111, 0.01351836],\n",
      "       [0.15696109, 0.01351836]]), array([6733.62207031, 6733.62207031, 6733.62207031]))\n",
      "           fun: 6733.6220703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 94\n",
      "           nit: 36\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.15696111, 0.01351836])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.779296875, params: [tensor(0.0624), tensor(0.0195)]\n",
      "epoch 39\n",
      " final_simplex: (array([[0.06554248, 0.01851491],\n",
      "       [0.06554287, 0.01851485],\n",
      "       [0.06554273, 0.01851481]]), array([6733.70019531, 6733.70019531, 6733.70019531]))\n",
      "           fun: 6733.7001953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 69\n",
      "           nit: 30\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.06554248, 0.01851491])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.7509765625, params: [tensor(0.0588), tensor(0.0115)]\n",
      "epoch 40\n",
      " final_simplex: (array([[0.06465729, 0.01810825],\n",
      "       [0.06465738, 0.01810822],\n",
      "       [0.06465722, 0.01810825]]), array([6733.68701172, 6733.68701172, 6733.68701172]))\n",
      "           fun: 6733.68701171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 89\n",
      "           nit: 36\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.06465729, 0.01810825])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6736.7529296875, params: [tensor(0.0066), tensor(0.0099)]\n",
      "epoch 41\n",
      " final_simplex: (array([[0.07795104, 0.01639227],\n",
      "       [0.07795092, 0.01639228],\n",
      "       [0.07795092, 0.01639228]]), array([6733.67529297, 6733.67529297, 6733.67529297]))\n",
      "           fun: 6733.67529296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 136\n",
      "           nit: 62\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.07795104, 0.01639227])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6741.40380859375, params: [tensor(0.1428), tensor(0.0077)]\n",
      "epoch 42\n",
      " final_simplex: (array([[0.13481518, 0.01386824],\n",
      "       [0.13481522, 0.01386825],\n",
      "       [0.13481441, 0.01386827]]), array([6733.63232422, 6733.63232422, 6733.63232422]))\n",
      "           fun: 6733.63232421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 104\n",
      "           nit: 44\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.13481518, 0.01386824])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.267578125, params: [tensor(0.2206), tensor(0.0136)]\n",
      "epoch 43\n",
      " final_simplex: (array([[0.23098525, 0.01229074],\n",
      "       [0.23098519, 0.01229074],\n",
      "       [0.23098525, 0.01229074]]), array([6733.61083984, 6733.61083984, 6733.61083984]))\n",
      "           fun: 6733.61083984375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 92\n",
      "           nit: 38\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.23098525, 0.01229074])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.08935546875, params: [tensor(0.0248), tensor(0.0254)]\n",
      "epoch 44\n",
      " final_simplex: (array([[0.02700996, 0.02698833],\n",
      "       [0.02701201, 0.02698692],\n",
      "       [0.02701035, 0.02698789]]), array([6733.97216797, 6733.97216797, 6733.97216797]))\n",
      "           fun: 6733.97216796875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 55\n",
      "           nit: 23\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.02700996, 0.02698833])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6736.0947265625, params: [tensor(0.0076), tensor(0.0180)]\n",
      "epoch 45\n",
      " final_simplex: (array([[0.06752234, 0.01793058],\n",
      "       [0.06752712, 0.01792993],\n",
      "       [0.06752193, 0.0179306 ]]), array([6733.67529297, 6733.67529297, 6733.67529297]))\n",
      "           fun: 6733.67529296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 118\n",
      "           nit: 55\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.06752234, 0.01793058])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.6376953125, params: [tensor(0.1836), tensor(0.0129)]\n",
      "epoch 46\n",
      " final_simplex: (array([[0.18940186, 0.01273159],\n",
      "       [0.18940183, 0.01273159],\n",
      "       [0.18940185, 0.01273159]]), array([6733.61181641, 6733.61181641, 6733.61181641]))\n",
      "           fun: 6733.61181640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 105\n",
      "           nit: 43\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.18940186, 0.01273159])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6749.38525390625, params: [tensor(0.0335), tensor(0.0537)]\n",
      "epoch 47\n",
      " final_simplex: (array([[0.03716843, 0.02339109],\n",
      "       [0.03716396, 0.02339275],\n",
      "       [0.03716543, 0.02339196]]), array([6733.82519531, 6733.82519531, 6733.82519531]))\n",
      "           fun: 6733.8251953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 70\n",
      "           nit: 30\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.03716843, 0.02339109])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.208984375, params: [tensor(0.4830), tensor(0.0119)]\n",
      "epoch 48\n",
      " final_simplex: (array([[0.50699032, 0.01100925],\n",
      "       [0.50698941, 0.01100926],\n",
      "       [0.50699016, 0.01100925]]), array([6733.61230469, 6733.61230469, 6733.61230469]))\n",
      "           fun: 6733.6123046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 81\n",
      "           nit: 35\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.50699032, 0.01100925])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.68310546875, params: [tensor(0.1110), tensor(0.0144)]\n",
      "epoch 49\n",
      " final_simplex: (array([[0.11608489, 0.01455993],\n",
      "       [0.11608489, 0.01455993],\n",
      "       [0.11608494, 0.01455993]]), array([6733.63525391, 6733.63525391, 6733.63525391]))\n",
      "           fun: 6733.63525390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 83\n",
      "           nit: 31\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.11608489, 0.01455993])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6736.7802734375, params: [tensor(0.2967), tensor(0.0099)]\n",
      "epoch 50\n",
      " final_simplex: (array([[0.28985087, 0.01180499],\n",
      "       [0.28985061, 0.01180499],\n",
      "       [0.28985072, 0.01180498]]), array([6733.60449219, 6733.60449219, 6733.60449219]))\n",
      "           fun: 6733.6044921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 93\n",
      "           nit: 41\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.28985087, 0.01180499])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.861328125, params: [tensor(0.1169), tensor(0.0116)]\n",
      "epoch 51\n",
      " final_simplex: (array([[0.12710857, 0.01410742],\n",
      "       [0.12710911, 0.01410742],\n",
      "       [0.12710859, 0.01410743]]), array([6733.62890625, 6733.62890625, 6733.62890625]))\n",
      "           fun: 6733.62890625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 79\n",
      "           nit: 31\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.12710857, 0.01410742])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6743.5751953125, params: [tensor(0.0158), tensor(0.0710)]\n",
      "epoch 52\n",
      " final_simplex: (array([[0.06095692, 0.01835929],\n",
      "       [0.06095418, 0.01835964],\n",
      "       [0.06095381, 0.01835975]]), array([6733.69580078, 6733.69580078, 6733.69580078]))\n",
      "           fun: 6733.69580078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 120\n",
      "           nit: 56\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.06095692, 0.01835929])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6744.47265625, params: [tensor(0.0935), tensor(0.0050)]\n",
      "epoch 53\n",
      " final_simplex: (array([[0.00214883, 0.0093358 ],\n",
      "       [0.00214883, 0.0093358 ],\n",
      "       [0.00214883, 0.0093358 ]]), array([6736.73242188, 6736.73242188, 6736.73242188]))\n",
      "           fun: 6736.732421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 118\n",
      "           nit: 48\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.00214883, 0.0093358 ])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6763.18798828125, params: [tensor(0.4239), tensor(0.0073)]\n",
      "epoch 54\n",
      " final_simplex: (array([[0.25721129, 0.01203866],\n",
      "       [0.25721079, 0.01203867],\n",
      "       [0.25721081, 0.01203867]]), array([6733.60595703, 6733.60595703, 6733.60595703]))\n",
      "           fun: 6733.60595703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 102\n",
      "           nit: 43\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.25721129, 0.01203866])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6754.38671875, params: [tensor(0.0390), tensor(0.0531)]\n",
      "epoch 55\n",
      " final_simplex: (array([[0.04369764, 0.02098616],\n",
      "       [0.04369908, 0.02098571],\n",
      "       [0.04369851, 0.02098594]]), array([6733.78466797, 6733.78466797, 6733.78466797]))\n",
      "           fun: 6733.78466796875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 83\n",
      "           nit: 35\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.04369764, 0.02098616])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6737.94189453125, params: [tensor(0.0767), tensor(0.0250)]\n",
      "epoch 56\n",
      " final_simplex: (array([[0.0823862 , 0.01669305],\n",
      "       [0.08238302, 0.01669328],\n",
      "       [0.08238688, 0.01669296]]), array([6733.65869141, 6733.65869141, 6733.65869141]))\n",
      "           fun: 6733.65869140625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 73\n",
      "           nit: 30\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.0823862 , 0.01669305])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6824.744140625, params: [tensor(0.1878), tensor(0.0305)]\n",
      "epoch 57\n",
      " final_simplex: (array([[0.21134326, 0.01252283],\n",
      "       [0.21134276, 0.01252283],\n",
      "       [0.21134391, 0.01252282]]), array([6733.60888672, 6733.60888672, 6733.60888672]))\n",
      "           fun: 6733.60888671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 99\n",
      "           nit: 40\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.21134326, 0.01252283])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6739.7255859375, params: [tensor(0.0235), tensor(0.0008)]\n",
      "epoch 58\n",
      " final_simplex: (array([[0.00014222, 0.0014577 ],\n",
      "       [0.00014222, 0.00145778],\n",
      "       [0.00014223, 0.00145774]]), array([6736.73095703, 6736.73095703, 6736.73095703]))\n",
      "           fun: 6736.73095703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 86\n",
      "           nit: 35\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.00014222, 0.0014577 ])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6736.6357421875, params: [tensor(0.0018), tensor(0.0149)]\n",
      "epoch 59\n",
      " final_simplex: (array([[0.00177883, 0.01605886],\n",
      "       [0.00177946, 0.01605604],\n",
      "       [0.00177878, 0.01605747]]), array([6736.61279297, 6736.61279297, 6736.61279297]))\n",
      "           fun: 6736.61279296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 41\n",
      "           nit: 17\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.00177883, 0.01605886])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6739.951171875, params: [tensor(0.0002), tensor(0.4303)]\n",
      "epoch 60\n",
      " final_simplex: (array([[0.00032857, 0.09074487],\n",
      "       [0.00032857, 0.09074388],\n",
      "       [0.00032856, 0.0907453 ]]), array([6736.53808594, 6736.53808594, 6736.53808594]))\n",
      "           fun: 6736.5380859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 96\n",
      "           nit: 40\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.00032857, 0.09074487])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.1064453125, params: [tensor(0.0520), tensor(0.0231)]\n",
      "epoch 61\n",
      " final_simplex: (array([[0.05815412, 0.018815  ],\n",
      "       [0.0581524 , 0.01881532],\n",
      "       [0.05815334, 0.01881512]]), array([6733.70898438, 6733.70898438, 6733.70898438]))\n",
      "           fun: 6733.708984375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 72\n",
      "           nit: 30\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.05815412, 0.018815  ])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.17041015625, params: [tensor(0.0638), tensor(0.0124)]\n",
      "epoch 62\n",
      " final_simplex: (array([[0.0700676 , 0.01742795],\n",
      "       [0.07006102, 0.01742872],\n",
      "       [0.0700639 , 0.01742835]]), array([6733.68017578, 6733.68017578, 6733.68017578]))\n",
      "           fun: 6733.68017578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 69\n",
      "           nit: 29\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.0700676 , 0.01742795])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.3251953125, params: [tensor(0.0293), tensor(0.0148)]\n",
      "epoch 63\n",
      " final_simplex: (array([[0.08881917, 0.01591764],\n",
      "       [0.08881917, 0.01591764],\n",
      "       [0.08881917, 0.01591764]]), array([6733.64990234, 6733.64990234, 6733.64990234]))\n",
      "           fun: 6733.64990234375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 143\n",
      "           nit: 59\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.08881917, 0.01591764])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.54248046875, params: [tensor(0.0320), tensor(0.0308)]\n",
      "epoch 64\n",
      " final_simplex: (array([[0.05621662, 0.01906619],\n",
      "       [0.05621662, 0.01906619],\n",
      "       [0.05621662, 0.01906619]]), array([6733.71337891, 6733.71337891, 6733.71337891]))\n",
      "           fun: 6733.71337890625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 131\n",
      "           nit: 54\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.05621662, 0.01906619])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.6748046875, params: [tensor(0.1215), tensor(0.0142)]\n",
      "epoch 65\n",
      " final_simplex: (array([[0.12615719, 0.01435091],\n",
      "       [0.1261572 , 0.0143509 ],\n",
      "       [0.12615731, 0.0143509 ]]), array([6733.63037109, 6733.63037109, 6733.63037109]))\n",
      "           fun: 6733.63037109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 78\n",
      "           nit: 31\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.12615719, 0.01435091])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.56689453125, params: [tensor(0.0452), tensor(0.0124)]\n",
      "epoch 66\n",
      " final_simplex: (array([[0.05204627, 0.01995155],\n",
      "       [0.05204626, 0.01995157],\n",
      "       [0.05204633, 0.01995155]]), array([6733.734375, 6733.734375, 6733.734375]))\n",
      "           fun: 6733.734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 94\n",
      "           nit: 38\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.05204627, 0.01995155])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.7041015625, params: [tensor(0.1174), tensor(0.0140)]\n",
      "epoch 67\n",
      " final_simplex: (array([[0.11678249, 0.01456999],\n",
      "       [0.11678164, 0.01457002],\n",
      "       [0.11678226, 0.01457001]]), array([6733.63574219, 6733.63574219, 6733.63574219]))\n",
      "           fun: 6733.6357421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 70\n",
      "           nit: 28\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.11678249, 0.01456999])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.98828125, params: [tensor(0.0921), tensor(0.0119)]\n",
      "epoch 68\n",
      " final_simplex: (array([[0.10065818, 0.01525571],\n",
      "       [0.10065832, 0.01525571],\n",
      "       [0.10065802, 0.01525573]]), array([6733.64111328, 6733.64111328, 6733.64111328]))\n",
      "           fun: 6733.64111328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 83\n",
      "           nit: 34\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.10065818, 0.01525571])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.740234375, params: [tensor(0.0591), tensor(0.0192)]\n",
      "epoch 69\n",
      " final_simplex: (array([[0.06020044, 0.0184957 ],\n",
      "       [0.06020045, 0.01849569],\n",
      "       [0.06020041, 0.01849569]]), array([6733.70507812, 6733.70507812, 6733.70507812]))\n",
      "           fun: 6733.705078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 83\n",
      "           nit: 33\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.06020044, 0.0184957 ])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.85546875, params: [tensor(0.0379), tensor(0.0237)]\n",
      "epoch 70\n",
      " final_simplex: (array([[0.04556966, 0.02118901],\n",
      "       [0.04557045, 0.02118895],\n",
      "       [0.04556994, 0.02118895]]), array([6733.75830078, 6733.75830078, 6733.75830078]))\n",
      "           fun: 6733.75830078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 72\n",
      "           nit: 33\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.04556966, 0.02118901])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.54345703125, params: [tensor(0.0168), tensor(0.0389)]\n",
      "epoch 71\n",
      " final_simplex: (array([[0.06269675, 0.01805308],\n",
      "       [0.06270778, 0.01805158],\n",
      "       [0.06270247, 0.01805234]]), array([6733.69921875, 6733.69921875, 6733.69921875]))\n",
      "           fun: 6733.69921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 89\n",
      "           nit: 40\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.06269675, 0.01805308])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.34912109375, params: [tensor(0.3352), tensor(0.0128)]\n",
      "epoch 72\n",
      " final_simplex: (array([[0.34910834, 0.01152204],\n",
      "       [0.34910836, 0.01152204],\n",
      "       [0.34910836, 0.01152204]]), array([6733.60839844, 6733.60839844, 6733.60839844]))\n",
      "           fun: 6733.6083984375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 106\n",
      "           nit: 38\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.34910834, 0.01152204])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6737.24267578125, params: [tensor(0.0390), tensor(0.0350)]\n",
      "epoch 73\n",
      " final_simplex: (array([[0.04577683, 0.02088416],\n",
      "       [0.04577919, 0.02088351],\n",
      "       [0.04577504, 0.0208846 ]]), array([6733.75244141, 6733.75244141, 6733.75244141]))\n",
      "           fun: 6733.75244140625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 77\n",
      "           nit: 35\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.04577683, 0.02088416])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.8994140625, params: [tensor(0.2935), tensor(0.0112)]\n",
      "epoch 74\n",
      " final_simplex: (array([[0.30304322, 0.01176306],\n",
      "       [0.30304321, 0.01176306],\n",
      "       [0.30304321, 0.01176306]]), array([6733.60595703, 6733.60595703, 6733.60595703]))\n",
      "           fun: 6733.60595703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 104\n",
      "           nit: 39\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.30304322, 0.01176306])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6737.890625, params: [tensor(0.0016), tensor(0.1315)]\n",
      "epoch 75\n",
      " final_simplex: (array([[0.06799519, 0.01761009],\n",
      "       [0.06799493, 0.01761007],\n",
      "       [0.0679962 , 0.01760989]]), array([6733.68261719, 6733.68261719, 6733.68261719]))\n",
      "           fun: 6733.6826171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 146\n",
      "           nit: 68\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.06799519, 0.01761009])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.67822265625, params: [tensor(0.4992), tensor(0.0111)]\n",
      "epoch 76\n",
      " final_simplex: (array([[0.49816105, 0.01099635],\n",
      "       [0.49816482, 0.01099634],\n",
      "       [0.49816347, 0.01099634]]), array([6733.59960938, 6733.59960938, 6733.59960938]))\n",
      "           fun: 6733.599609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 69\n",
      "           nit: 29\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.49816105, 0.01099635])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.2060546875, params: [tensor(0.0219), tensor(0.0256)]\n",
      "epoch 77\n",
      " final_simplex: (array([[0.07429387, 0.01705408],\n",
      "       [0.07429409, 0.01705404],\n",
      "       [0.07429411, 0.01705402]]), array([6733.66845703, 6733.66845703, 6733.66845703]))\n",
      "           fun: 6733.66845703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 109\n",
      "           nit: 51\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.07429387, 0.01705408])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.7216796875, params: [tensor(0.4430), tensor(0.0109)]\n",
      "epoch 78\n",
      " final_simplex: (array([[0.43025113, 0.01124112],\n",
      "       [0.43025251, 0.01124112],\n",
      "       [0.43025377, 0.01124111]]), array([6733.60253906, 6733.60253906, 6733.60253906]))\n",
      "           fun: 6733.6025390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 78\n",
      "           nit: 36\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.43025113, 0.01124112])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.744140625, params: [tensor(0.1046), tensor(0.0142)]\n",
      "epoch 79\n",
      " final_simplex: (array([[0.10455436, 0.01493532],\n",
      "       [0.10455418, 0.01493532],\n",
      "       [0.10455402, 0.01493531]]), array([6733.64453125, 6733.64453125, 6733.64453125]))\n",
      "           fun: 6733.64453125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 69\n",
      "           nit: 29\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.10455436, 0.01493532])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6758.70703125, params: [tensor(0.3001), tensor(0.0067)]\n",
      "epoch 80\n",
      " final_simplex: (array([[0.16793824, 0.01316989],\n",
      "       [0.16796297, 0.01316943],\n",
      "       [0.16795447, 0.01316959]]), array([6733.6171875, 6733.6171875, 6733.6171875]))\n",
      "           fun: 6733.6171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 98\n",
      "           nit: 45\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.16793824, 0.01316989])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.3349609375, params: [tensor(0.0049), tensor(0.0564)]\n",
      "epoch 81\n",
      " final_simplex: (array([[0.08781843, 0.01618835],\n",
      "       [0.08781437, 0.01618863],\n",
      "       [0.08781393, 0.01618874]]), array([6733.6484375, 6733.6484375, 6733.6484375]))\n",
      "           fun: 6733.6484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 124\n",
      "           nit: 58\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.08781843, 0.01618835])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6762.39892578125, params: [tensor(0.2419), tensor(0.0196)]\n",
      "epoch 82\n",
      " final_simplex: (array([[0.26378501, 0.01209354],\n",
      "       [0.26378491, 0.01209355],\n",
      "       [0.26378447, 0.01209355]]), array([6733.61279297, 6733.61279297, 6733.61279297]))\n",
      "           fun: 6733.61279296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 91\n",
      "           nit: 38\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.26378501, 0.01209354])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6736.12060546875, params: [tensor(0.0095), tensor(0.0610)]\n",
      "epoch 83\n",
      " final_simplex: (array([[0.07622576, 0.01686696],\n",
      "       [0.07626961, 0.01686282],\n",
      "       [0.07624774, 0.01686489]]), array([6733.6640625, 6733.6640625, 6733.6640625]))\n",
      "           fun: 6733.6640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 117\n",
      "           nit: 60\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.07622576, 0.01686696])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.63427734375, params: [tensor(0.1518), tensor(0.0134)]\n",
      "epoch 84\n",
      " final_simplex: (array([[0.1533786 , 0.01342837],\n",
      "       [0.15337858, 0.01342837],\n",
      "       [0.15337866, 0.01342837]]), array([6733.61914062, 6733.61914062, 6733.61914062]))\n",
      "           fun: 6733.619140625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 87\n",
      "           nit: 38\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.1533786 , 0.01342837])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6811.208984375, params: [tensor(0.1578), tensor(0.0325)]\n",
      "epoch 85\n",
      " final_simplex: (array([[0.16687052, 0.01323144],\n",
      "       [0.16686975, 0.01323145],\n",
      "       [0.1668699 , 0.01323146]]), array([6733.61816406, 6733.61816406, 6733.61816406]))\n",
      "           fun: 6733.6181640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 89\n",
      "           nit: 36\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.16687052, 0.01323144])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6738.396484375, params: [tensor(0.0514), tensor(0.0074)]\n",
      "epoch 86\n",
      " final_simplex: (array([[0.12078406, 0.01450461],\n",
      "       [0.12077486, 0.01450497],\n",
      "       [0.1207664 , 0.01450521]]), array([6733.63525391, 6733.63525391, 6733.63525391]))\n",
      "           fun: 6733.63525390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 92\n",
      "           nit: 45\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.12078406, 0.01450461])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.59912109375, params: [tensor(0.1670), tensor(0.0159)]\n",
      "epoch 87\n",
      " final_simplex: (array([[0.16883542, 0.01321852],\n",
      "       [0.16883539, 0.01321852],\n",
      "       [0.16883529, 0.01321853]]), array([6733.62353516, 6733.62353516, 6733.62353516]))\n",
      "           fun: 6733.62353515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 95\n",
      "           nit: 37\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.16883542, 0.01321852])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6735.07177734375, params: [tensor(0.0062), tensor(0.0453)]\n",
      "epoch 88\n",
      " final_simplex: (array([[0.1370423 , 0.01384199],\n",
      "       [0.13704231, 0.01384199],\n",
      "       [0.1370423 , 0.01384199]]), array([6733.62109375, 6733.62109375, 6733.62109375]))\n",
      "           fun: 6733.62109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 158\n",
      "           nit: 68\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.1370423 , 0.01384199])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6736.2939453125, params: [tensor(0.0384), tensor(0.0110)]\n",
      "epoch 89\n",
      " final_simplex: (array([[0.04746419, 0.02047855],\n",
      "       [0.04746418, 0.02047854],\n",
      "       [0.04746421, 0.02047854]]), array([6733.75390625, 6733.75390625, 6733.75390625]))\n",
      "           fun: 6733.75390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 89\n",
      "           nit: 34\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.04746419, 0.02047855])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.7734375, params: [tensor(0.1675), tensor(0.0139)]\n",
      "epoch 90\n",
      " final_simplex: (array([[0.1725157 , 0.0130225 ],\n",
      "       [0.17251496, 0.0130225 ],\n",
      "       [0.1725146 , 0.01302251]]), array([6733.61328125, 6733.61328125, 6733.61328125]))\n",
      "           fun: 6733.61328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 71\n",
      "           nit: 27\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.1725157, 0.0130225])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6748.53662109375, params: [tensor(0.1394), tensor(0.0228)]\n",
      "epoch 91\n",
      " final_simplex: (array([[0.15572127, 0.01358435],\n",
      "       [0.15571518, 0.01358457],\n",
      "       [0.15572111, 0.01358439]]), array([6733.625, 6733.625, 6733.625]))\n",
      "           fun: 6733.625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 72\n",
      "           nit: 31\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.15572127, 0.01358435])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.064453125, params: [tensor(0.0370), tensor(0.0265)]\n",
      "epoch 92\n",
      " final_simplex: (array([[0.03928108, 0.02246818],\n",
      "       [0.03928103, 0.02246822],\n",
      "       [0.03928113, 0.02246818]]), array([6733.8046875, 6733.8046875, 6733.8046875]))\n",
      "           fun: 6733.8046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 78\n",
      "           nit: 34\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.03928108, 0.02246818])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6734.798828125, params: [tensor(0.3808), tensor(0.0105)]\n",
      "epoch 93\n",
      " final_simplex: (array([[0.41099706, 0.01126635],\n",
      "       [0.41099555, 0.01126636],\n",
      "       [0.41099641, 0.01126636]]), array([6733.60351562, 6733.60351562, 6733.60351562]))\n",
      "           fun: 6733.603515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 75\n",
      "           nit: 29\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.41099706, 0.01126635])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.67333984375, params: [tensor(0.1320), tensor(0.0138)]\n",
      "epoch 94\n",
      " final_simplex: (array([[0.13432642, 0.01422577],\n",
      "       [0.13432672, 0.01422576],\n",
      "       [0.13432655, 0.01422576]]), array([6733.63574219, 6733.63574219, 6733.63574219]))\n",
      "           fun: 6733.6357421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 82\n",
      "           nit: 33\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.13432642, 0.01422577])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6736.03662109375, params: [tensor(0.0138), tensor(0.0526)]\n",
      "epoch 95\n",
      " final_simplex: (array([[0.01591099, 0.0329412 ],\n",
      "       [0.01590896, 0.03294352],\n",
      "       [0.01591727, 0.03293061]]), array([6734.29492188, 6734.29492188, 6734.29492188]))\n",
      "           fun: 6734.294921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 58\n",
      "           nit: 24\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.01591099, 0.0329412 ])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.8564453125, params: [tensor(0.1716), tensor(0.0123)]\n",
      "epoch 96\n",
      " final_simplex: (array([[0.17472795, 0.01315906],\n",
      "       [0.17472793, 0.01315906],\n",
      "       [0.17472793, 0.01315906]]), array([6733.61816406, 6733.61816406, 6733.61816406]))\n",
      "           fun: 6733.6181640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 106\n",
      "           nit: 42\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.17472795, 0.01315906])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6748.97900390625, params: [tensor(0.0913), tensor(0.0028)]\n",
      "epoch 97\n",
      " final_simplex: (array([[0.00022787, 0.00510055],\n",
      "       [0.00022926, 0.00510284],\n",
      "       [0.00022907, 0.00510165]]), array([6736.73242188, 6736.73242188, 6736.73242188]))\n",
      "           fun: 6736.732421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 77\n",
      "           nit: 33\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.00022787, 0.00510055])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6822.08935546875, params: [tensor(0.4913), tensor(0.0178)]\n",
      "epoch 98\n",
      " final_simplex: (array([[0.53202911, 0.01095179],\n",
      "       [0.53202621, 0.0109518 ],\n",
      "       [0.53202859, 0.0109518 ]]), array([6733.59472656, 6733.59472656, 6733.59472656]))\n",
      "           fun: 6733.5947265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 83\n",
      "           nit: 37\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.53202911, 0.01095179])\n",
      "minPrevious 6733.71728515625\n",
      "best ll: 6733.85888671875, params: [tensor(0.1621), tensor(0.0124)]\n",
      "epoch 99\n",
      " final_simplex: (array([[0.16510773, 0.01325775],\n",
      "       [0.16510636, 0.01325777],\n",
      "       [0.16510687, 0.01325777]]), array([6733.61621094, 6733.61621094, 6733.61621094]))\n",
      "           fun: 6733.6162109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 75\n",
      "           nit: 29\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.16510773, 0.01325775])\n",
      "minPrevious 6733.71728515625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lls': [6733.71728515625], 'params': [array([0.05863696, 0.01835999])]}"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitFnUniveriate(altCountsByGeneRR2, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 6786.0146484375, bestParams: [tensor(0.0058), tensor(8054.6973), tensor(22802.3750)]\n",
      "epoch 100\n",
      " final_simplex: (array([[4.99989276e-03, 2.41928302e+03, 3.56125064e+04],\n",
      "       [4.99989276e-03, 2.41928301e+03, 3.56125065e+04],\n",
      "       [4.99989276e-03, 2.41928301e+03, 3.56125065e+04],\n",
      "       [4.99989276e-03, 2.41928302e+03, 3.56125064e+04]]), array([6730.54541016, 6730.54541016, 6730.54541016, 6730.54541016]))\n",
      "           fun: 6730.54541015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 277\n",
      "           nit: 94\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.99989276e-03, 2.41928302e+03, 3.56125064e+04])\n",
      "best ll: 6853.6474609375, bestParams: [tensor(0.0060), tensor(20563.2168), tensor(6649.9810)]\n",
      "epoch 99\n",
      " final_simplex: (array([[2.60900984e-08, 2.80175248e+04, 1.02113960e+04],\n",
      "       [2.60899939e-08, 2.80175248e+04, 1.02113960e+04],\n",
      "       [2.60898817e-08, 2.80175247e+04, 1.02113960e+04],\n",
      "       [2.60901336e-08, 2.80175248e+04, 1.02113960e+04]]), array([6736.75634766, 6736.75634766, 6736.75634766, 6736.75634766]))\n",
      "           fun: 6736.75634765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 293\n",
      "           nit: 95\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.60900984e-08, 2.80175248e+04, 1.02113960e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[2.60900984e-08, 2.80175248e+04, 1.02113960e+04],\n",
      "       [2.60899939e-08, 2.80175248e+04, 1.02113960e+04],\n",
      "       [2.60898817e-08, 2.80175247e+04, 1.02113960e+04],\n",
      "       [2.60901336e-08, 2.80175248e+04, 1.02113960e+04]]), array([6736.75634766, 6736.75634766, 6736.75634766, 6736.75634766]))\n",
      "           fun: 6736.75634765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 293\n",
      "           nit: 95\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.60900984e-08, 2.80175248e+04, 1.02113960e+04])\n",
      "best ll: 6835.81201171875, bestParams: [tensor(0.0051), tensor(19940.2969), tensor(6030.9976)]\n",
      "epoch 99\n",
      " final_simplex: (array([[2.59447815e-07, 2.72241105e+04, 9.27431095e+03],\n",
      "       [2.59447690e-07, 2.72241106e+04, 9.27431097e+03],\n",
      "       [2.59447677e-07, 2.72241105e+04, 9.27431095e+03],\n",
      "       [2.59447538e-07, 2.72241106e+04, 9.27431096e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 287\n",
      "           nit: 92\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.59447815e-07, 2.72241105e+04, 9.27431095e+03])\n",
      "Failed to converge\n",
      " final_simplex: (array([[2.59447815e-07, 2.72241105e+04, 9.27431095e+03],\n",
      "       [2.59447690e-07, 2.72241106e+04, 9.27431097e+03],\n",
      "       [2.59447677e-07, 2.72241105e+04, 9.27431095e+03],\n",
      "       [2.59447538e-07, 2.72241106e+04, 9.27431096e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 287\n",
      "           nit: 92\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.59447815e-07, 2.72241105e+04, 9.27431095e+03])\n",
      "best ll: 6818.94677734375, bestParams: [tensor(0.0275), tensor(2251.1292), tensor(17373.7754)]\n",
      "epoch 99\n",
      " final_simplex: (array([[2.88330920e-02, 7.43513914e+02, 2.23945308e+04],\n",
      "       [2.88330919e-02, 7.43513907e+02, 2.23945309e+04],\n",
      "       [2.88330920e-02, 7.43513916e+02, 2.23945309e+04],\n",
      "       [2.88330918e-02, 7.43513906e+02, 2.23945308e+04]]), array([6725.23242188, 6725.23242188, 6725.23242188, 6725.23242188]))\n",
      "           fun: 6725.232421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 247\n",
      "           nit: 88\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.88330920e-02, 7.43513914e+02, 2.23945308e+04])\n",
      "minPrevious 6730.54541015625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[2.88330920e-02, 7.43513914e+02, 2.23945308e+04],\n",
      "       [2.88330919e-02, 7.43513907e+02, 2.23945309e+04],\n",
      "       [2.88330920e-02, 7.43513916e+02, 2.23945309e+04],\n",
      "       [2.88330918e-02, 7.43513906e+02, 2.23945308e+04]]), array([6725.23242188, 6725.23242188, 6725.23242188, 6725.23242188]))\n",
      "           fun: 6725.232421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 247\n",
      "           nit: 88\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.88330920e-02, 7.43513914e+02, 2.23945308e+04])\n",
      "best ll: 6733.33935546875, bestParams: [tensor(0.0100), tensor(834.3706), tensor(21413.1230)]\n",
      "epoch 98\n",
      " final_simplex: (array([[1.05171599e-02, 8.24171974e+02, 2.07718212e+04],\n",
      "       [1.05171599e-02, 8.24171964e+02, 2.07718211e+04],\n",
      "       [1.05171599e-02, 8.24171974e+02, 2.07718211e+04],\n",
      "       [1.05171599e-02, 8.24171970e+02, 2.07718211e+04]]), array([6731.38964844, 6731.38964844, 6731.38964844, 6731.38964844]))\n",
      "           fun: 6731.3896484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 230\n",
      "           nit: 78\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.05171599e-02, 8.24171974e+02, 2.07718212e+04])\n",
      "minPrevious 6725.232421875\n",
      "best ll: 6732.751953125, bestParams: [tensor(0.0299), tensor(346.0344), tensor(20011.9219)]\n",
      "epoch 97\n",
      " final_simplex: (array([[3.07817293e-02, 3.51364207e+02, 1.94933177e+04],\n",
      "       [3.07817293e-02, 3.51364207e+02, 1.94933177e+04],\n",
      "       [3.07817293e-02, 3.51364207e+02, 1.94933177e+04],\n",
      "       [3.07817293e-02, 3.51364207e+02, 1.94933178e+04]]), array([6726.44921875, 6726.44921875, 6726.44921875, 6726.44921875]))\n",
      "           fun: 6726.44921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 253\n",
      "           nit: 91\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.07817293e-02, 3.51364207e+02, 1.94933177e+04])\n",
      "minPrevious 6725.232421875\n",
      "best ll: 6746.3017578125, bestParams: [tensor(0.0886), tensor(586.5419), tensor(21604.9473)]\n",
      "epoch 96\n",
      " final_simplex: (array([[8.94077878e-02, 5.72665107e+02, 2.23863651e+04],\n",
      "       [8.94077877e-02, 5.72665106e+02, 2.23863651e+04],\n",
      "       [8.94077877e-02, 5.72665108e+02, 2.23863652e+04],\n",
      "       [8.94077881e-02, 5.72665106e+02, 2.23863651e+04]]), array([6713.66015625, 6713.66015625, 6713.66015625, 6713.66015625]))\n",
      "           fun: 6713.66015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 236\n",
      "           nit: 81\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.94077878e-02, 5.72665107e+02, 2.23863651e+04])\n",
      "minPrevious 6725.232421875\n",
      "better by at >= 1; new ll:  final_simplex: (array([[8.94077878e-02, 5.72665107e+02, 2.23863651e+04],\n",
      "       [8.94077877e-02, 5.72665106e+02, 2.23863651e+04],\n",
      "       [8.94077877e-02, 5.72665108e+02, 2.23863652e+04],\n",
      "       [8.94077881e-02, 5.72665106e+02, 2.23863651e+04]]), array([6713.66015625, 6713.66015625, 6713.66015625, 6713.66015625]))\n",
      "           fun: 6713.66015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 236\n",
      "           nit: 81\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.94077878e-02, 5.72665107e+02, 2.23863651e+04])\n",
      "best ll: 6783.037109375, bestParams: [tensor(0.0025), tensor(11103.7363), tensor(7183.8408)]\n",
      "epoch 95\n",
      " final_simplex: (array([[6.76631940e-07, 1.48742074e+04, 1.12280456e+04],\n",
      "       [6.76631810e-07, 1.48742074e+04, 1.12280457e+04],\n",
      "       [6.76631650e-07, 1.48742074e+04, 1.12280456e+04],\n",
      "       [6.76631918e-07, 1.48742074e+04, 1.12280456e+04]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 282\n",
      "           nit: 88\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.76631940e-07, 1.48742074e+04, 1.12280456e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[6.76631940e-07, 1.48742074e+04, 1.12280456e+04],\n",
      "       [6.76631810e-07, 1.48742074e+04, 1.12280457e+04],\n",
      "       [6.76631650e-07, 1.48742074e+04, 1.12280456e+04],\n",
      "       [6.76631918e-07, 1.48742074e+04, 1.12280456e+04]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 282\n",
      "           nit: 88\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.76631940e-07, 1.48742074e+04, 1.12280456e+04])\n",
      "best ll: 6753.3427734375, bestParams: [tensor(0.1778), tensor(163.5590), tensor(18691.3496)]\n",
      "epoch 95\n",
      " final_simplex: (array([[1.76929293e-01, 1.66514334e+02, 1.94480228e+04],\n",
      "       [1.76929298e-01, 1.66514331e+02, 1.94480228e+04],\n",
      "       [1.76929284e-01, 1.66514319e+02, 1.94480229e+04],\n",
      "       [1.76929289e-01, 1.66514329e+02, 1.94480229e+04]]), array([6684.12597656, 6684.12597656, 6684.12597656, 6684.12597656]))\n",
      "           fun: 6684.1259765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 211\n",
      "           nit: 80\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.76929293e-01, 1.66514334e+02, 1.94480228e+04])\n",
      "minPrevious 6713.66015625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[1.76929293e-01, 1.66514334e+02, 1.94480228e+04],\n",
      "       [1.76929298e-01, 1.66514331e+02, 1.94480228e+04],\n",
      "       [1.76929284e-01, 1.66514319e+02, 1.94480229e+04],\n",
      "       [1.76929289e-01, 1.66514329e+02, 1.94480229e+04]]), array([6684.12597656, 6684.12597656, 6684.12597656, 6684.12597656]))\n",
      "           fun: 6684.1259765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 211\n",
      "           nit: 80\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.76929293e-01, 1.66514334e+02, 1.94480228e+04])\n",
      "best ll: 6757.6669921875, bestParams: [tensor(0.0011), tensor(23816.0703), tensor(5396.2568)]\n",
      "epoch 94\n",
      " final_simplex: (array([[4.51054940e-10, 3.25288531e+04, 8.30081122e+03],\n",
      "       [4.51175839e-10, 3.25288531e+04, 8.30081122e+03],\n",
      "       [4.51508074e-10, 3.25288532e+04, 8.30081124e+03],\n",
      "       [4.51526993e-10, 3.25288531e+04, 8.30081122e+03]]), array([6736.75634766, 6736.75634766, 6736.75634766, 6736.75634766]))\n",
      "           fun: 6736.75634765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 268\n",
      "           nit: 85\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.51054940e-10, 3.25288531e+04, 8.30081122e+03])\n",
      "Failed to converge\n",
      " final_simplex: (array([[4.51054940e-10, 3.25288531e+04, 8.30081122e+03],\n",
      "       [4.51175839e-10, 3.25288531e+04, 8.30081122e+03],\n",
      "       [4.51508074e-10, 3.25288532e+04, 8.30081124e+03],\n",
      "       [4.51526993e-10, 3.25288531e+04, 8.30081122e+03]]), array([6736.75634766, 6736.75634766, 6736.75634766, 6736.75634766]))\n",
      "           fun: 6736.75634765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 268\n",
      "           nit: 85\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.51054940e-10, 3.25288531e+04, 8.30081122e+03])\n",
      "best ll: 6743.63818359375, bestParams: [tensor(0.0535), tensor(598.2400), tensor(23325.3379)]\n",
      "epoch 94\n",
      " final_simplex: (array([[5.40362181e-02, 5.65004442e+02, 2.34116672e+04],\n",
      "       [5.40362185e-02, 5.65004442e+02, 2.34116672e+04],\n",
      "       [5.40362183e-02, 5.65004443e+02, 2.34116673e+04],\n",
      "       [5.40362183e-02, 5.65004442e+02, 2.34116673e+04]]), array([6714.53076172, 6714.53076172, 6714.53076172, 6714.53076172]))\n",
      "           fun: 6714.53076171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 231\n",
      "           nit: 80\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.40362181e-02, 5.65004442e+02, 2.34116672e+04])\n",
      "minPrevious 6684.1259765625\n",
      "best ll: 6749.5517578125, bestParams: [tensor(0.0035), tensor(4181.2051), tensor(19185.3418)]\n",
      "epoch 93\n",
      " final_simplex: (array([[3.31861167e-03, 1.00187481e+03, 3.03888976e+04],\n",
      "       [3.31861166e-03, 1.00187479e+03, 3.03888977e+04],\n",
      "       [3.31861166e-03, 1.00187481e+03, 3.03888977e+04],\n",
      "       [3.31861166e-03, 1.00187482e+03, 3.03888976e+04]]), array([6732.84863281, 6732.84863281, 6732.84863281, 6732.84863281]))\n",
      "           fun: 6732.8486328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 271\n",
      "           nit: 100\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.31861167e-03, 1.00187481e+03, 3.03888976e+04])\n",
      "minPrevious 6684.1259765625\n",
      "best ll: 7083.6005859375, bestParams: [tensor(0.2519), tensor(817.8965), tensor(19126.7930)]\n",
      "epoch 92\n",
      " final_simplex: (array([[2.80477590e-01, 4.90093134e+02, 2.64054178e+04],\n",
      "       [2.80477589e-01, 4.90093133e+02, 2.64054178e+04],\n",
      "       [2.80477590e-01, 4.90093131e+02, 2.64054179e+04],\n",
      "       [2.80477589e-01, 4.90093134e+02, 2.64054177e+04]]), array([6681.078125, 6681.078125, 6681.078125, 6681.078125]))\n",
      "           fun: 6681.078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 261\n",
      "           nit: 99\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.80477590e-01, 4.90093134e+02, 2.64054178e+04])\n",
      "minPrevious 6684.1259765625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[2.80477590e-01, 4.90093134e+02, 2.64054178e+04],\n",
      "       [2.80477589e-01, 4.90093133e+02, 2.64054178e+04],\n",
      "       [2.80477590e-01, 4.90093131e+02, 2.64054179e+04],\n",
      "       [2.80477589e-01, 4.90093134e+02, 2.64054177e+04]]), array([6681.078125, 6681.078125, 6681.078125, 6681.078125]))\n",
      "           fun: 6681.078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 261\n",
      "           nit: 99\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.80477590e-01, 4.90093134e+02, 2.64054178e+04])\n",
      "best ll: 6744.646484375, bestParams: [tensor(0.1117), tensor(415.9337), tensor(18622.5156)]\n",
      "epoch 91\n",
      " final_simplex: (array([[1.10797801e-01, 4.23293872e+02, 1.88290550e+04],\n",
      "       [1.10797801e-01, 4.23293875e+02, 1.88290551e+04],\n",
      "       [1.10797801e-01, 4.23293879e+02, 1.88290549e+04],\n",
      "       [1.10797802e-01, 4.23293879e+02, 1.88290549e+04]]), array([6711.27978516, 6711.27978516, 6711.27978516, 6711.27978516]))\n",
      "           fun: 6711.27978515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 214\n",
      "           nit: 69\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.10797801e-01, 4.23293872e+02, 1.88290550e+04])\n",
      "minPrevious 6681.078125\n",
      "best ll: 7067.16943359375, bestParams: [tensor(0.0185), tensor(21182.2227), tensor(19360.8594)]\n",
      "epoch 90\n",
      " final_simplex: (array([[2.41757784e-08, 2.83704681e+04, 3.03187554e+04],\n",
      "       [2.41755506e-08, 2.83704681e+04, 3.03187555e+04],\n",
      "       [2.41774030e-08, 2.83704681e+04, 3.03187553e+04],\n",
      "       [2.41754022e-08, 2.83704681e+04, 3.03187554e+04]]), array([6736.75585938, 6736.75585938, 6736.75585938, 6736.75585938]))\n",
      "           fun: 6736.755859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 287\n",
      "           nit: 101\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.41757784e-08, 2.83704681e+04, 3.03187554e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[2.41757784e-08, 2.83704681e+04, 3.03187554e+04],\n",
      "       [2.41755506e-08, 2.83704681e+04, 3.03187555e+04],\n",
      "       [2.41774030e-08, 2.83704681e+04, 3.03187553e+04],\n",
      "       [2.41754022e-08, 2.83704681e+04, 3.03187554e+04]]), array([6736.75585938, 6736.75585938, 6736.75585938, 6736.75585938]))\n",
      "           fun: 6736.755859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 287\n",
      "           nit: 101\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.41757784e-08, 2.83704681e+04, 3.03187554e+04])\n",
      "best ll: 7034.49169921875, bestParams: [tensor(0.4527), tensor(448.8152), tensor(17574.9922)]\n",
      "epoch 90\n",
      " final_simplex: (array([[4.45568530e-01, 4.56672544e+02, 1.80796536e+04],\n",
      "       [4.45568531e-01, 4.56672544e+02, 1.80796536e+04],\n",
      "       [4.45568531e-01, 4.56672544e+02, 1.80796536e+04],\n",
      "       [4.45568529e-01, 4.56672542e+02, 1.80796537e+04]]), array([6828.64355469, 6828.64355469, 6828.64355469, 6828.64355469]))\n",
      "           fun: 6828.6435546875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 245\n",
      "           nit: 87\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.45568530e-01, 4.56672544e+02, 1.80796536e+04])\n",
      "minPrevious 6681.078125\n",
      "best ll: 6736.0322265625, bestParams: [tensor(0.0011), tensor(2199.6987), tensor(23695.0879)]\n",
      "epoch 89\n",
      " final_simplex: (array([[1.17355457e-03, 2.18946614e+03, 2.37343399e+04],\n",
      "       [1.17355456e-03, 2.18946615e+03, 2.37343398e+04],\n",
      "       [1.17355457e-03, 2.18946614e+03, 2.37343398e+04],\n",
      "       [1.17355458e-03, 2.18946613e+03, 2.37343398e+04]]), array([6735.77636719, 6735.77636719, 6735.77636719, 6735.77636719]))\n",
      "           fun: 6735.7763671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 243\n",
      "           nit: 83\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.17355457e-03, 2.18946614e+03, 2.37343399e+04])\n",
      "minPrevious 6681.078125\n",
      "best ll: 6735.68359375, bestParams: [tensor(0.0089), tensor(570.6688), tensor(24608.8828)]\n",
      "epoch 88\n",
      " final_simplex: (array([[9.11327796e-03, 5.72456462e+02, 2.43385661e+04],\n",
      "       [9.11327797e-03, 5.72456461e+02, 2.43385660e+04],\n",
      "       [9.11327796e-03, 5.72456461e+02, 2.43385660e+04],\n",
      "       [9.11327796e-03, 5.72456462e+02, 2.43385661e+04]]), array([6733.15429688, 6733.15429688, 6733.15429688, 6733.15429688]))\n",
      "           fun: 6733.154296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 243\n",
      "           nit: 79\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.11327796e-03, 5.72456462e+02, 2.43385661e+04])\n",
      "minPrevious 6681.078125\n",
      "best ll: 6776.78955078125, bestParams: [tensor(0.2646), tensor(428.9750), tensor(19417.4844)]\n",
      "epoch 87\n",
      " final_simplex: (array([[2.59454750e-01, 4.20987613e+02, 2.06935771e+04],\n",
      "       [2.59454750e-01, 4.20987612e+02, 2.06935770e+04],\n",
      "       [2.59454749e-01, 4.20987614e+02, 2.06935771e+04],\n",
      "       [2.59454750e-01, 4.20987612e+02, 2.06935770e+04]]), array([6678.58447266, 6678.58447266, 6678.58447266, 6678.58447266]))\n",
      "           fun: 6678.58447265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 239\n",
      "           nit: 83\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.59454750e-01, 4.20987613e+02, 2.06935771e+04])\n",
      "minPrevious 6681.078125\n",
      "better by at >= 1; new ll:  final_simplex: (array([[2.59454750e-01, 4.20987613e+02, 2.06935771e+04],\n",
      "       [2.59454750e-01, 4.20987612e+02, 2.06935770e+04],\n",
      "       [2.59454749e-01, 4.20987614e+02, 2.06935771e+04],\n",
      "       [2.59454750e-01, 4.20987612e+02, 2.06935770e+04]]), array([6678.58447266, 6678.58447266, 6678.58447266, 6678.58447266]))\n",
      "           fun: 6678.58447265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 239\n",
      "           nit: 83\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.59454750e-01, 4.20987613e+02, 2.06935771e+04])\n",
      "best ll: 6742.58642578125, bestParams: [tensor(0.0010), tensor(5788.4258), tensor(17466.8457)]\n",
      "epoch 86\n",
      " final_simplex: (array([[8.80181300e-04, 1.97847827e+03, 2.71769485e+04],\n",
      "       [8.80181304e-04, 1.97847824e+03, 2.71769485e+04],\n",
      "       [8.80181302e-04, 1.97847825e+03, 2.71769485e+04],\n",
      "       [8.80181303e-04, 1.97847827e+03, 2.71769484e+04]]), array([6735.52734375, 6735.52734375, 6735.52734375, 6735.52734375]))\n",
      "           fun: 6735.52734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 285\n",
      "           nit: 109\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.80181300e-04, 1.97847827e+03, 2.71769485e+04])\n",
      "minPrevious 6678.58447265625\n",
      "best ll: 6808.80712890625, bestParams: [tensor(0.0153), tensor(2280.0703), tensor(12095.1240)]\n",
      "epoch 85\n",
      " final_simplex: (array([[1.29604838e-02, 7.30603471e+02, 1.87661436e+04],\n",
      "       [1.29604839e-02, 7.30603460e+02, 1.87661436e+04],\n",
      "       [1.29604839e-02, 7.30603441e+02, 1.87661437e+04],\n",
      "       [1.29604839e-02, 7.30603441e+02, 1.87661437e+04]]), array([6729.25146484, 6729.25146484, 6729.25146484, 6729.25146484]))\n",
      "           fun: 6729.25146484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 262\n",
      "           nit: 102\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.29604838e-02, 7.30603471e+02, 1.87661436e+04])\n",
      "minPrevious 6678.58447265625\n",
      "best ll: 6929.912109375, bestParams: [tensor(0.0365), tensor(3274.2424), tensor(19458.4902)]\n",
      "epoch 84\n",
      " final_simplex: (array([[2.81595342e-02, 7.50761260e+02, 3.43045994e+04],\n",
      "       [2.81595342e-02, 7.50761260e+02, 3.43045994e+04],\n",
      "       [2.81595342e-02, 7.50761261e+02, 3.43045994e+04],\n",
      "       [2.81595342e-02, 7.50761258e+02, 3.43045994e+04]]), array([6710.18945312, 6710.18945312, 6710.18945312, 6710.18945312]))\n",
      "           fun: 6710.189453125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 297\n",
      "           nit: 100\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.81595342e-02, 7.50761260e+02, 3.43045994e+04])\n",
      "minPrevious 6678.58447265625\n",
      "best ll: 6729.560546875, bestParams: [tensor(0.3612), tensor(165.5730), tensor(18611.5078)]\n",
      "epoch 83\n",
      " final_simplex: (array([[3.72459492e-01, 1.68877903e+02, 1.95457448e+04],\n",
      "       [3.72459492e-01, 1.68877904e+02, 1.95457447e+04],\n",
      "       [3.72459492e-01, 1.68877904e+02, 1.95457447e+04],\n",
      "       [3.72459493e-01, 1.68877904e+02, 1.95457447e+04]]), array([6644.66845703, 6644.66845703, 6644.66845703, 6644.66845703]))\n",
      "           fun: 6644.66845703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 248\n",
      "           nit: 88\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.72459492e-01, 1.68877903e+02, 1.95457448e+04])\n",
      "minPrevious 6678.58447265625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.72459492e-01, 1.68877903e+02, 1.95457448e+04],\n",
      "       [3.72459492e-01, 1.68877904e+02, 1.95457447e+04],\n",
      "       [3.72459492e-01, 1.68877904e+02, 1.95457447e+04],\n",
      "       [3.72459493e-01, 1.68877904e+02, 1.95457447e+04]]), array([6644.66845703, 6644.66845703, 6644.66845703, 6644.66845703]))\n",
      "           fun: 6644.66845703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 248\n",
      "           nit: 88\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.72459492e-01, 1.68877903e+02, 1.95457448e+04])\n",
      "best ll: 6728.48681640625, bestParams: [tensor(0.4463), tensor(220.0474), tensor(24409.7109)]\n",
      "epoch 82\n",
      " final_simplex: (array([[4.53185343e-01, 2.23307950e+02, 2.52700651e+04],\n",
      "       [4.53185343e-01, 2.23307949e+02, 2.52700651e+04],\n",
      "       [4.53185336e-01, 2.23307950e+02, 2.52700651e+04],\n",
      "       [4.53185345e-01, 2.23307949e+02, 2.52700652e+04]]), array([6584.43847656, 6584.43847656, 6584.43847656, 6584.43847656]))\n",
      "           fun: 6584.4384765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 227\n",
      "           nit: 83\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.53185343e-01, 2.23307950e+02, 2.52700651e+04])\n",
      "minPrevious 6644.66845703125\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.53185343e-01, 2.23307950e+02, 2.52700651e+04],\n",
      "       [4.53185343e-01, 2.23307949e+02, 2.52700651e+04],\n",
      "       [4.53185336e-01, 2.23307950e+02, 2.52700651e+04],\n",
      "       [4.53185345e-01, 2.23307949e+02, 2.52700652e+04]]), array([6584.43847656, 6584.43847656, 6584.43847656, 6584.43847656]))\n",
      "           fun: 6584.4384765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 227\n",
      "           nit: 83\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.53185343e-01, 2.23307950e+02, 2.52700651e+04])\n",
      "best ll: 6834.5185546875, bestParams: [tensor(0.2438), tensor(411.2675), tensor(17300.8828)]\n",
      "epoch 81\n",
      " final_simplex: (array([[2.41780894e-01, 3.80997773e+02, 1.88225154e+04],\n",
      "       [2.41780895e-01, 3.80997770e+02, 1.88225154e+04],\n",
      "       [2.41780894e-01, 3.80997770e+02, 1.88225153e+04],\n",
      "       [2.41780898e-01, 3.80997773e+02, 1.88225154e+04]]), array([6697.61425781, 6697.61425781, 6697.61425781, 6697.61425781]))\n",
      "           fun: 6697.6142578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 216\n",
      "           nit: 70\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.41780894e-01, 3.80997773e+02, 1.88225154e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6760.7255859375, bestParams: [tensor(0.0014), tensor(12587.7227), tensor(12171.6357)]\n",
      "epoch 80\n",
      " final_simplex: (array([[8.52109621e-07, 1.52401509e+04, 1.87341189e+04],\n",
      "       [8.52109813e-07, 1.52401508e+04, 1.87341189e+04],\n",
      "       [8.52109294e-07, 1.52401508e+04, 1.87341189e+04],\n",
      "       [8.52109519e-07, 1.52401509e+04, 1.87341189e+04]]), array([6736.76269531, 6736.76269531, 6736.76269531, 6736.76269531]))\n",
      "           fun: 6736.7626953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 273\n",
      "           nit: 88\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.52109621e-07, 1.52401509e+04, 1.87341189e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[8.52109621e-07, 1.52401509e+04, 1.87341189e+04],\n",
      "       [8.52109813e-07, 1.52401508e+04, 1.87341189e+04],\n",
      "       [8.52109294e-07, 1.52401508e+04, 1.87341189e+04],\n",
      "       [8.52109519e-07, 1.52401509e+04, 1.87341189e+04]]), array([6736.76269531, 6736.76269531, 6736.76269531, 6736.76269531]))\n",
      "           fun: 6736.7626953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 273\n",
      "           nit: 88\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.52109621e-07, 1.52401509e+04, 1.87341189e+04])\n",
      "best ll: 6726.46826171875, bestParams: [tensor(0.4189), tensor(293.7684), tensor(22952.6426)]\n",
      "epoch 80\n",
      " final_simplex: (array([[4.06261377e-01, 2.96366234e+02, 2.39849901e+04],\n",
      "       [4.06261377e-01, 2.96366234e+02, 2.39849901e+04],\n",
      "       [4.06261376e-01, 2.96366235e+02, 2.39849900e+04],\n",
      "       [4.06261377e-01, 2.96366234e+02, 2.39849901e+04]]), array([6594.46337891, 6594.46337891, 6594.46337891, 6594.46337891]))\n",
      "           fun: 6594.46337890625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 256\n",
      "           nit: 91\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.06261377e-01, 2.96366234e+02, 2.39849901e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6749.453125, bestParams: [tensor(0.0913), tensor(455.0887), tensor(24076.7383)]\n",
      "epoch 79\n",
      " final_simplex: (array([[8.96344030e-02, 4.28873772e+02, 2.56381554e+04],\n",
      "       [8.96344018e-02, 4.28873774e+02, 2.56381555e+04],\n",
      "       [8.96344033e-02, 4.28873771e+02, 2.56381554e+04],\n",
      "       [8.96344027e-02, 4.28873771e+02, 2.56381555e+04]]), array([6708.27001953, 6708.27001953, 6708.27001953, 6708.27001953]))\n",
      "           fun: 6708.27001953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 237\n",
      "           nit: 83\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.96344030e-02, 4.28873772e+02, 2.56381554e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6781.79296875, bestParams: [tensor(0.0028), tensor(21736.6328), tensor(23724.2617)]\n",
      "epoch 78\n",
      " final_simplex: (array([[1.99608303e-06, 1.27362334e+04, 4.91146033e+04],\n",
      "       [1.99608276e-06, 1.27362334e+04, 4.91146033e+04],\n",
      "       [1.99608283e-06, 1.27362334e+04, 4.91146033e+04],\n",
      "       [1.99608273e-06, 1.27362334e+04, 4.91146033e+04]]), array([6736.74316406, 6736.74316406, 6736.74316406, 6736.74316406]))\n",
      "           fun: 6736.7431640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 304\n",
      "           nit: 118\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.99608303e-06, 1.27362334e+04, 4.91146033e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[1.99608303e-06, 1.27362334e+04, 4.91146033e+04],\n",
      "       [1.99608276e-06, 1.27362334e+04, 4.91146033e+04],\n",
      "       [1.99608283e-06, 1.27362334e+04, 4.91146033e+04],\n",
      "       [1.99608273e-06, 1.27362334e+04, 4.91146033e+04]]), array([6736.74316406, 6736.74316406, 6736.74316406, 6736.74316406]))\n",
      "           fun: 6736.7431640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 304\n",
      "           nit: 118\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.99608303e-06, 1.27362334e+04, 4.91146033e+04])\n",
      "best ll: 6735.52880859375, bestParams: [tensor(0.3596), tensor(465.8770), tensor(23159.0059)]\n",
      "epoch 78\n",
      " final_simplex: (array([[3.60839209e-01, 4.77892958e+02, 2.31923529e+04],\n",
      "       [3.60839208e-01, 4.77892956e+02, 2.31923530e+04],\n",
      "       [3.60839206e-01, 4.77892959e+02, 2.31923529e+04],\n",
      "       [3.60839216e-01, 4.77892958e+02, 2.31923529e+04]]), array([6700.83447266, 6700.83447266, 6700.83447266, 6700.83447266]))\n",
      "           fun: 6700.83447265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 224\n",
      "           nit: 78\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.60839209e-01, 4.77892958e+02, 2.31923529e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6796.0126953125, bestParams: [tensor(0.0031), tensor(15935.2119), tensor(7768.7153)]\n",
      "epoch 77\n",
      " final_simplex: (array([[4.39799931e-07, 2.13495344e+04, 1.21306423e+04],\n",
      "       [4.39799646e-07, 2.13495344e+04, 1.21306422e+04],\n",
      "       [4.39799528e-07, 2.13495344e+04, 1.21306422e+04],\n",
      "       [4.39800192e-07, 2.13495344e+04, 1.21306423e+04]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 271\n",
      "           nit: 87\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.39799931e-07, 2.13495344e+04, 1.21306423e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[4.39799931e-07, 2.13495344e+04, 1.21306423e+04],\n",
      "       [4.39799646e-07, 2.13495344e+04, 1.21306422e+04],\n",
      "       [4.39799528e-07, 2.13495344e+04, 1.21306422e+04],\n",
      "       [4.39800192e-07, 2.13495344e+04, 1.21306423e+04]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 271\n",
      "           nit: 87\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.39799931e-07, 2.13495344e+04, 1.21306423e+04])\n",
      "best ll: 6892.08251953125, bestParams: [tensor(0.0090), tensor(18185.0059), tensor(17256.4121)]\n",
      "epoch 77\n",
      " final_simplex: (array([[7.79541532e-07, 2.19227514e+04, 2.65144950e+04],\n",
      "       [7.79544035e-07, 2.19227513e+04, 2.65144950e+04],\n",
      "       [7.79542633e-07, 2.19227513e+04, 2.65144950e+04],\n",
      "       [7.79541360e-07, 2.19227514e+04, 2.65144950e+04]]), array([6736.76269531, 6736.76269531, 6736.76269531, 6736.76269531]))\n",
      "           fun: 6736.7626953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 277\n",
      "           nit: 101\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.79541532e-07, 2.19227514e+04, 2.65144950e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[7.79541532e-07, 2.19227514e+04, 2.65144950e+04],\n",
      "       [7.79544035e-07, 2.19227513e+04, 2.65144950e+04],\n",
      "       [7.79542633e-07, 2.19227513e+04, 2.65144950e+04],\n",
      "       [7.79541360e-07, 2.19227514e+04, 2.65144950e+04]]), array([6736.76269531, 6736.76269531, 6736.76269531, 6736.76269531]))\n",
      "           fun: 6736.7626953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 277\n",
      "           nit: 101\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.79541532e-07, 2.19227514e+04, 2.65144950e+04])\n",
      "best ll: 6740.517578125, bestParams: [tensor(0.0907), tensor(102.9401), tensor(9234.0146)]\n",
      "epoch 77\n",
      " final_simplex: (array([[9.48171904e-02, 9.75413735e+01, 8.65495430e+03],\n",
      "       [9.48171902e-02, 9.75413738e+01, 8.65495424e+03],\n",
      "       [9.48171907e-02, 9.75413737e+01, 8.65495427e+03],\n",
      "       [9.48171882e-02, 9.75413728e+01, 8.65495430e+03]]), array([6721.91162109, 6721.91162109, 6721.91162109, 6721.91162109]))\n",
      "           fun: 6721.91162109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 240\n",
      "           nit: 91\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.48171904e-02, 9.75413735e+01, 8.65495430e+03])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 7195.16845703125, bestParams: [tensor(0.1212), tensor(2144.9944), tensor(22457.0723)]\n",
      "epoch 76\n",
      " final_simplex: (array([[1.04550681e-01, 6.01655261e+02, 3.53845702e+04],\n",
      "       [1.04550681e-01, 6.01655276e+02, 3.53845701e+04],\n",
      "       [1.04550681e-01, 6.01655270e+02, 3.53845701e+04],\n",
      "       [1.04550682e-01, 6.01655264e+02, 3.53845701e+04]]), array([6664.36376953, 6664.36376953, 6664.36376953, 6664.36376953]))\n",
      "           fun: 6664.36376953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 270\n",
      "           nit: 99\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.04550681e-01, 6.01655261e+02, 3.53845702e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6823.60400390625, bestParams: [tensor(0.4163), tensor(445.2383), tensor(21045.3301)]\n",
      "epoch 75\n",
      " final_simplex: (array([[4.15439581e-01, 4.50617218e+02, 2.17045684e+04],\n",
      "       [4.15439581e-01, 4.50617218e+02, 2.17045685e+04],\n",
      "       [4.15439581e-01, 4.50617217e+02, 2.17045685e+04],\n",
      "       [4.15439580e-01, 4.50617218e+02, 2.17045684e+04]]), array([6725.97509766, 6725.97509766, 6725.97509766, 6725.97509766]))\n",
      "           fun: 6725.97509765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 244\n",
      "           nit: 80\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.15439581e-01, 4.50617218e+02, 2.17045684e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6743.02392578125, bestParams: [tensor(0.0233), tensor(354.3709), tensor(5806.1333)]\n",
      "epoch 74\n",
      " final_simplex: (array([[2.25522936e-02, 1.95658582e+02, 7.99448359e+03],\n",
      "       [2.25522936e-02, 1.95658582e+02, 7.99448358e+03],\n",
      "       [2.25522936e-02, 1.95658585e+02, 7.99448356e+03],\n",
      "       [2.25522935e-02, 1.95658588e+02, 7.99448352e+03]]), array([6729.83007812, 6729.83007812, 6729.83007812, 6729.83007812]))\n",
      "           fun: 6729.830078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 265\n",
      "           nit: 95\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.25522936e-02, 1.95658582e+02, 7.99448359e+03])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6744.0654296875, bestParams: [tensor(0.1726), tensor(307.6957), tensor(12074.9170)]\n",
      "epoch 73\n",
      " final_simplex: (array([[1.72620699e-01, 3.07695709e+02, 1.20749170e+04],\n",
      "       [1.72620675e-01, 3.07695716e+02, 1.20749169e+04],\n",
      "       [1.72620671e-01, 3.07695715e+02, 1.20749170e+04],\n",
      "       [1.72620653e-01, 3.07695712e+02, 1.20749170e+04]]), array([6744.06542969, 6744.06542969, 6744.06542969, 6744.06542969]))\n",
      "           fun: 6744.0654296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 196\n",
      "           nit: 62\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.72620699e-01, 3.07695709e+02, 1.20749170e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6740.1181640625, bestParams: [tensor(0.4817), tensor(278.7339), tensor(19827.2715)]\n",
      "epoch 72\n",
      " final_simplex: (array([[4.85323999e-01, 2.72351921e+02, 2.08970954e+04],\n",
      "       [4.85323993e-01, 2.72351923e+02, 2.08970955e+04],\n",
      "       [4.85323998e-01, 2.72351923e+02, 2.08970955e+04],\n",
      "       [4.85324003e-01, 2.72351920e+02, 2.08970954e+04]]), array([6590.43994141, 6590.43994141, 6590.43994141, 6590.43994141]))\n",
      "           fun: 6590.43994140625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 234\n",
      "           nit: 82\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.85323999e-01, 2.72351921e+02, 2.08970954e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6747.1142578125, bestParams: [tensor(0.0033), tensor(1922.8474), tensor(9180.6270)]\n",
      "epoch 71\n",
      " final_simplex: (array([[3.30380005e-03, 6.90288605e+02, 1.33030006e+04],\n",
      "       [3.30380000e-03, 6.90288611e+02, 1.33030006e+04],\n",
      "       [3.30379997e-03, 6.90288673e+02, 1.33030007e+04],\n",
      "       [3.30379994e-03, 6.90288664e+02, 1.33030006e+04]]), array([6735., 6735., 6735., 6735.]))\n",
      "           fun: 6735.0\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 240\n",
      "           nit: 83\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.30380005e-03, 6.90288605e+02, 1.33030006e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6827.4482421875, bestParams: [tensor(0.0051), tensor(24731.9160), tensor(18605.3320)]\n",
      "epoch 70\n",
      " final_simplex: (array([[7.14117892e-07, 3.31351032e+04, 2.90517309e+04],\n",
      "       [7.14118155e-07, 3.31351032e+04, 2.90517309e+04],\n",
      "       [7.14117889e-07, 3.31351032e+04, 2.90517309e+04],\n",
      "       [7.14117321e-07, 3.31351032e+04, 2.90517310e+04]]), array([6736.76464844, 6736.76464844, 6736.76464844, 6736.76464844]))\n",
      "           fun: 6736.7646484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 287\n",
      "           nit: 103\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.14117892e-07, 3.31351032e+04, 2.90517309e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[7.14117892e-07, 3.31351032e+04, 2.90517309e+04],\n",
      "       [7.14118155e-07, 3.31351032e+04, 2.90517309e+04],\n",
      "       [7.14117889e-07, 3.31351032e+04, 2.90517309e+04],\n",
      "       [7.14117321e-07, 3.31351032e+04, 2.90517310e+04]]), array([6736.76464844, 6736.76464844, 6736.76464844, 6736.76464844]))\n",
      "           fun: 6736.7646484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 287\n",
      "           nit: 103\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.14117892e-07, 3.31351032e+04, 2.90517309e+04])\n",
      "best ll: 6762.80126953125, bestParams: [tensor(0.1144), tensor(722.4831), tensor(20419.0430)]\n",
      "epoch 70\n",
      " final_simplex: (array([[1.14582107e-01, 7.23474154e+02, 2.05366835e+04],\n",
      "       [1.14582106e-01, 7.23474155e+02, 2.05366835e+04],\n",
      "       [1.14582106e-01, 7.23474156e+02, 2.05366835e+04],\n",
      "       [1.14582107e-01, 7.23474150e+02, 2.05366836e+04]]), array([6745.39208984, 6745.39208984, 6745.39208984, 6745.39208984]))\n",
      "           fun: 6745.39208984375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 241\n",
      "           nit: 89\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.14582107e-01, 7.23474154e+02, 2.05366835e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6735.18115234375, bestParams: [tensor(0.0037), tensor(1179.9963), tensor(20846.2305)]\n",
      "epoch 69\n",
      " final_simplex: (array([[3.82543935e-03, 1.13516626e+03, 2.11637686e+04],\n",
      "       [3.82543939e-03, 1.13516626e+03, 2.11637687e+04],\n",
      "       [3.82543937e-03, 1.13516625e+03, 2.11637687e+04],\n",
      "       [3.82543936e-03, 1.13516626e+03, 2.11637687e+04]]), array([6734.03955078, 6734.03955078, 6734.03955078, 6734.03955078]))\n",
      "           fun: 6734.03955078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 221\n",
      "           nit: 76\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.82543935e-03, 1.13516626e+03, 2.11637686e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6772.60791015625, bestParams: [tensor(0.0020), tensor(8249.3516), tensor(6634.4390)]\n",
      "epoch 68\n",
      " final_simplex: (array([[8.02122159e-07, 9.97329339e+03, 1.02055387e+04],\n",
      "       [8.02120972e-07, 9.97329344e+03, 1.02055387e+04],\n",
      "       [8.02122384e-07, 9.97329336e+03, 1.02055387e+04],\n",
      "       [8.02122206e-07, 9.97329330e+03, 1.02055387e+04]]), array([6736.76367188, 6736.76367188, 6736.76367188, 6736.76367188]))\n",
      "           fun: 6736.763671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 274\n",
      "           nit: 91\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.02122159e-07, 9.97329339e+03, 1.02055387e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[8.02122159e-07, 9.97329339e+03, 1.02055387e+04],\n",
      "       [8.02120972e-07, 9.97329344e+03, 1.02055387e+04],\n",
      "       [8.02122384e-07, 9.97329336e+03, 1.02055387e+04],\n",
      "       [8.02122206e-07, 9.97329330e+03, 1.02055387e+04]]), array([6736.76367188, 6736.76367188, 6736.76367188, 6736.76367188]))\n",
      "           fun: 6736.763671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 274\n",
      "           nit: 91\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.02122159e-07, 9.97329339e+03, 1.02055387e+04])\n",
      "best ll: 6749.4697265625, bestParams: [tensor(0.0703), tensor(574.8126), tensor(17983.8730)]\n",
      "epoch 68\n",
      " final_simplex: (array([[6.94367865e-02, 6.06578689e+02, 1.80233825e+04],\n",
      "       [6.94367865e-02, 6.06578688e+02, 1.80233826e+04],\n",
      "       [6.94367865e-02, 6.06578688e+02, 1.80233825e+04],\n",
      "       [6.94367868e-02, 6.06578687e+02, 1.80233825e+04]]), array([6723.28808594, 6723.28808594, 6723.28808594, 6723.28808594]))\n",
      "           fun: 6723.2880859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 253\n",
      "           nit: 99\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.94367865e-02, 6.06578689e+02, 1.80233825e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6786.65966796875, bestParams: [tensor(0.3239), tensor(301.6211), tensor(21911.6504)]\n",
      "epoch 67\n",
      " final_simplex: (array([[3.43441271e-01, 3.02083288e+02, 2.27288464e+04],\n",
      "       [3.43441271e-01, 3.02083290e+02, 2.27288464e+04],\n",
      "       [3.43441271e-01, 3.02083290e+02, 2.27288464e+04],\n",
      "       [3.43441271e-01, 3.02083290e+02, 2.27288463e+04]]), array([6612.37597656, 6612.37597656, 6612.37597656, 6612.37597656]))\n",
      "           fun: 6612.3759765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 250\n",
      "           nit: 93\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.43441271e-01, 3.02083288e+02, 2.27288464e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6762.015625, bestParams: [tensor(0.0368), tensor(1474.4825), tensor(24911.0527)]\n",
      "epoch 66\n",
      " final_simplex: (array([[3.23118474e-02, 1.37437678e+03, 2.79787443e+04],\n",
      "       [3.23118474e-02, 1.37437678e+03, 2.79787443e+04],\n",
      "       [3.23118473e-02, 1.37437678e+03, 2.79787443e+04],\n",
      "       [3.23118474e-02, 1.37437679e+03, 2.79787442e+04]]), array([6722.90625, 6722.90625, 6722.90625, 6722.90625]))\n",
      "           fun: 6722.90625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 242\n",
      "           nit: 81\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.23118474e-02, 1.37437678e+03, 2.79787443e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6741.646484375, bestParams: [tensor(0.0932), tensor(302.0010), tensor(13398.9277)]\n",
      "epoch 65\n",
      " final_simplex: (array([[9.15484928e-02, 2.92810848e+02, 1.45587777e+04],\n",
      "       [9.15484927e-02, 2.92810849e+02, 1.45587777e+04],\n",
      "       [9.15484929e-02, 2.92810849e+02, 1.45587776e+04],\n",
      "       [9.15484930e-02, 2.92810848e+02, 1.45587776e+04]]), array([6719.26074219, 6719.26074219, 6719.26074219, 6719.26074219]))\n",
      "           fun: 6719.2607421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 243\n",
      "           nit: 83\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.15484928e-02, 2.92810848e+02, 1.45587777e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6731.6748046875, bestParams: [tensor(0.3905), tensor(379.0970), tensor(24626.3574)]\n",
      "epoch 64\n",
      " final_simplex: (array([[3.91218094e-01, 3.95664643e+02, 2.47009170e+04],\n",
      "       [3.91218095e-01, 3.95664642e+02, 2.47009170e+04],\n",
      "       [3.91218094e-01, 3.95664643e+02, 2.47009171e+04],\n",
      "       [3.91218095e-01, 3.95664642e+02, 2.47009171e+04]]), array([6635.81542969, 6635.81542969, 6635.81542969, 6635.81542969]))\n",
      "           fun: 6635.8154296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 235\n",
      "           nit: 81\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.91218094e-01, 3.95664643e+02, 2.47009170e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6752.06640625, bestParams: [tensor(0.0288), tensor(1340.3727), tensor(22688.0957)]\n",
      "epoch 63\n",
      " final_simplex: (array([[2.93114053e-02, 1.38805981e+03, 2.27460027e+04],\n",
      "       [2.93114052e-02, 1.38805981e+03, 2.27460027e+04],\n",
      "       [2.93114052e-02, 1.38805981e+03, 2.27460026e+04],\n",
      "       [2.93114053e-02, 1.38805981e+03, 2.27460026e+04]]), array([6736.26953125, 6736.26953125, 6736.26953125, 6736.26953125]))\n",
      "           fun: 6736.26953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 243\n",
      "           nit: 82\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.93114053e-02, 1.38805981e+03, 2.27460027e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6876.2470703125, bestParams: [tensor(0.0084), tensor(7905.2578), tensor(8561.1416)]\n",
      "epoch 62\n",
      " final_simplex: (array([[1.72149593e-06, 5.55159912e+03, 1.73243911e+04],\n",
      "       [1.72149553e-06, 5.55159917e+03, 1.73243910e+04],\n",
      "       [1.72149564e-06, 5.55159916e+03, 1.73243910e+04],\n",
      "       [1.72149576e-06, 5.55159912e+03, 1.73243911e+04]]), array([6736.74951172, 6736.74951172, 6736.74951172, 6736.74951172]))\n",
      "           fun: 6736.74951171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 283\n",
      "           nit: 101\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.72149593e-06, 5.55159912e+03, 1.73243911e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[1.72149593e-06, 5.55159912e+03, 1.73243911e+04],\n",
      "       [1.72149553e-06, 5.55159917e+03, 1.73243910e+04],\n",
      "       [1.72149564e-06, 5.55159916e+03, 1.73243910e+04],\n",
      "       [1.72149576e-06, 5.55159912e+03, 1.73243911e+04]]), array([6736.74951172, 6736.74951172, 6736.74951172, 6736.74951172]))\n",
      "           fun: 6736.74951171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 283\n",
      "           nit: 101\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.72149593e-06, 5.55159912e+03, 1.73243911e+04])\n",
      "best ll: 6686.59619140625, bestParams: [tensor(0.3712), tensor(417.7963), tensor(24918.0469)]\n",
      "epoch 62\n",
      " final_simplex: (array([[3.72241672e-01, 4.23766632e+02, 2.58752229e+04],\n",
      "       [3.72241671e-01, 4.23766633e+02, 2.58752229e+04],\n",
      "       [3.72241673e-01, 4.23766630e+02, 2.58752229e+04],\n",
      "       [3.72241673e-01, 4.23766631e+02, 2.58752228e+04]]), array([6637.43457031, 6637.43457031, 6637.43457031, 6637.43457031]))\n",
      "           fun: 6637.4345703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 249\n",
      "           nit: 96\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.72241672e-01, 4.23766632e+02, 2.58752229e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6999.548828125, bestParams: [tensor(0.0146), tensor(15189.2646), tensor(12455.7617)]\n",
      "epoch 61\n",
      " final_simplex: (array([[7.26611560e-07, 1.83097184e+04, 1.91376142e+04],\n",
      "       [7.26608076e-07, 1.83097183e+04, 1.91376142e+04],\n",
      "       [7.26609261e-07, 1.83097184e+04, 1.91376142e+04],\n",
      "       [7.26606258e-07, 1.83097185e+04, 1.91376142e+04]]), array([6736.76367188, 6736.76367188, 6736.76367188, 6736.76367188]))\n",
      "           fun: 6736.763671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 271\n",
      "           nit: 100\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.26611560e-07, 1.83097184e+04, 1.91376142e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[7.26611560e-07, 1.83097184e+04, 1.91376142e+04],\n",
      "       [7.26608076e-07, 1.83097183e+04, 1.91376142e+04],\n",
      "       [7.26609261e-07, 1.83097184e+04, 1.91376142e+04],\n",
      "       [7.26606258e-07, 1.83097185e+04, 1.91376142e+04]]), array([6736.76367188, 6736.76367188, 6736.76367188, 6736.76367188]))\n",
      "           fun: 6736.763671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 271\n",
      "           nit: 100\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.26611560e-07, 1.83097184e+04, 1.91376142e+04])\n",
      "best ll: 6758.2626953125, bestParams: [tensor(0.0931), tensor(462.0731), tensor(14118.1318)]\n",
      "epoch 61\n",
      " final_simplex: (array([[9.63788166e-02, 4.49615672e+02, 1.49797940e+04],\n",
      "       [9.63788171e-02, 4.49615671e+02, 1.49797939e+04],\n",
      "       [9.63788146e-02, 4.49615676e+02, 1.49797940e+04],\n",
      "       [9.63788153e-02, 4.49615674e+02, 1.49797940e+04]]), array([6719.76855469, 6719.76855469, 6719.76855469, 6719.76855469]))\n",
      "           fun: 6719.7685546875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 227\n",
      "           nit: 80\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.63788166e-02, 4.49615672e+02, 1.49797940e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6855.00048828125, bestParams: [tensor(0.0062), tensor(21834.2188), tensor(10659.0625)]\n",
      "epoch 60\n",
      " final_simplex: (array([[5.07756259e-07, 2.92728255e+04, 1.65579894e+04],\n",
      "       [5.07756025e-07, 2.92728255e+04, 1.65579895e+04],\n",
      "       [5.07755800e-07, 2.92728255e+04, 1.65579894e+04],\n",
      "       [5.07755756e-07, 2.92728255e+04, 1.65579894e+04]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 279\n",
      "           nit: 91\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.07756259e-07, 2.92728255e+04, 1.65579894e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[5.07756259e-07, 2.92728255e+04, 1.65579894e+04],\n",
      "       [5.07756025e-07, 2.92728255e+04, 1.65579895e+04],\n",
      "       [5.07755800e-07, 2.92728255e+04, 1.65579894e+04],\n",
      "       [5.07755756e-07, 2.92728255e+04, 1.65579894e+04]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 279\n",
      "           nit: 91\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.07756259e-07, 2.92728255e+04, 1.65579894e+04])\n",
      "best ll: 6737.15478515625, bestParams: [tensor(0.0314), tensor(307.8441), tensor(9741.4902)]\n",
      "epoch 60\n",
      " final_simplex: (array([[3.01107877e-02, 3.15539469e+02, 1.01321185e+04],\n",
      "       [3.01107880e-02, 3.15539466e+02, 1.01321185e+04],\n",
      "       [3.01107879e-02, 3.15539467e+02, 1.01321185e+04],\n",
      "       [3.01107876e-02, 3.15539470e+02, 1.01321184e+04]]), array([6728.859375, 6728.859375, 6728.859375, 6728.859375]))\n",
      "           fun: 6728.859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 225\n",
      "           nit: 80\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.01107877e-02, 3.15539469e+02, 1.01321185e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6753.466796875, bestParams: [tensor(0.0070), tensor(241.4044), tensor(1518.5723)]\n",
      "epoch 59\n",
      " final_simplex: (array([[6.60001307e-03, 1.02841851e+02, 2.19433169e+03],\n",
      "       [6.60001070e-03, 1.02841818e+02, 2.19433169e+03],\n",
      "       [6.60001040e-03, 1.02841814e+02, 2.19433175e+03],\n",
      "       [6.60001289e-03, 1.02841842e+02, 2.19433169e+03]]), array([6734.90722656, 6734.90722656, 6734.90722656, 6734.90722656]))\n",
      "           fun: 6734.9072265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 218\n",
      "           nit: 84\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.60001307e-03, 1.02841851e+02, 2.19433169e+03])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6738.03271484375, bestParams: [tensor(0.0128), tensor(270.2549), tensor(16794.8691)]\n",
      "epoch 58\n",
      " final_simplex: (array([[1.23707097e-02, 2.68405141e+02, 1.81698127e+04],\n",
      "       [1.23707099e-02, 2.68405136e+02, 1.81698127e+04],\n",
      "       [1.23707098e-02, 2.68405141e+02, 1.81698127e+04],\n",
      "       [1.23707097e-02, 2.68405140e+02, 1.81698128e+04]]), array([6732.66699219, 6732.66699219, 6732.66699219, 6732.66699219]))\n",
      "           fun: 6732.6669921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 214\n",
      "           nit: 69\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.23707097e-02, 2.68405141e+02, 1.81698127e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6806.125, bestParams: [tensor(0.0666), tensor(1025.1410), tensor(16103.2480)]\n",
      "epoch 57\n",
      " final_simplex: (array([[5.58622002e-02, 7.03423315e+02, 2.32939659e+04],\n",
      "       [5.58621999e-02, 7.03423314e+02, 2.32939660e+04],\n",
      "       [5.58622003e-02, 7.03423316e+02, 2.32939659e+04],\n",
      "       [5.58622003e-02, 7.03423319e+02, 2.32939659e+04]]), array([6719.87646484, 6719.87646484, 6719.87646484, 6719.87646484]))\n",
      "           fun: 6719.87646484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 268\n",
      "           nit: 98\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.58622002e-02, 7.03423315e+02, 2.32939659e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6722.6083984375, bestParams: [tensor(0.3636), tensor(136.0591), tensor(24987.8457)]\n",
      "epoch 56\n",
      " final_simplex: (array([[3.63504825e-01, 1.38990725e+02, 2.56752634e+04],\n",
      "       [3.63504829e-01, 1.38990726e+02, 2.56752635e+04],\n",
      "       [3.63504827e-01, 1.38990725e+02, 2.56752633e+04],\n",
      "       [3.63504825e-01, 1.38990726e+02, 2.56752634e+04]]), array([6681.51708984, 6681.51708984, 6681.51708984, 6681.51708984]))\n",
      "           fun: 6681.51708984375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 204\n",
      "           nit: 60\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.63504825e-01, 1.38990725e+02, 2.56752634e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6979.0068359375, bestParams: [tensor(0.0217), tensor(4830.5947), tensor(12666.8789)]\n",
      "epoch 55\n",
      " final_simplex: (array([[6.20210484e-04, 3.07975062e+03, 2.48732965e+04],\n",
      "       [6.20210474e-04, 3.07975063e+03, 2.48732965e+04],\n",
      "       [6.20210518e-04, 3.07975064e+03, 2.48732964e+04],\n",
      "       [6.20210504e-04, 3.07975064e+03, 2.48732964e+04]]), array([6736.28808594, 6736.28808594, 6736.28808594, 6736.28808594]))\n",
      "           fun: 6736.2880859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 266\n",
      "           nit: 94\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.20210484e-04, 3.07975062e+03, 2.48732965e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6731.7275390625, bestParams: [tensor(0.1615), tensor(273.1802), tensor(23222.9277)]\n",
      "epoch 54\n",
      " final_simplex: (array([[1.59708458e-01, 2.80509154e+02, 2.40527157e+04],\n",
      "       [1.59708458e-01, 2.80509154e+02, 2.40527157e+04],\n",
      "       [1.59708458e-01, 2.80509154e+02, 2.40527157e+04],\n",
      "       [1.59708459e-01, 2.80509154e+02, 2.40527156e+04]]), array([6687.89404297, 6687.89404297, 6687.89404297, 6687.89404297]))\n",
      "           fun: 6687.89404296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 233\n",
      "           nit: 75\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.59708458e-01, 2.80509154e+02, 2.40527157e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6799.35986328125, bestParams: [tensor(0.0032), tensor(8645.4473), tensor(1777.2828)]\n",
      "epoch 53\n",
      " final_simplex: (array([[1.90275961e-08, 1.17999018e+04, 2.73249684e+03],\n",
      "       [1.90273771e-08, 1.17999018e+04, 2.73249683e+03],\n",
      "       [1.90272629e-08, 1.17999017e+04, 2.73249683e+03],\n",
      "       [1.90284538e-08, 1.17999018e+04, 2.73249683e+03]]), array([6736.75634766, 6736.75634766, 6736.75634766, 6736.75634766]))\n",
      "           fun: 6736.75634765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 269\n",
      "           nit: 94\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.90275961e-08, 1.17999018e+04, 2.73249684e+03])\n",
      "Failed to converge\n",
      " final_simplex: (array([[1.90275961e-08, 1.17999018e+04, 2.73249684e+03],\n",
      "       [1.90273771e-08, 1.17999018e+04, 2.73249683e+03],\n",
      "       [1.90272629e-08, 1.17999017e+04, 2.73249683e+03],\n",
      "       [1.90284538e-08, 1.17999018e+04, 2.73249683e+03]]), array([6736.75634766, 6736.75634766, 6736.75634766, 6736.75634766]))\n",
      "           fun: 6736.75634765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 269\n",
      "           nit: 94\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.90275961e-08, 1.17999018e+04, 2.73249684e+03])\n",
      "best ll: 6741.01416015625, bestParams: [tensor(0.0019), tensor(4645.5679), tensor(23055.0371)]\n",
      "epoch 53\n",
      " final_simplex: (array([[2.11715975e-03, 2.42966338e+03, 2.98056979e+04],\n",
      "       [2.11715976e-03, 2.42966337e+03, 2.98056979e+04],\n",
      "       [2.11715975e-03, 2.42966345e+03, 2.98056978e+04],\n",
      "       [2.11715975e-03, 2.42966338e+03, 2.98056978e+04]]), array([6734.32861328, 6734.32861328, 6734.32861328, 6734.32861328]))\n",
      "           fun: 6734.32861328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 249\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.11715975e-03, 2.42966338e+03, 2.98056979e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6767.4501953125, bestParams: [tensor(0.0067), tensor(2192.0496), tensor(9839.2969)]\n",
      "epoch 52\n",
      " final_simplex: (array([[5.86779089e-03, 7.58614946e+02, 1.56441976e+04],\n",
      "       [5.86779114e-03, 7.58614923e+02, 1.56441976e+04],\n",
      "       [5.86779095e-03, 7.58614980e+02, 1.56441976e+04],\n",
      "       [5.86779092e-03, 7.58614974e+02, 1.56441975e+04]]), array([6733.32275391, 6733.32275391, 6733.32275391, 6733.32275391]))\n",
      "           fun: 6733.32275390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 250\n",
      "           nit: 100\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.86779089e-03, 7.58614946e+02, 1.56441976e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6782.3291015625, bestParams: [tensor(0.3419), tensor(442.8904), tensor(23077.3535)]\n",
      "epoch 51\n",
      " final_simplex: (array([[3.49284135e-01, 4.36403335e+02, 2.37413822e+04],\n",
      "       [3.49284138e-01, 4.36403331e+02, 2.37413822e+04],\n",
      "       [3.49284135e-01, 4.36403335e+02, 2.37413821e+04],\n",
      "       [3.49284137e-01, 4.36403332e+02, 2.37413822e+04]]), array([6645.01367188, 6645.01367188, 6645.01367188, 6645.01367188]))\n",
      "           fun: 6645.013671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 233\n",
      "           nit: 81\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.49284135e-01, 4.36403335e+02, 2.37413822e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 7034.94970703125, bestParams: [tensor(0.0149), tensor(24097.4980), tensor(2220.1104)]\n",
      "epoch 50\n",
      " final_simplex: (array([[1.57081064e-07, 3.29169142e+04, 3.41532367e+03],\n",
      "       [1.57080050e-07, 3.29169141e+04, 3.41532367e+03],\n",
      "       [1.57079166e-07, 3.29169143e+04, 3.41532368e+03],\n",
      "       [1.57086027e-07, 3.29169141e+04, 3.41532367e+03]]), array([6736.765625, 6736.765625, 6736.765625, 6736.765625]))\n",
      "           fun: 6736.765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 265\n",
      "           nit: 93\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.57081064e-07, 3.29169142e+04, 3.41532367e+03])\n",
      "Failed to converge\n",
      " final_simplex: (array([[1.57081064e-07, 3.29169142e+04, 3.41532367e+03],\n",
      "       [1.57080050e-07, 3.29169141e+04, 3.41532367e+03],\n",
      "       [1.57079166e-07, 3.29169143e+04, 3.41532368e+03],\n",
      "       [1.57086027e-07, 3.29169141e+04, 3.41532367e+03]]), array([6736.765625, 6736.765625, 6736.765625, 6736.765625]))\n",
      "           fun: 6736.765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 265\n",
      "           nit: 93\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.57081064e-07, 3.29169142e+04, 3.41532367e+03])\n",
      "best ll: 6739.63134765625, bestParams: [tensor(0.3488), tensor(428.0399), tensor(24970.6426)]\n",
      "epoch 50\n",
      " final_simplex: (array([[3.48414805e-01, 4.22035613e+02, 2.66874585e+04],\n",
      "       [3.48414802e-01, 4.22035613e+02, 2.66874584e+04],\n",
      "       [3.48414806e-01, 4.22035615e+02, 2.66874585e+04],\n",
      "       [3.48414801e-01, 4.22035614e+02, 2.66874585e+04]]), array([6646.42578125, 6646.42578125, 6646.42578125, 6646.42578125]))\n",
      "           fun: 6646.42578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 226\n",
      "           nit: 78\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.48414805e-01, 4.22035613e+02, 2.66874585e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6807.2890625, bestParams: [tensor(0.1538), tensor(232.8616), tensor(6991.2241)]\n",
      "epoch 49\n",
      " final_simplex: (array([[1.24731210e-01, 1.88207380e+02, 9.37317147e+03],\n",
      "       [1.24731210e-01, 1.88207379e+02, 9.37317156e+03],\n",
      "       [1.24731210e-01, 1.88207381e+02, 9.37317146e+03],\n",
      "       [1.24731210e-01, 1.88207380e+02, 9.37317150e+03]]), array([6720.31884766, 6720.31884766, 6720.31884766, 6720.31884766]))\n",
      "           fun: 6720.31884765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 258\n",
      "           nit: 102\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.24731210e-01, 1.88207380e+02, 9.37317147e+03])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6739.65234375, bestParams: [tensor(0.0725), tensor(327.0951), tensor(9352.4326)]\n",
      "epoch 48\n",
      " final_simplex: (array([[7.25339116e-02, 3.27071952e+02, 9.35202349e+03],\n",
      "       [7.25339120e-02, 3.27071945e+02, 9.35202349e+03],\n",
      "       [7.25339102e-02, 3.27071943e+02, 9.35202343e+03],\n",
      "       [7.25339116e-02, 3.27071941e+02, 9.35202342e+03]]), array([6737.65722656, 6737.65722656, 6737.65722656, 6737.65722656]))\n",
      "           fun: 6737.6572265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 201\n",
      "           nit: 62\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.25339116e-02, 3.27071952e+02, 9.35202349e+03])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6736.62109375, bestParams: [tensor(0.0005), tensor(1632.0404), tensor(23354.7832)]\n",
      "epoch 47\n",
      " final_simplex: (array([[5.57817061e-04, 1.47420934e+03, 2.50863690e+04],\n",
      "       [5.57817060e-04, 1.47420934e+03, 2.50863689e+04],\n",
      "       [5.57817058e-04, 1.47420934e+03, 2.50863689e+04],\n",
      "       [5.57817060e-04, 1.47420933e+03, 2.50863691e+04]]), array([6736.33203125, 6736.33203125, 6736.33203125, 6736.33203125]))\n",
      "           fun: 6736.33203125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 241\n",
      "           nit: 84\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.57817061e-04, 1.47420934e+03, 2.50863690e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6744.7158203125, bestParams: [tensor(0.0101), tensor(1373.4857), tensor(13953.2480)]\n",
      "epoch 46\n",
      " final_simplex: (array([[9.89918176e-03, 1.05011102e+03, 1.77837250e+04],\n",
      "       [9.89918174e-03, 1.05011103e+03, 1.77837250e+04],\n",
      "       [9.89918172e-03, 1.05011104e+03, 1.77837249e+04],\n",
      "       [9.89918176e-03, 1.05011103e+03, 1.77837250e+04]]), array([6730.22802734, 6730.22802734, 6730.22802734, 6730.22802734]))\n",
      "           fun: 6730.22802734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 254\n",
      "           nit: 94\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.89918176e-03, 1.05011102e+03, 1.77837250e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6763.10986328125, bestParams: [tensor(0.1554), tensor(114.3414), tensor(13668.6396)]\n",
      "epoch 45\n",
      " final_simplex: (array([[1.50302016e-01, 1.20524398e+02, 1.44317743e+04],\n",
      "       [1.50302014e-01, 1.20524390e+02, 1.44317743e+04],\n",
      "       [1.50302019e-01, 1.20524395e+02, 1.44317743e+04],\n",
      "       [1.50302015e-01, 1.20524394e+02, 1.44317743e+04]]), array([6706.84472656, 6706.84472656, 6706.84472656, 6706.84472656]))\n",
      "           fun: 6706.8447265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 205\n",
      "           nit: 66\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.50302016e-01, 1.20524398e+02, 1.44317743e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6872.24951171875, bestParams: [tensor(0.0079), tensor(15039.8369), tensor(14477.7295)]\n",
      "epoch 44\n",
      " final_simplex: (array([[9.10111033e-07, 2.01129360e+04, 2.29403879e+04],\n",
      "       [9.10111039e-07, 2.01129360e+04, 2.29403879e+04],\n",
      "       [9.10110982e-07, 2.01129360e+04, 2.29403879e+04],\n",
      "       [9.10111172e-07, 2.01129360e+04, 2.29403879e+04]]), array([6736.76367188, 6736.76367188, 6736.76367188, 6736.76367188]))\n",
      "           fun: 6736.763671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 296\n",
      "           nit: 103\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.10111033e-07, 2.01129360e+04, 2.29403879e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[9.10111033e-07, 2.01129360e+04, 2.29403879e+04],\n",
      "       [9.10111039e-07, 2.01129360e+04, 2.29403879e+04],\n",
      "       [9.10110982e-07, 2.01129360e+04, 2.29403879e+04],\n",
      "       [9.10111172e-07, 2.01129360e+04, 2.29403879e+04]]), array([6736.76367188, 6736.76367188, 6736.76367188, 6736.76367188]))\n",
      "           fun: 6736.763671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 296\n",
      "           nit: 103\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.10111033e-07, 2.01129360e+04, 2.29403879e+04])\n",
      "best ll: 6768.27978515625, bestParams: [tensor(0.0043), tensor(3046.9409), tensor(9265.4004)]\n",
      "epoch 44\n",
      " final_simplex: (array([[3.41685770e-03, 7.50976035e+02, 1.49648680e+04],\n",
      "       [3.41685770e-03, 7.50976030e+02, 1.49648680e+04],\n",
      "       [3.41685770e-03, 7.50976003e+02, 1.49648681e+04],\n",
      "       [3.41685770e-03, 7.50976009e+02, 1.49648681e+04]]), array([6734.44775391, 6734.44775391, 6734.44775391, 6734.44775391]))\n",
      "           fun: 6734.44775390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 266\n",
      "           nit: 94\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.41685770e-03, 7.50976035e+02, 1.49648680e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6761.33251953125, bestParams: [tensor(0.3409), tensor(361.8807), tensor(23632.9121)]\n",
      "epoch 43\n",
      " final_simplex: (array([[3.44751471e-01, 3.47547387e+02, 2.33097335e+04],\n",
      "       [3.44751471e-01, 3.47547387e+02, 2.33097335e+04],\n",
      "       [3.44751470e-01, 3.47547387e+02, 2.33097335e+04],\n",
      "       [3.44751471e-01, 3.47547387e+02, 2.33097336e+04]]), array([6639.99951172, 6639.99951172, 6639.99951172, 6639.99951172]))\n",
      "           fun: 6639.99951171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 239\n",
      "           nit: 74\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.44751471e-01, 3.47547387e+02, 2.33097335e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6790.7255859375, bestParams: [tensor(0.0223), tensor(419.4037), tensor(3441.7664)]\n",
      "epoch 42\n",
      " final_simplex: (array([[1.85598374e-02, 1.47165688e+02, 5.46788306e+03],\n",
      "       [1.85598378e-02, 1.47165680e+02, 5.46788311e+03],\n",
      "       [1.85598371e-02, 1.47165687e+02, 5.46788307e+03],\n",
      "       [1.85598378e-02, 1.47165676e+02, 5.46788315e+03]]), array([6733.04101562, 6733.04101562, 6733.04101562, 6733.04101562]))\n",
      "           fun: 6733.041015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 243\n",
      "           nit: 95\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.85598374e-02, 1.47165688e+02, 5.46788306e+03])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6743.05859375, bestParams: [tensor(0.0004), tensor(14535.5615), tensor(11140.4873)]\n",
      "epoch 41\n",
      " final_simplex: (array([[9.01428803e-07, 1.75326108e+04, 1.71222781e+04],\n",
      "       [9.01428859e-07, 1.75326108e+04, 1.71222781e+04],\n",
      "       [9.01428369e-07, 1.75326109e+04, 1.71222782e+04],\n",
      "       [9.01428474e-07, 1.75326108e+04, 1.71222781e+04]]), array([6736.76416016, 6736.76416016, 6736.76416016, 6736.76416016]))\n",
      "           fun: 6736.76416015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 258\n",
      "           nit: 77\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.01428803e-07, 1.75326108e+04, 1.71222781e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[9.01428803e-07, 1.75326108e+04, 1.71222781e+04],\n",
      "       [9.01428859e-07, 1.75326108e+04, 1.71222781e+04],\n",
      "       [9.01428369e-07, 1.75326109e+04, 1.71222782e+04],\n",
      "       [9.01428474e-07, 1.75326108e+04, 1.71222781e+04]]), array([6736.76416016, 6736.76416016, 6736.76416016, 6736.76416016]))\n",
      "           fun: 6736.76416015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 258\n",
      "           nit: 77\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.01428803e-07, 1.75326108e+04, 1.71222781e+04])\n",
      "best ll: 6730.533203125, bestParams: [tensor(0.3223), tensor(409.9466), tensor(22594.7012)]\n",
      "epoch 41\n",
      " final_simplex: (array([[3.18718139e-01, 4.17538229e+02, 2.37662783e+04],\n",
      "       [3.18718138e-01, 4.17538229e+02, 2.37662782e+04],\n",
      "       [3.18718138e-01, 4.17538230e+02, 2.37662782e+04],\n",
      "       [3.18718138e-01, 4.17538231e+02, 2.37662782e+04]]), array([6667.61669922, 6667.61669922, 6667.61669922, 6667.61669922]))\n",
      "           fun: 6667.61669921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 238\n",
      "           nit: 81\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.18718139e-01, 4.17538229e+02, 2.37662783e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6759.43359375, bestParams: [tensor(0.0017), tensor(16883.7012), tensor(24450.6074)]\n",
      "epoch 40\n",
      " final_simplex: (array([[2.04972236e-06, 1.03233016e+04, 4.74588598e+04],\n",
      "       [2.04972303e-06, 1.03233016e+04, 4.74588597e+04],\n",
      "       [2.04972242e-06, 1.03233016e+04, 4.74588597e+04],\n",
      "       [2.04972261e-06, 1.03233016e+04, 4.74588598e+04]]), array([6736.74121094, 6736.74121094, 6736.74121094, 6736.74121094]))\n",
      "           fun: 6736.7412109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 300\n",
      "           nit: 111\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.04972236e-06, 1.03233016e+04, 4.74588598e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[2.04972236e-06, 1.03233016e+04, 4.74588598e+04],\n",
      "       [2.04972303e-06, 1.03233016e+04, 4.74588597e+04],\n",
      "       [2.04972242e-06, 1.03233016e+04, 4.74588597e+04],\n",
      "       [2.04972261e-06, 1.03233016e+04, 4.74588598e+04]]), array([6736.74121094, 6736.74121094, 6736.74121094, 6736.74121094]))\n",
      "           fun: 6736.7412109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 300\n",
      "           nit: 111\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.04972236e-06, 1.03233016e+04, 4.74588598e+04])\n",
      "best ll: 6756.201171875, bestParams: [tensor(0.0118), tensor(2365.4568), tensor(19599.4590)]\n",
      "epoch 40\n",
      " final_simplex: (array([[1.11598069e-02, 2.19988832e+03, 2.40052939e+04],\n",
      "       [1.11598069e-02, 2.19988833e+03, 2.40052938e+04],\n",
      "       [1.11598069e-02, 2.19988832e+03, 2.40052938e+04],\n",
      "       [1.11598070e-02, 2.19988833e+03, 2.40052938e+04]]), array([6739.62109375, 6739.62109375, 6739.62109375, 6739.62109375]))\n",
      "           fun: 6739.62109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 254\n",
      "           nit: 91\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.11598069e-02, 2.19988832e+03, 2.40052939e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6746.4912109375, bestParams: [tensor(0.0005), tensor(18422.1230), tensor(9905.0420)]\n",
      "epoch 39\n",
      " final_simplex: (array([[4.49185869e-07, 2.46395653e+04, 1.56421948e+04],\n",
      "       [4.49185873e-07, 2.46395653e+04, 1.56421947e+04],\n",
      "       [4.49185688e-07, 2.46395653e+04, 1.56421947e+04],\n",
      "       [4.49185976e-07, 2.46395653e+04, 1.56421947e+04]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 266\n",
      "           nit: 80\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.49185869e-07, 2.46395653e+04, 1.56421948e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[4.49185869e-07, 2.46395653e+04, 1.56421948e+04],\n",
      "       [4.49185873e-07, 2.46395653e+04, 1.56421947e+04],\n",
      "       [4.49185688e-07, 2.46395653e+04, 1.56421947e+04],\n",
      "       [4.49185976e-07, 2.46395653e+04, 1.56421947e+04]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 266\n",
      "           nit: 80\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.49185869e-07, 2.46395653e+04, 1.56421948e+04])\n",
      "best ll: 6804.20703125, bestParams: [tensor(0.0040), tensor(17966.3262), tensor(17254.2949)]\n",
      "epoch 39\n",
      " final_simplex: (array([[2.81531008e-08, 2.16621052e+04, 2.65125815e+04],\n",
      "       [2.81518568e-08, 2.16621052e+04, 2.65125814e+04],\n",
      "       [2.81519320e-08, 2.16621053e+04, 2.65125815e+04],\n",
      "       [2.81507268e-08, 2.16621053e+04, 2.65125815e+04]]), array([6736.75585938, 6736.75585938, 6736.75585938, 6736.75585938]))\n",
      "           fun: 6736.755859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 272\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.81531008e-08, 2.16621052e+04, 2.65125815e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[2.81531008e-08, 2.16621052e+04, 2.65125815e+04],\n",
      "       [2.81518568e-08, 2.16621052e+04, 2.65125814e+04],\n",
      "       [2.81519320e-08, 2.16621053e+04, 2.65125815e+04],\n",
      "       [2.81507268e-08, 2.16621053e+04, 2.65125815e+04]]), array([6736.75585938, 6736.75585938, 6736.75585938, 6736.75585938]))\n",
      "           fun: 6736.755859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 272\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.81531008e-08, 2.16621052e+04, 2.65125815e+04])\n",
      "best ll: 6790.2177734375, bestParams: [tensor(0.0322), tensor(710.5519), tensor(7698.5103)]\n",
      "epoch 39\n",
      " final_simplex: (array([[3.14484203e-02, 3.27942975e+02, 1.03600596e+04],\n",
      "       [3.14484210e-02, 3.27942971e+02, 1.03600595e+04],\n",
      "       [3.14484208e-02, 3.27942970e+02, 1.03600595e+04],\n",
      "       [3.14484205e-02, 3.27942967e+02, 1.03600596e+04]]), array([6729.84423828, 6729.84423828, 6729.84423828, 6729.84423828]))\n",
      "           fun: 6729.84423828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 250\n",
      "           nit: 92\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.14484203e-02, 3.27942975e+02, 1.03600596e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6734.38330078125, bestParams: [tensor(0.0629), tensor(105.5240), tensor(20130.3086)]\n",
      "epoch 38\n",
      " final_simplex: (array([[6.28776135e-02, 1.05735008e+02, 2.11352211e+04],\n",
      "       [6.28776138e-02, 1.05735007e+02, 2.11352211e+04],\n",
      "       [6.28776136e-02, 1.05735007e+02, 2.11352212e+04],\n",
      "       [6.28776138e-02, 1.05735007e+02, 2.11352211e+04]]), array([6724.03125, 6724.03125, 6724.03125, 6724.03125]))\n",
      "           fun: 6724.03125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 214\n",
      "           nit: 68\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.28776135e-02, 1.05735008e+02, 2.11352211e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6736.0283203125, bestParams: [tensor(0.0018), tensor(1315.4388), tensor(18455.3047)]\n",
      "epoch 37\n",
      " final_simplex: (array([[1.75683825e-03, 1.40204534e+03, 1.85494651e+04],\n",
      "       [1.75683825e-03, 1.40204534e+03, 1.85494652e+04],\n",
      "       [1.75683825e-03, 1.40204534e+03, 1.85494650e+04],\n",
      "       [1.75683824e-03, 1.40204535e+03, 1.85494652e+04]]), array([6735.25195312, 6735.25195312, 6735.25195312, 6735.25195312]))\n",
      "           fun: 6735.251953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 247\n",
      "           nit: 88\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.75683825e-03, 1.40204534e+03, 1.85494651e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6744.044921875, bestParams: [tensor(0.0128), tensor(1698.4178), tensor(20018.2324)]\n",
      "epoch 36\n",
      " final_simplex: (array([[1.25083529e-02, 1.44788498e+03, 2.32495472e+04],\n",
      "       [1.25083531e-02, 1.44788497e+03, 2.32495471e+04],\n",
      "       [1.25083530e-02, 1.44788497e+03, 2.32495471e+04],\n",
      "       [1.25083529e-02, 1.44788499e+03, 2.32495471e+04]]), array([6731.93945312, 6731.93945312, 6731.93945312, 6731.93945312]))\n",
      "           fun: 6731.939453125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 237\n",
      "           nit: 87\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.25083529e-02, 1.44788498e+03, 2.32495472e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6759.09765625, bestParams: [tensor(0.0014), tensor(12626.6719), tensor(14116.8398)]\n",
      "epoch 35\n",
      " final_simplex: (array([[1.99369758e-06, 7.22857992e+03, 2.94091230e+04],\n",
      "       [1.99369721e-06, 7.22857992e+03, 2.94091230e+04],\n",
      "       [1.99369766e-06, 7.22857993e+03, 2.94091229e+04],\n",
      "       [1.99369729e-06, 7.22857997e+03, 2.94091229e+04]]), array([6736.74414062, 6736.74414062, 6736.74414062, 6736.74414062]))\n",
      "           fun: 6736.744140625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 269\n",
      "           nit: 97\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.99369758e-06, 7.22857992e+03, 2.94091230e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[1.99369758e-06, 7.22857992e+03, 2.94091230e+04],\n",
      "       [1.99369721e-06, 7.22857992e+03, 2.94091230e+04],\n",
      "       [1.99369766e-06, 7.22857993e+03, 2.94091229e+04],\n",
      "       [1.99369729e-06, 7.22857997e+03, 2.94091229e+04]]), array([6736.74414062, 6736.74414062, 6736.74414062, 6736.74414062]))\n",
      "           fun: 6736.744140625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 269\n",
      "           nit: 97\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.99369758e-06, 7.22857992e+03, 2.94091230e+04])\n",
      "best ll: 6799.373046875, bestParams: [tensor(0.0035), tensor(14717.8896), tensor(11369.4414)]\n",
      "epoch 35\n",
      " final_simplex: (array([[2.92931614e-08, 1.77553271e+04, 1.74739375e+04],\n",
      "       [2.92930620e-08, 1.77553270e+04, 1.74739375e+04],\n",
      "       [2.92926564e-08, 1.77553270e+04, 1.74739375e+04],\n",
      "       [2.92926985e-08, 1.77553270e+04, 1.74739375e+04]]), array([6736.75585938, 6736.75585938, 6736.75585938, 6736.75585938]))\n",
      "           fun: 6736.755859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 284\n",
      "           nit: 93\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.92931614e-08, 1.77553271e+04, 1.74739375e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[2.92931614e-08, 1.77553271e+04, 1.74739375e+04],\n",
      "       [2.92930620e-08, 1.77553270e+04, 1.74739375e+04],\n",
      "       [2.92926564e-08, 1.77553270e+04, 1.74739375e+04],\n",
      "       [2.92926985e-08, 1.77553270e+04, 1.74739375e+04]]), array([6736.75585938, 6736.75585938, 6736.75585938, 6736.75585938]))\n",
      "           fun: 6736.755859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 284\n",
      "           nit: 93\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.92931614e-08, 1.77553271e+04, 1.74739375e+04])\n",
      "best ll: 6771.3916015625, bestParams: [tensor(0.0077), tensor(4491.0806), tensor(21248.1230)]\n",
      "epoch 35\n",
      " final_simplex: (array([[3.10092080e-03, 2.74703366e+03, 3.98192954e+04],\n",
      "       [3.10092078e-03, 2.74703366e+03, 3.98192955e+04],\n",
      "       [3.10092079e-03, 2.74703365e+03, 3.98192955e+04],\n",
      "       [3.10092080e-03, 2.74703366e+03, 3.98192954e+04]]), array([6733.43066406, 6733.43066406, 6733.43066406, 6733.43066406]))\n",
      "           fun: 6733.4306640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 285\n",
      "           nit: 106\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.10092080e-03, 2.74703366e+03, 3.98192954e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6678.08642578125, bestParams: [tensor(0.2348), tensor(146.2953), tensor(16509.0508)]\n",
      "epoch 34\n",
      " final_simplex: (array([[2.46495921e-01, 1.46295726e+02, 1.65089863e+04],\n",
      "       [2.46495921e-01, 1.46295729e+02, 1.65089863e+04],\n",
      "       [2.46495924e-01, 1.46295727e+02, 1.65089864e+04],\n",
      "       [2.46495911e-01, 1.46295726e+02, 1.65089864e+04]]), array([6670.20214844, 6670.20214844, 6670.20214844, 6670.20214844]))\n",
      "           fun: 6670.2021484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 200\n",
      "           nit: 63\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.46495921e-01, 1.46295726e+02, 1.65089863e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6738.228515625, bestParams: [tensor(0.0120), tensor(101.9992), tensor(17289.2500)]\n",
      "epoch 33\n",
      " final_simplex: (array([[1.20328362e-02, 1.09475955e+02, 1.65288446e+04],\n",
      "       [1.20328362e-02, 1.09475955e+02, 1.65288445e+04],\n",
      "       [1.20328361e-02, 1.09475955e+02, 1.65288445e+04],\n",
      "       [1.20328361e-02, 1.09475955e+02, 1.65288445e+04]]), array([6733.25878906, 6733.25878906, 6733.25878906, 6733.25878906]))\n",
      "           fun: 6733.2587890625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 244\n",
      "           nit: 82\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.20328362e-02, 1.09475955e+02, 1.65288446e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6805.8818359375, bestParams: [tensor(0.0035), tensor(19596.9082), tensor(6071.6812)]\n",
      "epoch 32\n",
      " final_simplex: (array([[2.03348418e-07, 2.62631765e+04, 9.46138306e+03],\n",
      "       [2.03348226e-07, 2.62631765e+04, 9.46138303e+03],\n",
      "       [2.03348548e-07, 2.62631764e+04, 9.46138314e+03],\n",
      "       [2.03347984e-07, 2.62631765e+04, 9.46138306e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 273\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.03348418e-07, 2.62631765e+04, 9.46138306e+03])\n",
      "Failed to converge\n",
      " final_simplex: (array([[2.03348418e-07, 2.62631765e+04, 9.46138306e+03],\n",
      "       [2.03348226e-07, 2.62631765e+04, 9.46138303e+03],\n",
      "       [2.03348548e-07, 2.62631764e+04, 9.46138314e+03],\n",
      "       [2.03347984e-07, 2.62631765e+04, 9.46138306e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 273\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.03348418e-07, 2.62631765e+04, 9.46138306e+03])\n",
      "best ll: 6793.33837890625, bestParams: [tensor(0.0052), tensor(7335.7842), tensor(16246.0615)]\n",
      "epoch 32\n",
      " final_simplex: (array([[2.50061616e-04, 4.63006117e+03, 2.97250143e+04],\n",
      "       [2.50061610e-04, 4.63006116e+03, 2.97250143e+04],\n",
      "       [2.50061596e-04, 4.63006116e+03, 2.97250142e+04],\n",
      "       [2.50061600e-04, 4.63006115e+03, 2.97250143e+04]]), array([6736.53613281, 6736.53613281, 6736.53613281, 6736.53613281]))\n",
      "           fun: 6736.5361328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 269\n",
      "           nit: 98\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.50061616e-04, 4.63006117e+03, 2.97250143e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6771.3359375, bestParams: [tensor(0.1173), tensor(626.4078), tensor(19204.6367)]\n",
      "epoch 31\n",
      " final_simplex: (array([[1.17458122e-01, 6.13048142e+02, 2.01617745e+04],\n",
      "       [1.17458121e-01, 6.13048144e+02, 2.01617745e+04],\n",
      "       [1.17458122e-01, 6.13048141e+02, 2.01617745e+04],\n",
      "       [1.17458122e-01, 6.13048141e+02, 2.01617746e+04]]), array([6718.52929688, 6718.52929688, 6718.52929688, 6718.52929688]))\n",
      "           fun: 6718.529296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 230\n",
      "           nit: 81\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.17458122e-01, 6.13048142e+02, 2.01617745e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6792.22998046875, bestParams: [tensor(0.0202), tensor(1667.5919), tensor(12785.4082)]\n",
      "epoch 30\n",
      " final_simplex: (array([[9.70848128e-03, 9.38038105e+02, 2.20021141e+04],\n",
      "       [9.70848128e-03, 9.38038100e+02, 2.20021142e+04],\n",
      "       [9.70848156e-03, 9.38038065e+02, 2.20021142e+04],\n",
      "       [9.70848156e-03, 9.38038108e+02, 2.20021140e+04]]), array([6731.50146484, 6731.50146484, 6731.50146484, 6731.50146484]))\n",
      "           fun: 6731.50146484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 261\n",
      "           nit: 107\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.70848128e-03, 9.38038105e+02, 2.20021141e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6915.0126953125, bestParams: [tensor(0.0091), tensor(12865.5566), tensor(4397.7188)]\n",
      "epoch 29\n",
      " final_simplex: (array([[1.06372207e-07, 1.72302590e+04, 6.89079658e+03],\n",
      "       [1.06372337e-07, 1.72302590e+04, 6.89079655e+03],\n",
      "       [1.06373034e-07, 1.72302590e+04, 6.89079650e+03],\n",
      "       [1.06373366e-07, 1.72302590e+04, 6.89079654e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 275\n",
      "           nit: 92\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.06372207e-07, 1.72302590e+04, 6.89079658e+03])\n",
      "Failed to converge\n",
      " final_simplex: (array([[1.06372207e-07, 1.72302590e+04, 6.89079658e+03],\n",
      "       [1.06372337e-07, 1.72302590e+04, 6.89079655e+03],\n",
      "       [1.06373034e-07, 1.72302590e+04, 6.89079650e+03],\n",
      "       [1.06373366e-07, 1.72302590e+04, 6.89079654e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 275\n",
      "           nit: 92\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.06372207e-07, 1.72302590e+04, 6.89079658e+03])\n",
      "best ll: 6740.1884765625, bestParams: [tensor(0.0201), tensor(956.6620), tensor(16576.9219)]\n",
      "epoch 29\n",
      " final_simplex: (array([[2.06563374e-02, 9.92094784e+02, 1.71908825e+04],\n",
      "       [2.06563379e-02, 9.92094768e+02, 1.71908826e+04],\n",
      "       [2.06563372e-02, 9.92094797e+02, 1.71908825e+04],\n",
      "       [2.06563371e-02, 9.92094794e+02, 1.71908825e+04]]), array([6731.91210938, 6731.91210938, 6731.91210938, 6731.91210938]))\n",
      "           fun: 6731.912109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 216\n",
      "           nit: 73\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.06563374e-02, 9.92094784e+02, 1.71908825e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6778.0, bestParams: [tensor(0.0271), tensor(1888.9285), tensor(20558.7578)]\n",
      "epoch 28\n",
      " final_simplex: (array([[1.97806031e-02, 1.81884774e+03, 2.91374769e+04],\n",
      "       [1.97806032e-02, 1.81884774e+03, 2.91374768e+04],\n",
      "       [1.97806031e-02, 1.81884774e+03, 2.91374769e+04],\n",
      "       [1.97806032e-02, 1.81884774e+03, 2.91374768e+04]]), array([6727.96679688, 6727.96679688, 6727.96679688, 6727.96679688]))\n",
      "           fun: 6727.966796875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 270\n",
      "           nit: 103\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.97806031e-02, 1.81884774e+03, 2.91374769e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6773.8984375, bestParams: [tensor(0.0153), tensor(2390.5522), tensor(17447.8086)]\n",
      "epoch 27\n",
      " final_simplex: (array([[9.29870867e-03, 2.03234388e+03, 2.64347573e+04],\n",
      "       [9.29870868e-03, 2.03234388e+03, 2.64347573e+04],\n",
      "       [9.29870862e-03, 2.03234388e+03, 2.64347573e+04],\n",
      "       [9.29870865e-03, 2.03234387e+03, 2.64347574e+04]]), array([6733.19580078, 6733.19580078, 6733.19580078, 6733.19580078]))\n",
      "           fun: 6733.19580078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 261\n",
      "           nit: 93\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.29870867e-03, 2.03234388e+03, 2.64347573e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6856.505859375, bestParams: [tensor(0.0063), tensor(18503.2070), tensor(9257.1172)]\n",
      "epoch 26\n",
      " final_simplex: (array([[5.15212437e-07, 2.48069857e+04, 1.43801810e+04],\n",
      "       [5.15212199e-07, 2.48069856e+04, 1.43801811e+04],\n",
      "       [5.15211972e-07, 2.48069857e+04, 1.43801810e+04],\n",
      "       [5.15212676e-07, 2.48069856e+04, 1.43801811e+04]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 277\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.15212437e-07, 2.48069857e+04, 1.43801810e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[5.15212437e-07, 2.48069857e+04, 1.43801810e+04],\n",
      "       [5.15212199e-07, 2.48069856e+04, 1.43801811e+04],\n",
      "       [5.15211972e-07, 2.48069857e+04, 1.43801810e+04],\n",
      "       [5.15212676e-07, 2.48069856e+04, 1.43801811e+04]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 277\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.15212437e-07, 2.48069857e+04, 1.43801810e+04])\n",
      "best ll: 6781.51513671875, bestParams: [tensor(0.0025), tensor(22318.9746), tensor(16297.7939)]\n",
      "epoch 26\n",
      " final_simplex: (array([[3.90152221e-07, 2.98355331e+04, 2.59004596e+04],\n",
      "       [3.90152187e-07, 2.98355332e+04, 2.59004595e+04],\n",
      "       [3.90152277e-07, 2.98355332e+04, 2.59004595e+04],\n",
      "       [3.90152186e-07, 2.98355332e+04, 2.59004595e+04]]), array([6736.76464844, 6736.76464844, 6736.76464844, 6736.76464844]))\n",
      "           fun: 6736.7646484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 299\n",
      "           nit: 96\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.90152221e-07, 2.98355331e+04, 2.59004596e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[3.90152221e-07, 2.98355331e+04, 2.59004596e+04],\n",
      "       [3.90152187e-07, 2.98355332e+04, 2.59004595e+04],\n",
      "       [3.90152277e-07, 2.98355332e+04, 2.59004595e+04],\n",
      "       [3.90152186e-07, 2.98355332e+04, 2.59004595e+04]]), array([6736.76464844, 6736.76464844, 6736.76464844, 6736.76464844]))\n",
      "           fun: 6736.7646484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 299\n",
      "           nit: 96\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.90152221e-07, 2.98355331e+04, 2.59004596e+04])\n",
      "best ll: 6768.56884765625, bestParams: [tensor(0.3596), tensor(171.0005), tensor(16670.0820)]\n",
      "epoch 26\n",
      " final_simplex: (array([[3.57636864e-01, 1.72760754e+02, 1.68629779e+04],\n",
      "       [3.57636863e-01, 1.72760754e+02, 1.68629780e+04],\n",
      "       [3.57636866e-01, 1.72760753e+02, 1.68629780e+04],\n",
      "       [3.57636860e-01, 1.72760755e+02, 1.68629780e+04]]), array([6622.09082031, 6622.09082031, 6622.09082031, 6622.09082031]))\n",
      "           fun: 6622.0908203125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 234\n",
      "           nit: 82\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.57636864e-01, 1.72760754e+02, 1.68629779e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6899.39990234375, bestParams: [tensor(0.0099), tensor(17142.1934), tensor(19825.8125)]\n",
      "epoch 25\n",
      " final_simplex: (array([[7.96601505e-07, 1.90584943e+04, 3.14504003e+04],\n",
      "       [7.96603024e-07, 1.90584943e+04, 3.14504003e+04],\n",
      "       [7.96601344e-07, 1.90584943e+04, 3.14504004e+04],\n",
      "       [7.96600324e-07, 1.90584944e+04, 3.14504002e+04]]), array([6736.76025391, 6736.76025391, 6736.76025391, 6736.76025391]))\n",
      "           fun: 6736.76025390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 278\n",
      "           nit: 104\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.96601505e-07, 1.90584943e+04, 3.14504003e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[7.96601505e-07, 1.90584943e+04, 3.14504003e+04],\n",
      "       [7.96603024e-07, 1.90584943e+04, 3.14504003e+04],\n",
      "       [7.96601344e-07, 1.90584943e+04, 3.14504004e+04],\n",
      "       [7.96600324e-07, 1.90584944e+04, 3.14504002e+04]]), array([6736.76025391, 6736.76025391, 6736.76025391, 6736.76025391]))\n",
      "           fun: 6736.76025390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 278\n",
      "           nit: 104\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.96601505e-07, 1.90584943e+04, 3.14504003e+04])\n",
      "best ll: 6748.48388671875, bestParams: [tensor(0.0010), tensor(11723.6133), tensor(19836.2949)]\n",
      "epoch 25\n",
      " final_simplex: (array([[1.16477200e-04, 4.98663165e+03, 4.81615921e+04],\n",
      "       [1.16477198e-04, 4.98663172e+03, 4.81615921e+04],\n",
      "       [1.16477193e-04, 4.98663172e+03, 4.81615920e+04],\n",
      "       [1.16477197e-04, 4.98663165e+03, 4.81615922e+04]]), array([6736.53759766, 6736.53759766, 6736.53759766, 6736.53759766]))\n",
      "           fun: 6736.53759765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 257\n",
      "           nit: 94\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.16477200e-04, 4.98663165e+03, 4.81615921e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6742.47705078125, bestParams: [tensor(0.0346), tensor(471.9428), tensor(9049.5459)]\n",
      "epoch 24\n",
      " final_simplex: (array([[3.55009966e-02, 4.37483998e+02, 9.94826549e+03],\n",
      "       [3.55009958e-02, 4.37483992e+02, 9.94826544e+03],\n",
      "       [3.55009976e-02, 4.37483981e+02, 9.94826555e+03],\n",
      "       [3.55009956e-02, 4.37484005e+02, 9.94826551e+03]]), array([6733.97851562, 6733.97851562, 6733.97851562, 6733.97851562]))\n",
      "           fun: 6733.978515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 210\n",
      "           nit: 74\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.55009966e-02, 4.37483998e+02, 9.94826549e+03])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6990.4423828125, bestParams: [tensor(0.0404), tensor(755.8662), tensor(4053.9985)]\n",
      "epoch 23\n",
      " final_simplex: (array([[9.03354169e-03, 4.06449557e+02, 8.16846563e+03],\n",
      "       [9.03354286e-03, 4.06449486e+02, 8.16846564e+03],\n",
      "       [9.03354179e-03, 4.06449551e+02, 8.16846565e+03],\n",
      "       [9.03354252e-03, 4.06449496e+02, 8.16846570e+03]]), array([6733.50976562, 6733.50976562, 6733.50976562, 6733.50976562]))\n",
      "           fun: 6733.509765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 246\n",
      "           nit: 98\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.03354169e-03, 4.06449557e+02, 8.16846563e+03])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 7042.32080078125, bestParams: [tensor(0.0176), tensor(12895.0762), tensor(12979.6064)]\n",
      "epoch 22\n",
      " final_simplex: (array([[7.81038214e-07, 1.55498075e+04, 1.99453366e+04],\n",
      "       [7.81037427e-07, 1.55498075e+04, 1.99453366e+04],\n",
      "       [7.81037626e-07, 1.55498075e+04, 1.99453366e+04],\n",
      "       [7.81039876e-07, 1.55498074e+04, 1.99453366e+04]]), array([6736.76220703, 6736.76220703, 6736.76220703, 6736.76220703]))\n",
      "           fun: 6736.76220703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 274\n",
      "           nit: 103\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.81038214e-07, 1.55498075e+04, 1.99453366e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[7.81038214e-07, 1.55498075e+04, 1.99453366e+04],\n",
      "       [7.81037427e-07, 1.55498075e+04, 1.99453366e+04],\n",
      "       [7.81037626e-07, 1.55498075e+04, 1.99453366e+04],\n",
      "       [7.81039876e-07, 1.55498074e+04, 1.99453366e+04]]), array([6736.76220703, 6736.76220703, 6736.76220703, 6736.76220703]))\n",
      "           fun: 6736.76220703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 274\n",
      "           nit: 103\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.81038214e-07, 1.55498075e+04, 1.99453366e+04])\n",
      "best ll: 6791.431640625, bestParams: [tensor(0.0028), tensor(13967.0049), tensor(4617.5293)]\n",
      "epoch 22\n",
      " final_simplex: (array([[1.43979507e-07, 1.90688878e+04, 7.10071627e+03],\n",
      "       [1.43979461e-07, 1.90688878e+04, 7.10071625e+03],\n",
      "       [1.43979950e-07, 1.90688879e+04, 7.10071628e+03],\n",
      "       [1.43979073e-07, 1.90688878e+04, 7.10071626e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 271\n",
      "           nit: 88\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.43979507e-07, 1.90688878e+04, 7.10071627e+03])\n",
      "Failed to converge\n",
      " final_simplex: (array([[1.43979507e-07, 1.90688878e+04, 7.10071627e+03],\n",
      "       [1.43979461e-07, 1.90688878e+04, 7.10071625e+03],\n",
      "       [1.43979950e-07, 1.90688879e+04, 7.10071628e+03],\n",
      "       [1.43979073e-07, 1.90688878e+04, 7.10071626e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 271\n",
      "           nit: 88\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.43979507e-07, 1.90688878e+04, 7.10071627e+03])\n",
      "best ll: 6808.802734375, bestParams: [tensor(0.2339), tensor(339.5902), tensor(15417.8574)]\n",
      "epoch 22\n",
      " final_simplex: (array([[2.29017102e-01, 3.44994967e+02, 1.60944090e+04],\n",
      "       [2.29017102e-01, 3.44994967e+02, 1.60944090e+04],\n",
      "       [2.29017102e-01, 3.44994966e+02, 1.60944091e+04],\n",
      "       [2.29017103e-01, 3.44994965e+02, 1.60944090e+04]]), array([6693.70117188, 6693.70117188, 6693.70117188, 6693.70117188]))\n",
      "           fun: 6693.701171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 251\n",
      "           nit: 86\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.29017102e-01, 3.44994967e+02, 1.60944090e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6765.6748046875, bestParams: [tensor(0.0017), tensor(15350.3672), tensor(14230.8311)]\n",
      "epoch 21\n",
      " final_simplex: (array([[1.57474499e-06, 1.13105653e+04, 2.83159959e+04],\n",
      "       [1.57474499e-06, 1.13105654e+04, 2.83159958e+04],\n",
      "       [1.57474503e-06, 1.13105654e+04, 2.83159958e+04],\n",
      "       [1.57474496e-06, 1.13105653e+04, 2.83159959e+04]]), array([6736.75341797, 6736.75341797, 6736.75341797, 6736.75341797]))\n",
      "           fun: 6736.75341796875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 276\n",
      "           nit: 89\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.57474499e-06, 1.13105653e+04, 2.83159959e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[1.57474499e-06, 1.13105653e+04, 2.83159959e+04],\n",
      "       [1.57474499e-06, 1.13105654e+04, 2.83159958e+04],\n",
      "       [1.57474503e-06, 1.13105654e+04, 2.83159958e+04],\n",
      "       [1.57474496e-06, 1.13105653e+04, 2.83159959e+04]]), array([6736.75341797, 6736.75341797, 6736.75341797, 6736.75341797]))\n",
      "           fun: 6736.75341796875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 276\n",
      "           nit: 89\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.57474499e-06, 1.13105653e+04, 2.83159959e+04])\n",
      "best ll: 6697.0927734375, bestParams: [tensor(0.4493), tensor(170.6117), tensor(23282.7461)]\n",
      "epoch 21\n",
      " final_simplex: (array([[4.68002679e-01, 1.72901586e+02, 2.25881303e+04],\n",
      "       [4.68002680e-01, 1.72901587e+02, 2.25881303e+04],\n",
      "       [4.68002682e-01, 1.72901582e+02, 2.25881303e+04],\n",
      "       [4.68002676e-01, 1.72901588e+02, 2.25881303e+04]]), array([6632.87988281, 6632.87988281, 6632.87988281, 6632.87988281]))\n",
      "           fun: 6632.8798828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 224\n",
      "           nit: 82\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.68002679e-01, 1.72901586e+02, 2.25881303e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6807.99072265625, bestParams: [tensor(0.0323), tensor(2015.3549), tensor(19740.2441)]\n",
      "epoch 20\n",
      " final_simplex: (array([[2.00017288e-02, 1.18740440e+03, 2.94204723e+04],\n",
      "       [2.00017285e-02, 1.18740440e+03, 2.94204724e+04],\n",
      "       [2.00017287e-02, 1.18740439e+03, 2.94204723e+04],\n",
      "       [2.00017286e-02, 1.18740440e+03, 2.94204723e+04]]), array([6720.61767578, 6720.61767578, 6720.61767578, 6720.61767578]))\n",
      "           fun: 6720.61767578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 278\n",
      "           nit: 107\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.00017288e-02, 1.18740440e+03, 2.94204723e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6772.47509765625, bestParams: [tensor(0.0018), tensor(13610.4795), tensor(3407.8862)]\n",
      "epoch 19\n",
      " final_simplex: (array([[2.80517270e-08, 1.86650757e+04, 5.25733835e+03],\n",
      "       [2.80515358e-08, 1.86650757e+04, 5.25733833e+03],\n",
      "       [2.80514493e-08, 1.86650757e+04, 5.25733834e+03],\n",
      "       [2.80517011e-08, 1.86650757e+04, 5.25733834e+03]]), array([6736.75634766, 6736.75634766, 6736.75634766, 6736.75634766]))\n",
      "           fun: 6736.75634765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 280\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.80517270e-08, 1.86650757e+04, 5.25733835e+03])\n",
      "Failed to converge\n",
      " final_simplex: (array([[2.80517270e-08, 1.86650757e+04, 5.25733835e+03],\n",
      "       [2.80515358e-08, 1.86650757e+04, 5.25733833e+03],\n",
      "       [2.80514493e-08, 1.86650757e+04, 5.25733834e+03],\n",
      "       [2.80517011e-08, 1.86650757e+04, 5.25733834e+03]]), array([6736.75634766, 6736.75634766, 6736.75634766, 6736.75634766]))\n",
      "           fun: 6736.75634765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 280\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.80517270e-08, 1.86650757e+04, 5.25733835e+03])\n",
      "best ll: 6815.65673828125, bestParams: [tensor(0.3495), tensor(113.8709), tensor(24734.4199)]\n",
      "epoch 19\n",
      " final_simplex: (array([[3.39427858e-01, 1.16746566e+02, 2.54233099e+04],\n",
      "       [3.39427858e-01, 1.16746567e+02, 2.54233099e+04],\n",
      "       [3.39427857e-01, 1.16746566e+02, 2.54233100e+04],\n",
      "       [3.39427856e-01, 1.16746566e+02, 2.54233099e+04]]), array([6684.21484375, 6684.21484375, 6684.21484375, 6684.21484375]))\n",
      "           fun: 6684.21484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 224\n",
      "           nit: 76\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.39427858e-01, 1.16746566e+02, 2.54233099e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6751.92236328125, bestParams: [tensor(0.1046), tensor(525.2759), tensor(16521.7246)]\n",
      "epoch 18\n",
      " final_simplex: (array([[1.05394356e-01, 5.16291608e+02, 1.64867378e+04],\n",
      "       [1.05394354e-01, 5.16291611e+02, 1.64867378e+04],\n",
      "       [1.05394351e-01, 5.16291613e+02, 1.64867378e+04],\n",
      "       [1.05394353e-01, 5.16291611e+02, 1.64867378e+04]]), array([6726.53417969, 6726.53417969, 6726.53417969, 6726.53417969]))\n",
      "           fun: 6726.5341796875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 223\n",
      "           nit: 77\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.05394356e-01, 5.16291608e+02, 1.64867378e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6734.46630859375, bestParams: [tensor(0.0713), tensor(161.2333), tensor(10458.2637)]\n",
      "epoch 17\n",
      " final_simplex: (array([[7.03078062e-02, 1.54199446e+02, 1.12588574e+04],\n",
      "       [7.03078083e-02, 1.54199446e+02, 1.12588575e+04],\n",
      "       [7.03078068e-02, 1.54199445e+02, 1.12588575e+04],\n",
      "       [7.03078090e-02, 1.54199447e+02, 1.12588574e+04]]), array([6723.74462891, 6723.74462891, 6723.74462891, 6723.74462891]))\n",
      "           fun: 6723.74462890625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 224\n",
      "           nit: 84\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.03078062e-02, 1.54199446e+02, 1.12588574e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6815.06884765625, bestParams: [tensor(0.0039), tensor(16797.6367), tensor(154.5027)]\n",
      "epoch 16\n",
      " final_simplex: (array([[4.68200314e-07, 2.29400080e+04, 2.37637701e+02],\n",
      "       [4.68200039e-07, 2.29400080e+04, 2.37637701e+02],\n",
      "       [4.68199939e-07, 2.29400079e+04, 2.37637700e+02],\n",
      "       [4.68200268e-07, 2.29400079e+04, 2.37637701e+02]]), array([6736.765625, 6736.765625, 6736.765625, 6736.765625]))\n",
      "           fun: 6736.765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 280\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.68200314e-07, 2.29400080e+04, 2.37637701e+02])\n",
      "Failed to converge\n",
      " final_simplex: (array([[4.68200314e-07, 2.29400080e+04, 2.37637701e+02],\n",
      "       [4.68200039e-07, 2.29400080e+04, 2.37637701e+02],\n",
      "       [4.68199939e-07, 2.29400079e+04, 2.37637700e+02],\n",
      "       [4.68200268e-07, 2.29400079e+04, 2.37637701e+02]]), array([6736.765625, 6736.765625, 6736.765625, 6736.765625]))\n",
      "           fun: 6736.765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 280\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.68200314e-07, 2.29400080e+04, 2.37637701e+02])\n",
      "best ll: 6821.998046875, bestParams: [tensor(0.0044), tensor(19142.6582), tensor(5568.0332)]\n",
      "epoch 16\n",
      " final_simplex: (array([[2.23118502e-07, 2.61351095e+04, 8.56237642e+03],\n",
      "       [2.23118455e-07, 2.61351095e+04, 8.56237640e+03],\n",
      "       [2.23118298e-07, 2.61351095e+04, 8.56237641e+03],\n",
      "       [2.23118734e-07, 2.61351095e+04, 8.56237642e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 282\n",
      "           nit: 93\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.23118502e-07, 2.61351095e+04, 8.56237642e+03])\n",
      "Failed to converge\n",
      " final_simplex: (array([[2.23118502e-07, 2.61351095e+04, 8.56237642e+03],\n",
      "       [2.23118455e-07, 2.61351095e+04, 8.56237640e+03],\n",
      "       [2.23118298e-07, 2.61351095e+04, 8.56237641e+03],\n",
      "       [2.23118734e-07, 2.61351095e+04, 8.56237642e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 282\n",
      "           nit: 93\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.23118502e-07, 2.61351095e+04, 8.56237642e+03])\n",
      "best ll: 6713.08349609375, bestParams: [tensor(0.4762), tensor(122.3544), tensor(16862.6777)]\n",
      "epoch 16\n",
      " final_simplex: (array([[4.92984824e-01, 1.23996770e+02, 1.64889412e+04],\n",
      "       [4.92984826e-01, 1.23996770e+02, 1.64889412e+04],\n",
      "       [4.92984857e-01, 1.23996769e+02, 1.64889412e+04],\n",
      "       [4.92984839e-01, 1.23996770e+02, 1.64889411e+04]]), array([6597.95800781, 6597.95800781, 6597.95800781, 6597.95800781]))\n",
      "           fun: 6597.9580078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 211\n",
      "           nit: 72\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.92984824e-01, 1.23996770e+02, 1.64889412e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6844.04248046875, bestParams: [tensor(0.0145), tensor(3457.7136), tensor(13314.3857)]\n",
      "epoch 15\n",
      " final_simplex: (array([[1.17076734e-02, 1.14023947e+03, 2.14621481e+04],\n",
      "       [1.17076734e-02, 1.14023947e+03, 2.14621480e+04],\n",
      "       [1.17076734e-02, 1.14023947e+03, 2.14621480e+04],\n",
      "       [1.17076733e-02, 1.14023945e+03, 2.14621482e+04]]), array([6731.56884766, 6731.56884766, 6731.56884766, 6731.56884766]))\n",
      "           fun: 6731.56884765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 271\n",
      "           nit: 99\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.17076734e-02, 1.14023947e+03, 2.14621481e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6767.763671875, bestParams: [tensor(0.0021), tensor(13111.5186), tensor(16363.8662)]\n",
      "epoch 14\n",
      " final_simplex: (array([[1.97479993e-06, 7.35266873e+03, 3.04724353e+04],\n",
      "       [1.97480014e-06, 7.35266873e+03, 3.04724353e+04],\n",
      "       [1.97480204e-06, 7.35266875e+03, 3.04724354e+04],\n",
      "       [1.97480028e-06, 7.35266877e+03, 3.04724354e+04]]), array([6736.74462891, 6736.74462891, 6736.74462891, 6736.74462891]))\n",
      "           fun: 6736.74462890625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 268\n",
      "           nit: 92\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.97479993e-06, 7.35266873e+03, 3.04724353e+04])\n",
      "Failed to converge\n",
      " final_simplex: (array([[1.97479993e-06, 7.35266873e+03, 3.04724353e+04],\n",
      "       [1.97480014e-06, 7.35266873e+03, 3.04724353e+04],\n",
      "       [1.97480204e-06, 7.35266875e+03, 3.04724354e+04],\n",
      "       [1.97480028e-06, 7.35266877e+03, 3.04724354e+04]]), array([6736.74462891, 6736.74462891, 6736.74462891, 6736.74462891]))\n",
      "           fun: 6736.74462890625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 268\n",
      "           nit: 92\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.97479993e-06, 7.35266873e+03, 3.04724353e+04])\n",
      "best ll: 6737.07421875, bestParams: [tensor(0.0004), tensor(4321.5337), tensor(23325.2734)]\n",
      "epoch 14\n",
      " final_simplex: (array([[4.27485227e-04, 3.31209011e+03, 2.76652224e+04],\n",
      "       [4.27485227e-04, 3.31209011e+03, 2.76652223e+04],\n",
      "       [4.27485227e-04, 3.31209009e+03, 2.76652224e+04],\n",
      "       [4.27485226e-04, 3.31209009e+03, 2.76652224e+04]]), array([6736.33447266, 6736.33447266, 6736.33447266, 6736.33447266]))\n",
      "           fun: 6736.33447265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 261\n",
      "           nit: 100\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.27485227e-04, 3.31209011e+03, 2.76652224e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6767.9423828125, bestParams: [tensor(0.0074), tensor(3337.9468), tensor(16194.3662)]\n",
      "epoch 13\n",
      " final_simplex: (array([[2.25992769e-03, 1.19958932e+03, 2.75614809e+04],\n",
      "       [2.25992770e-03, 1.19958932e+03, 2.75614809e+04],\n",
      "       [2.25992776e-03, 1.19958933e+03, 2.75614808e+04],\n",
      "       [2.25992773e-03, 1.19958933e+03, 2.75614809e+04]]), array([6734.89160156, 6734.89160156, 6734.89160156, 6734.89160156]))\n",
      "           fun: 6734.8916015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 273\n",
      "           nit: 106\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.25992769e-03, 1.19958932e+03, 2.75614809e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6740.3837890625, bestParams: [tensor(0.0003), tensor(19460.9902), tensor(24803.1055)]\n",
      "epoch 12\n",
      " final_simplex: (array([[1.85364856e-04, 1.31920887e+03, 4.82948594e+04],\n",
      "       [1.85364856e-04, 1.31920883e+03, 4.82948594e+04],\n",
      "       [1.85364856e-04, 1.31920881e+03, 4.82948594e+04],\n",
      "       [1.85364856e-04, 1.31920886e+03, 4.82948594e+04]]), array([6736.55224609, 6736.55224609, 6736.55224609, 6736.55224609]))\n",
      "           fun: 6736.55224609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 284\n",
      "           nit: 103\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.85364856e-04, 1.31920887e+03, 4.82948594e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6705.859375, bestParams: [tensor(0.2070), tensor(207.3891), tensor(14924.3496)]\n",
      "epoch 11\n",
      " final_simplex: (array([[2.12881144e-01, 2.02703052e+02, 1.50947425e+04],\n",
      "       [2.12881145e-01, 2.02703049e+02, 1.50947425e+04],\n",
      "       [2.12881145e-01, 2.02703057e+02, 1.50947425e+04],\n",
      "       [2.12881146e-01, 2.02703050e+02, 1.50947425e+04]]), array([6673.03662109, 6673.03662109, 6673.03662109, 6673.03662109]))\n",
      "           fun: 6673.03662109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 212\n",
      "           nit: 73\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.12881144e-01, 2.02703052e+02, 1.50947425e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6739.01806640625, bestParams: [tensor(0.0002), tensor(9514.4326), tensor(16073.1387)]\n",
      "epoch 10\n",
      " final_simplex: (array([[1.63094676e-04, 2.87528140e+03, 2.84231015e+04],\n",
      "       [1.63094680e-04, 2.87528147e+03, 2.84231015e+04],\n",
      "       [1.63094677e-04, 2.87528148e+03, 2.84231014e+04],\n",
      "       [1.63094676e-04, 2.87528140e+03, 2.84231014e+04]]), array([6736.546875, 6736.546875, 6736.546875, 6736.546875]))\n",
      "           fun: 6736.546875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 262\n",
      "           nit: 99\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.63094676e-04, 2.87528140e+03, 2.84231015e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6740.8642578125, bestParams: [tensor(0.0016), tensor(3002.2900), tensor(13813.4941)]\n",
      "epoch 9\n",
      " final_simplex: (array([[1.19173428e-03, 1.46018901e+03, 2.29583086e+04],\n",
      "       [1.19173428e-03, 1.46018901e+03, 2.29583086e+04],\n",
      "       [1.19173429e-03, 1.46018899e+03, 2.29583087e+04],\n",
      "       [1.19173429e-03, 1.46018900e+03, 2.29583086e+04]]), array([6735.72851562, 6735.72851562, 6735.72851562, 6735.72851562]))\n",
      "           fun: 6735.728515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 269\n",
      "           nit: 101\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.19173428e-03, 1.46018901e+03, 2.29583086e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6723.01220703125, bestParams: [tensor(0.2796), tensor(205.3320), tensor(21052.7695)]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.87038411e-01, 2.02724390e+02, 2.14924381e+04],\n",
      "       [2.87038411e-01, 2.02724390e+02, 2.14924380e+04],\n",
      "       [2.87038410e-01, 2.02724391e+02, 2.14924381e+04],\n",
      "       [2.87038403e-01, 2.02724395e+02, 2.14924381e+04]]), array([6657.45703125, 6657.45703125, 6657.45703125, 6657.45703125]))\n",
      "           fun: 6657.45703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 230\n",
      "           nit: 84\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.87038411e-01, 2.02724390e+02, 2.14924381e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6743.9599609375, bestParams: [tensor(0.0053), tensor(2585.8777), tensor(19285.2871)]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.75166983e-03, 1.45371805e+03, 2.79422603e+04],\n",
      "       [3.75166984e-03, 1.45371806e+03, 2.79422602e+04],\n",
      "       [3.75166984e-03, 1.45371806e+03, 2.79422602e+04],\n",
      "       [3.75166983e-03, 1.45371804e+03, 2.79422603e+04]]), array([6732.75683594, 6732.75683594, 6732.75683594, 6732.75683594]))\n",
      "           fun: 6732.7568359375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 286\n",
      "           nit: 106\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.75166983e-03, 1.45371805e+03, 2.79422603e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6714.94091796875, bestParams: [tensor(0.4268), tensor(132.7256), tensor(15954.1504)]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.41484768e-01, 1.33357625e+02, 1.54330771e+04],\n",
      "       [4.41484768e-01, 1.33357623e+02, 1.54330772e+04],\n",
      "       [4.41484772e-01, 1.33357622e+02, 1.54330772e+04],\n",
      "       [4.41484768e-01, 1.33357623e+02, 1.54330771e+04]]), array([6629.00390625, 6629.00390625, 6629.00390625, 6629.00390625]))\n",
      "           fun: 6629.00390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 224\n",
      "           nit: 79\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.41484768e-01, 1.33357625e+02, 1.54330771e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6673.611328125, bestParams: [tensor(0.2736), tensor(232.2219), tensor(23298.3574)]\n",
      "epoch 5\n",
      " final_simplex: (array([[2.82816202e-01, 2.30068362e+02, 2.35006889e+04],\n",
      "       [2.82816202e-01, 2.30068363e+02, 2.35006889e+04],\n",
      "       [2.82816201e-01, 2.30068363e+02, 2.35006889e+04],\n",
      "       [2.82816201e-01, 2.30068363e+02, 2.35006889e+04]]), array([6657.2578125, 6657.2578125, 6657.2578125, 6657.2578125]))\n",
      "           fun: 6657.2578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 237\n",
      "           nit: 84\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.82816202e-01, 2.30068362e+02, 2.35006889e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6776.50244140625, bestParams: [tensor(0.0031), tensor(14816.4336), tensor(24936.3262)]\n",
      "epoch 4\n",
      " final_simplex: (array([[1.89272674e-04, 9.52686095e+03, 4.91249513e+04],\n",
      "       [1.89272664e-04, 9.52686092e+03, 4.91249513e+04],\n",
      "       [1.89272671e-04, 9.52686096e+03, 4.91249512e+04],\n",
      "       [1.89272664e-04, 9.52686090e+03, 4.91249513e+04]]), array([6736.61914062, 6736.61914062, 6736.61914062, 6736.61914062]))\n",
      "           fun: 6736.619140625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 282\n",
      "           nit: 109\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.89272674e-04, 9.52686095e+03, 4.91249513e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6774.36572265625, bestParams: [tensor(0.0019), tensor(12271.3691), tensor(2182.7410)]\n",
      "epoch 3\n",
      " final_simplex: (array([[6.97461717e-09, 1.66986871e+04, 3.34868383e+03],\n",
      "       [6.97453562e-09, 1.66986870e+04, 3.34868382e+03],\n",
      "       [6.97538424e-09, 1.66986870e+04, 3.34868382e+03],\n",
      "       [6.97549326e-09, 1.66986871e+04, 3.34868384e+03]]), array([6736.75634766, 6736.75634766, 6736.75634766, 6736.75634766]))\n",
      "           fun: 6736.75634765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 268\n",
      "           nit: 87\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.97461717e-09, 1.66986871e+04, 3.34868383e+03])\n",
      "Failed to converge\n",
      " final_simplex: (array([[6.97461717e-09, 1.66986871e+04, 3.34868383e+03],\n",
      "       [6.97453562e-09, 1.66986870e+04, 3.34868382e+03],\n",
      "       [6.97538424e-09, 1.66986870e+04, 3.34868382e+03],\n",
      "       [6.97549326e-09, 1.66986871e+04, 3.34868384e+03]]), array([6736.75634766, 6736.75634766, 6736.75634766, 6736.75634766]))\n",
      "           fun: 6736.75634765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 268\n",
      "           nit: 87\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.97461717e-09, 1.66986871e+04, 3.34868383e+03])\n",
      "best ll: 6758.18212890625, bestParams: [tensor(0.0047), tensor(1929.5247), tensor(8334.7236)]\n",
      "epoch 3\n",
      " final_simplex: (array([[1.74176766e-03, 9.06734295e+02, 1.38749511e+04],\n",
      "       [1.74176760e-03, 9.06734294e+02, 1.38749511e+04],\n",
      "       [1.74176762e-03, 9.06734321e+02, 1.38749510e+04],\n",
      "       [1.74176757e-03, 9.06734320e+02, 1.38749511e+04]]), array([6735.56835938, 6735.56835938, 6735.56835938, 6735.56835938]))\n",
      "           fun: 6735.568359375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 256\n",
      "           nit: 99\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.74176766e-03, 9.06734295e+02, 1.38749511e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6800.8916015625, bestParams: [tensor(0.0032), tensor(21061.7383), tensor(3580.9729)]\n",
      "epoch 2\n",
      " final_simplex: (array([[6.75324562e-08, 2.87455054e+04, 5.50544479e+03],\n",
      "       [6.75329570e-08, 2.87455055e+04, 5.50544480e+03],\n",
      "       [6.75329319e-08, 2.87455054e+04, 5.50544480e+03],\n",
      "       [6.75332399e-08, 2.87455054e+04, 5.50544480e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 278\n",
      "           nit: 93\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.75324562e-08, 2.87455054e+04, 5.50544479e+03])\n",
      "Failed to converge\n",
      " final_simplex: (array([[6.75324562e-08, 2.87455054e+04, 5.50544479e+03],\n",
      "       [6.75329570e-08, 2.87455055e+04, 5.50544480e+03],\n",
      "       [6.75329319e-08, 2.87455054e+04, 5.50544480e+03],\n",
      "       [6.75332399e-08, 2.87455054e+04, 5.50544480e+03]]), array([6736.76513672, 6736.76513672, 6736.76513672, 6736.76513672]))\n",
      "           fun: 6736.76513671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 278\n",
      "           nit: 93\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.75324562e-08, 2.87455054e+04, 5.50544479e+03])\n",
      "best ll: 6741.34814453125, bestParams: [tensor(0.0030), tensor(1248.6786), tensor(7497.8955)]\n",
      "epoch 2\n",
      " final_simplex: (array([[2.68884736e-03, 6.73057056e+02, 1.04282434e+04],\n",
      "       [2.68884740e-03, 6.73057013e+02, 1.04282433e+04],\n",
      "       [2.68884735e-03, 6.73057054e+02, 1.04282433e+04],\n",
      "       [2.68884736e-03, 6.73057001e+02, 1.04282434e+04]]), array([6735.27148438, 6735.27148438, 6735.27148438, 6735.27148438]))\n",
      "           fun: 6735.271484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 231\n",
      "           nit: 82\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.68884736e-03, 6.73057056e+02, 1.04282434e+04])\n",
      "minPrevious 6584.4384765625\n",
      "best ll: 6743.89404296875, bestParams: [tensor(0.0118), tensor(1479.9531), tensor(15588.9092)]\n",
      "epoch 1\n",
      " final_simplex: (array([[1.16261368e-02, 1.47689461e+03, 1.60275444e+04],\n",
      "       [1.16261368e-02, 1.47689462e+03, 1.60275443e+04],\n",
      "       [1.16261368e-02, 1.47689462e+03, 1.60275444e+04],\n",
      "       [1.16261368e-02, 1.47689462e+03, 1.60275444e+04]]), array([6740.12695312, 6740.12695312, 6740.12695312, 6740.12695312]))\n",
      "           fun: 6740.126953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 249\n",
      "           nit: 90\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.16261368e-02, 1.47689461e+03, 1.60275444e+04])\n",
      "minPrevious 6584.4384765625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lls': [6730.54541015625,\n",
       "  6725.232421875,\n",
       "  6713.66015625,\n",
       "  6684.1259765625,\n",
       "  6681.078125,\n",
       "  6678.58447265625,\n",
       "  6644.66845703125,\n",
       "  6584.4384765625],\n",
       " 'params': [array([4.99989276e-03, 2.41928302e+03, 3.56125064e+04]),\n",
       "  array([2.88330920e-02, 7.43513914e+02, 2.23945308e+04]),\n",
       "  array([8.94077878e-02, 5.72665107e+02, 2.23863651e+04]),\n",
       "  array([1.76929293e-01, 1.66514334e+02, 1.94480228e+04]),\n",
       "  array([2.80477590e-01, 4.90093134e+02, 2.64054178e+04]),\n",
       "  array([2.59454750e-01, 4.20987613e+02, 2.06935771e+04]),\n",
       "  array([3.72459492e-01, 1.68877903e+02, 1.95457448e+04]),\n",
       "  array([4.53185343e-01, 2.23307950e+02, 2.52700651e+04])],\n",
       " 'llTrajectory': [6730.54541015625,\n",
       "  6725.232421875,\n",
       "  6731.3896484375,\n",
       "  6726.44921875,\n",
       "  6713.66015625,\n",
       "  6684.1259765625,\n",
       "  6714.53076171875,\n",
       "  6732.8486328125,\n",
       "  6681.078125,\n",
       "  6711.27978515625,\n",
       "  6828.6435546875,\n",
       "  6735.7763671875,\n",
       "  6733.154296875,\n",
       "  6678.58447265625,\n",
       "  6735.52734375,\n",
       "  6729.25146484375,\n",
       "  6710.189453125,\n",
       "  6644.66845703125,\n",
       "  6584.4384765625,\n",
       "  6697.6142578125,\n",
       "  6594.46337890625,\n",
       "  6708.27001953125,\n",
       "  6700.83447265625,\n",
       "  6721.91162109375,\n",
       "  6664.36376953125,\n",
       "  6725.97509765625,\n",
       "  6729.830078125,\n",
       "  6744.0654296875,\n",
       "  6590.43994140625,\n",
       "  6735.0,\n",
       "  6745.39208984375,\n",
       "  6734.03955078125,\n",
       "  6723.2880859375,\n",
       "  6612.3759765625,\n",
       "  6722.90625,\n",
       "  6719.2607421875,\n",
       "  6635.8154296875,\n",
       "  6736.26953125,\n",
       "  6637.4345703125,\n",
       "  6719.7685546875,\n",
       "  6728.859375,\n",
       "  6734.9072265625,\n",
       "  6732.6669921875,\n",
       "  6719.87646484375,\n",
       "  6681.51708984375,\n",
       "  6736.2880859375,\n",
       "  6687.89404296875,\n",
       "  6734.32861328125,\n",
       "  6733.32275390625,\n",
       "  6645.013671875,\n",
       "  6646.42578125,\n",
       "  6720.31884765625,\n",
       "  6737.6572265625,\n",
       "  6736.33203125,\n",
       "  6730.22802734375,\n",
       "  6706.8447265625,\n",
       "  6734.44775390625,\n",
       "  6639.99951171875,\n",
       "  6733.041015625,\n",
       "  6667.61669921875,\n",
       "  6739.62109375,\n",
       "  6729.84423828125,\n",
       "  6724.03125,\n",
       "  6735.251953125,\n",
       "  6731.939453125,\n",
       "  6733.4306640625,\n",
       "  6670.2021484375,\n",
       "  6733.2587890625,\n",
       "  6736.5361328125,\n",
       "  6718.529296875,\n",
       "  6731.50146484375,\n",
       "  6731.912109375,\n",
       "  6727.966796875,\n",
       "  6733.19580078125,\n",
       "  6622.0908203125,\n",
       "  6736.53759765625,\n",
       "  6733.978515625,\n",
       "  6733.509765625,\n",
       "  6693.701171875,\n",
       "  6632.8798828125,\n",
       "  6720.61767578125,\n",
       "  6684.21484375,\n",
       "  6726.5341796875,\n",
       "  6723.74462890625,\n",
       "  6597.9580078125,\n",
       "  6731.56884765625,\n",
       "  6736.33447265625,\n",
       "  6734.8916015625,\n",
       "  6736.55224609375,\n",
       "  6673.03662109375,\n",
       "  6736.546875,\n",
       "  6735.728515625,\n",
       "  6657.45703125,\n",
       "  6732.7568359375,\n",
       "  6629.00390625,\n",
       "  6657.2578125,\n",
       "  6736.619140625,\n",
       "  6735.568359375,\n",
       "  6735.271484375,\n",
       "  6740.126953125]}"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR2, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR2Shape5, pDs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0088)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Beta(2.23307950e+02, 2.52700651e+04).sample([10_000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0008)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Beta(2.20865706e+02, 1.73544747e+04).sample([10_000,]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lls': [7355.49267578125,\n",
       "  7333.8359375,\n",
       "  7300.3642578125,\n",
       "  7281.3369140625,\n",
       "  7238.92529296875],\n",
       " 'params': [array([9.66787834e-03, 1.42133762e+03, 2.15332299e+04]),\n",
       "  array([6.31166028e-02, 9.84300518e+02, 1.84012287e+04]),\n",
       "  array([4.62429754e-01, 1.02643266e+02, 9.81715662e+03]),\n",
       "  array([2.25484731e-01, 5.18447344e+02, 2.35247035e+04]),\n",
       "  array([3.62738958e-01, 2.50432693e+02, 1.87756988e+04])],\n",
       " 'llTrajectory': [7355.49267578125,\n",
       "  7485.82177734375,\n",
       "  7355.57861328125,\n",
       "  7354.6181640625,\n",
       "  7333.8359375,\n",
       "  7359.93212890625,\n",
       "  7358.654296875,\n",
       "  7338.5205078125,\n",
       "  7335.873046875,\n",
       "  7352.79296875,\n",
       "  7334.01708984375,\n",
       "  7333.89111328125,\n",
       "  7300.3642578125,\n",
       "  7281.3369140625,\n",
       "  7238.92529296875,\n",
       "  7362.92041015625,\n",
       "  7305.7060546875,\n",
       "  7261.984375,\n",
       "  7366.9189453125,\n",
       "  7369.890625,\n",
       "  7339.08740234375,\n",
       "  7370.15283203125,\n",
       "  7335.2919921875,\n",
       "  7261.0712890625,\n",
       "  7351.4765625,\n",
       "  7377.07080078125,\n",
       "  7343.87451171875,\n",
       "  7336.4501953125,\n",
       "  7331.4619140625,\n",
       "  7305.3583984375,\n",
       "  7354.21630859375,\n",
       "  7360.92822265625,\n",
       "  7313.125,\n",
       "  7316.19775390625,\n",
       "  7320.7587890625,\n",
       "  7356.9384765625,\n",
       "  7336.20703125,\n",
       "  7346.087890625,\n",
       "  7308.03076171875,\n",
       "  7352.8583984375,\n",
       "  7331.8740234375,\n",
       "  7372.35400390625,\n",
       "  7362.845703125,\n",
       "  7362.5966796875,\n",
       "  7326.6357421875,\n",
       "  7341.623046875,\n",
       "  7300.40771484375,\n",
       "  7308.861328125,\n",
       "  7355.49462890625,\n",
       "  7308.0390625]}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGeneRR3, pDs, nEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0132)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Beta(2.50432693e+02, 1.87756988e+04).sample([10_000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lls': [7340.373046875], 'params': [array([0.08547521, 0.03181683])]}"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitFnUniveriate(altCountsByGeneRR3, pDs, nEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0159)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Beta(3.84376856e+02, 2.37879954e+04).sample([10_000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsRR2Shape5 = []\n",
    "for i in range(1):\n",
    "    res = fitFnUniveriateBetaBinomial(altCountsByGeneRR2Shape5, pDs, nEpochs=50, minLLThresholdCount=50, debug=False)\n",
    "    resultsRR2Shape5.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lls': [6817.6005859375, 6814.3828125],\n",
       "  'params': [array([2.34587560e-01, 1.99969552e+02, 1.61202184e+04]),\n",
       "   array([3.28159124e-01, 2.66578908e+02, 2.01303242e+04])],\n",
       "  'llTrajectory': [6817.6005859375,\n",
       "   6903.1416015625,\n",
       "   6885.47021484375,\n",
       "   6833.05908203125,\n",
       "   6912.18115234375,\n",
       "   6868.33837890625,\n",
       "   6889.697265625,\n",
       "   6895.404296875,\n",
       "   6903.62353515625,\n",
       "   6876.1875,\n",
       "   6882.2685546875,\n",
       "   6852.44189453125,\n",
       "   6898.1982421875,\n",
       "   6897.2275390625,\n",
       "   6901.4296875,\n",
       "   6904.9931640625,\n",
       "   6942.68408203125,\n",
       "   6875.3408203125,\n",
       "   6914.2236328125,\n",
       "   6882.2197265625,\n",
       "   6899.33251953125,\n",
       "   6902.41650390625,\n",
       "   6868.17822265625,\n",
       "   6866.6064453125,\n",
       "   6893.92626953125,\n",
       "   6821.7998046875,\n",
       "   6911.041015625,\n",
       "   6907.1181640625,\n",
       "   6814.3828125,\n",
       "   6899.52587890625,\n",
       "   6827.578125,\n",
       "   6896.44140625,\n",
       "   6846.3251953125,\n",
       "   6889.94970703125,\n",
       "   6850.04296875,\n",
       "   6878.6787109375,\n",
       "   6903.27978515625,\n",
       "   6902.85498046875,\n",
       "   6905.4462890625,\n",
       "   6900.25439453125,\n",
       "   6860.58740234375,\n",
       "   6905.4443359375,\n",
       "   6876.85302734375,\n",
       "   6910.56591796875,\n",
       "   6882.13818359375,\n",
       "   6914.1005859375,\n",
       "   6898.4892578125,\n",
       "   6908.3154296875,\n",
       "   6914.37890625,\n",
       "   6839.86962890625]}]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsRR2Shape5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0120)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Beta(1.96912591e+02, 1.61461738e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lls': [10124.2939453125,\n",
       "  10066.521484375,\n",
       "  10063.009765625,\n",
       "  10059.4296875,\n",
       "  10053.1123046875,\n",
       "  10043.328125,\n",
       "  9996.23828125],\n",
       " 'params': [array([1.19730032e-01, 2.81320565e+03, 1.94763629e+04]),\n",
       "  array([8.79649187e-02, 1.00275498e+03, 8.87885867e+03]),\n",
       "  array([8.88721415e-02, 1.18696574e+03, 9.43838963e+03]),\n",
       "  array([8.03672363e-02, 3.29971747e+03, 2.29027703e+04]),\n",
       "  array([8.19716447e-02, 2.30129681e+03, 2.02745043e+04]),\n",
       "  array([9.86181399e-02, 1.58579542e+03, 1.51586491e+04]),\n",
       "  array([1.09034962e-01, 3.30289057e+03, 2.94460355e+04])],\n",
       " 'llTrajectory': [10124.2939453125,\n",
       "  10066.521484375,\n",
       "  10129.74609375,\n",
       "  10127.625,\n",
       "  10149.1748046875,\n",
       "  10063.009765625,\n",
       "  10059.4296875,\n",
       "  10083.16015625,\n",
       "  10247.310546875,\n",
       "  10064.158203125,\n",
       "  10064.521484375,\n",
       "  10053.1123046875,\n",
       "  10071.951171875,\n",
       "  10121.005859375,\n",
       "  10066.048828125,\n",
       "  10043.328125,\n",
       "  10064.9033203125,\n",
       "  10202.591796875,\n",
       "  10096.3046875,\n",
       "  9996.23828125,\n",
       "  10166.6201171875,\n",
       "  10045.0927734375,\n",
       "  10166.4736328125,\n",
       "  10209.552734375,\n",
       "  10058.7587890625,\n",
       "  10091.7646484375,\n",
       "  10050.455078125,\n",
       "  10246.322265625,\n",
       "  10085.4091796875,\n",
       "  10061.1337890625,\n",
       "  10080.2236328125,\n",
       "  10055.775390625,\n",
       "  10196.751953125,\n",
       "  10268.2294921875,\n",
       "  10036.1083984375,\n",
       "  10064.146484375,\n",
       "  10069.0830078125,\n",
       "  10040.5625,\n",
       "  10066.337890625,\n",
       "  10064.96875,\n",
       "  10231.9580078125,\n",
       "  10078.4609375,\n",
       "  10109.939453125,\n",
       "  10158.822265625,\n",
       "  10068.9814453125,\n",
       "  10138.79296875,\n",
       "  10085.1826171875,\n",
       "  10045.80859375,\n",
       "  10047.1806640625,\n",
       "  10130.9580078125]}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=50, minLLThresholdCount=50, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1009)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Beta(3.30289057e+03, 2.94460355e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't really work resConstrained = fitFnUniveriateBetaBinomialConstrained(altCountsByGeneRR2Shape5, pDs, nEpochs=10, minLLThresholdCount=10, debug=True)\n",
    "#resConstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lls': [9942.6953125, 9931.8056640625, 9918.7255859375, 9913.626953125],\n",
       " 'params': [array([7.04979495e-02, 9.26033106e+02, 6.94024613e+03]),\n",
       "  array([8.31190609e-02, 1.01507705e+03, 7.34901877e+03]),\n",
       "  array([6.36296139e-02, 2.47790499e+03, 1.77108614e+04]),\n",
       "  array([7.14476610e-02, 2.44224478e+03, 1.85504643e+04])],\n",
       " 'llTrajectory': [9942.6953125,\n",
       "  9931.8056640625,\n",
       "  9942.0263671875,\n",
       "  9918.7255859375,\n",
       "  9941.1787109375,\n",
       "  9952.3408203125,\n",
       "  9927.3984375,\n",
       "  9930.4599609375,\n",
       "  9913.626953125,\n",
       "  9920.98828125]}"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=10, minLLThresholdCount=10, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"lls\": [], \"inferredAlphas\": [], \"inferredPis\": [], \"inferredPDVs\": [], \"trueMeanPDVs\": [], \"truePis\": []}\n",
    "cachedData = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cachedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 95.,  12.,   1.,   0.],\n",
      "        [ 63.,   2.,   2.,   0.],\n",
      "        [139.,   6.,   1.,   0.],\n",
      "        ...,\n",
      "        [108.,   2.,   1.,   0.],\n",
      "        [163.,   0.,   2.,   1.],\n",
      "        [ 82.,   1.,   4.,   0.]])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood4 at 0x7fed18c928c0>\n",
      "best ll: 52985.25, bestParams: [tensor(0.3764), tensor(0.0979), tensor(0.0304), tensor(8734.0029), tensor(11604.1221), tensor(14842.6357), tensor(3523.9084)]\n",
      "epoch 0\n",
      " final_simplex: (array([[9.21313754e-01, 5.19977324e-02, 2.46891359e-02, 7.63129915e+03,\n",
      "        1.09954904e+04, 1.04187442e+04, 2.87768230e+03],\n",
      "       [9.21313754e-01, 5.19977318e-02, 2.46891358e-02, 7.63129921e+03,\n",
      "        1.09954904e+04, 1.04187441e+04, 2.87768231e+03],\n",
      "       [9.21313754e-01, 5.19977319e-02, 2.46891358e-02, 7.63129921e+03,\n",
      "        1.09954904e+04, 1.04187442e+04, 2.87768231e+03],\n",
      "       [9.21313754e-01, 5.19977319e-02, 2.46891358e-02, 7.63129922e+03,\n",
      "        1.09954904e+04, 1.04187441e+04, 2.87768231e+03],\n",
      "       [9.21313754e-01, 5.19977322e-02, 2.46891358e-02, 7.63129922e+03,\n",
      "        1.09954904e+04, 1.04187441e+04, 2.87768230e+03],\n",
      "       [9.21313755e-01, 5.19977317e-02, 2.46891359e-02, 7.63129924e+03,\n",
      "        1.09954904e+04, 1.04187442e+04, 2.87768230e+03],\n",
      "       [9.21313755e-01, 5.19977321e-02, 2.46891359e-02, 7.63129923e+03,\n",
      "        1.09954904e+04, 1.04187441e+04, 2.87768230e+03],\n",
      "       [9.21313754e-01, 5.19977319e-02, 2.46891359e-02, 7.63129925e+03,\n",
      "        1.09954904e+04, 1.04187441e+04, 2.87768230e+03]]), array([37747.70703125, 37747.70703125, 37747.70703125, 37747.70703125,\n",
      "       37747.70703125, 37747.70703125, 37747.70703125, 37747.70703125]))\n",
      "           fun: 37747.70703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1144\n",
      "           nit: 358\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.21313754e-01, 5.19977324e-02, 2.46891359e-02, 7.63129915e+03,\n",
      "       1.09954904e+04, 1.04187442e+04, 2.87768230e+03])\n",
      "best ll: 57515.32421875, bestParams: [tensor(0.2968), tensor(0.1545), tensor(0.1579), tensor(13854.7559), tensor(14864.1592), tensor(12730.2344), tensor(20170.7051)]\n",
      "epoch 1\n",
      " final_simplex: (array([[8.03178949e-01, 1.36416690e-01, 5.99801721e-02, 1.44889988e+04,\n",
      "        9.46937983e+03, 1.04255977e+04, 1.49212675e+04],\n",
      "       [8.03178949e-01, 1.36416690e-01, 5.99801718e-02, 1.44889988e+04,\n",
      "        9.46937982e+03, 1.04255977e+04, 1.49212675e+04],\n",
      "       [8.03178949e-01, 1.36416690e-01, 5.99801721e-02, 1.44889988e+04,\n",
      "        9.46937982e+03, 1.04255977e+04, 1.49212675e+04],\n",
      "       [8.03178950e-01, 1.36416690e-01, 5.99801717e-02, 1.44889988e+04,\n",
      "        9.46937984e+03, 1.04255976e+04, 1.49212675e+04],\n",
      "       [8.03178948e-01, 1.36416690e-01, 5.99801720e-02, 1.44889988e+04,\n",
      "        9.46937985e+03, 1.04255976e+04, 1.49212675e+04],\n",
      "       [8.03178949e-01, 1.36416690e-01, 5.99801721e-02, 1.44889988e+04,\n",
      "        9.46937983e+03, 1.04255976e+04, 1.49212675e+04],\n",
      "       [8.03178948e-01, 1.36416690e-01, 5.99801719e-02, 1.44889988e+04,\n",
      "        9.46937981e+03, 1.04255977e+04, 1.49212676e+04],\n",
      "       [8.03178949e-01, 1.36416690e-01, 5.99801719e-02, 1.44889988e+04,\n",
      "        9.46937986e+03, 1.04255976e+04, 1.49212675e+04]]), array([40563.28125, 40563.28125, 40563.28125, 40563.28125, 40563.28125,\n",
      "       40563.28125, 40563.28125, 40563.28125]))\n",
      "           fun: 40563.28125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1191\n",
      "           nit: 367\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.03178949e-01, 1.36416690e-01, 5.99801721e-02, 1.44889988e+04,\n",
      "       9.46937983e+03, 1.04255977e+04, 1.49212675e+04])\n",
      "minPrevious 37747.70703125\n",
      "best ll: 59061.9453125, bestParams: [tensor(0.2737), tensor(0.2057), tensor(0.0912), tensor(1508.5795), tensor(1595.7721), tensor(1179.4131), tensor(14485.2852)]\n",
      "epoch 2\n",
      " final_simplex: (array([[9.66399979e-01, 3.30410292e-02, 2.57367581e-04, 6.89309099e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934977e+04],\n",
      "       [9.66399979e-01, 3.30410296e-02, 2.57367517e-04, 6.89309098e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934977e+04],\n",
      "       [9.66399979e-01, 3.30410293e-02, 2.57367622e-04, 6.89309099e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934977e+04],\n",
      "       [9.66399978e-01, 3.30410301e-02, 2.57367614e-04, 6.89309096e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934976e+04],\n",
      "       [9.66399978e-01, 3.30410302e-02, 2.57367633e-04, 6.89309097e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934976e+04],\n",
      "       [9.66399977e-01, 3.30410306e-02, 2.57367709e-04, 6.89309093e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934976e+04],\n",
      "       [9.66399978e-01, 3.30410299e-02, 2.57367568e-04, 6.89309093e+02,\n",
      "        1.32700454e+03, 1.35791174e+03, 1.99934977e+04],\n",
      "       [9.66399978e-01, 3.30410301e-02, 2.57367613e-04, 6.89309094e+02,\n",
      "        1.32700454e+03, 1.35791174e+03, 1.99934976e+04]]), array([36906.63671875, 36906.63671875, 36906.63671875, 36906.63671875,\n",
      "       36906.63671875, 36906.63671875, 36906.63671875, 36906.63671875]))\n",
      "           fun: 36906.63671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1341\n",
      "           nit: 476\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.66399979e-01, 3.30410292e-02, 2.57367581e-04, 6.89309099e+02,\n",
      "       1.32700454e+03, 1.35791173e+03, 1.99934977e+04])\n",
      "minPrevious 37747.70703125\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.66399979e-01, 3.30410292e-02, 2.57367581e-04, 6.89309099e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934977e+04],\n",
      "       [9.66399979e-01, 3.30410296e-02, 2.57367517e-04, 6.89309098e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934977e+04],\n",
      "       [9.66399979e-01, 3.30410293e-02, 2.57367622e-04, 6.89309099e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934977e+04],\n",
      "       [9.66399978e-01, 3.30410301e-02, 2.57367614e-04, 6.89309096e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934976e+04],\n",
      "       [9.66399978e-01, 3.30410302e-02, 2.57367633e-04, 6.89309097e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934976e+04],\n",
      "       [9.66399977e-01, 3.30410306e-02, 2.57367709e-04, 6.89309093e+02,\n",
      "        1.32700454e+03, 1.35791173e+03, 1.99934976e+04],\n",
      "       [9.66399978e-01, 3.30410299e-02, 2.57367568e-04, 6.89309093e+02,\n",
      "        1.32700454e+03, 1.35791174e+03, 1.99934977e+04],\n",
      "       [9.66399978e-01, 3.30410301e-02, 2.57367613e-04, 6.89309094e+02,\n",
      "        1.32700454e+03, 1.35791174e+03, 1.99934976e+04]]), array([36906.63671875, 36906.63671875, 36906.63671875, 36906.63671875,\n",
      "       36906.63671875, 36906.63671875, 36906.63671875, 36906.63671875]))\n",
      "           fun: 36906.63671875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1341\n",
      "           nit: 476\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.66399979e-01, 3.30410292e-02, 2.57367581e-04, 6.89309099e+02,\n",
      "       1.32700454e+03, 1.35791173e+03, 1.99934977e+04])\n",
      "best ll: 57947.96875, bestParams: [tensor(0.3263), tensor(0.0569), tensor(0.2420), tensor(4991.8467), tensor(14190.0020), tensor(23369.6387), tensor(6379.2324)]\n",
      "epoch 3\n",
      " final_simplex: (array([[8.58261761e-01, 2.82805502e-02, 1.09158144e-01, 3.30291731e+03,\n",
      "        1.71995034e+04, 1.62752969e+04, 5.89940447e+03],\n",
      "       [8.58261763e-01, 2.82805499e-02, 1.09158142e-01, 3.30291740e+03,\n",
      "        1.71995034e+04, 1.62752969e+04, 5.89940447e+03],\n",
      "       [8.58261763e-01, 2.82805500e-02, 1.09158142e-01, 3.30291738e+03,\n",
      "        1.71995034e+04, 1.62752968e+04, 5.89940448e+03],\n",
      "       [8.58261762e-01, 2.82805500e-02, 1.09158143e-01, 3.30291736e+03,\n",
      "        1.71995034e+04, 1.62752969e+04, 5.89940447e+03],\n",
      "       [8.58261763e-01, 2.82805499e-02, 1.09158142e-01, 3.30291734e+03,\n",
      "        1.71995034e+04, 1.62752968e+04, 5.89940449e+03],\n",
      "       [8.58261763e-01, 2.82805500e-02, 1.09158142e-01, 3.30291737e+03,\n",
      "        1.71995034e+04, 1.62752968e+04, 5.89940449e+03],\n",
      "       [8.58261762e-01, 2.82805500e-02, 1.09158142e-01, 3.30291737e+03,\n",
      "        1.71995033e+04, 1.62752969e+04, 5.89940447e+03],\n",
      "       [8.58261762e-01, 2.82805500e-02, 1.09158142e-01, 3.30291736e+03,\n",
      "        1.71995034e+04, 1.62752969e+04, 5.89940447e+03]]), array([38883.80078125, 38883.80078125, 38883.80078125, 38883.80078125,\n",
      "       38883.80078125, 38883.80078125, 38883.80078125, 38883.80078125]))\n",
      "           fun: 38883.80078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1273\n",
      "           nit: 447\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.58261761e-01, 2.82805502e-02, 1.09158144e-01, 3.30291731e+03,\n",
      "       1.71995034e+04, 1.62752969e+04, 5.89940447e+03])\n",
      "minPrevious 36906.63671875\n",
      "best ll: 57506.11328125, bestParams: [tensor(0.2713), tensor(0.0694), tensor(0.0719), tensor(17716.9375), tensor(18139.4492), tensor(19317.7422), tensor(12943.7344)]\n",
      "epoch 4\n",
      " final_simplex: (array([[9.27842094e-01, 4.36518886e-02, 2.78944868e-02, 8.46666208e+03,\n",
      "        1.96608998e+04, 2.07425609e+04, 2.94384352e+03],\n",
      "       [9.27842089e-01, 4.36518889e-02, 2.78944873e-02, 8.46666209e+03,\n",
      "        1.96608998e+04, 2.07425608e+04, 2.94384357e+03],\n",
      "       [9.27842088e-01, 4.36518888e-02, 2.78944876e-02, 8.46666209e+03,\n",
      "        1.96608998e+04, 2.07425608e+04, 2.94384362e+03],\n",
      "       [9.27842090e-01, 4.36518888e-02, 2.78944872e-02, 8.46666210e+03,\n",
      "        1.96608998e+04, 2.07425608e+04, 2.94384356e+03],\n",
      "       [9.27842088e-01, 4.36518889e-02, 2.78944873e-02, 8.46666204e+03,\n",
      "        1.96608998e+04, 2.07425608e+04, 2.94384359e+03],\n",
      "       [9.27842090e-01, 4.36518888e-02, 2.78944873e-02, 8.46666208e+03,\n",
      "        1.96608997e+04, 2.07425609e+04, 2.94384359e+03],\n",
      "       [9.27842093e-01, 4.36518888e-02, 2.78944870e-02, 8.46666206e+03,\n",
      "        1.96608998e+04, 2.07425609e+04, 2.94384353e+03],\n",
      "       [9.27842093e-01, 4.36518886e-02, 2.78944869e-02, 8.46666203e+03,\n",
      "        1.96608998e+04, 2.07425608e+04, 2.94384353e+03]]), array([37344.921875, 37344.921875, 37344.921875, 37344.921875,\n",
      "       37344.921875, 37344.921875, 37344.921875, 37344.921875]))\n",
      "           fun: 37344.921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1200\n",
      "           nit: 405\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.27842094e-01, 4.36518886e-02, 2.78944868e-02, 8.46666208e+03,\n",
      "       1.96608998e+04, 2.07425609e+04, 2.94384352e+03])\n",
      "minPrevious 36906.63671875\n",
      "best ll: 55138.09375, bestParams: [tensor(0.3326), tensor(0.0118), tensor(0.0858), tensor(12714.7305), tensor(16556.7852), tensor(23081.7539), tensor(6142.4028)]\n",
      "epoch 5\n",
      " final_simplex: (array([[9.78651681e-01, 7.44731432e-03, 1.02163436e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457814e+03],\n",
      "       [9.78651682e-01, 7.44731432e-03, 1.02163433e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457813e+03],\n",
      "       [9.78651684e-01, 7.44731435e-03, 1.02163430e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457814e+03],\n",
      "       [9.78651682e-01, 7.44731433e-03, 1.02163434e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457815e+03],\n",
      "       [9.78651686e-01, 7.44731436e-03, 1.02163425e-02, 1.02221257e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457817e+03],\n",
      "       [9.78651684e-01, 7.44731432e-03, 1.02163430e-02, 1.02221257e+04,\n",
      "        1.85138051e+04, 1.60417854e+04, 4.93457816e+03],\n",
      "       [9.78651684e-01, 7.44731434e-03, 1.02163431e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457814e+03],\n",
      "       [9.78651683e-01, 7.44731433e-03, 1.02163431e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457815e+03]]), array([36532.29296875, 36532.29296875, 36532.29296875, 36532.29296875,\n",
      "       36532.29296875, 36532.29296875, 36532.29296875, 36532.29296875]))\n",
      "           fun: 36532.29296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1208\n",
      "           nit: 395\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.78651681e-01, 7.44731432e-03, 1.02163436e-02, 1.02221258e+04,\n",
      "       1.85138050e+04, 1.60417854e+04, 4.93457814e+03])\n",
      "minPrevious 36906.63671875\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.78651681e-01, 7.44731432e-03, 1.02163436e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457814e+03],\n",
      "       [9.78651682e-01, 7.44731432e-03, 1.02163433e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457813e+03],\n",
      "       [9.78651684e-01, 7.44731435e-03, 1.02163430e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457814e+03],\n",
      "       [9.78651682e-01, 7.44731433e-03, 1.02163434e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457815e+03],\n",
      "       [9.78651686e-01, 7.44731436e-03, 1.02163425e-02, 1.02221257e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457817e+03],\n",
      "       [9.78651684e-01, 7.44731432e-03, 1.02163430e-02, 1.02221257e+04,\n",
      "        1.85138051e+04, 1.60417854e+04, 4.93457816e+03],\n",
      "       [9.78651684e-01, 7.44731434e-03, 1.02163431e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457814e+03],\n",
      "       [9.78651683e-01, 7.44731433e-03, 1.02163431e-02, 1.02221258e+04,\n",
      "        1.85138050e+04, 1.60417854e+04, 4.93457815e+03]]), array([36532.29296875, 36532.29296875, 36532.29296875, 36532.29296875,\n",
      "       36532.29296875, 36532.29296875, 36532.29296875, 36532.29296875]))\n",
      "           fun: 36532.29296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1208\n",
      "           nit: 395\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.78651681e-01, 7.44731432e-03, 1.02163436e-02, 1.02221258e+04,\n",
      "       1.85138050e+04, 1.60417854e+04, 4.93457814e+03])\n",
      "best ll: 50243.08203125, bestParams: [tensor(0.4324), tensor(0.0348), tensor(0.0424), tensor(5104.7808), tensor(8784.0410), tensor(9177.2861), tensor(21580.7480)]\n",
      "epoch 6\n",
      " final_simplex: (array([[9.37834116e-01, 3.28716650e-02, 2.85604598e-02, 4.99861313e+03,\n",
      "        6.45450963e+03, 6.18551814e+03, 2.24095261e+04],\n",
      "       [9.37834117e-01, 3.28716649e-02, 2.85604598e-02, 4.99861311e+03,\n",
      "        6.45450963e+03, 6.18551814e+03, 2.24095262e+04],\n",
      "       [9.37834117e-01, 3.28716649e-02, 2.85604598e-02, 4.99861310e+03,\n",
      "        6.45450963e+03, 6.18551814e+03, 2.24095262e+04],\n",
      "       [9.37834116e-01, 3.28716649e-02, 2.85604598e-02, 4.99861311e+03,\n",
      "        6.45450963e+03, 6.18551814e+03, 2.24095261e+04],\n",
      "       [9.37834117e-01, 3.28716649e-02, 2.85604598e-02, 4.99861309e+03,\n",
      "        6.45450963e+03, 6.18551814e+03, 2.24095262e+04],\n",
      "       [9.37834116e-01, 3.28716649e-02, 2.85604598e-02, 4.99861312e+03,\n",
      "        6.45450963e+03, 6.18551814e+03, 2.24095261e+04],\n",
      "       [9.37834116e-01, 3.28716650e-02, 2.85604598e-02, 4.99861312e+03,\n",
      "        6.45450964e+03, 6.18551813e+03, 2.24095261e+04],\n",
      "       [9.37834116e-01, 3.28716650e-02, 2.85604598e-02, 4.99861311e+03,\n",
      "        6.45450962e+03, 6.18551815e+03, 2.24095261e+04]]), array([37465.34765625, 37465.34765625, 37465.34765625, 37465.34765625,\n",
      "       37465.34765625, 37465.34765625, 37465.34765625, 37465.34765625]))\n",
      "           fun: 37465.34765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1249\n",
      "           nit: 393\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.37834116e-01, 3.28716650e-02, 2.85604598e-02, 4.99861313e+03,\n",
      "       6.45450963e+03, 6.18551814e+03, 2.24095261e+04])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 57013.703125, bestParams: [tensor(0.2982), tensor(0.1924), tensor(0.0677), tensor(2069.9124), tensor(21087.6172), tensor(22606.0078), tensor(7151.6895)]\n",
      "epoch 7\n",
      " final_simplex: (array([[7.75996062e-01, 1.73264964e-01, 4.87380608e-02, 1.32247714e+03,\n",
      "        1.66354025e+04, 1.74461231e+04, 3.68623142e+03],\n",
      "       [7.75996059e-01, 1.73264965e-01, 4.87380611e-02, 1.32247714e+03,\n",
      "        1.66354025e+04, 1.74461231e+04, 3.68623147e+03],\n",
      "       [7.75996059e-01, 1.73264965e-01, 4.87380613e-02, 1.32247714e+03,\n",
      "        1.66354025e+04, 1.74461231e+04, 3.68623145e+03],\n",
      "       [7.75996060e-01, 1.73264965e-01, 4.87380611e-02, 1.32247714e+03,\n",
      "        1.66354025e+04, 1.74461230e+04, 3.68623146e+03],\n",
      "       [7.75996060e-01, 1.73264966e-01, 4.87380608e-02, 1.32247713e+03,\n",
      "        1.66354025e+04, 1.74461231e+04, 3.68623150e+03],\n",
      "       [7.75996062e-01, 1.73264965e-01, 4.87380607e-02, 1.32247713e+03,\n",
      "        1.66354025e+04, 1.74461230e+04, 3.68623148e+03],\n",
      "       [7.75996060e-01, 1.73264965e-01, 4.87380608e-02, 1.32247713e+03,\n",
      "        1.66354025e+04, 1.74461231e+04, 3.68623147e+03],\n",
      "       [7.75996060e-01, 1.73264965e-01, 4.87380612e-02, 1.32247714e+03,\n",
      "        1.66354025e+04, 1.74461230e+04, 3.68623144e+03]]), array([40715.8359375, 40715.8359375, 40715.8359375, 40715.8359375,\n",
      "       40715.8359375, 40715.8359375, 40715.8359375, 40715.8359375]))\n",
      "           fun: 40715.8359375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1188\n",
      "           nit: 390\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.75996062e-01, 1.73264964e-01, 4.87380608e-02, 1.32247714e+03,\n",
      "       1.66354025e+04, 1.74461231e+04, 3.68623142e+03])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 59767.47265625, bestParams: [tensor(0.2663), tensor(0.0758), tensor(0.3048), tensor(22929.3965), tensor(21220.8633), tensor(16580.8008), tensor(21999.8809)]\n",
      "epoch 8\n",
      " final_simplex: (array([[9.53989643e-01, 3.94064493e-02, 2.53598282e-03, 1.82350011e+04,\n",
      "        1.05134270e+04, 1.02759457e+04, 2.26658825e+04],\n",
      "       [9.53989643e-01, 3.94064492e-02, 2.53598326e-03, 1.82350012e+04,\n",
      "        1.05134270e+04, 1.02759457e+04, 2.26658825e+04],\n",
      "       [9.53989643e-01, 3.94064492e-02, 2.53598308e-03, 1.82350012e+04,\n",
      "        1.05134270e+04, 1.02759457e+04, 2.26658825e+04],\n",
      "       [9.53989643e-01, 3.94064493e-02, 2.53598287e-03, 1.82350012e+04,\n",
      "        1.05134270e+04, 1.02759457e+04, 2.26658825e+04],\n",
      "       [9.53989643e-01, 3.94064493e-02, 2.53598257e-03, 1.82350012e+04,\n",
      "        1.05134270e+04, 1.02759457e+04, 2.26658825e+04],\n",
      "       [9.53989643e-01, 3.94064492e-02, 2.53598257e-03, 1.82350012e+04,\n",
      "        1.05134270e+04, 1.02759457e+04, 2.26658825e+04],\n",
      "       [9.53989643e-01, 3.94064493e-02, 2.53598259e-03, 1.82350011e+04,\n",
      "        1.05134270e+04, 1.02759457e+04, 2.26658825e+04],\n",
      "       [9.53989643e-01, 3.94064493e-02, 2.53598248e-03, 1.82350012e+04,\n",
      "        1.05134270e+04, 1.02759457e+04, 2.26658825e+04]]), array([37029.3125, 37029.3125, 37029.3125, 37029.3125, 37029.3125,\n",
      "       37029.3125, 37029.3125, 37029.3125]))\n",
      "           fun: 37029.3125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 439\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.53989643e-01, 3.94064493e-02, 2.53598282e-03, 1.82350011e+04,\n",
      "       1.05134270e+04, 1.02759457e+04, 2.26658825e+04])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 53747.0859375, bestParams: [tensor(0.3985), tensor(0.0645), tensor(0.0091), tensor(21946.5391), tensor(10213.3604), tensor(17320.8340), tensor(2770.7991)]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.67469812e-01, 2.28063829e-02, 4.16790000e-03, 1.77765720e+04,\n",
      "        1.43419683e+04, 1.37415205e+04, 2.49893094e+03],\n",
      "       [9.67469812e-01, 2.28063830e-02, 4.16790003e-03, 1.77765719e+04,\n",
      "        1.43419682e+04, 1.37415205e+04, 2.49893094e+03],\n",
      "       [9.67469812e-01, 2.28063832e-02, 4.16789994e-03, 1.77765719e+04,\n",
      "        1.43419682e+04, 1.37415205e+04, 2.49893094e+03],\n",
      "       [9.67469812e-01, 2.28063832e-02, 4.16789993e-03, 1.77765719e+04,\n",
      "        1.43419682e+04, 1.37415205e+04, 2.49893093e+03],\n",
      "       [9.67469812e-01, 2.28063831e-02, 4.16789993e-03, 1.77765719e+04,\n",
      "        1.43419682e+04, 1.37415205e+04, 2.49893093e+03],\n",
      "       [9.67469812e-01, 2.28063831e-02, 4.16789996e-03, 1.77765719e+04,\n",
      "        1.43419682e+04, 1.37415205e+04, 2.49893094e+03],\n",
      "       [9.67469812e-01, 2.28063830e-02, 4.16789999e-03, 1.77765719e+04,\n",
      "        1.43419682e+04, 1.37415205e+04, 2.49893094e+03],\n",
      "       [9.67469813e-01, 2.28063832e-02, 4.16789991e-03, 1.77765719e+04,\n",
      "        1.43419682e+04, 1.37415205e+04, 2.49893093e+03]]), array([36763.45703125, 36763.45703125, 36763.45703125, 36763.45703125,\n",
      "       36763.45703125, 36763.45703125, 36763.45703125, 36763.45703125]))\n",
      "           fun: 36763.45703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1215\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.67469812e-01, 2.28063829e-02, 4.16790000e-03, 1.77765720e+04,\n",
      "       1.43419683e+04, 1.37415205e+04, 2.49893094e+03])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 57021.2578125, bestParams: [tensor(0.2925), tensor(0.1556), tensor(0.0913), tensor(13420.7988), tensor(10911.1064), tensor(10061.9551), tensor(12969.9492)]\n",
      "epoch 10\n",
      " final_simplex: (array([[8.24698382e-01, 9.21686536e-02, 8.05905030e-02, 8.48032575e+03,\n",
      "        7.48824887e+03, 8.11914773e+03, 1.40690833e+04],\n",
      "       [8.24698383e-01, 9.21686530e-02, 8.05905030e-02, 8.48032568e+03,\n",
      "        7.48824891e+03, 8.11914774e+03, 1.40690833e+04],\n",
      "       [8.24698383e-01, 9.21686531e-02, 8.05905031e-02, 8.48032574e+03,\n",
      "        7.48824886e+03, 8.11914775e+03, 1.40690832e+04],\n",
      "       [8.24698382e-01, 9.21686535e-02, 8.05905029e-02, 8.48032575e+03,\n",
      "        7.48824887e+03, 8.11914773e+03, 1.40690833e+04],\n",
      "       [8.24698384e-01, 9.21686530e-02, 8.05905029e-02, 8.48032574e+03,\n",
      "        7.48824885e+03, 8.11914775e+03, 1.40690833e+04],\n",
      "       [8.24698383e-01, 9.21686532e-02, 8.05905029e-02, 8.48032576e+03,\n",
      "        7.48824885e+03, 8.11914775e+03, 1.40690833e+04],\n",
      "       [8.24698383e-01, 9.21686528e-02, 8.05905030e-02, 8.48032566e+03,\n",
      "        7.48824891e+03, 8.11914776e+03, 1.40690833e+04],\n",
      "       [8.24698383e-01, 9.21686531e-02, 8.05905030e-02, 8.48032570e+03,\n",
      "        7.48824890e+03, 8.11914773e+03, 1.40690833e+04]]), array([39955.640625, 39955.640625, 39955.640625, 39955.640625,\n",
      "       39955.640625, 39955.640625, 39955.640625, 39955.640625]))\n",
      "           fun: 39955.640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1235\n",
      "           nit: 421\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.24698382e-01, 9.21686536e-02, 8.05905030e-02, 8.48032575e+03,\n",
      "       7.48824887e+03, 8.11914773e+03, 1.40690833e+04])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 56895.65234375, bestParams: [tensor(0.3078), tensor(0.2551), tensor(0.0315), tensor(17480.5625), tensor(16881.4434), tensor(20441.6094), tensor(22900.6953)]\n",
      "epoch 11\n",
      " final_simplex: (array([[7.67796336e-01, 2.06510052e-01, 1.74512564e-02, 1.02562704e+04,\n",
      "        1.95513841e+04, 1.80758499e+04, 1.94977572e+04],\n",
      "       [7.67796335e-01, 2.06510053e-01, 1.74512565e-02, 1.02562703e+04,\n",
      "        1.95513841e+04, 1.80758499e+04, 1.94977572e+04],\n",
      "       [7.67796335e-01, 2.06510052e-01, 1.74512564e-02, 1.02562703e+04,\n",
      "        1.95513841e+04, 1.80758499e+04, 1.94977572e+04],\n",
      "       [7.67796335e-01, 2.06510052e-01, 1.74512564e-02, 1.02562703e+04,\n",
      "        1.95513841e+04, 1.80758499e+04, 1.94977572e+04],\n",
      "       [7.67796335e-01, 2.06510052e-01, 1.74512564e-02, 1.02562703e+04,\n",
      "        1.95513841e+04, 1.80758499e+04, 1.94977572e+04],\n",
      "       [7.67796336e-01, 2.06510052e-01, 1.74512564e-02, 1.02562703e+04,\n",
      "        1.95513841e+04, 1.80758499e+04, 1.94977572e+04],\n",
      "       [7.67796336e-01, 2.06510052e-01, 1.74512563e-02, 1.02562703e+04,\n",
      "        1.95513841e+04, 1.80758499e+04, 1.94977572e+04],\n",
      "       [7.67796337e-01, 2.06510052e-01, 1.74512563e-02, 1.02562703e+04,\n",
      "        1.95513841e+04, 1.80758499e+04, 1.94977572e+04]]), array([41232.4765625, 41232.4765625, 41232.4765625, 41232.4765625,\n",
      "       41232.4765625, 41232.4765625, 41232.4765625, 41232.4765625]))\n",
      "           fun: 41232.4765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1246\n",
      "           nit: 408\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.67796336e-01, 2.06510052e-01, 1.74512564e-02, 1.02562704e+04,\n",
      "       1.95513841e+04, 1.80758499e+04, 1.94977572e+04])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 58855.68359375, bestParams: [tensor(0.2781), tensor(0.2004), tensor(0.1447), tensor(15895.0625), tensor(22262.1074), tensor(19966.0957), tensor(12244.9033)]\n",
      "epoch 12\n",
      " final_simplex: (array([[9.25859922e-01, 9.55064316e-03, 5.99219294e-02, 2.03989203e+04,\n",
      "        1.48778046e+04, 1.49518505e+04, 1.48886371e+04],\n",
      "       [9.25859920e-01, 9.55064326e-03, 5.99219297e-02, 2.03989203e+04,\n",
      "        1.48778046e+04, 1.49518505e+04, 1.48886371e+04],\n",
      "       [9.25859920e-01, 9.55064340e-03, 5.99219299e-02, 2.03989203e+04,\n",
      "        1.48778046e+04, 1.49518505e+04, 1.48886371e+04],\n",
      "       [9.25859922e-01, 9.55064289e-03, 5.99219297e-02, 2.03989203e+04,\n",
      "        1.48778046e+04, 1.49518505e+04, 1.48886371e+04],\n",
      "       [9.25859921e-01, 9.55064321e-03, 5.99219297e-02, 2.03989203e+04,\n",
      "        1.48778046e+04, 1.49518505e+04, 1.48886371e+04],\n",
      "       [9.25859921e-01, 9.55064323e-03, 5.99219295e-02, 2.03989203e+04,\n",
      "        1.48778046e+04, 1.49518505e+04, 1.48886371e+04],\n",
      "       [9.25859920e-01, 9.55064332e-03, 5.99219298e-02, 2.03989203e+04,\n",
      "        1.48778046e+04, 1.49518505e+04, 1.48886371e+04],\n",
      "       [9.25859920e-01, 9.55064307e-03, 5.99219294e-02, 2.03989203e+04,\n",
      "        1.48778047e+04, 1.49518505e+04, 1.48886372e+04]]), array([37526.125, 37526.125, 37526.125, 37526.125, 37526.125, 37526.125,\n",
      "       37526.125, 37526.125]))\n",
      "           fun: 37526.125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1310\n",
      "           nit: 472\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.25859922e-01, 9.55064316e-03, 5.99219294e-02, 2.03989203e+04,\n",
      "       1.48778046e+04, 1.49518505e+04, 1.48886371e+04])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 56950.39453125, bestParams: [tensor(0.2923), tensor(0.0512), tensor(0.2259), tensor(22812.4746), tensor(23037.2598), tensor(21584.8477), tensor(20578.9414)]\n",
      "epoch 13\n",
      " final_simplex: (array([[3.06878522e-01, 5.12063624e-02, 2.25928623e-01, 2.28146143e+04,\n",
      "        2.30371728e+04, 2.15844067e+04, 2.05808542e+04],\n",
      "       [3.06878522e-01, 5.12063624e-02, 2.25928623e-01, 2.28146142e+04,\n",
      "        2.30371728e+04, 2.15844067e+04, 2.05808543e+04],\n",
      "       [3.06878522e-01, 5.12063624e-02, 2.25928623e-01, 2.28146142e+04,\n",
      "        2.30371728e+04, 2.15844067e+04, 2.05808543e+04],\n",
      "       [3.06878522e-01, 5.12063624e-02, 2.25928623e-01, 2.28146143e+04,\n",
      "        2.30371728e+04, 2.15844067e+04, 2.05808543e+04],\n",
      "       [3.06878522e-01, 5.12063624e-02, 2.25928623e-01, 2.28146143e+04,\n",
      "        2.30371728e+04, 2.15844067e+04, 2.05808542e+04],\n",
      "       [3.06878522e-01, 5.12063624e-02, 2.25928623e-01, 2.28146143e+04,\n",
      "        2.30371728e+04, 2.15844067e+04, 2.05808543e+04],\n",
      "       [3.06878523e-01, 5.12063624e-02, 2.25928623e-01, 2.28146143e+04,\n",
      "        2.30371728e+04, 2.15844067e+04, 2.05808543e+04],\n",
      "       [3.06878523e-01, 5.12063624e-02, 2.25928623e-01, 2.28146142e+04,\n",
      "        2.30371728e+04, 2.15844067e+04, 2.05808542e+04]]), array([56208.7109375, 56208.7109375, 56208.7109375, 56208.7109375,\n",
      "       56208.7109375, 56208.7109375, 56208.7109375, 56208.7109375]))\n",
      "           fun: 56208.7109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1139\n",
      "           nit: 290\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.06878522e-01, 5.12063624e-02, 2.25928623e-01, 2.28146143e+04,\n",
      "       2.30371728e+04, 2.15844067e+04, 2.05808542e+04])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 56015.44921875, bestParams: [tensor(0.4129), tensor(0.0544), tensor(0.0889), tensor(14682.6514), tensor(8384.9668), tensor(18242.1348), tensor(6582.5991)]\n",
      "epoch 14\n",
      " final_simplex: (array([[8.88811024e-01, 4.52116814e-02, 6.35498596e-02, 1.09323452e+04,\n",
      "        1.00527947e+04, 9.38007144e+03, 6.98841483e+03],\n",
      "       [8.88811024e-01, 4.52116815e-02, 6.35498594e-02, 1.09323452e+04,\n",
      "        1.00527947e+04, 9.38007145e+03, 6.98841480e+03],\n",
      "       [8.88811024e-01, 4.52116814e-02, 6.35498595e-02, 1.09323452e+04,\n",
      "        1.00527947e+04, 9.38007145e+03, 6.98841479e+03],\n",
      "       [8.88811024e-01, 4.52116815e-02, 6.35498597e-02, 1.09323453e+04,\n",
      "        1.00527947e+04, 9.38007147e+03, 6.98841478e+03],\n",
      "       [8.88811024e-01, 4.52116814e-02, 6.35498596e-02, 1.09323452e+04,\n",
      "        1.00527947e+04, 9.38007147e+03, 6.98841480e+03],\n",
      "       [8.88811024e-01, 4.52116814e-02, 6.35498597e-02, 1.09323452e+04,\n",
      "        1.00527947e+04, 9.38007147e+03, 6.98841482e+03],\n",
      "       [8.88811024e-01, 4.52116815e-02, 6.35498595e-02, 1.09323453e+04,\n",
      "        1.00527947e+04, 9.38007146e+03, 6.98841479e+03],\n",
      "       [8.88811024e-01, 4.52116815e-02, 6.35498596e-02, 1.09323452e+04,\n",
      "        1.00527947e+04, 9.38007139e+03, 6.98841481e+03]]), array([38408.625, 38408.625, 38408.625, 38408.625, 38408.625, 38408.625,\n",
      "       38408.625, 38408.625]))\n",
      "           fun: 38408.625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1291\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.88811024e-01, 4.52116814e-02, 6.35498596e-02, 1.09323452e+04,\n",
      "       1.00527947e+04, 9.38007144e+03, 6.98841483e+03])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 57219.44140625, bestParams: [tensor(0.3037), tensor(0.1059), tensor(0.1980), tensor(21566.9746), tensor(11405.7637), tensor(9691.4092), tensor(1470.3417)]\n",
      "epoch 15\n",
      " final_simplex: (array([[8.93257847e-01, 8.71720886e-02, 1.45966778e-02, 2.24878107e+04,\n",
      "        1.01942374e+04, 1.04861997e+04, 1.04809798e+03],\n",
      "       [8.93257847e-01, 8.71720885e-02, 1.45966782e-02, 2.24878106e+04,\n",
      "        1.01942374e+04, 1.04861997e+04, 1.04809798e+03],\n",
      "       [8.93257847e-01, 8.71720886e-02, 1.45966779e-02, 2.24878107e+04,\n",
      "        1.01942374e+04, 1.04861997e+04, 1.04809798e+03],\n",
      "       [8.93257847e-01, 8.71720886e-02, 1.45966780e-02, 2.24878107e+04,\n",
      "        1.01942374e+04, 1.04861997e+04, 1.04809798e+03],\n",
      "       [8.93257846e-01, 8.71720886e-02, 1.45966780e-02, 2.24878107e+04,\n",
      "        1.01942374e+04, 1.04861997e+04, 1.04809798e+03],\n",
      "       [8.93257847e-01, 8.71720885e-02, 1.45966781e-02, 2.24878106e+04,\n",
      "        1.01942374e+04, 1.04861997e+04, 1.04809798e+03],\n",
      "       [8.93257847e-01, 8.71720885e-02, 1.45966781e-02, 2.24878106e+04,\n",
      "        1.01942374e+04, 1.04861997e+04, 1.04809798e+03],\n",
      "       [8.93257847e-01, 8.71720886e-02, 1.45966780e-02, 2.24878107e+04,\n",
      "        1.01942374e+04, 1.04861997e+04, 1.04809798e+03]]), array([38273.32421875, 38273.32421875, 38273.32421875, 38273.32421875,\n",
      "       38273.32421875, 38273.32421875, 38273.32421875, 38273.32421875]))\n",
      "           fun: 38273.32421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1325\n",
      "           nit: 413\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.93257847e-01, 8.71720886e-02, 1.45966778e-02, 2.24878107e+04,\n",
      "       1.01942374e+04, 1.04861997e+04, 1.04809798e+03])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 51567.86328125, bestParams: [tensor(0.4008), tensor(0.0438), tensor(0.0641), tensor(214.5946), tensor(7227.5327), tensor(6749.6987), tensor(17493.8379)]\n",
      "epoch 16\n",
      " final_simplex: (array([[9.43384412e-01, 2.92901980e-02, 2.50560494e-02, 2.00715194e+02,\n",
      "        6.22507400e+03, 6.57007841e+03, 1.48893456e+04],\n",
      "       [9.43384412e-01, 2.92901980e-02, 2.50560493e-02, 2.00715194e+02,\n",
      "        6.22507401e+03, 6.57007841e+03, 1.48893456e+04],\n",
      "       [9.43384413e-01, 2.92901980e-02, 2.50560492e-02, 2.00715193e+02,\n",
      "        6.22507400e+03, 6.57007842e+03, 1.48893456e+04],\n",
      "       [9.43384413e-01, 2.92901980e-02, 2.50560493e-02, 2.00715194e+02,\n",
      "        6.22507400e+03, 6.57007841e+03, 1.48893456e+04],\n",
      "       [9.43384413e-01, 2.92901980e-02, 2.50560491e-02, 2.00715194e+02,\n",
      "        6.22507402e+03, 6.57007842e+03, 1.48893456e+04],\n",
      "       [9.43384413e-01, 2.92901980e-02, 2.50560490e-02, 2.00715195e+02,\n",
      "        6.22507401e+03, 6.57007841e+03, 1.48893456e+04],\n",
      "       [9.43384413e-01, 2.92901979e-02, 2.50560490e-02, 2.00715196e+02,\n",
      "        6.22507401e+03, 6.57007841e+03, 1.48893455e+04],\n",
      "       [9.43384413e-01, 2.92901979e-02, 2.50560490e-02, 2.00715195e+02,\n",
      "        6.22507400e+03, 6.57007842e+03, 1.48893456e+04]]), array([37356.55859375, 37356.55859375, 37356.55859375, 37356.55859375,\n",
      "       37356.55859375, 37356.55859375, 37356.55859375, 37356.55859375]))\n",
      "           fun: 37356.55859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1164\n",
      "           nit: 373\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.43384412e-01, 2.92901980e-02, 2.50560494e-02, 2.00715194e+02,\n",
      "       6.22507400e+03, 6.57007841e+03, 1.48893456e+04])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 56855.4140625, bestParams: [tensor(0.3064), tensor(0.1167), tensor(0.0911), tensor(12451.8203), tensor(10153.8398), tensor(13921.3984), tensor(9519.8232)]\n",
      "epoch 17\n",
      " final_simplex: (array([[8.39261401e-01, 1.01161113e-01, 5.91152379e-02, 9.77966219e+03,\n",
      "        7.72786523e+03, 7.40272905e+03, 7.84409935e+03],\n",
      "       [8.39261400e-01, 1.01161112e-01, 5.91152380e-02, 9.77966225e+03,\n",
      "        7.72786523e+03, 7.40272905e+03, 7.84409926e+03],\n",
      "       [8.39261399e-01, 1.01161114e-01, 5.91152373e-02, 9.77966218e+03,\n",
      "        7.72786521e+03, 7.40272901e+03, 7.84409932e+03],\n",
      "       [8.39261400e-01, 1.01161113e-01, 5.91152382e-02, 9.77966221e+03,\n",
      "        7.72786528e+03, 7.40272903e+03, 7.84409929e+03],\n",
      "       [8.39261400e-01, 1.01161113e-01, 5.91152379e-02, 9.77966219e+03,\n",
      "        7.72786527e+03, 7.40272905e+03, 7.84409928e+03],\n",
      "       [8.39261400e-01, 1.01161113e-01, 5.91152373e-02, 9.77966219e+03,\n",
      "        7.72786522e+03, 7.40272904e+03, 7.84409938e+03],\n",
      "       [8.39261400e-01, 1.01161112e-01, 5.91152379e-02, 9.77966226e+03,\n",
      "        7.72786522e+03, 7.40272899e+03, 7.84409930e+03],\n",
      "       [8.39261401e-01, 1.01161112e-01, 5.91152376e-02, 9.77966227e+03,\n",
      "        7.72786523e+03, 7.40272898e+03, 7.84409928e+03]]), array([39687.61328125, 39687.61328125, 39687.61328125, 39687.61328125,\n",
      "       39687.61328125, 39687.61328125, 39687.61328125, 39687.61328125]))\n",
      "           fun: 39687.61328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1134\n",
      "           nit: 377\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.39261401e-01, 1.01161113e-01, 5.91152379e-02, 9.77966219e+03,\n",
      "       7.72786523e+03, 7.40272905e+03, 7.84409935e+03])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 53315.3828125, bestParams: [tensor(0.3500), tensor(0.0577), tensor(0.0185), tensor(16914.6875), tensor(12415.8623), tensor(13593.8438), tensor(4062.4583)]\n",
      "epoch 18\n",
      " final_simplex: (array([[9.30329913e-01, 5.63404153e-02, 1.18701537e-02, 1.55343424e+04,\n",
      "        1.26799380e+04, 1.25071940e+04, 1.69410987e+03],\n",
      "       [9.30329912e-01, 5.63404152e-02, 1.18701536e-02, 1.55343425e+04,\n",
      "        1.26799381e+04, 1.25071940e+04, 1.69410986e+03],\n",
      "       [9.30329911e-01, 5.63404152e-02, 1.18701536e-02, 1.55343425e+04,\n",
      "        1.26799381e+04, 1.25071941e+04, 1.69410987e+03],\n",
      "       [9.30329914e-01, 5.63404155e-02, 1.18701537e-02, 1.55343424e+04,\n",
      "        1.26799381e+04, 1.25071940e+04, 1.69410985e+03],\n",
      "       [9.30329911e-01, 5.63404152e-02, 1.18701536e-02, 1.55343425e+04,\n",
      "        1.26799381e+04, 1.25071941e+04, 1.69410987e+03],\n",
      "       [9.30329911e-01, 5.63404152e-02, 1.18701537e-02, 1.55343425e+04,\n",
      "        1.26799380e+04, 1.25071941e+04, 1.69410988e+03],\n",
      "       [9.30329910e-01, 5.63404152e-02, 1.18701535e-02, 1.55343425e+04,\n",
      "        1.26799381e+04, 1.25071940e+04, 1.69410988e+03],\n",
      "       [9.30329914e-01, 5.63404150e-02, 1.18701536e-02, 1.55343425e+04,\n",
      "        1.26799381e+04, 1.25071941e+04, 1.69410985e+03]]), array([37567.19921875, 37567.19921875, 37567.19921875, 37567.19921875,\n",
      "       37567.19921875, 37567.19921875, 37567.19921875, 37567.19921875]))\n",
      "           fun: 37567.19921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1176\n",
      "           nit: 395\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.30329913e-01, 5.63404153e-02, 1.18701537e-02, 1.55343424e+04,\n",
      "       1.26799380e+04, 1.25071940e+04, 1.69410987e+03])\n",
      "minPrevious 36532.29296875\n",
      "best ll: 56083.984375, bestParams: [tensor(0.3169), tensor(0.2415), tensor(0.0047), tensor(6077.6284), tensor(23163.7715), tensor(24013.8594), tensor(15410.2637)]\n",
      "epoch 19\n",
      " final_simplex: (array([[9.65087847e-01, 3.00801649e-02, 2.10413668e-03, 3.25241597e+03,\n",
      "        1.71977572e+04, 1.74407641e+04, 2.00219416e+04],\n",
      "       [9.65087846e-01, 3.00801654e-02, 2.10413665e-03, 3.25241600e+03,\n",
      "        1.71977572e+04, 1.74407641e+04, 2.00219416e+04],\n",
      "       [9.65087847e-01, 3.00801643e-02, 2.10413668e-03, 3.25241597e+03,\n",
      "        1.71977573e+04, 1.74407641e+04, 2.00219416e+04],\n",
      "       [9.65087847e-01, 3.00801646e-02, 2.10413665e-03, 3.25241597e+03,\n",
      "        1.71977572e+04, 1.74407641e+04, 2.00219416e+04],\n",
      "       [9.65087847e-01, 3.00801647e-02, 2.10413665e-03, 3.25241597e+03,\n",
      "        1.71977572e+04, 1.74407641e+04, 2.00219416e+04],\n",
      "       [9.65087847e-01, 3.00801649e-02, 2.10413666e-03, 3.25241598e+03,\n",
      "        1.71977572e+04, 1.74407640e+04, 2.00219416e+04],\n",
      "       [9.65087847e-01, 3.00801645e-02, 2.10413668e-03, 3.25241597e+03,\n",
      "        1.71977573e+04, 1.74407640e+04, 2.00219416e+04],\n",
      "       [9.65087846e-01, 3.00801654e-02, 2.10413666e-03, 3.25241598e+03,\n",
      "        1.71977572e+04, 1.74407640e+04, 2.00219416e+04]]), array([36342.86328125, 36342.86328125, 36342.86328125, 36342.86328125,\n",
      "       36342.86328125, 36342.86328125, 36342.86328125, 36342.86328125]))\n",
      "           fun: 36342.86328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1235\n",
      "           nit: 431\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.65087847e-01, 3.00801649e-02, 2.10413668e-03, 3.25241597e+03,\n",
      "       1.71977572e+04, 1.74407641e+04, 2.00219416e+04])\n",
      "minPrevious 36532.29296875\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.65087847e-01, 3.00801649e-02, 2.10413668e-03, 3.25241597e+03,\n",
      "        1.71977572e+04, 1.74407641e+04, 2.00219416e+04],\n",
      "       [9.65087846e-01, 3.00801654e-02, 2.10413665e-03, 3.25241600e+03,\n",
      "        1.71977572e+04, 1.74407641e+04, 2.00219416e+04],\n",
      "       [9.65087847e-01, 3.00801643e-02, 2.10413668e-03, 3.25241597e+03,\n",
      "        1.71977573e+04, 1.74407641e+04, 2.00219416e+04],\n",
      "       [9.65087847e-01, 3.00801646e-02, 2.10413665e-03, 3.25241597e+03,\n",
      "        1.71977572e+04, 1.74407641e+04, 2.00219416e+04],\n",
      "       [9.65087847e-01, 3.00801647e-02, 2.10413665e-03, 3.25241597e+03,\n",
      "        1.71977572e+04, 1.74407641e+04, 2.00219416e+04],\n",
      "       [9.65087847e-01, 3.00801649e-02, 2.10413666e-03, 3.25241598e+03,\n",
      "        1.71977572e+04, 1.74407640e+04, 2.00219416e+04],\n",
      "       [9.65087847e-01, 3.00801645e-02, 2.10413668e-03, 3.25241597e+03,\n",
      "        1.71977573e+04, 1.74407640e+04, 2.00219416e+04],\n",
      "       [9.65087846e-01, 3.00801654e-02, 2.10413666e-03, 3.25241598e+03,\n",
      "        1.71977572e+04, 1.74407640e+04, 2.00219416e+04]]), array([36342.86328125, 36342.86328125, 36342.86328125, 36342.86328125,\n",
      "       36342.86328125, 36342.86328125, 36342.86328125, 36342.86328125]))\n",
      "           fun: 36342.86328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1235\n",
      "           nit: 431\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.65087847e-01, 3.00801649e-02, 2.10413668e-03, 3.25241597e+03,\n",
      "       1.71977572e+04, 1.74407641e+04, 2.00219416e+04])\n",
      "inferredPis tensor([0.9651, 0.0301, 0.0021], dtype=torch.float64)\n",
      "inferredAlphas tensor([ 3252.4160, 17197.7572, 17440.7641, 20021.9416], dtype=torch.float64)\n",
      "truth0 tensor(0.7519) truth1 tensor(0.1111) truth2 tensor(0.1121) truthBoth tensor(0.0250)\n",
      "params on run 0 {'lls': [58132.7578125, 61020.8984375, 62816.03125, 61310.28125, 59964.953125, 47473.921875, 47433.734375, 47816.32421875, 47210.3984375, 51822.578125, 51970.546875, 47609.4609375, 52364.7734375, 53773.0390625, 47233.921875, 36342.86328125], 'inferredAlphas': [tensor([17771.7538,   267.5774,   285.4237, 19323.4289], dtype=torch.float64), tensor([17391.5067,   389.1159,   504.1465, 38945.6315], dtype=torch.float64), tensor([26599.6834,   330.5187,   522.2450, 20474.0527], dtype=torch.float64), tensor([17159.0905,   229.1438,   192.1196, 23702.7612], dtype=torch.float64), tensor([14365.2776,   353.8587,   277.5095, 36615.7416], dtype=torch.float64), tensor([4681.1768, 1514.9906,  279.5278, 6430.2365], dtype=torch.float64), tensor([11636.0228,  1941.4431,   317.7839,  2432.4090], dtype=torch.float64), tensor([3466.6976,  105.4401,  574.8790,  884.2902], dtype=torch.float64), tensor([  190.1304,   255.3843,  1367.9433, 10051.6183], dtype=torch.float64), tensor([13347.1036,  2995.2070,   679.1869,  9964.7306], dtype=torch.float64), tensor([3050.1159,  274.5893, 1270.7564, 7251.8219], dtype=torch.float64), tensor([1902.8937,  238.1495, 1249.7712, 7914.4684], dtype=torch.float64), tensor([20414.2533,  1255.3286,  5495.8171, 24486.6440], dtype=torch.float64), tensor([ 5422.4410,  1070.5042,  5035.1884, 34394.7350], dtype=torch.float64), tensor([6116.3640, 1549.1665,  277.2773, 5735.0947], dtype=torch.float64), tensor([ 3252.4160, 17197.7572, 17440.7641, 20021.9416], dtype=torch.float64)], 'inferredPis': [tensor([0.2745, 0.5123, 0.0037], dtype=torch.float64), tensor([0.2424, 0.2423, 0.0335], dtype=torch.float64), tensor([0.2477, 0.1574, 0.0414], dtype=torch.float64), tensor([0.2670, 0.3576, 0.1152], dtype=torch.float64), tensor([0.4350, 0.2494, 0.0647], dtype=torch.float64), tensor([0.1319, 0.8504, 0.0173], dtype=torch.float64), tensor([0.1121, 0.8709, 0.0016], dtype=torch.float64), tensor([0.7272, 0.2531, 0.0189], dtype=torch.float64), tensor([0.8014, 0.1978, 0.0008], dtype=torch.float64), tensor([0.1527, 0.5340, 0.0406], dtype=torch.float64), tensor([4.4252e-01, 2.4141e-01, 6.9015e-05], dtype=torch.float64), tensor([0.7311, 0.2567, 0.0100], dtype=torch.float64), tensor([0.4108, 0.3023, 0.0150], dtype=torch.float64), tensor([0.4187, 0.1117, 0.0518], dtype=torch.float64), tensor([0.2033, 0.7863, 0.0045], dtype=torch.float64), tensor([0.9651, 0.0301, 0.0021], dtype=torch.float64)], 'inferredPDVs': [tensor([0.4720, 0.0071, 0.0076, 0.5133], dtype=torch.float64), tensor([0.3039, 0.0068, 0.0088, 0.6805], dtype=torch.float64), tensor([0.5550, 0.0069, 0.0109, 0.4272], dtype=torch.float64), tensor([0.4156, 0.0056, 0.0047, 0.5742], dtype=torch.float64), tensor([0.2783, 0.0069, 0.0054, 0.7095], dtype=torch.float64), tensor([0.3627, 0.1174, 0.0217, 0.4982], dtype=torch.float64), tensor([0.7126, 0.1189, 0.0195, 0.1490], dtype=torch.float64), tensor([0.6890, 0.0210, 0.1143, 0.1758], dtype=torch.float64), tensor([0.0160, 0.0215, 0.1153, 0.8471], dtype=torch.float64), tensor([0.4945, 0.1110, 0.0252, 0.3693], dtype=torch.float64), tensor([0.2575, 0.0232, 0.1073, 0.6120], dtype=torch.float64), tensor([0.1683, 0.0210, 0.1106, 0.7001], dtype=torch.float64), tensor([0.3952, 0.0243, 0.1064, 0.4741], dtype=torch.float64), tensor([0.1181, 0.0233, 0.1096, 0.7490], dtype=torch.float64), tensor([0.4472, 0.1133, 0.0203, 0.4192], dtype=torch.float64), tensor([0.0562, 0.2969, 0.3011, 0.3458], dtype=torch.float64)], 'trueMeanPDVs': [tensor([0.7547, 0.1096, 0.1105, 0.0252]), tensor([0.7520, 0.1114, 0.1113, 0.0253]), tensor([0.7523, 0.1111, 0.1116, 0.0250]), tensor([0.7518, 0.1113, 0.1112, 0.0257]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7510, 0.1117, 0.1118, 0.0255]), tensor([0.7535, 0.1110, 0.1105, 0.0250]), tensor([0.7503, 0.1121, 0.1120, 0.0256]), tensor([0.7542, 0.1103, 0.1109, 0.0246]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250])], 'truePis': [tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500])]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 85.,  17.,   1.,   0.],\n",
      "        [ 74.,   6.,   3.,   0.],\n",
      "        [113.,  21.,   6.,   0.],\n",
      "        ...,\n",
      "        [143.,   0.,   2.,   0.],\n",
      "        [142.,   4.,   0.,   0.],\n",
      "        [ 52.,   1.,   0.,   0.]])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood4 at 0x7febac6c4d40>\n",
      "best ll: 54822.609375, bestParams: [tensor(0.3556), tensor(0.0063), tensor(0.0603), tensor(12043.8613), tensor(16484.6699), tensor(10179.4365), tensor(593.4254)]\n",
      "epoch 0\n",
      " final_simplex: (array([[9.76242840e-01, 3.67678672e-03, 1.95046370e-02, 5.20409564e+03,\n",
      "        1.33348894e+04, 1.34234617e+04, 5.88021381e+02],\n",
      "       [9.76242840e-01, 3.67678673e-03, 1.95046369e-02, 5.20409570e+03,\n",
      "        1.33348894e+04, 1.34234617e+04, 5.88021383e+02],\n",
      "       [9.76242839e-01, 3.67678670e-03, 1.95046366e-02, 5.20409574e+03,\n",
      "        1.33348894e+04, 1.34234617e+04, 5.88021382e+02],\n",
      "       [9.76242839e-01, 3.67678673e-03, 1.95046369e-02, 5.20409567e+03,\n",
      "        1.33348894e+04, 1.34234617e+04, 5.88021384e+02],\n",
      "       [9.76242839e-01, 3.67678673e-03, 1.95046368e-02, 5.20409573e+03,\n",
      "        1.33348894e+04, 1.34234617e+04, 5.88021381e+02],\n",
      "       [9.76242839e-01, 3.67678671e-03, 1.95046368e-02, 5.20409570e+03,\n",
      "        1.33348894e+04, 1.34234617e+04, 5.88021383e+02],\n",
      "       [9.76242840e-01, 3.67678671e-03, 1.95046370e-02, 5.20409564e+03,\n",
      "        1.33348895e+04, 1.34234617e+04, 5.88021383e+02],\n",
      "       [9.76242839e-01, 3.67678671e-03, 1.95046369e-02, 5.20409568e+03,\n",
      "        1.33348895e+04, 1.34234617e+04, 5.88021382e+02]]), array([36641.8125, 36641.8125, 36641.8125, 36641.8125, 36641.8125,\n",
      "       36641.8125, 36641.8125, 36641.8125]))\n",
      "           fun: 36641.8125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1180\n",
      "           nit: 395\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.76242840e-01, 3.67678672e-03, 1.95046370e-02, 5.20409564e+03,\n",
      "       1.33348894e+04, 1.34234617e+04, 5.88021381e+02])\n",
      "best ll: 59462.34765625, bestParams: [tensor(0.2547), tensor(0.1834), tensor(0.1196), tensor(22203.2520), tensor(5423.7095), tensor(5616.9927), tensor(7398.4941)]\n",
      "epoch 1\n",
      " final_simplex: (array([[9.78780448e-01, 2.57929544e-03, 1.85633879e-03, 1.36028747e+04,\n",
      "        5.46206913e+03, 5.09765519e+03, 1.05793258e+02],\n",
      "       [9.78780449e-01, 2.57929526e-03, 1.85633841e-03, 1.36028748e+04,\n",
      "        5.46206915e+03, 5.09765520e+03, 1.05793210e+02],\n",
      "       [9.78780448e-01, 2.57929499e-03, 1.85633898e-03, 1.36028748e+04,\n",
      "        5.46206913e+03, 5.09765520e+03, 1.05793227e+02],\n",
      "       [9.78780449e-01, 2.57929540e-03, 1.85633782e-03, 1.36028748e+04,\n",
      "        5.46206916e+03, 5.09765519e+03, 1.05793196e+02],\n",
      "       [9.78780449e-01, 2.57929531e-03, 1.85633805e-03, 1.36028748e+04,\n",
      "        5.46206915e+03, 5.09765519e+03, 1.05793196e+02],\n",
      "       [9.78780448e-01, 2.57929513e-03, 1.85633908e-03, 1.36028748e+04,\n",
      "        5.46206913e+03, 5.09765520e+03, 1.05793232e+02],\n",
      "       [9.78780449e-01, 2.57929545e-03, 1.85633872e-03, 1.36028747e+04,\n",
      "        5.46206914e+03, 5.09765521e+03, 1.05793226e+02],\n",
      "       [9.78780447e-01, 2.57929493e-03, 1.85633886e-03, 1.36028748e+04,\n",
      "        5.46206914e+03, 5.09765521e+03, 1.05793212e+02]]), array([36634.9375, 36634.9375, 36634.9375, 36634.9375, 36634.9375,\n",
      "       36634.9375, 36634.9375, 36634.9375]))\n",
      "           fun: 36634.9375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1335\n",
      "           nit: 468\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.78780448e-01, 2.57929544e-03, 1.85633879e-03, 1.36028747e+04,\n",
      "       5.46206913e+03, 5.09765519e+03, 1.05793258e+02])\n",
      "minPrevious 36641.8125\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.78780448e-01, 2.57929544e-03, 1.85633879e-03, 1.36028747e+04,\n",
      "        5.46206913e+03, 5.09765519e+03, 1.05793258e+02],\n",
      "       [9.78780449e-01, 2.57929526e-03, 1.85633841e-03, 1.36028748e+04,\n",
      "        5.46206915e+03, 5.09765520e+03, 1.05793210e+02],\n",
      "       [9.78780448e-01, 2.57929499e-03, 1.85633898e-03, 1.36028748e+04,\n",
      "        5.46206913e+03, 5.09765520e+03, 1.05793227e+02],\n",
      "       [9.78780449e-01, 2.57929540e-03, 1.85633782e-03, 1.36028748e+04,\n",
      "        5.46206916e+03, 5.09765519e+03, 1.05793196e+02],\n",
      "       [9.78780449e-01, 2.57929531e-03, 1.85633805e-03, 1.36028748e+04,\n",
      "        5.46206915e+03, 5.09765519e+03, 1.05793196e+02],\n",
      "       [9.78780448e-01, 2.57929513e-03, 1.85633908e-03, 1.36028748e+04,\n",
      "        5.46206913e+03, 5.09765520e+03, 1.05793232e+02],\n",
      "       [9.78780449e-01, 2.57929545e-03, 1.85633872e-03, 1.36028747e+04,\n",
      "        5.46206914e+03, 5.09765521e+03, 1.05793226e+02],\n",
      "       [9.78780447e-01, 2.57929493e-03, 1.85633886e-03, 1.36028748e+04,\n",
      "        5.46206914e+03, 5.09765521e+03, 1.05793212e+02]]), array([36634.9375, 36634.9375, 36634.9375, 36634.9375, 36634.9375,\n",
      "       36634.9375, 36634.9375, 36634.9375]))\n",
      "           fun: 36634.9375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1335\n",
      "           nit: 468\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.78780448e-01, 2.57929544e-03, 1.85633879e-03, 1.36028747e+04,\n",
      "       5.46206913e+03, 5.09765519e+03, 1.05793258e+02])\n",
      "best ll: 52020.56640625, bestParams: [tensor(0.3933), tensor(0.0430), tensor(0.0657), tensor(23122.5527), tensor(9392.9043), tensor(11255.1406), tensor(13925.7988)]\n",
      "epoch 2\n",
      " final_simplex: (array([[9.34966077e-01, 2.25494491e-02, 4.22067096e-02, 2.02787470e+04,\n",
      "        8.66769262e+03, 8.32355129e+03, 1.66883469e+04],\n",
      "       [9.34966077e-01, 2.25494490e-02, 4.22067095e-02, 2.02787470e+04,\n",
      "        8.66769261e+03, 8.32355131e+03, 1.66883470e+04],\n",
      "       [9.34966077e-01, 2.25494490e-02, 4.22067094e-02, 2.02787470e+04,\n",
      "        8.66769259e+03, 8.32355133e+03, 1.66883469e+04],\n",
      "       [9.34966076e-01, 2.25494490e-02, 4.22067099e-02, 2.02787469e+04,\n",
      "        8.66769261e+03, 8.32355133e+03, 1.66883469e+04],\n",
      "       [9.34966077e-01, 2.25494488e-02, 4.22067095e-02, 2.02787470e+04,\n",
      "        8.66769258e+03, 8.32355136e+03, 1.66883470e+04],\n",
      "       [9.34966076e-01, 2.25494489e-02, 4.22067095e-02, 2.02787470e+04,\n",
      "        8.66769255e+03, 8.32355138e+03, 1.66883470e+04],\n",
      "       [9.34966077e-01, 2.25494493e-02, 4.22067097e-02, 2.02787469e+04,\n",
      "        8.66769263e+03, 8.32355129e+03, 1.66883469e+04],\n",
      "       [9.34966077e-01, 2.25494488e-02, 4.22067091e-02, 2.02787470e+04,\n",
      "        8.66769255e+03, 8.32355138e+03, 1.66883470e+04]]), array([37538.3828125, 37538.3828125, 37538.3828125, 37538.3828125,\n",
      "       37538.3828125, 37538.3828125, 37538.3828125, 37538.3828125]))\n",
      "           fun: 37538.3828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1152\n",
      "           nit: 383\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.34966077e-01, 2.25494491e-02, 4.22067096e-02, 2.02787470e+04,\n",
      "       8.66769262e+03, 8.32355129e+03, 1.66883469e+04])\n",
      "minPrevious 36634.9375\n",
      "best ll: 54392.56640625, bestParams: [tensor(0.3297), tensor(0.0297), tensor(0.0895), tensor(20355.1719), tensor(1752.6177), tensor(1744.5811), tensor(21702.0020)]\n",
      "epoch 3\n",
      " final_simplex: (array([[9.17527927e-01, 2.41130124e-02, 5.80730452e-02, 1.51052912e+04,\n",
      "        1.25233621e+03, 1.23712323e+03, 1.78225686e+04],\n",
      "       [9.17527927e-01, 2.41130124e-02, 5.80730452e-02, 1.51052911e+04,\n",
      "        1.25233621e+03, 1.23712323e+03, 1.78225685e+04],\n",
      "       [9.17527927e-01, 2.41130124e-02, 5.80730452e-02, 1.51052911e+04,\n",
      "        1.25233621e+03, 1.23712323e+03, 1.78225685e+04],\n",
      "       [9.17527927e-01, 2.41130124e-02, 5.80730452e-02, 1.51052911e+04,\n",
      "        1.25233621e+03, 1.23712323e+03, 1.78225685e+04],\n",
      "       [9.17527927e-01, 2.41130124e-02, 5.80730452e-02, 1.51052911e+04,\n",
      "        1.25233621e+03, 1.23712323e+03, 1.78225685e+04],\n",
      "       [9.17527927e-01, 2.41130124e-02, 5.80730452e-02, 1.51052911e+04,\n",
      "        1.25233621e+03, 1.23712323e+03, 1.78225685e+04],\n",
      "       [9.17527927e-01, 2.41130124e-02, 5.80730452e-02, 1.51052911e+04,\n",
      "        1.25233621e+03, 1.23712323e+03, 1.78225685e+04],\n",
      "       [9.17527927e-01, 2.41130124e-02, 5.80730452e-02, 1.51052911e+04,\n",
      "        1.25233621e+03, 1.23712323e+03, 1.78225685e+04]]), array([37996.1953125, 37996.1953125, 37996.1953125, 37996.1953125,\n",
      "       37996.1953125, 37996.1953125, 37996.1953125, 37996.1953125]))\n",
      "           fun: 37996.1953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1337\n",
      "           nit: 435\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.17527927e-01, 2.41130124e-02, 5.80730452e-02, 1.51052912e+04,\n",
      "       1.25233621e+03, 1.23712323e+03, 1.78225686e+04])\n",
      "minPrevious 36634.9375\n",
      "best ll: 54024.23828125, bestParams: [tensor(0.3665), tensor(0.1204), tensor(0.0194), tensor(16159.1934), tensor(16730.3633), tensor(23708.2051), tensor(23588.0703)]\n",
      "epoch 4\n",
      " final_simplex: (array([[8.90890262e-01, 8.80247155e-02, 1.50257671e-02, 1.92067341e+04,\n",
      "        1.60267350e+04, 1.42576824e+04, 2.22311874e+04],\n",
      "       [8.90890263e-01, 8.80247153e-02, 1.50257671e-02, 1.92067341e+04,\n",
      "        1.60267350e+04, 1.42576825e+04, 2.22311874e+04],\n",
      "       [8.90890263e-01, 8.80247153e-02, 1.50257671e-02, 1.92067340e+04,\n",
      "        1.60267350e+04, 1.42576824e+04, 2.22311875e+04],\n",
      "       [8.90890263e-01, 8.80247152e-02, 1.50257671e-02, 1.92067340e+04,\n",
      "        1.60267350e+04, 1.42576824e+04, 2.22311875e+04],\n",
      "       [8.90890263e-01, 8.80247152e-02, 1.50257671e-02, 1.92067340e+04,\n",
      "        1.60267350e+04, 1.42576825e+04, 2.22311875e+04],\n",
      "       [8.90890263e-01, 8.80247153e-02, 1.50257671e-02, 1.92067340e+04,\n",
      "        1.60267350e+04, 1.42576825e+04, 2.22311874e+04],\n",
      "       [8.90890263e-01, 8.80247153e-02, 1.50257671e-02, 1.92067341e+04,\n",
      "        1.60267350e+04, 1.42576824e+04, 2.22311875e+04],\n",
      "       [8.90890263e-01, 8.80247153e-02, 1.50257671e-02, 1.92067341e+04,\n",
      "        1.60267350e+04, 1.42576825e+04, 2.22311874e+04]]), array([38428.3828125, 38428.3828125, 38428.3828125, 38428.3828125,\n",
      "       38428.3828125, 38428.3828125, 38428.3828125, 38428.3828125]))\n",
      "           fun: 38428.3828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1270\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.90890262e-01, 8.80247155e-02, 1.50257671e-02, 1.92067341e+04,\n",
      "       1.60267350e+04, 1.42576824e+04, 2.22311874e+04])\n",
      "minPrevious 36634.9375\n",
      "best ll: 57529.90625, bestParams: [tensor(0.2677), tensor(0.0858), tensor(0.0379), tensor(14636.8281), tensor(18633.6152), tensor(16992.7793), tensor(11300.1689)]\n",
      "epoch 5\n",
      " final_simplex: (array([[8.03732608e-01, 1.29894628e-01, 6.42695601e-05, 1.47729194e+04,\n",
      "        9.94436817e+03, 1.06325505e+04, 2.45810569e+01],\n",
      "       [8.03732609e-01, 1.29894628e-01, 6.42694616e-05, 1.47729194e+04,\n",
      "        9.94436815e+03, 1.06325505e+04, 2.45810541e+01],\n",
      "       [8.03732609e-01, 1.29894628e-01, 6.42694637e-05, 1.47729194e+04,\n",
      "        9.94436813e+03, 1.06325505e+04, 2.45810531e+01],\n",
      "       [8.03732608e-01, 1.29894628e-01, 6.42694134e-05, 1.47729194e+04,\n",
      "        9.94436813e+03, 1.06325505e+04, 2.45810536e+01],\n",
      "       [8.03732610e-01, 1.29894628e-01, 6.42693004e-05, 1.47729194e+04,\n",
      "        9.94436813e+03, 1.06325505e+04, 2.45810483e+01],\n",
      "       [8.03732610e-01, 1.29894629e-01, 6.42694144e-05, 1.47729193e+04,\n",
      "        9.94436813e+03, 1.06325505e+04, 2.45810633e+01],\n",
      "       [8.03732610e-01, 1.29894628e-01, 6.42694125e-05, 1.47729193e+04,\n",
      "        9.94436813e+03, 1.06325505e+04, 2.45810635e+01],\n",
      "       [8.03732608e-01, 1.29894628e-01, 6.42694724e-05, 1.47729194e+04,\n",
      "        9.94436816e+03, 1.06325505e+04, 2.45810451e+01]]), array([40335.64453125, 40335.64453125, 40335.64453125, 40335.64453125,\n",
      "       40335.64453125, 40335.64453125, 40335.64453125, 40335.64453125]))\n",
      "           fun: 40335.64453125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1188\n",
      "           nit: 382\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.03732608e-01, 1.29894628e-01, 6.42695601e-05, 1.47729194e+04,\n",
      "       9.94436817e+03, 1.06325505e+04, 2.45810569e+01])\n",
      "minPrevious 36634.9375\n",
      "best ll: 54771.69140625, bestParams: [tensor(0.3258), tensor(0.0342), tensor(0.1005), tensor(17126.0371), tensor(13204.3496), tensor(12205.7246), tensor(17894.7227)]\n",
      "epoch 6\n",
      " final_simplex: (array([[8.87400495e-01, 1.08602130e-02, 9.89567307e-02, 1.17783189e+04,\n",
      "        1.11881229e+04, 1.07838632e+04, 1.14031915e+04],\n",
      "       [8.87400496e-01, 1.08602129e-02, 9.89567303e-02, 1.17783188e+04,\n",
      "        1.11881229e+04, 1.07838632e+04, 1.14031916e+04],\n",
      "       [8.87400495e-01, 1.08602130e-02, 9.89567305e-02, 1.17783188e+04,\n",
      "        1.11881229e+04, 1.07838632e+04, 1.14031916e+04],\n",
      "       [8.87400495e-01, 1.08602130e-02, 9.89567305e-02, 1.17783188e+04,\n",
      "        1.11881229e+04, 1.07838632e+04, 1.14031916e+04],\n",
      "       [8.87400496e-01, 1.08602130e-02, 9.89567304e-02, 1.17783189e+04,\n",
      "        1.11881229e+04, 1.07838633e+04, 1.14031915e+04],\n",
      "       [8.87400495e-01, 1.08602130e-02, 9.89567305e-02, 1.17783189e+04,\n",
      "        1.11881229e+04, 1.07838632e+04, 1.14031916e+04],\n",
      "       [8.87400496e-01, 1.08602130e-02, 9.89567303e-02, 1.17783188e+04,\n",
      "        1.11881230e+04, 1.07838632e+04, 1.14031916e+04],\n",
      "       [8.87400496e-01, 1.08602130e-02, 9.89567303e-02, 1.17783189e+04,\n",
      "        1.11881229e+04, 1.07838633e+04, 1.14031916e+04]]), array([38532.50390625, 38532.50390625, 38532.50390625, 38532.50390625,\n",
      "       38532.50390625, 38532.50390625, 38532.50390625, 38532.50390625]))\n",
      "           fun: 38532.50390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1181\n",
      "           nit: 387\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.87400495e-01, 1.08602130e-02, 9.89567307e-02, 1.17783189e+04,\n",
      "       1.11881229e+04, 1.07838632e+04, 1.14031915e+04])\n",
      "minPrevious 36634.9375\n",
      "best ll: 55155.83984375, bestParams: [tensor(0.3369), tensor(0.0719), tensor(0.1881), tensor(19778.6621), tensor(14293.6592), tensor(14513.6104), tensor(7949.8521)]\n",
      "epoch 7\n",
      " final_simplex: (array([[8.34677918e-01, 3.55212359e-02, 1.27369706e-01, 1.92306619e+04,\n",
      "        8.56688003e+03, 9.11352272e+03, 5.40609573e+03],\n",
      "       [8.34677917e-01, 3.55212361e-02, 1.27369707e-01, 1.92306619e+04,\n",
      "        8.56688002e+03, 9.11352270e+03, 5.40609574e+03],\n",
      "       [8.34677917e-01, 3.55212361e-02, 1.27369707e-01, 1.92306619e+04,\n",
      "        8.56688006e+03, 9.11352270e+03, 5.40609575e+03],\n",
      "       [8.34677917e-01, 3.55212361e-02, 1.27369707e-01, 1.92306619e+04,\n",
      "        8.56688004e+03, 9.11352271e+03, 5.40609574e+03],\n",
      "       [8.34677917e-01, 3.55212362e-02, 1.27369706e-01, 1.92306620e+04,\n",
      "        8.56687998e+03, 9.11352269e+03, 5.40609574e+03],\n",
      "       [8.34677918e-01, 3.55212359e-02, 1.27369706e-01, 1.92306619e+04,\n",
      "        8.56688004e+03, 9.11352274e+03, 5.40609573e+03],\n",
      "       [8.34677919e-01, 3.55212360e-02, 1.27369706e-01, 1.92306619e+04,\n",
      "        8.56688001e+03, 9.11352272e+03, 5.40609573e+03],\n",
      "       [8.34677918e-01, 3.55212359e-02, 1.27369706e-01, 1.92306619e+04,\n",
      "        8.56688003e+03, 9.11352271e+03, 5.40609573e+03]]), array([39680.2734375, 39680.2734375, 39680.2734375, 39680.2734375,\n",
      "       39680.2734375, 39680.2734375, 39680.2734375, 39680.2734375]))\n",
      "           fun: 39680.2734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 415\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.34677918e-01, 3.55212359e-02, 1.27369706e-01, 1.92306619e+04,\n",
      "       8.56688003e+03, 9.11352272e+03, 5.40609573e+03])\n",
      "minPrevious 36634.9375\n",
      "best ll: 55572.140625, bestParams: [tensor(0.3063), tensor(0.0066), tensor(0.0887), tensor(4689.6533), tensor(21343.5371), tensor(18351.5527), tensor(2236.8428)]\n",
      "epoch 8\n",
      " final_simplex: (array([[9.22520373e-01, 8.18621365e-03, 6.72486474e-02, 2.89224665e+03,\n",
      "        7.79447978e+03, 7.81880040e+03, 9.36624795e+02],\n",
      "       [9.22520373e-01, 8.18621365e-03, 6.72486472e-02, 2.89224664e+03,\n",
      "        7.79447978e+03, 7.81880043e+03, 9.36624795e+02],\n",
      "       [9.22520373e-01, 8.18621370e-03, 6.72486474e-02, 2.89224667e+03,\n",
      "        7.79447978e+03, 7.81880043e+03, 9.36624800e+02],\n",
      "       [9.22520374e-01, 8.18621364e-03, 6.72486469e-02, 2.89224663e+03,\n",
      "        7.79447978e+03, 7.81880045e+03, 9.36624794e+02],\n",
      "       [9.22520371e-01, 8.18621365e-03, 6.72486484e-02, 2.89224668e+03,\n",
      "        7.79447987e+03, 7.81880038e+03, 9.36624787e+02],\n",
      "       [9.22520371e-01, 8.18621368e-03, 6.72486484e-02, 2.89224659e+03,\n",
      "        7.79447979e+03, 7.81880042e+03, 9.36624803e+02],\n",
      "       [9.22520373e-01, 8.18621365e-03, 6.72486472e-02, 2.89224665e+03,\n",
      "        7.79447985e+03, 7.81880047e+03, 9.36624790e+02],\n",
      "       [9.22520373e-01, 8.18621362e-03, 6.72486477e-02, 2.89224665e+03,\n",
      "        7.79447979e+03, 7.81880036e+03, 9.36624788e+02]]), array([37701.71484375, 37701.71484375, 37701.71484375, 37701.71484375,\n",
      "       37701.71484375, 37701.71484375, 37701.71484375, 37701.71484375]))\n",
      "           fun: 37701.71484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1190\n",
      "           nit: 417\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.22520373e-01, 8.18621365e-03, 6.72486474e-02, 2.89224665e+03,\n",
      "       7.79447978e+03, 7.81880040e+03, 9.36624795e+02])\n",
      "minPrevious 36634.9375\n",
      "best ll: 57337.890625, bestParams: [tensor(0.3009), tensor(0.2031), tensor(0.1066), tensor(15311.0723), tensor(12445.8623), tensor(11074.0742), tensor(14672.4453)]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.14636135e-01, 7.47903278e-03, 7.73448846e-02, 1.46188644e+04,\n",
      "        1.17510495e+04, 1.05301150e+04, 1.19061029e+04],\n",
      "       [9.14636135e-01, 7.47903333e-03, 7.73448844e-02, 1.46188643e+04,\n",
      "        1.17510495e+04, 1.05301150e+04, 1.19061029e+04],\n",
      "       [9.14636136e-01, 7.47903255e-03, 7.73448845e-02, 1.46188644e+04,\n",
      "        1.17510495e+04, 1.05301150e+04, 1.19061029e+04],\n",
      "       [9.14636137e-01, 7.47903172e-03, 7.73448844e-02, 1.46188644e+04,\n",
      "        1.17510495e+04, 1.05301150e+04, 1.19061029e+04],\n",
      "       [9.14636138e-01, 7.47903125e-03, 7.73448844e-02, 1.46188644e+04,\n",
      "        1.17510495e+04, 1.05301151e+04, 1.19061029e+04],\n",
      "       [9.14636137e-01, 7.47903213e-03, 7.73448843e-02, 1.46188643e+04,\n",
      "        1.17510495e+04, 1.05301150e+04, 1.19061029e+04],\n",
      "       [9.14636137e-01, 7.47903086e-03, 7.73448846e-02, 1.46188644e+04,\n",
      "        1.17510495e+04, 1.05301150e+04, 1.19061029e+04],\n",
      "       [9.14636138e-01, 7.47903169e-03, 7.73448842e-02, 1.46188643e+04,\n",
      "        1.17510495e+04, 1.05301151e+04, 1.19061028e+04]]), array([38028.46875, 38028.46875, 38028.46875, 38028.46875, 38028.46875,\n",
      "       38028.46875, 38028.46875, 38028.46875]))\n",
      "           fun: 38028.46875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1220\n",
      "           nit: 434\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.14636135e-01, 7.47903278e-03, 7.73448846e-02, 1.46188644e+04,\n",
      "       1.17510495e+04, 1.05301150e+04, 1.19061029e+04])\n",
      "minPrevious 36634.9375\n",
      "best ll: 60228.93359375, bestParams: [tensor(0.2443), tensor(0.1853), tensor(0.0965), tensor(14212.8359), tensor(16548.2969), tensor(20133.9590), tensor(17781.8359)]\n",
      "epoch 10\n",
      " final_simplex: (array([[7.80211739e-01, 1.11986264e-01, 9.92357949e-02, 4.94222407e+03,\n",
      "        9.46294911e+03, 1.02682278e+04, 1.78834946e+04],\n",
      "       [7.80211738e-01, 1.11986264e-01, 9.92357950e-02, 4.94222406e+03,\n",
      "        9.46294908e+03, 1.02682278e+04, 1.78834946e+04],\n",
      "       [7.80211740e-01, 1.11986262e-01, 9.92357949e-02, 4.94222410e+03,\n",
      "        9.46294906e+03, 1.02682278e+04, 1.78834946e+04],\n",
      "       [7.80211738e-01, 1.11986263e-01, 9.92357950e-02, 4.94222401e+03,\n",
      "        9.46294920e+03, 1.02682278e+04, 1.78834946e+04],\n",
      "       [7.80211739e-01, 1.11986262e-01, 9.92357949e-02, 4.94222405e+03,\n",
      "        9.46294916e+03, 1.02682278e+04, 1.78834946e+04],\n",
      "       [7.80211739e-01, 1.11986263e-01, 9.92357950e-02, 4.94222398e+03,\n",
      "        9.46294919e+03, 1.02682278e+04, 1.78834946e+04],\n",
      "       [7.80211739e-01, 1.11986265e-01, 9.92357952e-02, 4.94222402e+03,\n",
      "        9.46294905e+03, 1.02682278e+04, 1.78834946e+04],\n",
      "       [7.80211739e-01, 1.11986264e-01, 9.92357950e-02, 4.94222408e+03,\n",
      "        9.46294904e+03, 1.02682278e+04, 1.78834946e+04]]), array([41091.5078125, 41091.5078125, 41091.5078125, 41091.5078125,\n",
      "       41091.5078125, 41091.5078125, 41091.5078125, 41091.5078125]))\n",
      "           fun: 41091.5078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 440\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.80211739e-01, 1.11986264e-01, 9.92357949e-02, 4.94222407e+03,\n",
      "       9.46294911e+03, 1.02682278e+04, 1.78834946e+04])\n",
      "minPrevious 36634.9375\n",
      "best ll: 58668.8984375, bestParams: [tensor(0.2499), tensor(0.0109), tensor(0.1514), tensor(20908.4629), tensor(12545.0068), tensor(12417.3184), tensor(24538.1484)]\n",
      "epoch 11\n",
      " final_simplex: (array([[9.89429338e-01, 9.34101723e-03, 8.94275329e-04, 1.87936775e+04,\n",
      "        6.57008739e+03, 6.57845029e+03, 6.24460928e+03],\n",
      "       [9.89429338e-01, 9.34101726e-03, 8.94275089e-04, 1.87936776e+04,\n",
      "        6.57008738e+03, 6.57845030e+03, 6.24460923e+03],\n",
      "       [9.89429338e-01, 9.34101726e-03, 8.94275005e-04, 1.87936776e+04,\n",
      "        6.57008737e+03, 6.57845030e+03, 6.24460923e+03],\n",
      "       [9.89429338e-01, 9.34101725e-03, 8.94275472e-04, 1.87936776e+04,\n",
      "        6.57008738e+03, 6.57845028e+03, 6.24460923e+03],\n",
      "       [9.89429338e-01, 9.34101725e-03, 8.94275219e-04, 1.87936776e+04,\n",
      "        6.57008738e+03, 6.57845030e+03, 6.24460925e+03],\n",
      "       [9.89429338e-01, 9.34101727e-03, 8.94275014e-04, 1.87936776e+04,\n",
      "        6.57008737e+03, 6.57845029e+03, 6.24460922e+03],\n",
      "       [9.89429338e-01, 9.34101725e-03, 8.94275165e-04, 1.87936776e+04,\n",
      "        6.57008739e+03, 6.57845029e+03, 6.24460923e+03],\n",
      "       [9.89429338e-01, 9.34101724e-03, 8.94275216e-04, 1.87936776e+04,\n",
      "        6.57008739e+03, 6.57845028e+03, 6.24460926e+03]]), array([36413.9609375, 36413.9609375, 36413.9609375, 36413.9609375,\n",
      "       36413.9609375, 36413.9609375, 36413.9609375, 36413.9609375]))\n",
      "           fun: 36413.9609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1238\n",
      "           nit: 410\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.89429338e-01, 9.34101723e-03, 8.94275329e-04, 1.87936775e+04,\n",
      "       6.57008739e+03, 6.57845029e+03, 6.24460928e+03])\n",
      "minPrevious 36634.9375\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.89429338e-01, 9.34101723e-03, 8.94275329e-04, 1.87936775e+04,\n",
      "        6.57008739e+03, 6.57845029e+03, 6.24460928e+03],\n",
      "       [9.89429338e-01, 9.34101726e-03, 8.94275089e-04, 1.87936776e+04,\n",
      "        6.57008738e+03, 6.57845030e+03, 6.24460923e+03],\n",
      "       [9.89429338e-01, 9.34101726e-03, 8.94275005e-04, 1.87936776e+04,\n",
      "        6.57008737e+03, 6.57845030e+03, 6.24460923e+03],\n",
      "       [9.89429338e-01, 9.34101725e-03, 8.94275472e-04, 1.87936776e+04,\n",
      "        6.57008738e+03, 6.57845028e+03, 6.24460923e+03],\n",
      "       [9.89429338e-01, 9.34101725e-03, 8.94275219e-04, 1.87936776e+04,\n",
      "        6.57008738e+03, 6.57845030e+03, 6.24460925e+03],\n",
      "       [9.89429338e-01, 9.34101727e-03, 8.94275014e-04, 1.87936776e+04,\n",
      "        6.57008737e+03, 6.57845029e+03, 6.24460922e+03],\n",
      "       [9.89429338e-01, 9.34101725e-03, 8.94275165e-04, 1.87936776e+04,\n",
      "        6.57008739e+03, 6.57845029e+03, 6.24460923e+03],\n",
      "       [9.89429338e-01, 9.34101724e-03, 8.94275216e-04, 1.87936776e+04,\n",
      "        6.57008739e+03, 6.57845028e+03, 6.24460926e+03]]), array([36413.9609375, 36413.9609375, 36413.9609375, 36413.9609375,\n",
      "       36413.9609375, 36413.9609375, 36413.9609375, 36413.9609375]))\n",
      "           fun: 36413.9609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1238\n",
      "           nit: 410\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.89429338e-01, 9.34101723e-03, 8.94275329e-04, 1.87936775e+04,\n",
      "       6.57008739e+03, 6.57845029e+03, 6.24460928e+03])\n",
      "best ll: 56706.65234375, bestParams: [tensor(0.3124), tensor(0.0732), tensor(0.1610), tensor(4811.6450), tensor(18693.2461), tensor(23721.5000), tensor(9491.1016)]\n",
      "epoch 12\n",
      " final_simplex: (array([[9.08195436e-01, 8.08852989e-02, 6.68524143e-03, 5.19122602e+03,\n",
      "        1.69934069e+04, 1.67694484e+04, 5.85637511e+03],\n",
      "       [9.08195438e-01, 8.08852989e-02, 6.68524107e-03, 5.19122600e+03,\n",
      "        1.69934069e+04, 1.67694484e+04, 5.85637509e+03],\n",
      "       [9.08195439e-01, 8.08852989e-02, 6.68524095e-03, 5.19122602e+03,\n",
      "        1.69934069e+04, 1.67694484e+04, 5.85637507e+03],\n",
      "       [9.08195436e-01, 8.08852991e-02, 6.68524122e-03, 5.19122602e+03,\n",
      "        1.69934069e+04, 1.67694484e+04, 5.85637512e+03],\n",
      "       [9.08195437e-01, 8.08852990e-02, 6.68524128e-03, 5.19122601e+03,\n",
      "        1.69934069e+04, 1.67694484e+04, 5.85637510e+03],\n",
      "       [9.08195438e-01, 8.08852987e-02, 6.68524103e-03, 5.19122601e+03,\n",
      "        1.69934069e+04, 1.67694484e+04, 5.85637510e+03],\n",
      "       [9.08195437e-01, 8.08852990e-02, 6.68524120e-03, 5.19122601e+03,\n",
      "        1.69934069e+04, 1.67694485e+04, 5.85637512e+03],\n",
      "       [9.08195438e-01, 8.08852989e-02, 6.68524092e-03, 5.19122601e+03,\n",
      "        1.69934069e+04, 1.67694484e+04, 5.85637509e+03]]), array([37855.30859375, 37855.30859375, 37855.30859375, 37855.30859375,\n",
      "       37855.30859375, 37855.30859375, 37855.30859375, 37855.30859375]))\n",
      "           fun: 37855.30859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1187\n",
      "           nit: 391\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.08195436e-01, 8.08852989e-02, 6.68524143e-03, 5.19122602e+03,\n",
      "       1.69934069e+04, 1.67694484e+04, 5.85637511e+03])\n",
      "minPrevious 36413.9609375\n",
      "best ll: 57384.34765625, bestParams: [tensor(0.3088), tensor(0.1362), tensor(0.1885), tensor(12393.5400), tensor(2524.2080), tensor(3262.1360), tensor(12062.0303)]\n",
      "epoch 13\n",
      " final_simplex: (array([[9.58852122e-01, 3.82215085e-02, 1.26587857e-03, 1.14867168e+04,\n",
      "        2.59487247e+03, 2.46426952e+03, 1.49618614e+04],\n",
      "       [9.58852122e-01, 3.82215086e-02, 1.26587855e-03, 1.14867169e+04,\n",
      "        2.59487247e+03, 2.46426952e+03, 1.49618613e+04],\n",
      "       [9.58852122e-01, 3.82215087e-02, 1.26587853e-03, 1.14867169e+04,\n",
      "        2.59487247e+03, 2.46426952e+03, 1.49618613e+04],\n",
      "       [9.58852122e-01, 3.82215086e-02, 1.26587844e-03, 1.14867169e+04,\n",
      "        2.59487248e+03, 2.46426951e+03, 1.49618613e+04],\n",
      "       [9.58852122e-01, 3.82215086e-02, 1.26587860e-03, 1.14867169e+04,\n",
      "        2.59487247e+03, 2.46426952e+03, 1.49618613e+04],\n",
      "       [9.58852122e-01, 3.82215086e-02, 1.26587855e-03, 1.14867168e+04,\n",
      "        2.59487248e+03, 2.46426952e+03, 1.49618613e+04],\n",
      "       [9.58852122e-01, 3.82215086e-02, 1.26587844e-03, 1.14867169e+04,\n",
      "        2.59487248e+03, 2.46426952e+03, 1.49618613e+04],\n",
      "       [9.58852122e-01, 3.82215086e-02, 1.26587844e-03, 1.14867169e+04,\n",
      "        2.59487248e+03, 2.46426952e+03, 1.49618613e+04]]), array([37138.921875, 37138.921875, 37138.921875, 37138.921875,\n",
      "       37138.921875, 37138.921875, 37138.921875, 37138.921875]))\n",
      "           fun: 37138.921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1345\n",
      "           nit: 465\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.58852122e-01, 3.82215085e-02, 1.26587857e-03, 1.14867168e+04,\n",
      "       2.59487247e+03, 2.46426952e+03, 1.49618614e+04])\n",
      "minPrevious 36413.9609375\n",
      "best ll: 58738.9140625, bestParams: [tensor(0.2474), tensor(0.0211), tensor(0.1171), tensor(6330.5225), tensor(11487.2158), tensor(13315.1387), tensor(13004.4072)]\n",
      "epoch 14\n",
      " final_simplex: (array([[9.90582380e-01, 4.12032166e-03, 3.16003813e-03, 7.56217335e+03,\n",
      "        8.36831204e+03, 8.77973518e+03, 8.74643454e+03],\n",
      "       [9.90582380e-01, 4.12032185e-03, 3.16003808e-03, 7.56217330e+03,\n",
      "        8.36831205e+03, 8.77973518e+03, 8.74643461e+03],\n",
      "       [9.90582379e-01, 4.12032183e-03, 3.16003817e-03, 7.56217331e+03,\n",
      "        8.36831205e+03, 8.77973517e+03, 8.74643460e+03],\n",
      "       [9.90582380e-01, 4.12032176e-03, 3.16003793e-03, 7.56217333e+03,\n",
      "        8.36831207e+03, 8.77973517e+03, 8.74643456e+03],\n",
      "       [9.90582380e-01, 4.12032187e-03, 3.16003821e-03, 7.56217330e+03,\n",
      "        8.36831205e+03, 8.77973518e+03, 8.74643462e+03],\n",
      "       [9.90582380e-01, 4.12032185e-03, 3.16003835e-03, 7.56217330e+03,\n",
      "        8.36831206e+03, 8.77973516e+03, 8.74643462e+03],\n",
      "       [9.90582379e-01, 4.12032166e-03, 3.16003812e-03, 7.56217335e+03,\n",
      "        8.36831206e+03, 8.77973516e+03, 8.74643452e+03],\n",
      "       [9.90582380e-01, 4.12032181e-03, 3.16003801e-03, 7.56217332e+03,\n",
      "        8.36831207e+03, 8.77973516e+03, 8.74643457e+03]]), array([36234.44921875, 36234.44921875, 36234.44921875, 36234.44921875,\n",
      "       36234.44921875, 36234.44921875, 36234.44921875, 36234.44921875]))\n",
      "           fun: 36234.44921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1260\n",
      "           nit: 402\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.90582380e-01, 4.12032166e-03, 3.16003813e-03, 7.56217335e+03,\n",
      "       8.36831204e+03, 8.77973518e+03, 8.74643454e+03])\n",
      "minPrevious 36413.9609375\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.90582380e-01, 4.12032166e-03, 3.16003813e-03, 7.56217335e+03,\n",
      "        8.36831204e+03, 8.77973518e+03, 8.74643454e+03],\n",
      "       [9.90582380e-01, 4.12032185e-03, 3.16003808e-03, 7.56217330e+03,\n",
      "        8.36831205e+03, 8.77973518e+03, 8.74643461e+03],\n",
      "       [9.90582379e-01, 4.12032183e-03, 3.16003817e-03, 7.56217331e+03,\n",
      "        8.36831205e+03, 8.77973517e+03, 8.74643460e+03],\n",
      "       [9.90582380e-01, 4.12032176e-03, 3.16003793e-03, 7.56217333e+03,\n",
      "        8.36831207e+03, 8.77973517e+03, 8.74643456e+03],\n",
      "       [9.90582380e-01, 4.12032187e-03, 3.16003821e-03, 7.56217330e+03,\n",
      "        8.36831205e+03, 8.77973518e+03, 8.74643462e+03],\n",
      "       [9.90582380e-01, 4.12032185e-03, 3.16003835e-03, 7.56217330e+03,\n",
      "        8.36831206e+03, 8.77973516e+03, 8.74643462e+03],\n",
      "       [9.90582379e-01, 4.12032166e-03, 3.16003812e-03, 7.56217335e+03,\n",
      "        8.36831206e+03, 8.77973516e+03, 8.74643452e+03],\n",
      "       [9.90582380e-01, 4.12032181e-03, 3.16003801e-03, 7.56217332e+03,\n",
      "        8.36831207e+03, 8.77973516e+03, 8.74643457e+03]]), array([36234.44921875, 36234.44921875, 36234.44921875, 36234.44921875,\n",
      "       36234.44921875, 36234.44921875, 36234.44921875, 36234.44921875]))\n",
      "           fun: 36234.44921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1260\n",
      "           nit: 402\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.90582380e-01, 4.12032166e-03, 3.16003813e-03, 7.56217335e+03,\n",
      "       8.36831204e+03, 8.77973518e+03, 8.74643454e+03])\n",
      "best ll: 57389.7578125, bestParams: [tensor(0.2829), tensor(0.0316), tensor(0.1106), tensor(6930.6304), tensor(3355.6809), tensor(4403.8315), tensor(5041.9341)]\n",
      "epoch 15\n",
      " final_simplex: (array([[9.38989262e-01, 1.63651717e-02, 4.42916679e-02, 4.22160397e+03,\n",
      "        3.82922144e+03, 3.78093574e+03, 3.32162713e+03],\n",
      "       [9.38989262e-01, 1.63651717e-02, 4.42916674e-02, 4.22160400e+03,\n",
      "        3.82922143e+03, 3.78093576e+03, 3.32162711e+03],\n",
      "       [9.38989262e-01, 1.63651718e-02, 4.42916673e-02, 4.22160400e+03,\n",
      "        3.82922141e+03, 3.78093578e+03, 3.32162710e+03],\n",
      "       [9.38989262e-01, 1.63651717e-02, 4.42916677e-02, 4.22160398e+03,\n",
      "        3.82922144e+03, 3.78093575e+03, 3.32162713e+03],\n",
      "       [9.38989262e-01, 1.63651717e-02, 4.42916676e-02, 4.22160400e+03,\n",
      "        3.82922143e+03, 3.78093576e+03, 3.32162711e+03],\n",
      "       [9.38989262e-01, 1.63651717e-02, 4.42916678e-02, 4.22160398e+03,\n",
      "        3.82922144e+03, 3.78093574e+03, 3.32162713e+03],\n",
      "       [9.38989262e-01, 1.63651716e-02, 4.42916681e-02, 4.22160396e+03,\n",
      "        3.82922146e+03, 3.78093573e+03, 3.32162716e+03],\n",
      "       [9.38989262e-01, 1.63651720e-02, 4.42916667e-02, 4.22160405e+03,\n",
      "        3.82922137e+03, 3.78093581e+03, 3.32162704e+03]]), array([37533.1015625, 37533.1015625, 37533.1015625, 37533.1015625,\n",
      "       37533.1015625, 37533.1015625, 37533.1015625, 37533.1015625]))\n",
      "           fun: 37533.1015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1279\n",
      "           nit: 454\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.38989262e-01, 1.63651717e-02, 4.42916679e-02, 4.22160397e+03,\n",
      "       3.82922144e+03, 3.78093574e+03, 3.32162713e+03])\n",
      "minPrevious 36234.44921875\n",
      "best ll: 55701.2421875, bestParams: [tensor(0.2996), tensor(0.1098), tensor(0.0285), tensor(22293.1406), tensor(23760.0117), tensor(22706.9297), tensor(22891.8125)]\n",
      "epoch 16\n",
      " final_simplex: (array([[3.13536672e-01, 1.09506574e-01, 2.83406658e-02, 2.23458964e+04,\n",
      "        2.37789738e+04, 2.27627694e+04, 2.29368083e+04],\n",
      "       [3.13536672e-01, 1.09506574e-01, 2.83406657e-02, 2.23458964e+04,\n",
      "        2.37789738e+04, 2.27627694e+04, 2.29368083e+04],\n",
      "       [3.13536672e-01, 1.09506574e-01, 2.83406657e-02, 2.23458965e+04,\n",
      "        2.37789738e+04, 2.27627694e+04, 2.29368083e+04],\n",
      "       [3.13536672e-01, 1.09506574e-01, 2.83406657e-02, 2.23458965e+04,\n",
      "        2.37789738e+04, 2.27627694e+04, 2.29368084e+04],\n",
      "       [3.13536672e-01, 1.09506574e-01, 2.83406657e-02, 2.23458964e+04,\n",
      "        2.37789738e+04, 2.27627695e+04, 2.29368083e+04],\n",
      "       [3.13536672e-01, 1.09506574e-01, 2.83406657e-02, 2.23458965e+04,\n",
      "        2.37789738e+04, 2.27627694e+04, 2.29368083e+04],\n",
      "       [3.13536673e-01, 1.09506574e-01, 2.83406657e-02, 2.23458963e+04,\n",
      "        2.37789738e+04, 2.27627694e+04, 2.29368083e+04],\n",
      "       [3.13536672e-01, 1.09506574e-01, 2.83406657e-02, 2.23458965e+04,\n",
      "        2.37789738e+04, 2.27627694e+04, 2.29368083e+04]]), array([54818.3203125, 54818.3203125, 54818.3203125, 54818.3203125,\n",
      "       54818.3203125, 54818.3203125, 54818.3203125, 54818.3203125]))\n",
      "           fun: 54818.3203125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1082\n",
      "           nit: 279\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.13536672e-01, 1.09506574e-01, 2.83406658e-02, 2.23458964e+04,\n",
      "       2.37789738e+04, 2.27627694e+04, 2.29368083e+04])\n",
      "minPrevious 36234.44921875\n",
      "best ll: 52971.53125, bestParams: [tensor(0.3927), tensor(0.0538), tensor(0.0187), tensor(22039.4805), tensor(9875.8457), tensor(14381.5264), tensor(21152.0957)]\n",
      "epoch 17\n",
      " final_simplex: (array([[9.53405417e-01, 2.75640455e-02, 1.57255905e-02, 1.26075280e+04,\n",
      "        1.10017736e+04, 1.05598573e+04, 2.11712147e+04],\n",
      "       [9.53405416e-01, 2.75640456e-02, 1.57255906e-02, 1.26075279e+04,\n",
      "        1.10017736e+04, 1.05598573e+04, 2.11712147e+04],\n",
      "       [9.53405416e-01, 2.75640456e-02, 1.57255906e-02, 1.26075279e+04,\n",
      "        1.10017736e+04, 1.05598573e+04, 2.11712147e+04],\n",
      "       [9.53405415e-01, 2.75640454e-02, 1.57255908e-02, 1.26075279e+04,\n",
      "        1.10017736e+04, 1.05598573e+04, 2.11712147e+04],\n",
      "       [9.53405416e-01, 2.75640454e-02, 1.57255907e-02, 1.26075279e+04,\n",
      "        1.10017736e+04, 1.05598573e+04, 2.11712147e+04],\n",
      "       [9.53405416e-01, 2.75640455e-02, 1.57255907e-02, 1.26075279e+04,\n",
      "        1.10017736e+04, 1.05598573e+04, 2.11712147e+04],\n",
      "       [9.53405416e-01, 2.75640456e-02, 1.57255906e-02, 1.26075279e+04,\n",
      "        1.10017736e+04, 1.05598573e+04, 2.11712147e+04],\n",
      "       [9.53405417e-01, 2.75640455e-02, 1.57255906e-02, 1.26075280e+04,\n",
      "        1.10017736e+04, 1.05598573e+04, 2.11712147e+04]]), array([37119.74609375, 37119.74609375, 37119.74609375, 37119.74609375,\n",
      "       37119.74609375, 37119.74609375, 37119.74609375, 37119.74609375]))\n",
      "           fun: 37119.74609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1263\n",
      "           nit: 411\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.53405417e-01, 2.75640455e-02, 1.57255905e-02, 1.26075280e+04,\n",
      "       1.10017736e+04, 1.05598573e+04, 2.11712147e+04])\n",
      "minPrevious 36234.44921875\n",
      "best ll: 54659.0859375, bestParams: [tensor(0.3347), tensor(0.0015), tensor(0.1438), tensor(18437.8867), tensor(17449.1836), tensor(17924.8125), tensor(14649.8398)]\n",
      "epoch 18\n",
      " final_simplex: (array([[9.61681055e-01, 1.33372585e-03, 3.34040687e-02, 1.49048386e+04,\n",
      "        1.40266145e+04, 1.46000169e+04, 1.30694923e+04],\n",
      "       [9.61681055e-01, 1.33372585e-03, 3.34040688e-02, 1.49048385e+04,\n",
      "        1.40266145e+04, 1.46000169e+04, 1.30694923e+04],\n",
      "       [9.61681055e-01, 1.33372585e-03, 3.34040688e-02, 1.49048385e+04,\n",
      "        1.40266145e+04, 1.46000169e+04, 1.30694923e+04],\n",
      "       [9.61681055e-01, 1.33372585e-03, 3.34040688e-02, 1.49048385e+04,\n",
      "        1.40266145e+04, 1.46000169e+04, 1.30694923e+04],\n",
      "       [9.61681055e-01, 1.33372585e-03, 3.34040688e-02, 1.49048385e+04,\n",
      "        1.40266145e+04, 1.46000169e+04, 1.30694923e+04],\n",
      "       [9.61681055e-01, 1.33372585e-03, 3.34040688e-02, 1.49048385e+04,\n",
      "        1.40266145e+04, 1.46000169e+04, 1.30694923e+04],\n",
      "       [9.61681055e-01, 1.33372585e-03, 3.34040688e-02, 1.49048385e+04,\n",
      "        1.40266145e+04, 1.46000169e+04, 1.30694923e+04],\n",
      "       [9.61681055e-01, 1.33372585e-03, 3.34040688e-02, 1.49048385e+04,\n",
      "        1.40266145e+04, 1.46000169e+04, 1.30694923e+04]]), array([36814.7421875, 36814.7421875, 36814.7421875, 36814.7421875,\n",
      "       36814.7421875, 36814.7421875, 36814.7421875, 36814.7421875]))\n",
      "           fun: 36814.7421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1326\n",
      "           nit: 458\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.61681055e-01, 1.33372585e-03, 3.34040687e-02, 1.49048386e+04,\n",
      "       1.40266145e+04, 1.46000169e+04, 1.30694923e+04])\n",
      "minPrevious 36234.44921875\n",
      "best ll: 56901.4453125, bestParams: [tensor(0.3866), tensor(0.0603), tensor(0.0905), tensor(24644.5469), tensor(10981.7051), tensor(23433.6855), tensor(6012.7339)]\n",
      "epoch 19\n",
      " final_simplex: (array([[8.82265253e-01, 6.31892023e-02, 4.74684973e-02, 2.14732636e+04,\n",
      "        1.47062161e+04, 1.53477731e+04, 4.50726258e+03],\n",
      "       [8.82265254e-01, 6.31892023e-02, 4.74684971e-02, 2.14732635e+04,\n",
      "        1.47062161e+04, 1.53477731e+04, 4.50726257e+03],\n",
      "       [8.82265253e-01, 6.31892023e-02, 4.74684975e-02, 2.14732636e+04,\n",
      "        1.47062161e+04, 1.53477731e+04, 4.50726260e+03],\n",
      "       [8.82265253e-01, 6.31892023e-02, 4.74684976e-02, 2.14732637e+04,\n",
      "        1.47062161e+04, 1.53477731e+04, 4.50726261e+03],\n",
      "       [8.82265253e-01, 6.31892024e-02, 4.74684977e-02, 2.14732635e+04,\n",
      "        1.47062161e+04, 1.53477731e+04, 4.50726259e+03],\n",
      "       [8.82265253e-01, 6.31892023e-02, 4.74684973e-02, 2.14732636e+04,\n",
      "        1.47062161e+04, 1.53477731e+04, 4.50726259e+03],\n",
      "       [8.82265254e-01, 6.31892023e-02, 4.74684972e-02, 2.14732636e+04,\n",
      "        1.47062161e+04, 1.53477731e+04, 4.50726257e+03],\n",
      "       [8.82265253e-01, 6.31892023e-02, 4.74684973e-02, 2.14732636e+04,\n",
      "        1.47062161e+04, 1.53477732e+04, 4.50726258e+03]]), array([38374.5078125, 38374.5078125, 38374.5078125, 38374.5078125,\n",
      "       38374.5078125, 38374.5078125, 38374.5078125, 38374.5078125]))\n",
      "           fun: 38374.5078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1287\n",
      "           nit: 458\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.82265253e-01, 6.31892023e-02, 4.74684973e-02, 2.14732636e+04,\n",
      "       1.47062161e+04, 1.53477731e+04, 4.50726258e+03])\n",
      "minPrevious 36234.44921875\n",
      "inferredPis tensor([0.9906, 0.0041, 0.0032], dtype=torch.float64)\n",
      "inferredAlphas tensor([7562.1733, 8368.3120, 8779.7352, 8746.4345], dtype=torch.float64)\n",
      "truth0 tensor(0.7519) truth1 tensor(0.1111) truth2 tensor(0.1121) truthBoth tensor(0.0250)\n",
      "params on run 1 {'lls': [58132.7578125, 61020.8984375, 62816.03125, 61310.28125, 59964.953125, 47473.921875, 47433.734375, 47816.32421875, 47210.3984375, 51822.578125, 51970.546875, 47609.4609375, 52364.7734375, 53773.0390625, 47233.921875, 36342.86328125, 36234.44921875], 'inferredAlphas': [tensor([17771.7538,   267.5774,   285.4237, 19323.4289], dtype=torch.float64), tensor([17391.5067,   389.1159,   504.1465, 38945.6315], dtype=torch.float64), tensor([26599.6834,   330.5187,   522.2450, 20474.0527], dtype=torch.float64), tensor([17159.0905,   229.1438,   192.1196, 23702.7612], dtype=torch.float64), tensor([14365.2776,   353.8587,   277.5095, 36615.7416], dtype=torch.float64), tensor([4681.1768, 1514.9906,  279.5278, 6430.2365], dtype=torch.float64), tensor([11636.0228,  1941.4431,   317.7839,  2432.4090], dtype=torch.float64), tensor([3466.6976,  105.4401,  574.8790,  884.2902], dtype=torch.float64), tensor([  190.1304,   255.3843,  1367.9433, 10051.6183], dtype=torch.float64), tensor([13347.1036,  2995.2070,   679.1869,  9964.7306], dtype=torch.float64), tensor([3050.1159,  274.5893, 1270.7564, 7251.8219], dtype=torch.float64), tensor([1902.8937,  238.1495, 1249.7712, 7914.4684], dtype=torch.float64), tensor([20414.2533,  1255.3286,  5495.8171, 24486.6440], dtype=torch.float64), tensor([ 5422.4410,  1070.5042,  5035.1884, 34394.7350], dtype=torch.float64), tensor([6116.3640, 1549.1665,  277.2773, 5735.0947], dtype=torch.float64), tensor([ 3252.4160, 17197.7572, 17440.7641, 20021.9416], dtype=torch.float64), tensor([7562.1733, 8368.3120, 8779.7352, 8746.4345], dtype=torch.float64)], 'inferredPis': [tensor([0.2745, 0.5123, 0.0037], dtype=torch.float64), tensor([0.2424, 0.2423, 0.0335], dtype=torch.float64), tensor([0.2477, 0.1574, 0.0414], dtype=torch.float64), tensor([0.2670, 0.3576, 0.1152], dtype=torch.float64), tensor([0.4350, 0.2494, 0.0647], dtype=torch.float64), tensor([0.1319, 0.8504, 0.0173], dtype=torch.float64), tensor([0.1121, 0.8709, 0.0016], dtype=torch.float64), tensor([0.7272, 0.2531, 0.0189], dtype=torch.float64), tensor([0.8014, 0.1978, 0.0008], dtype=torch.float64), tensor([0.1527, 0.5340, 0.0406], dtype=torch.float64), tensor([4.4252e-01, 2.4141e-01, 6.9015e-05], dtype=torch.float64), tensor([0.7311, 0.2567, 0.0100], dtype=torch.float64), tensor([0.4108, 0.3023, 0.0150], dtype=torch.float64), tensor([0.4187, 0.1117, 0.0518], dtype=torch.float64), tensor([0.2033, 0.7863, 0.0045], dtype=torch.float64), tensor([0.9651, 0.0301, 0.0021], dtype=torch.float64), tensor([0.9906, 0.0041, 0.0032], dtype=torch.float64)], 'inferredPDVs': [tensor([0.4720, 0.0071, 0.0076, 0.5133], dtype=torch.float64), tensor([0.3039, 0.0068, 0.0088, 0.6805], dtype=torch.float64), tensor([0.5550, 0.0069, 0.0109, 0.4272], dtype=torch.float64), tensor([0.4156, 0.0056, 0.0047, 0.5742], dtype=torch.float64), tensor([0.2783, 0.0069, 0.0054, 0.7095], dtype=torch.float64), tensor([0.3627, 0.1174, 0.0217, 0.4982], dtype=torch.float64), tensor([0.7126, 0.1189, 0.0195, 0.1490], dtype=torch.float64), tensor([0.6890, 0.0210, 0.1143, 0.1758], dtype=torch.float64), tensor([0.0160, 0.0215, 0.1153, 0.8471], dtype=torch.float64), tensor([0.4945, 0.1110, 0.0252, 0.3693], dtype=torch.float64), tensor([0.2575, 0.0232, 0.1073, 0.6120], dtype=torch.float64), tensor([0.1683, 0.0210, 0.1106, 0.7001], dtype=torch.float64), tensor([0.3952, 0.0243, 0.1064, 0.4741], dtype=torch.float64), tensor([0.1181, 0.0233, 0.1096, 0.7490], dtype=torch.float64), tensor([0.4472, 0.1133, 0.0203, 0.4192], dtype=torch.float64), tensor([0.0562, 0.2969, 0.3011, 0.3458], dtype=torch.float64), tensor([0.2260, 0.2501, 0.2624, 0.2614], dtype=torch.float64)], 'trueMeanPDVs': [tensor([0.7547, 0.1096, 0.1105, 0.0252]), tensor([0.7520, 0.1114, 0.1113, 0.0253]), tensor([0.7523, 0.1111, 0.1116, 0.0250]), tensor([0.7518, 0.1113, 0.1112, 0.0257]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7510, 0.1117, 0.1118, 0.0255]), tensor([0.7535, 0.1110, 0.1105, 0.0250]), tensor([0.7503, 0.1121, 0.1120, 0.0256]), tensor([0.7542, 0.1103, 0.1109, 0.0246]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250])], 'truePis': [tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500])]}\n",
      "tensor([[117.,  22.,   1.,   0.],\n",
      "        [ 85.,   7.,   1.,   0.],\n",
      "        [145.,   8.,   5.,   0.],\n",
      "        ...,\n",
      "        [ 90.,   1.,   0.,   0.],\n",
      "        [157.,   1.,   3.,   1.],\n",
      "        [129.,   1.,   0.,   0.]])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood4 at 0x7feafd642320>\n",
      "best ll: 56329.953125, bestParams: [tensor(0.3056), tensor(0.1139), tensor(0.0498), tensor(6650.5601), tensor(12575.7461), tensor(12457.4893), tensor(20389.5410)]\n",
      "epoch 0\n",
      " final_simplex: (array([[8.92082162e-01, 6.44555157e-02, 4.04296631e-02, 4.89020908e+03,\n",
      "        8.80202294e+03, 9.41431819e+03, 1.55335227e+04],\n",
      "       [8.92082163e-01, 6.44555157e-02, 4.04296630e-02, 4.89020905e+03,\n",
      "        8.80202292e+03, 9.41431821e+03, 1.55335227e+04],\n",
      "       [8.92082162e-01, 6.44555157e-02, 4.04296633e-02, 4.89020907e+03,\n",
      "        8.80202294e+03, 9.41431818e+03, 1.55335227e+04],\n",
      "       [8.92082163e-01, 6.44555158e-02, 4.04296630e-02, 4.89020905e+03,\n",
      "        8.80202292e+03, 9.41431818e+03, 1.55335227e+04],\n",
      "       [8.92082163e-01, 6.44555157e-02, 4.04296631e-02, 4.89020906e+03,\n",
      "        8.80202294e+03, 9.41431818e+03, 1.55335227e+04],\n",
      "       [8.92082163e-01, 6.44555158e-02, 4.04296631e-02, 4.89020906e+03,\n",
      "        8.80202291e+03, 9.41431816e+03, 1.55335227e+04],\n",
      "       [8.92082163e-01, 6.44555158e-02, 4.04296631e-02, 4.89020906e+03,\n",
      "        8.80202290e+03, 9.41431816e+03, 1.55335227e+04],\n",
      "       [8.92082163e-01, 6.44555157e-02, 4.04296631e-02, 4.89020906e+03,\n",
      "        8.80202292e+03, 9.41431820e+03, 1.55335227e+04]]), array([38898.4296875, 38898.4296875, 38898.4296875, 38898.4296875,\n",
      "       38898.4296875, 38898.4296875, 38898.4296875, 38898.4296875]))\n",
      "           fun: 38898.4296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1240\n",
      "           nit: 402\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.92082162e-01, 6.44555157e-02, 4.04296631e-02, 4.89020908e+03,\n",
      "       8.80202294e+03, 9.41431819e+03, 1.55335227e+04])\n",
      "best ll: 54119.01171875, bestParams: [tensor(0.3600), tensor(0.1836), tensor(0.0174), tensor(15711.9033), tensor(24409.8555), tensor(24449.9297), tensor(24169.1992)]\n",
      "epoch 1\n",
      " final_simplex: (array([[8.48153138e-01, 1.37214193e-01, 1.21295588e-02, 1.54856541e+04,\n",
      "        1.75877013e+04, 1.53516154e+04, 2.39268686e+04],\n",
      "       [8.48153138e-01, 1.37214194e-01, 1.21295587e-02, 1.54856541e+04,\n",
      "        1.75877013e+04, 1.53516154e+04, 2.39268686e+04],\n",
      "       [8.48153137e-01, 1.37214194e-01, 1.21295587e-02, 1.54856541e+04,\n",
      "        1.75877013e+04, 1.53516154e+04, 2.39268686e+04],\n",
      "       [8.48153137e-01, 1.37214194e-01, 1.21295587e-02, 1.54856540e+04,\n",
      "        1.75877013e+04, 1.53516154e+04, 2.39268685e+04],\n",
      "       [8.48153137e-01, 1.37214193e-01, 1.21295588e-02, 1.54856541e+04,\n",
      "        1.75877013e+04, 1.53516154e+04, 2.39268686e+04],\n",
      "       [8.48153138e-01, 1.37214194e-01, 1.21295587e-02, 1.54856541e+04,\n",
      "        1.75877013e+04, 1.53516154e+04, 2.39268686e+04],\n",
      "       [8.48153138e-01, 1.37214194e-01, 1.21295587e-02, 1.54856541e+04,\n",
      "        1.75877013e+04, 1.53516154e+04, 2.39268686e+04],\n",
      "       [8.48153137e-01, 1.37214194e-01, 1.21295587e-02, 1.54856540e+04,\n",
      "        1.75877013e+04, 1.53516154e+04, 2.39268685e+04]]), array([39771.34765625, 39771.34765625, 39771.34765625, 39771.34765625,\n",
      "       39771.34765625, 39771.34765625, 39771.34765625, 39771.34765625]))\n",
      "           fun: 39771.34765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1274\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.48153138e-01, 1.37214193e-01, 1.21295588e-02, 1.54856541e+04,\n",
      "       1.75877013e+04, 1.53516154e+04, 2.39268686e+04])\n",
      "minPrevious 38898.4296875\n",
      "best ll: 57726.98828125, bestParams: [tensor(0.3195), tensor(0.0992), tensor(0.1383), tensor(11016.7188), tensor(13116.2646), tensor(8347.0762), tensor(8821.0859)]\n",
      "epoch 2\n",
      " final_simplex: (array([[8.63260460e-01, 6.44151605e-02, 7.01015917e-02, 9.06661914e+03,\n",
      "        8.98525223e+03, 8.79181350e+03, 6.81231220e+03],\n",
      "       [8.63260462e-01, 6.44151606e-02, 7.01015906e-02, 9.06661906e+03,\n",
      "        8.98525226e+03, 8.79181351e+03, 6.81231220e+03],\n",
      "       [8.63260463e-01, 6.44151604e-02, 7.01015905e-02, 9.06661907e+03,\n",
      "        8.98525227e+03, 8.79181349e+03, 6.81231223e+03],\n",
      "       [8.63260460e-01, 6.44151604e-02, 7.01015910e-02, 9.06661912e+03,\n",
      "        8.98525227e+03, 8.79181349e+03, 6.81231224e+03],\n",
      "       [8.63260461e-01, 6.44151609e-02, 7.01015910e-02, 9.06661904e+03,\n",
      "        8.98525226e+03, 8.79181350e+03, 6.81231223e+03],\n",
      "       [8.63260462e-01, 6.44151602e-02, 7.01015907e-02, 9.06661912e+03,\n",
      "        8.98525225e+03, 8.79181349e+03, 6.81231223e+03],\n",
      "       [8.63260460e-01, 6.44151604e-02, 7.01015913e-02, 9.06661914e+03,\n",
      "        8.98525224e+03, 8.79181351e+03, 6.81231219e+03],\n",
      "       [8.63260463e-01, 6.44151606e-02, 7.01015903e-02, 9.06661905e+03,\n",
      "        8.98525223e+03, 8.79181351e+03, 6.81231219e+03]]), array([39547.5859375, 39547.5859375, 39547.5859375, 39547.5859375,\n",
      "       39547.5859375, 39547.5859375, 39547.5859375, 39547.5859375]))\n",
      "           fun: 39547.5859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1234\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.63260460e-01, 6.44151605e-02, 7.01015917e-02, 9.06661914e+03,\n",
      "       8.98525223e+03, 8.79181350e+03, 6.81231220e+03])\n",
      "minPrevious 38898.4296875\n",
      "best ll: 55722.88671875, bestParams: [tensor(0.3341), tensor(0.0767), tensor(0.1762), tensor(15224.3486), tensor(14690.8770), tensor(14392.6133), tensor(24336.3965)]\n",
      "epoch 3\n",
      " final_simplex: (array([[8.13671417e-01, 5.89631609e-02, 1.19936421e-01, 1.43542530e+04,\n",
      "        1.35972669e+04, 1.61899092e+04, 1.28634702e+04],\n",
      "       [8.13671420e-01, 5.89631613e-02, 1.19936419e-01, 1.43542530e+04,\n",
      "        1.35972669e+04, 1.61899092e+04, 1.28634702e+04],\n",
      "       [8.13671418e-01, 5.89631610e-02, 1.19936420e-01, 1.43542530e+04,\n",
      "        1.35972669e+04, 1.61899092e+04, 1.28634701e+04],\n",
      "       [8.13671420e-01, 5.89631612e-02, 1.19936419e-01, 1.43542530e+04,\n",
      "        1.35972669e+04, 1.61899092e+04, 1.28634703e+04],\n",
      "       [8.13671418e-01, 5.89631613e-02, 1.19936419e-01, 1.43542530e+04,\n",
      "        1.35972669e+04, 1.61899092e+04, 1.28634702e+04],\n",
      "       [8.13671419e-01, 5.89631610e-02, 1.19936420e-01, 1.43542530e+04,\n",
      "        1.35972669e+04, 1.61899093e+04, 1.28634702e+04],\n",
      "       [8.13671419e-01, 5.89631609e-02, 1.19936420e-01, 1.43542530e+04,\n",
      "        1.35972669e+04, 1.61899092e+04, 1.28634702e+04],\n",
      "       [8.13671419e-01, 5.89631609e-02, 1.19936420e-01, 1.43542530e+04,\n",
      "        1.35972669e+04, 1.61899093e+04, 1.28634702e+04]]), array([40763.703125, 40763.703125, 40763.703125, 40763.703125,\n",
      "       40763.703125, 40763.703125, 40763.703125, 40763.703125]))\n",
      "           fun: 40763.703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1205\n",
      "           nit: 353\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.13671417e-01, 5.89631609e-02, 1.19936421e-01, 1.43542530e+04,\n",
      "       1.35972669e+04, 1.61899092e+04, 1.28634702e+04])\n",
      "minPrevious 38898.4296875\n",
      "best ll: 56239.4609375, bestParams: [tensor(0.3288), tensor(0.0493), tensor(0.1529), tensor(9728.8281), tensor(12000.1992), tensor(16745.1309), tensor(13614.7334)]\n",
      "epoch 4\n",
      " final_simplex: (array([[9.33494539e-01, 4.00105791e-02, 2.49658657e-02, 4.65719080e+03,\n",
      "        1.36129730e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494540e-01, 4.00105790e-02, 2.49658655e-02, 4.65719080e+03,\n",
      "        1.36129730e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494540e-01, 4.00105789e-02, 2.49658655e-02, 4.65719079e+03,\n",
      "        1.36129730e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494539e-01, 4.00105791e-02, 2.49658655e-02, 4.65719080e+03,\n",
      "        1.36129731e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494540e-01, 4.00105791e-02, 2.49658655e-02, 4.65719080e+03,\n",
      "        1.36129730e+04, 1.23775796e+04, 1.53141361e+04],\n",
      "       [9.33494540e-01, 4.00105789e-02, 2.49658658e-02, 4.65719080e+03,\n",
      "        1.36129730e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494539e-01, 4.00105790e-02, 2.49658657e-02, 4.65719079e+03,\n",
      "        1.36129730e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494539e-01, 4.00105790e-02, 2.49658663e-02, 4.65719079e+03,\n",
      "        1.36129729e+04, 1.23775798e+04, 1.53141361e+04]]), array([38070.8515625, 38070.8515625, 38070.8515625, 38070.8515625,\n",
      "       38070.8515625, 38070.8515625, 38070.8515625, 38070.8515625]))\n",
      "           fun: 38070.8515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1245\n",
      "           nit: 412\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.33494539e-01, 4.00105791e-02, 2.49658657e-02, 4.65719080e+03,\n",
      "       1.36129730e+04, 1.23775797e+04, 1.53141361e+04])\n",
      "minPrevious 38898.4296875\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.33494539e-01, 4.00105791e-02, 2.49658657e-02, 4.65719080e+03,\n",
      "        1.36129730e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494540e-01, 4.00105790e-02, 2.49658655e-02, 4.65719080e+03,\n",
      "        1.36129730e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494540e-01, 4.00105789e-02, 2.49658655e-02, 4.65719079e+03,\n",
      "        1.36129730e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494539e-01, 4.00105791e-02, 2.49658655e-02, 4.65719080e+03,\n",
      "        1.36129731e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494540e-01, 4.00105791e-02, 2.49658655e-02, 4.65719080e+03,\n",
      "        1.36129730e+04, 1.23775796e+04, 1.53141361e+04],\n",
      "       [9.33494540e-01, 4.00105789e-02, 2.49658658e-02, 4.65719080e+03,\n",
      "        1.36129730e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494539e-01, 4.00105790e-02, 2.49658657e-02, 4.65719079e+03,\n",
      "        1.36129730e+04, 1.23775797e+04, 1.53141361e+04],\n",
      "       [9.33494539e-01, 4.00105790e-02, 2.49658663e-02, 4.65719079e+03,\n",
      "        1.36129729e+04, 1.23775798e+04, 1.53141361e+04]]), array([38070.8515625, 38070.8515625, 38070.8515625, 38070.8515625,\n",
      "       38070.8515625, 38070.8515625, 38070.8515625, 38070.8515625]))\n",
      "           fun: 38070.8515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1245\n",
      "           nit: 412\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.33494539e-01, 4.00105791e-02, 2.49658657e-02, 4.65719080e+03,\n",
      "       1.36129730e+04, 1.23775797e+04, 1.53141361e+04])\n",
      "best ll: 56085.0234375, bestParams: [tensor(0.3284), tensor(0.2482), tensor(0.0107), tensor(11314.8545), tensor(7164.7310), tensor(6277.9121), tensor(21361.5234)]\n",
      "epoch 5\n",
      " final_simplex: (array([[9.82291308e-01, 4.23503622e-04, 1.07134898e-02, 9.40477576e+03,\n",
      "        5.70683088e+03, 5.60758649e+03, 9.92788350e+03],\n",
      "       [9.82291307e-01, 4.23503834e-04, 1.07134898e-02, 9.40477577e+03,\n",
      "        5.70683088e+03, 5.60758649e+03, 9.92788352e+03],\n",
      "       [9.82291308e-01, 4.23503457e-04, 1.07134898e-02, 9.40477573e+03,\n",
      "        5.70683089e+03, 5.60758648e+03, 9.92788358e+03],\n",
      "       [9.82291308e-01, 4.23503459e-04, 1.07134897e-02, 9.40477583e+03,\n",
      "        5.70683089e+03, 5.60758649e+03, 9.92788347e+03],\n",
      "       [9.82291307e-01, 4.23503581e-04, 1.07134897e-02, 9.40477585e+03,\n",
      "        5.70683089e+03, 5.60758649e+03, 9.92788345e+03],\n",
      "       [9.82291307e-01, 4.23503768e-04, 1.07134897e-02, 9.40477581e+03,\n",
      "        5.70683090e+03, 5.60758649e+03, 9.92788350e+03],\n",
      "       [9.82291308e-01, 4.23503483e-04, 1.07134898e-02, 9.40477575e+03,\n",
      "        5.70683089e+03, 5.60758648e+03, 9.92788355e+03],\n",
      "       [9.82291307e-01, 4.23502851e-04, 1.07134898e-02, 9.40477572e+03,\n",
      "        5.70683091e+03, 5.60758647e+03, 9.92788354e+03]]), array([37030.8125, 37030.8125, 37030.8125, 37030.8125, 37030.8125,\n",
      "       37030.8125, 37030.8125, 37030.8125]))\n",
      "           fun: 37030.8125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1257\n",
      "           nit: 420\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.82291308e-01, 4.23503622e-04, 1.07134898e-02, 9.40477576e+03,\n",
      "       5.70683088e+03, 5.60758649e+03, 9.92788350e+03])\n",
      "minPrevious 38070.8515625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.82291308e-01, 4.23503622e-04, 1.07134898e-02, 9.40477576e+03,\n",
      "        5.70683088e+03, 5.60758649e+03, 9.92788350e+03],\n",
      "       [9.82291307e-01, 4.23503834e-04, 1.07134898e-02, 9.40477577e+03,\n",
      "        5.70683088e+03, 5.60758649e+03, 9.92788352e+03],\n",
      "       [9.82291308e-01, 4.23503457e-04, 1.07134898e-02, 9.40477573e+03,\n",
      "        5.70683089e+03, 5.60758648e+03, 9.92788358e+03],\n",
      "       [9.82291308e-01, 4.23503459e-04, 1.07134897e-02, 9.40477583e+03,\n",
      "        5.70683089e+03, 5.60758649e+03, 9.92788347e+03],\n",
      "       [9.82291307e-01, 4.23503581e-04, 1.07134897e-02, 9.40477585e+03,\n",
      "        5.70683089e+03, 5.60758649e+03, 9.92788345e+03],\n",
      "       [9.82291307e-01, 4.23503768e-04, 1.07134897e-02, 9.40477581e+03,\n",
      "        5.70683090e+03, 5.60758649e+03, 9.92788350e+03],\n",
      "       [9.82291308e-01, 4.23503483e-04, 1.07134898e-02, 9.40477575e+03,\n",
      "        5.70683089e+03, 5.60758648e+03, 9.92788355e+03],\n",
      "       [9.82291307e-01, 4.23502851e-04, 1.07134898e-02, 9.40477572e+03,\n",
      "        5.70683091e+03, 5.60758647e+03, 9.92788354e+03]]), array([37030.8125, 37030.8125, 37030.8125, 37030.8125, 37030.8125,\n",
      "       37030.8125, 37030.8125, 37030.8125]))\n",
      "           fun: 37030.8125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1257\n",
      "           nit: 420\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.82291308e-01, 4.23503622e-04, 1.07134898e-02, 9.40477576e+03,\n",
      "       5.70683088e+03, 5.60758649e+03, 9.92788350e+03])\n",
      "best ll: 59120.52734375, bestParams: [tensor(0.2406), tensor(0.0149), tensor(0.0410), tensor(9510.2002), tensor(20944.4980), tensor(16217.9141), tensor(1685.8025)]\n",
      "epoch 6\n",
      " final_simplex: (array([[8.47391895e-01, 1.15168168e-02, 4.10502660e-02, 1.40280884e+02,\n",
      "        1.64533658e+04, 1.90968860e+04, 6.90042601e+02],\n",
      "       [8.47391896e-01, 1.15168168e-02, 4.10502662e-02, 1.40280947e+02,\n",
      "        1.64533658e+04, 1.90968860e+04, 6.90042606e+02],\n",
      "       [8.47391896e-01, 1.15168168e-02, 4.10502662e-02, 1.40280937e+02,\n",
      "        1.64533658e+04, 1.90968860e+04, 6.90042599e+02],\n",
      "       [8.47391898e-01, 1.15168168e-02, 4.10502661e-02, 1.40280948e+02,\n",
      "        1.64533658e+04, 1.90968860e+04, 6.90042601e+02],\n",
      "       [8.47391899e-01, 1.15168168e-02, 4.10502660e-02, 1.40280967e+02,\n",
      "        1.64533658e+04, 1.90968860e+04, 6.90042604e+02],\n",
      "       [8.47391897e-01, 1.15168168e-02, 4.10502662e-02, 1.40280951e+02,\n",
      "        1.64533658e+04, 1.90968860e+04, 6.90042594e+02],\n",
      "       [8.47391898e-01, 1.15168168e-02, 4.10502662e-02, 1.40280980e+02,\n",
      "        1.64533658e+04, 1.90968860e+04, 6.90042606e+02],\n",
      "       [8.47391898e-01, 1.15168168e-02, 4.10502661e-02, 1.40280926e+02,\n",
      "        1.64533657e+04, 1.90968860e+04, 6.90042592e+02]]), array([39575.51171875, 39575.51171875, 39575.51171875, 39575.51171875,\n",
      "       39575.51171875, 39575.51171875, 39575.51171875, 39575.51171875]))\n",
      "           fun: 39575.51171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1274\n",
      "           nit: 451\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.47391895e-01, 1.15168168e-02, 4.10502660e-02, 1.40280884e+02,\n",
      "       1.64533658e+04, 1.90968860e+04, 6.90042601e+02])\n",
      "minPrevious 37030.8125\n",
      "best ll: 60242.11328125, bestParams: [tensor(0.2801), tensor(0.2746), tensor(0.1253), tensor(23118.8574), tensor(20355.0449), tensor(15202.0361), tensor(10134.2529)]\n",
      "epoch 7\n",
      " final_simplex: (array([[9.94925554e-01, 2.25322318e-03, 5.09304724e-04, 2.42339895e+04,\n",
      "        1.31085658e+04, 1.21191812e+04, 1.02091235e+04],\n",
      "       [9.94925554e-01, 2.25322309e-03, 5.09304946e-04, 2.42339894e+04,\n",
      "        1.31085658e+04, 1.21191812e+04, 1.02091236e+04],\n",
      "       [9.94925553e-01, 2.25322353e-03, 5.09305034e-04, 2.42339895e+04,\n",
      "        1.31085658e+04, 1.21191812e+04, 1.02091236e+04],\n",
      "       [9.94925554e-01, 2.25322317e-03, 5.09304797e-04, 2.42339895e+04,\n",
      "        1.31085658e+04, 1.21191812e+04, 1.02091235e+04],\n",
      "       [9.94925553e-01, 2.25322319e-03, 5.09304943e-04, 2.42339894e+04,\n",
      "        1.31085658e+04, 1.21191812e+04, 1.02091236e+04],\n",
      "       [9.94925554e-01, 2.25322325e-03, 5.09304628e-04, 2.42339894e+04,\n",
      "        1.31085658e+04, 1.21191813e+04, 1.02091235e+04],\n",
      "       [9.94925554e-01, 2.25322343e-03, 5.09304730e-04, 2.42339894e+04,\n",
      "        1.31085658e+04, 1.21191813e+04, 1.02091235e+04],\n",
      "       [9.94925554e-01, 2.25322327e-03, 5.09304698e-04, 2.42339894e+04,\n",
      "        1.31085658e+04, 1.21191813e+04, 1.02091235e+04]]), array([36770.3828125, 36770.3828125, 36770.3828125, 36770.3828125,\n",
      "       36770.3828125, 36770.3828125, 36770.3828125, 36770.3828125]))\n",
      "           fun: 36770.3828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1297\n",
      "           nit: 435\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.94925554e-01, 2.25322318e-03, 5.09304724e-04, 2.42339895e+04,\n",
      "       1.31085658e+04, 1.21191812e+04, 1.02091235e+04])\n",
      "minPrevious 37030.8125\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.94925554e-01, 2.25322318e-03, 5.09304724e-04, 2.42339895e+04,\n",
      "        1.31085658e+04, 1.21191812e+04, 1.02091235e+04],\n",
      "       [9.94925554e-01, 2.25322309e-03, 5.09304946e-04, 2.42339894e+04,\n",
      "        1.31085658e+04, 1.21191812e+04, 1.02091236e+04],\n",
      "       [9.94925553e-01, 2.25322353e-03, 5.09305034e-04, 2.42339895e+04,\n",
      "        1.31085658e+04, 1.21191812e+04, 1.02091236e+04],\n",
      "       [9.94925554e-01, 2.25322317e-03, 5.09304797e-04, 2.42339895e+04,\n",
      "        1.31085658e+04, 1.21191812e+04, 1.02091235e+04],\n",
      "       [9.94925553e-01, 2.25322319e-03, 5.09304943e-04, 2.42339894e+04,\n",
      "        1.31085658e+04, 1.21191812e+04, 1.02091236e+04],\n",
      "       [9.94925554e-01, 2.25322325e-03, 5.09304628e-04, 2.42339894e+04,\n",
      "        1.31085658e+04, 1.21191813e+04, 1.02091235e+04],\n",
      "       [9.94925554e-01, 2.25322343e-03, 5.09304730e-04, 2.42339894e+04,\n",
      "        1.31085658e+04, 1.21191813e+04, 1.02091235e+04],\n",
      "       [9.94925554e-01, 2.25322327e-03, 5.09304698e-04, 2.42339894e+04,\n",
      "        1.31085658e+04, 1.21191813e+04, 1.02091235e+04]]), array([36770.3828125, 36770.3828125, 36770.3828125, 36770.3828125,\n",
      "       36770.3828125, 36770.3828125, 36770.3828125, 36770.3828125]))\n",
      "           fun: 36770.3828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1297\n",
      "           nit: 435\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.94925554e-01, 2.25322318e-03, 5.09304724e-04, 2.42339895e+04,\n",
      "       1.31085658e+04, 1.21191812e+04, 1.02091235e+04])\n",
      "best ll: 57073.71875, bestParams: [tensor(0.2831), tensor(0.0036), tensor(0.0651), tensor(10594.5957), tensor(20524.4570), tensor(15877.9443), tensor(15738.1279)]\n",
      "epoch 8\n",
      " final_simplex: (array([[9.75474901e-01, 9.68508345e-04, 2.29439548e-02, 1.84576298e+04,\n",
      "        1.26430071e+04, 1.26562926e+04, 1.26840573e+04],\n",
      "       [9.75474901e-01, 9.68508331e-04, 2.29439548e-02, 1.84576298e+04,\n",
      "        1.26430071e+04, 1.26562926e+04, 1.26840574e+04],\n",
      "       [9.75474901e-01, 9.68508334e-04, 2.29439548e-02, 1.84576298e+04,\n",
      "        1.26430071e+04, 1.26562926e+04, 1.26840573e+04],\n",
      "       [9.75474900e-01, 9.68508330e-04, 2.29439548e-02, 1.84576298e+04,\n",
      "        1.26430071e+04, 1.26562926e+04, 1.26840574e+04],\n",
      "       [9.75474901e-01, 9.68508330e-04, 2.29439548e-02, 1.84576298e+04,\n",
      "        1.26430071e+04, 1.26562926e+04, 1.26840574e+04],\n",
      "       [9.75474901e-01, 9.68508341e-04, 2.29439548e-02, 1.84576298e+04,\n",
      "        1.26430071e+04, 1.26562926e+04, 1.26840573e+04],\n",
      "       [9.75474901e-01, 9.68508329e-04, 2.29439548e-02, 1.84576298e+04,\n",
      "        1.26430071e+04, 1.26562927e+04, 1.26840574e+04],\n",
      "       [9.75474901e-01, 9.68508338e-04, 2.29439548e-02, 1.84576298e+04,\n",
      "        1.26430071e+04, 1.26562926e+04, 1.26840573e+04]]), array([37081.61328125, 37081.61328125, 37081.61328125, 37081.61328125,\n",
      "       37081.61328125, 37081.61328125, 37081.61328125, 37081.61328125]))\n",
      "           fun: 37081.61328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1280\n",
      "           nit: 415\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.75474901e-01, 9.68508345e-04, 2.29439548e-02, 1.84576298e+04,\n",
      "       1.26430071e+04, 1.26562926e+04, 1.26840573e+04])\n",
      "minPrevious 36770.3828125\n",
      "best ll: 53574.0078125, bestParams: [tensor(0.3795), tensor(0.1567), tensor(0.0397), tensor(21066.3340), tensor(7513.8486), tensor(8687.7412), tensor(14604.3164)]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.42578411e-01, 3.45278997e-02, 2.26088593e-02, 1.92057959e+04,\n",
      "        6.92909414e+03, 6.66670114e+03, 1.76172076e+04],\n",
      "       [9.42578410e-01, 3.45279003e-02, 2.26088593e-02, 1.92057959e+04,\n",
      "        6.92909414e+03, 6.66670115e+03, 1.76172075e+04],\n",
      "       [9.42578410e-01, 3.45279004e-02, 2.26088592e-02, 1.92057959e+04,\n",
      "        6.92909413e+03, 6.66670115e+03, 1.76172075e+04],\n",
      "       [9.42578411e-01, 3.45278998e-02, 2.26088593e-02, 1.92057959e+04,\n",
      "        6.92909417e+03, 6.66670114e+03, 1.76172076e+04],\n",
      "       [9.42578411e-01, 3.45279002e-02, 2.26088592e-02, 1.92057959e+04,\n",
      "        6.92909412e+03, 6.66670116e+03, 1.76172076e+04],\n",
      "       [9.42578410e-01, 3.45279006e-02, 2.26088591e-02, 1.92057959e+04,\n",
      "        6.92909412e+03, 6.66670113e+03, 1.76172076e+04],\n",
      "       [9.42578409e-01, 3.45279009e-02, 2.26088593e-02, 1.92057958e+04,\n",
      "        6.92909411e+03, 6.66670118e+03, 1.76172075e+04],\n",
      "       [9.42578412e-01, 3.45278996e-02, 2.26088593e-02, 1.92057959e+04,\n",
      "        6.92909417e+03, 6.66670110e+03, 1.76172076e+04]]), array([37892.5859375, 37892.5859375, 37892.5859375, 37892.5859375,\n",
      "       37892.5859375, 37892.5859375, 37892.5859375, 37892.5859375]))\n",
      "           fun: 37892.5859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1233\n",
      "           nit: 437\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.42578411e-01, 3.45278997e-02, 2.26088593e-02, 1.92057959e+04,\n",
      "       6.92909414e+03, 6.66670114e+03, 1.76172076e+04])\n",
      "minPrevious 36770.3828125\n",
      "best ll: 55818.62109375, bestParams: [tensor(0.3090), tensor(0.0303), tensor(0.0140), tensor(19385.4531), tensor(19910.4414), tensor(23285.9121), tensor(13867.6738)]\n",
      "epoch 10\n",
      " final_simplex: (array([[9.71989102e-01, 1.15809298e-02, 1.39500318e-02, 1.98136643e+04,\n",
      "        1.33290165e+04, 1.30788164e+04, 5.83965836e+03],\n",
      "       [9.71989102e-01, 1.15809300e-02, 1.39500317e-02, 1.98136643e+04,\n",
      "        1.33290165e+04, 1.30788164e+04, 5.83965830e+03],\n",
      "       [9.71989102e-01, 1.15809298e-02, 1.39500317e-02, 1.98136642e+04,\n",
      "        1.33290165e+04, 1.30788164e+04, 5.83965834e+03],\n",
      "       [9.71989102e-01, 1.15809299e-02, 1.39500318e-02, 1.98136642e+04,\n",
      "        1.33290165e+04, 1.30788164e+04, 5.83965833e+03],\n",
      "       [9.71989102e-01, 1.15809300e-02, 1.39500318e-02, 1.98136642e+04,\n",
      "        1.33290165e+04, 1.30788164e+04, 5.83965830e+03],\n",
      "       [9.71989102e-01, 1.15809299e-02, 1.39500317e-02, 1.98136643e+04,\n",
      "        1.33290165e+04, 1.30788164e+04, 5.83965834e+03],\n",
      "       [9.71989101e-01, 1.15809300e-02, 1.39500317e-02, 1.98136643e+04,\n",
      "        1.33290165e+04, 1.30788164e+04, 5.83965831e+03],\n",
      "       [9.71989102e-01, 1.15809299e-02, 1.39500317e-02, 1.98136642e+04,\n",
      "        1.33290165e+04, 1.30788164e+04, 5.83965835e+03]]), array([37181.45703125, 37181.45703125, 37181.45703125, 37181.45703125,\n",
      "       37181.45703125, 37181.45703125, 37181.45703125, 37181.45703125]))\n",
      "           fun: 37181.45703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1217\n",
      "           nit: 397\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.71989102e-01, 1.15809298e-02, 1.39500318e-02, 1.98136643e+04,\n",
      "       1.33290165e+04, 1.30788164e+04, 5.83965836e+03])\n",
      "minPrevious 36770.3828125\n",
      "best ll: 56946.26953125, bestParams: [tensor(0.3044), tensor(0.0386), tensor(0.0472), tensor(13026.6133), tensor(19178.0840), tensor(13094.9521), tensor(2537.0710)]\n",
      "epoch 11\n",
      " final_simplex: (array([[9.28631644e-01, 3.06514798e-02, 3.80861307e-02, 1.08377832e+04,\n",
      "        9.37928743e+03, 9.70515658e+03, 4.67982632e+02],\n",
      "       [9.28631644e-01, 3.06514795e-02, 3.80861309e-02, 1.08377833e+04,\n",
      "        9.37928739e+03, 9.70515659e+03, 4.67982626e+02],\n",
      "       [9.28631645e-01, 3.06514797e-02, 3.80861307e-02, 1.08377832e+04,\n",
      "        9.37928738e+03, 9.70515660e+03, 4.67982633e+02],\n",
      "       [9.28631645e-01, 3.06514796e-02, 3.80861309e-02, 1.08377833e+04,\n",
      "        9.37928739e+03, 9.70515660e+03, 4.67982627e+02],\n",
      "       [9.28631644e-01, 3.06514796e-02, 3.80861308e-02, 1.08377833e+04,\n",
      "        9.37928740e+03, 9.70515659e+03, 4.67982628e+02],\n",
      "       [9.28631644e-01, 3.06514797e-02, 3.80861307e-02, 1.08377832e+04,\n",
      "        9.37928740e+03, 9.70515659e+03, 4.67982639e+02],\n",
      "       [9.28631644e-01, 3.06514797e-02, 3.80861308e-02, 1.08377832e+04,\n",
      "        9.37928741e+03, 9.70515658e+03, 4.67982633e+02],\n",
      "       [9.28631644e-01, 3.06514797e-02, 3.80861308e-02, 1.08377832e+04,\n",
      "        9.37928741e+03, 9.70515657e+03, 4.67982631e+02]]), array([38067.30078125, 38067.30078125, 38067.30078125, 38067.30078125,\n",
      "       38067.30078125, 38067.30078125, 38067.30078125, 38067.30078125]))\n",
      "           fun: 38067.30078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1239\n",
      "           nit: 422\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.28631644e-01, 3.06514798e-02, 3.80861307e-02, 1.08377832e+04,\n",
      "       9.37928743e+03, 9.70515658e+03, 4.67982632e+02])\n",
      "minPrevious 36770.3828125\n",
      "best ll: 55388.1640625, bestParams: [tensor(0.3061), tensor(0.0034), tensor(0.0093), tensor(5225.4575), tensor(21348.2891), tensor(19689.5195), tensor(3481.6101)]\n",
      "epoch 12\n",
      " final_simplex: (array([[9.86393624e-01, 2.54632508e-03, 9.20302758e-03, 2.00092909e+03,\n",
      "        1.05358966e+04, 1.04144358e+04, 2.50771027e+03],\n",
      "       [9.86393623e-01, 2.54632501e-03, 9.20302765e-03, 2.00092911e+03,\n",
      "        1.05358966e+04, 1.04144358e+04, 2.50771029e+03],\n",
      "       [9.86393623e-01, 2.54632507e-03, 9.20302764e-03, 2.00092911e+03,\n",
      "        1.05358966e+04, 1.04144358e+04, 2.50771027e+03],\n",
      "       [9.86393624e-01, 2.54632506e-03, 9.20302764e-03, 2.00092909e+03,\n",
      "        1.05358966e+04, 1.04144358e+04, 2.50771028e+03],\n",
      "       [9.86393624e-01, 2.54632505e-03, 9.20302763e-03, 2.00092909e+03,\n",
      "        1.05358966e+04, 1.04144357e+04, 2.50771028e+03],\n",
      "       [9.86393623e-01, 2.54632503e-03, 9.20302766e-03, 2.00092910e+03,\n",
      "        1.05358966e+04, 1.04144357e+04, 2.50771029e+03],\n",
      "       [9.86393623e-01, 2.54632503e-03, 9.20302768e-03, 2.00092910e+03,\n",
      "        1.05358966e+04, 1.04144357e+04, 2.50771029e+03],\n",
      "       [9.86393623e-01, 2.54632504e-03, 9.20302761e-03, 2.00092911e+03,\n",
      "        1.05358967e+04, 1.04144358e+04, 2.50771028e+03]]), array([36858.7734375, 36858.7734375, 36858.7734375, 36858.7734375,\n",
      "       36858.7734375, 36858.7734375, 36858.7734375, 36858.7734375]))\n",
      "           fun: 36858.7734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1227\n",
      "           nit: 450\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.86393624e-01, 2.54632508e-03, 9.20302758e-03, 2.00092909e+03,\n",
      "       1.05358966e+04, 1.04144358e+04, 2.50771027e+03])\n",
      "minPrevious 36770.3828125\n",
      "best ll: 60108.3828125, bestParams: [tensor(0.2608), tensor(0.3394), tensor(0.0138), tensor(16512.2227), tensor(13281.0908), tensor(11831.3037), tensor(11052.9307)]\n",
      "epoch 13\n",
      " final_simplex: (array([[9.80358642e-01, 9.15515580e-04, 1.67444250e-02, 1.01953771e+04,\n",
      "        4.88309300e+03, 4.88363223e+03, 5.73313082e+03],\n",
      "       [9.80358644e-01, 9.15516259e-04, 1.67444250e-02, 1.01953770e+04,\n",
      "        4.88309300e+03, 4.88363223e+03, 5.73313080e+03],\n",
      "       [9.80358643e-01, 9.15515907e-04, 1.67444250e-02, 1.01953771e+04,\n",
      "        4.88309299e+03, 4.88363224e+03, 5.73313080e+03],\n",
      "       [9.80358642e-01, 9.15515684e-04, 1.67444250e-02, 1.01953771e+04,\n",
      "        4.88309299e+03, 4.88363223e+03, 5.73313081e+03],\n",
      "       [9.80358643e-01, 9.15515804e-04, 1.67444250e-02, 1.01953771e+04,\n",
      "        4.88309300e+03, 4.88363222e+03, 5.73313079e+03],\n",
      "       [9.80358643e-01, 9.15515478e-04, 1.67444250e-02, 1.01953771e+04,\n",
      "        4.88309298e+03, 4.88363224e+03, 5.73313080e+03],\n",
      "       [9.80358643e-01, 9.15515527e-04, 1.67444250e-02, 1.01953771e+04,\n",
      "        4.88309298e+03, 4.88363224e+03, 5.73313081e+03],\n",
      "       [9.80358643e-01, 9.15515334e-04, 1.67444249e-02, 1.01953771e+04,\n",
      "        4.88309297e+03, 4.88363225e+03, 5.73313079e+03]]), array([37036.73046875, 37036.73046875, 37036.73046875, 37036.73046875,\n",
      "       37036.73046875, 37036.73046875, 37036.73046875, 37036.73046875]))\n",
      "           fun: 37036.73046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1257\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.80358642e-01, 9.15515580e-04, 1.67444250e-02, 1.01953771e+04,\n",
      "       4.88309300e+03, 4.88363223e+03, 5.73313082e+03])\n",
      "minPrevious 36770.3828125\n",
      "best ll: 52529.15234375, bestParams: [tensor(0.4349), tensor(0.0410), tensor(0.0217), tensor(7574.5020), tensor(13955.2842), tensor(23331.4609), tensor(5477.9062)]\n",
      "epoch 14\n",
      " final_simplex: (array([[9.44717975e-01, 3.89111859e-02, 1.40050709e-02, 6.76712230e+03,\n",
      "        1.81917073e+04, 1.59015513e+04, 4.91623512e+03],\n",
      "       [9.44717971e-01, 3.89111860e-02, 1.40050709e-02, 6.76712235e+03,\n",
      "        1.81917073e+04, 1.59015512e+04, 4.91623512e+03],\n",
      "       [9.44717969e-01, 3.89111857e-02, 1.40050709e-02, 6.76712237e+03,\n",
      "        1.81917073e+04, 1.59015513e+04, 4.91623516e+03],\n",
      "       [9.44717972e-01, 3.89111859e-02, 1.40050709e-02, 6.76712235e+03,\n",
      "        1.81917073e+04, 1.59015512e+04, 4.91623512e+03],\n",
      "       [9.44717974e-01, 3.89111857e-02, 1.40050709e-02, 6.76712232e+03,\n",
      "        1.81917072e+04, 1.59015512e+04, 4.91623514e+03],\n",
      "       [9.44717971e-01, 3.89111860e-02, 1.40050710e-02, 6.76712233e+03,\n",
      "        1.81917072e+04, 1.59015512e+04, 4.91623511e+03],\n",
      "       [9.44717973e-01, 3.89111861e-02, 1.40050708e-02, 6.76712236e+03,\n",
      "        1.81917073e+04, 1.59015512e+04, 4.91623511e+03],\n",
      "       [9.44717972e-01, 3.89111860e-02, 1.40050708e-02, 6.76712236e+03,\n",
      "        1.81917073e+04, 1.59015512e+04, 4.91623513e+03]]), array([37427.5625, 37427.5625, 37427.5625, 37427.5625, 37427.5625,\n",
      "       37427.5625, 37427.5625, 37427.5625]))\n",
      "           fun: 37427.5625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1145\n",
      "           nit: 359\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.44717975e-01, 3.89111859e-02, 1.40050709e-02, 6.76712230e+03,\n",
      "       1.81917073e+04, 1.59015513e+04, 4.91623512e+03])\n",
      "minPrevious 36770.3828125\n",
      "best ll: 57187.76171875, bestParams: [tensor(0.2976), tensor(0.0402), tensor(0.1470), tensor(14896.0059), tensor(15241.0596), tensor(19506.1270), tensor(22570.5566)]\n",
      "epoch 15\n",
      " final_simplex: (array([[9.52414081e-01, 4.07180756e-02, 4.81102204e-03, 4.97818441e+03,\n",
      "        1.28075993e+04, 1.25298207e+04, 2.05867294e+04],\n",
      "       [9.52414081e-01, 4.07180757e-02, 4.81102186e-03, 4.97818444e+03,\n",
      "        1.28075993e+04, 1.25298207e+04, 2.05867293e+04],\n",
      "       [9.52414081e-01, 4.07180756e-02, 4.81102212e-03, 4.97818438e+03,\n",
      "        1.28075993e+04, 1.25298207e+04, 2.05867294e+04],\n",
      "       [9.52414081e-01, 4.07180757e-02, 4.81102211e-03, 4.97818443e+03,\n",
      "        1.28075992e+04, 1.25298207e+04, 2.05867294e+04],\n",
      "       [9.52414081e-01, 4.07180757e-02, 4.81102183e-03, 4.97818441e+03,\n",
      "        1.28075993e+04, 1.25298207e+04, 2.05867294e+04],\n",
      "       [9.52414082e-01, 4.07180758e-02, 4.81102189e-03, 4.97818447e+03,\n",
      "        1.28075992e+04, 1.25298207e+04, 2.05867293e+04],\n",
      "       [9.52414081e-01, 4.07180756e-02, 4.81102210e-03, 4.97818442e+03,\n",
      "        1.28075993e+04, 1.25298207e+04, 2.05867294e+04],\n",
      "       [9.52414081e-01, 4.07180756e-02, 4.81102215e-03, 4.97818440e+03,\n",
      "        1.28075992e+04, 1.25298207e+04, 2.05867294e+04]]), array([37511.51171875, 37511.51171875, 37511.51171875, 37511.51171875,\n",
      "       37511.51171875, 37511.51171875, 37511.51171875, 37511.51171875]))\n",
      "           fun: 37511.51171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.52414081e-01, 4.07180756e-02, 4.81102204e-03, 4.97818441e+03,\n",
      "       1.28075993e+04, 1.25298207e+04, 2.05867294e+04])\n",
      "minPrevious 36770.3828125\n",
      "best ll: 58722.4296875, bestParams: [tensor(0.2835), tensor(0.0513), tensor(0.2397), tensor(14041.1279), tensor(8957.7080), tensor(10854.1133), tensor(18127.8730)]\n",
      "epoch 16\n",
      " final_simplex: (array([[9.08522378e-01, 6.14628767e-02, 9.01141554e-03, 1.76089036e+04,\n",
      "        8.40580115e+03, 9.56870101e+03, 1.14263102e+02],\n",
      "       [9.08522377e-01, 6.14628769e-02, 9.01141401e-03, 1.76089036e+04,\n",
      "        8.40580115e+03, 9.56870103e+03, 1.14263157e+02],\n",
      "       [9.08522380e-01, 6.14628771e-02, 9.01141287e-03, 1.76089036e+04,\n",
      "        8.40580112e+03, 9.56870104e+03, 1.14263021e+02],\n",
      "       [9.08522376e-01, 6.14628769e-02, 9.01141485e-03, 1.76089035e+04,\n",
      "        8.40580118e+03, 9.56870104e+03, 1.14263154e+02],\n",
      "       [9.08522378e-01, 6.14628769e-02, 9.01141395e-03, 1.76089036e+04,\n",
      "        8.40580116e+03, 9.56870101e+03, 1.14263140e+02],\n",
      "       [9.08522379e-01, 6.14628772e-02, 9.01141246e-03, 1.76089036e+04,\n",
      "        8.40580112e+03, 9.56870105e+03, 1.14263080e+02],\n",
      "       [9.08522380e-01, 6.14628773e-02, 9.01141144e-03, 1.76089036e+04,\n",
      "        8.40580113e+03, 9.56870110e+03, 1.14263062e+02],\n",
      "       [9.08522379e-01, 6.14628771e-02, 9.01141297e-03, 1.76089036e+04,\n",
      "        8.40580109e+03, 9.56870100e+03, 1.14263114e+02]]), array([38592.46484375, 38592.46484375, 38592.46484375, 38592.46484375,\n",
      "       38592.46484375, 38592.46484375, 38592.46484375, 38592.46484375]))\n",
      "           fun: 38592.46484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1263\n",
      "           nit: 447\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.08522378e-01, 6.14628767e-02, 9.01141554e-03, 1.76089036e+04,\n",
      "       8.40580115e+03, 9.56870101e+03, 1.14263102e+02])\n",
      "minPrevious 36770.3828125\n",
      "best ll: 57340.2109375, bestParams: [tensor(0.2890), tensor(0.0353), tensor(0.1631), tensor(6990.3887), tensor(22222.8184), tensor(22395.4277), tensor(14137.8525)]\n",
      "epoch 17\n",
      " final_simplex: (array([[8.61691598e-01, 2.46722724e-02, 1.08667524e-01, 2.76365701e+03,\n",
      "        2.25039705e+04, 2.17300376e+04, 7.38174924e+03],\n",
      "       [8.61691597e-01, 2.46722724e-02, 1.08667524e-01, 2.76365704e+03,\n",
      "        2.25039705e+04, 2.17300376e+04, 7.38174924e+03],\n",
      "       [8.61691596e-01, 2.46722723e-02, 1.08667524e-01, 2.76365702e+03,\n",
      "        2.25039706e+04, 2.17300376e+04, 7.38174925e+03],\n",
      "       [8.61691596e-01, 2.46722724e-02, 1.08667524e-01, 2.76365702e+03,\n",
      "        2.25039706e+04, 2.17300376e+04, 7.38174927e+03],\n",
      "       [8.61691596e-01, 2.46722723e-02, 1.08667524e-01, 2.76365702e+03,\n",
      "        2.25039706e+04, 2.17300375e+04, 7.38174927e+03],\n",
      "       [8.61691597e-01, 2.46722724e-02, 1.08667524e-01, 2.76365702e+03,\n",
      "        2.25039705e+04, 2.17300376e+04, 7.38174926e+03],\n",
      "       [8.61691597e-01, 2.46722723e-02, 1.08667524e-01, 2.76365701e+03,\n",
      "        2.25039706e+04, 2.17300375e+04, 7.38174927e+03],\n",
      "       [8.61691598e-01, 2.46722723e-02, 1.08667524e-01, 2.76365703e+03,\n",
      "        2.25039706e+04, 2.17300375e+04, 7.38174924e+03]]), array([39257.31640625, 39257.31640625, 39257.31640625, 39257.31640625,\n",
      "       39257.31640625, 39257.31640625, 39257.31640625, 39257.31640625]))\n",
      "           fun: 39257.31640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1236\n",
      "           nit: 417\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.61691598e-01, 2.46722724e-02, 1.08667524e-01, 2.76365701e+03,\n",
      "       2.25039705e+04, 2.17300376e+04, 7.38174924e+03])\n",
      "minPrevious 36770.3828125\n",
      "best ll: 56337.734375, bestParams: [tensor(0.3068), tensor(0.0750), tensor(0.1040), tensor(22124.5000), tensor(15570.8906), tensor(17299.1836), tensor(5316.1187)]\n",
      "epoch 18\n",
      " final_simplex: (array([[9.37637217e-01, 1.15962424e-02, 4.81759155e-02, 9.51031588e+03,\n",
      "        1.22324687e+04, 1.29695966e+04, 7.34563252e+03],\n",
      "       [9.37637217e-01, 1.15962419e-02, 4.81759155e-02, 9.51031597e+03,\n",
      "        1.22324687e+04, 1.29695966e+04, 7.34563248e+03],\n",
      "       [9.37637217e-01, 1.15962418e-02, 4.81759158e-02, 9.51031595e+03,\n",
      "        1.22324688e+04, 1.29695966e+04, 7.34563250e+03],\n",
      "       [9.37637217e-01, 1.15962419e-02, 4.81759159e-02, 9.51031588e+03,\n",
      "        1.22324688e+04, 1.29695967e+04, 7.34563250e+03],\n",
      "       [9.37637217e-01, 1.15962421e-02, 4.81759157e-02, 9.51031591e+03,\n",
      "        1.22324688e+04, 1.29695967e+04, 7.34563249e+03],\n",
      "       [9.37637217e-01, 1.15962417e-02, 4.81759156e-02, 9.51031598e+03,\n",
      "        1.22324687e+04, 1.29695966e+04, 7.34563249e+03],\n",
      "       [9.37637217e-01, 1.15962419e-02, 4.81759156e-02, 9.51031593e+03,\n",
      "        1.22324687e+04, 1.29695966e+04, 7.34563251e+03],\n",
      "       [9.37637217e-01, 1.15962419e-02, 4.81759155e-02, 9.51031590e+03,\n",
      "        1.22324687e+04, 1.29695966e+04, 7.34563252e+03]]), array([37926.57421875, 37926.57421875, 37926.57421875, 37926.57421875,\n",
      "       37926.57421875, 37926.57421875, 37926.57421875, 37926.57421875]))\n",
      "           fun: 37926.57421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1282\n",
      "           nit: 467\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.37637217e-01, 1.15962424e-02, 4.81759155e-02, 9.51031588e+03,\n",
      "       1.22324687e+04, 1.29695966e+04, 7.34563252e+03])\n",
      "minPrevious 36770.3828125\n",
      "best ll: 56597.90234375, bestParams: [tensor(0.3182), tensor(0.1810), tensor(0.0764), tensor(11829.4170), tensor(17325.6445), tensor(18756.8633), tensor(4067.7461)]\n",
      "epoch 19\n",
      " final_simplex: (array([[8.05356905e-01, 1.20261790e-01, 7.33041709e-02, 6.94464503e+03,\n",
      "        1.60090194e+04, 1.38083154e+04, 3.16728158e+03],\n",
      "       [8.05356910e-01, 1.20261788e-01, 7.33041714e-02, 6.94464509e+03,\n",
      "        1.60090194e+04, 1.38083154e+04, 3.16728157e+03],\n",
      "       [8.05356908e-01, 1.20261788e-01, 7.33041713e-02, 6.94464508e+03,\n",
      "        1.60090194e+04, 1.38083154e+04, 3.16728157e+03],\n",
      "       [8.05356909e-01, 1.20261788e-01, 7.33041713e-02, 6.94464503e+03,\n",
      "        1.60090194e+04, 1.38083154e+04, 3.16728157e+03],\n",
      "       [8.05356907e-01, 1.20261789e-01, 7.33041711e-02, 6.94464498e+03,\n",
      "        1.60090194e+04, 1.38083154e+04, 3.16728156e+03],\n",
      "       [8.05356907e-01, 1.20261789e-01, 7.33041713e-02, 6.94464512e+03,\n",
      "        1.60090195e+04, 1.38083155e+04, 3.16728157e+03],\n",
      "       [8.05356906e-01, 1.20261789e-01, 7.33041709e-02, 6.94464511e+03,\n",
      "        1.60090194e+04, 1.38083155e+04, 3.16728157e+03],\n",
      "       [8.05356908e-01, 1.20261789e-01, 7.33041708e-02, 6.94464496e+03,\n",
      "        1.60090195e+04, 1.38083154e+04, 3.16728154e+03]]), array([40937.6484375, 40937.6484375, 40937.6484375, 40937.6484375,\n",
      "       40937.6484375, 40937.6484375, 40937.6484375, 40937.6484375]))\n",
      "           fun: 40937.6484375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1168\n",
      "           nit: 408\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.05356905e-01, 1.20261790e-01, 7.33041709e-02, 6.94464503e+03,\n",
      "       1.60090194e+04, 1.38083154e+04, 3.16728158e+03])\n",
      "minPrevious 36770.3828125\n",
      "inferredPis tensor([9.9493e-01, 2.2532e-03, 5.0930e-04], dtype=torch.float64)\n",
      "inferredAlphas tensor([24233.9895, 13108.5658, 12119.1812, 10209.1235], dtype=torch.float64)\n",
      "truth0 tensor(0.7519) truth1 tensor(0.1111) truth2 tensor(0.1121) truthBoth tensor(0.0250)\n",
      "params on run 2 {'lls': [58132.7578125, 61020.8984375, 62816.03125, 61310.28125, 59964.953125, 47473.921875, 47433.734375, 47816.32421875, 47210.3984375, 51822.578125, 51970.546875, 47609.4609375, 52364.7734375, 53773.0390625, 47233.921875, 36342.86328125, 36234.44921875, 36770.3828125], 'inferredAlphas': [tensor([17771.7538,   267.5774,   285.4237, 19323.4289], dtype=torch.float64), tensor([17391.5067,   389.1159,   504.1465, 38945.6315], dtype=torch.float64), tensor([26599.6834,   330.5187,   522.2450, 20474.0527], dtype=torch.float64), tensor([17159.0905,   229.1438,   192.1196, 23702.7612], dtype=torch.float64), tensor([14365.2776,   353.8587,   277.5095, 36615.7416], dtype=torch.float64), tensor([4681.1768, 1514.9906,  279.5278, 6430.2365], dtype=torch.float64), tensor([11636.0228,  1941.4431,   317.7839,  2432.4090], dtype=torch.float64), tensor([3466.6976,  105.4401,  574.8790,  884.2902], dtype=torch.float64), tensor([  190.1304,   255.3843,  1367.9433, 10051.6183], dtype=torch.float64), tensor([13347.1036,  2995.2070,   679.1869,  9964.7306], dtype=torch.float64), tensor([3050.1159,  274.5893, 1270.7564, 7251.8219], dtype=torch.float64), tensor([1902.8937,  238.1495, 1249.7712, 7914.4684], dtype=torch.float64), tensor([20414.2533,  1255.3286,  5495.8171, 24486.6440], dtype=torch.float64), tensor([ 5422.4410,  1070.5042,  5035.1884, 34394.7350], dtype=torch.float64), tensor([6116.3640, 1549.1665,  277.2773, 5735.0947], dtype=torch.float64), tensor([ 3252.4160, 17197.7572, 17440.7641, 20021.9416], dtype=torch.float64), tensor([7562.1733, 8368.3120, 8779.7352, 8746.4345], dtype=torch.float64), tensor([24233.9895, 13108.5658, 12119.1812, 10209.1235], dtype=torch.float64)], 'inferredPis': [tensor([0.2745, 0.5123, 0.0037], dtype=torch.float64), tensor([0.2424, 0.2423, 0.0335], dtype=torch.float64), tensor([0.2477, 0.1574, 0.0414], dtype=torch.float64), tensor([0.2670, 0.3576, 0.1152], dtype=torch.float64), tensor([0.4350, 0.2494, 0.0647], dtype=torch.float64), tensor([0.1319, 0.8504, 0.0173], dtype=torch.float64), tensor([0.1121, 0.8709, 0.0016], dtype=torch.float64), tensor([0.7272, 0.2531, 0.0189], dtype=torch.float64), tensor([0.8014, 0.1978, 0.0008], dtype=torch.float64), tensor([0.1527, 0.5340, 0.0406], dtype=torch.float64), tensor([4.4252e-01, 2.4141e-01, 6.9015e-05], dtype=torch.float64), tensor([0.7311, 0.2567, 0.0100], dtype=torch.float64), tensor([0.4108, 0.3023, 0.0150], dtype=torch.float64), tensor([0.4187, 0.1117, 0.0518], dtype=torch.float64), tensor([0.2033, 0.7863, 0.0045], dtype=torch.float64), tensor([0.9651, 0.0301, 0.0021], dtype=torch.float64), tensor([0.9906, 0.0041, 0.0032], dtype=torch.float64), tensor([9.9493e-01, 2.2532e-03, 5.0930e-04], dtype=torch.float64)], 'inferredPDVs': [tensor([0.4720, 0.0071, 0.0076, 0.5133], dtype=torch.float64), tensor([0.3039, 0.0068, 0.0088, 0.6805], dtype=torch.float64), tensor([0.5550, 0.0069, 0.0109, 0.4272], dtype=torch.float64), tensor([0.4156, 0.0056, 0.0047, 0.5742], dtype=torch.float64), tensor([0.2783, 0.0069, 0.0054, 0.7095], dtype=torch.float64), tensor([0.3627, 0.1174, 0.0217, 0.4982], dtype=torch.float64), tensor([0.7126, 0.1189, 0.0195, 0.1490], dtype=torch.float64), tensor([0.6890, 0.0210, 0.1143, 0.1758], dtype=torch.float64), tensor([0.0160, 0.0215, 0.1153, 0.8471], dtype=torch.float64), tensor([0.4945, 0.1110, 0.0252, 0.3693], dtype=torch.float64), tensor([0.2575, 0.0232, 0.1073, 0.6120], dtype=torch.float64), tensor([0.1683, 0.0210, 0.1106, 0.7001], dtype=torch.float64), tensor([0.3952, 0.0243, 0.1064, 0.4741], dtype=torch.float64), tensor([0.1181, 0.0233, 0.1096, 0.7490], dtype=torch.float64), tensor([0.4472, 0.1133, 0.0203, 0.4192], dtype=torch.float64), tensor([0.0562, 0.2969, 0.3011, 0.3458], dtype=torch.float64), tensor([0.2260, 0.2501, 0.2624, 0.2614], dtype=torch.float64), tensor([0.4061, 0.2197, 0.2031, 0.1711], dtype=torch.float64)], 'trueMeanPDVs': [tensor([0.7547, 0.1096, 0.1105, 0.0252]), tensor([0.7520, 0.1114, 0.1113, 0.0253]), tensor([0.7523, 0.1111, 0.1116, 0.0250]), tensor([0.7518, 0.1113, 0.1112, 0.0257]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7510, 0.1117, 0.1118, 0.0255]), tensor([0.7535, 0.1110, 0.1105, 0.0250]), tensor([0.7503, 0.1121, 0.1120, 0.0256]), tensor([0.7542, 0.1103, 0.1109, 0.0246]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250])], 'truePis': [tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500])]}\n",
      "tensor([[ 43.,   6.,   1.,   0.],\n",
      "        [ 57.,  16.,   1.,   0.],\n",
      "        [ 66.,   6.,   2.,   0.],\n",
      "        ...,\n",
      "        [ 69.,   3.,   2.,   1.],\n",
      "        [ 71.,   1.,   0.,   0.],\n",
      "        [124.,   1.,   1.,   0.]])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood4 at 0x7feafd642320>\n",
      "best ll: 56303.890625, bestParams: [tensor(0.2924), tensor(0.0530), tensor(0.0606), tensor(20079.2773), tensor(20237.4062), tensor(20527.8984), tensor(16181.4873)]\n",
      "epoch 0\n",
      " final_simplex: (array([[9.11288607e-01, 6.25282495e-02, 1.72625665e-02, 1.67617495e+04,\n",
      "        1.66862149e+04, 1.61929190e+04, 1.05152866e+04],\n",
      "       [9.11288608e-01, 6.25282496e-02, 1.72625664e-02, 1.67617495e+04,\n",
      "        1.66862149e+04, 1.61929190e+04, 1.05152866e+04],\n",
      "       [9.11288607e-01, 6.25282496e-02, 1.72625665e-02, 1.67617495e+04,\n",
      "        1.66862148e+04, 1.61929190e+04, 1.05152866e+04],\n",
      "       [9.11288607e-01, 6.25282495e-02, 1.72625665e-02, 1.67617495e+04,\n",
      "        1.66862149e+04, 1.61929190e+04, 1.05152866e+04],\n",
      "       [9.11288607e-01, 6.25282495e-02, 1.72625665e-02, 1.67617495e+04,\n",
      "        1.66862148e+04, 1.61929190e+04, 1.05152867e+04],\n",
      "       [9.11288607e-01, 6.25282495e-02, 1.72625665e-02, 1.67617495e+04,\n",
      "        1.66862149e+04, 1.61929190e+04, 1.05152866e+04],\n",
      "       [9.11288607e-01, 6.25282495e-02, 1.72625665e-02, 1.67617495e+04,\n",
      "        1.66862149e+04, 1.61929190e+04, 1.05152866e+04],\n",
      "       [9.11288607e-01, 6.25282495e-02, 1.72625665e-02, 1.67617495e+04,\n",
      "        1.66862149e+04, 1.61929190e+04, 1.05152866e+04]]), array([38043.0859375, 38043.0859375, 38043.0859375, 38043.0859375,\n",
      "       38043.0859375, 38043.0859375, 38043.0859375, 38043.0859375]))\n",
      "           fun: 38043.0859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1269\n",
      "           nit: 453\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.11288607e-01, 6.25282495e-02, 1.72625665e-02, 1.67617495e+04,\n",
      "       1.66862149e+04, 1.61929190e+04, 1.05152866e+04])\n",
      "best ll: 51758.578125, bestParams: [tensor(0.4074), tensor(0.0952), tensor(0.0224), tensor(15466.9238), tensor(24455.4512), tensor(24480.1348), tensor(19186.5586)]\n",
      "epoch 1\n",
      " final_simplex: (array([[9.30900395e-01, 5.45100776e-02, 1.20263681e-02, 8.22343603e+03,\n",
      "        1.58540047e+04, 1.33020183e+04, 1.94746037e+04],\n",
      "       [9.30900394e-01, 5.45100776e-02, 1.20263681e-02, 8.22343602e+03,\n",
      "        1.58540047e+04, 1.33020183e+04, 1.94746037e+04],\n",
      "       [9.30900394e-01, 5.45100776e-02, 1.20263681e-02, 8.22343601e+03,\n",
      "        1.58540047e+04, 1.33020184e+04, 1.94746037e+04],\n",
      "       [9.30900395e-01, 5.45100778e-02, 1.20263680e-02, 8.22343601e+03,\n",
      "        1.58540047e+04, 1.33020184e+04, 1.94746037e+04],\n",
      "       [9.30900393e-01, 5.45100776e-02, 1.20263682e-02, 8.22343599e+03,\n",
      "        1.58540047e+04, 1.33020184e+04, 1.94746037e+04],\n",
      "       [9.30900395e-01, 5.45100776e-02, 1.20263681e-02, 8.22343602e+03,\n",
      "        1.58540047e+04, 1.33020183e+04, 1.94746037e+04],\n",
      "       [9.30900394e-01, 5.45100775e-02, 1.20263681e-02, 8.22343602e+03,\n",
      "        1.58540047e+04, 1.33020183e+04, 1.94746037e+04],\n",
      "       [9.30900395e-01, 5.45100775e-02, 1.20263681e-02, 8.22343603e+03,\n",
      "        1.58540047e+04, 1.33020183e+04, 1.94746037e+04]]), array([37915.3046875, 37915.3046875, 37915.3046875, 37915.3046875,\n",
      "       37915.3046875, 37915.3046875, 37915.3046875, 37915.3046875]))\n",
      "           fun: 37915.3046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1231\n",
      "           nit: 397\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.30900395e-01, 5.45100776e-02, 1.20263681e-02, 8.22343603e+03,\n",
      "       1.58540047e+04, 1.33020183e+04, 1.94746037e+04])\n",
      "minPrevious 38043.0859375\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.30900395e-01, 5.45100776e-02, 1.20263681e-02, 8.22343603e+03,\n",
      "        1.58540047e+04, 1.33020183e+04, 1.94746037e+04],\n",
      "       [9.30900394e-01, 5.45100776e-02, 1.20263681e-02, 8.22343602e+03,\n",
      "        1.58540047e+04, 1.33020183e+04, 1.94746037e+04],\n",
      "       [9.30900394e-01, 5.45100776e-02, 1.20263681e-02, 8.22343601e+03,\n",
      "        1.58540047e+04, 1.33020184e+04, 1.94746037e+04],\n",
      "       [9.30900395e-01, 5.45100778e-02, 1.20263680e-02, 8.22343601e+03,\n",
      "        1.58540047e+04, 1.33020184e+04, 1.94746037e+04],\n",
      "       [9.30900393e-01, 5.45100776e-02, 1.20263682e-02, 8.22343599e+03,\n",
      "        1.58540047e+04, 1.33020184e+04, 1.94746037e+04],\n",
      "       [9.30900395e-01, 5.45100776e-02, 1.20263681e-02, 8.22343602e+03,\n",
      "        1.58540047e+04, 1.33020183e+04, 1.94746037e+04],\n",
      "       [9.30900394e-01, 5.45100775e-02, 1.20263681e-02, 8.22343602e+03,\n",
      "        1.58540047e+04, 1.33020183e+04, 1.94746037e+04],\n",
      "       [9.30900395e-01, 5.45100775e-02, 1.20263681e-02, 8.22343603e+03,\n",
      "        1.58540047e+04, 1.33020183e+04, 1.94746037e+04]]), array([37915.3046875, 37915.3046875, 37915.3046875, 37915.3046875,\n",
      "       37915.3046875, 37915.3046875, 37915.3046875, 37915.3046875]))\n",
      "           fun: 37915.3046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1231\n",
      "           nit: 397\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.30900395e-01, 5.45100776e-02, 1.20263681e-02, 8.22343603e+03,\n",
      "       1.58540047e+04, 1.33020183e+04, 1.94746037e+04])\n",
      "best ll: 55384.6484375, bestParams: [tensor(0.3361), tensor(0.0669), tensor(0.1259), tensor(1054.9014), tensor(15249.8467), tensor(12985.1572), tensor(5509.5483)]\n",
      "epoch 2\n",
      " final_simplex: (array([[8.95870899e-01, 3.75525552e-02, 6.36623528e-02, 8.22394155e+02,\n",
      "        1.02866167e+04, 1.00349858e+04, 6.69891423e+03],\n",
      "       [8.95870901e-01, 3.75525540e-02, 6.36623526e-02, 8.22394153e+02,\n",
      "        1.02866166e+04, 1.00349858e+04, 6.69891429e+03],\n",
      "       [8.95870900e-01, 3.75525548e-02, 6.36623523e-02, 8.22394154e+02,\n",
      "        1.02866166e+04, 1.00349858e+04, 6.69891427e+03],\n",
      "       [8.95870900e-01, 3.75525546e-02, 6.36623526e-02, 8.22394152e+02,\n",
      "        1.02866166e+04, 1.00349858e+04, 6.69891427e+03],\n",
      "       [8.95870899e-01, 3.75525554e-02, 6.36623527e-02, 8.22394146e+02,\n",
      "        1.02866166e+04, 1.00349858e+04, 6.69891425e+03],\n",
      "       [8.95870900e-01, 3.75525547e-02, 6.36623525e-02, 8.22394156e+02,\n",
      "        1.02866166e+04, 1.00349858e+04, 6.69891425e+03],\n",
      "       [8.95870900e-01, 3.75525550e-02, 6.36623525e-02, 8.22394150e+02,\n",
      "        1.02866167e+04, 1.00349858e+04, 6.69891426e+03],\n",
      "       [8.95870900e-01, 3.75525549e-02, 6.36623522e-02, 8.22394147e+02,\n",
      "        1.02866167e+04, 1.00349858e+04, 6.69891427e+03]]), array([38698.40625, 38698.40625, 38698.40625, 38698.40625, 38698.40625,\n",
      "       38698.40625, 38698.40625, 38698.40625]))\n",
      "           fun: 38698.40625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1191\n",
      "           nit: 393\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.95870899e-01, 3.75525552e-02, 6.36623528e-02, 8.22394155e+02,\n",
      "       1.02866167e+04, 1.00349858e+04, 6.69891423e+03])\n",
      "minPrevious 37915.3046875\n",
      "best ll: 55892.1171875, bestParams: [tensor(0.4061), tensor(0.0066), tensor(0.0440), tensor(11902.8457), tensor(14666.5576), tensor(6999.9302), tensor(9788.4521)]\n",
      "epoch 3\n",
      " final_simplex: (array([[9.56290889e-01, 4.56395558e-03, 3.65346165e-02, 7.75880318e+03,\n",
      "        8.50413094e+03, 9.13891158e+03, 9.10528351e+03],\n",
      "       [9.56290889e-01, 4.56395559e-03, 3.65346164e-02, 7.75880317e+03,\n",
      "        8.50413095e+03, 9.13891158e+03, 9.10528351e+03],\n",
      "       [9.56290889e-01, 4.56395559e-03, 3.65346165e-02, 7.75880317e+03,\n",
      "        8.50413095e+03, 9.13891158e+03, 9.10528351e+03],\n",
      "       [9.56290889e-01, 4.56395558e-03, 3.65346165e-02, 7.75880318e+03,\n",
      "        8.50413094e+03, 9.13891158e+03, 9.10528353e+03],\n",
      "       [9.56290889e-01, 4.56395559e-03, 3.65346165e-02, 7.75880318e+03,\n",
      "        8.50413094e+03, 9.13891158e+03, 9.10528348e+03],\n",
      "       [9.56290889e-01, 4.56395561e-03, 3.65346165e-02, 7.75880314e+03,\n",
      "        8.50413095e+03, 9.13891157e+03, 9.10528342e+03],\n",
      "       [9.56290889e-01, 4.56395559e-03, 3.65346165e-02, 7.75880316e+03,\n",
      "        8.50413095e+03, 9.13891157e+03, 9.10528350e+03],\n",
      "       [9.56290889e-01, 4.56395559e-03, 3.65346165e-02, 7.75880316e+03,\n",
      "        8.50413095e+03, 9.13891157e+03, 9.10528351e+03]]), array([37451.61328125, 37451.61328125, 37451.61328125, 37451.61328125,\n",
      "       37451.61328125, 37451.61328125, 37451.61328125, 37451.61328125]))\n",
      "           fun: 37451.61328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 407\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.56290889e-01, 4.56395558e-03, 3.65346165e-02, 7.75880318e+03,\n",
      "       8.50413094e+03, 9.13891158e+03, 9.10528351e+03])\n",
      "minPrevious 37915.3046875\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.56290889e-01, 4.56395558e-03, 3.65346165e-02, 7.75880318e+03,\n",
      "        8.50413094e+03, 9.13891158e+03, 9.10528351e+03],\n",
      "       [9.56290889e-01, 4.56395559e-03, 3.65346164e-02, 7.75880317e+03,\n",
      "        8.50413095e+03, 9.13891158e+03, 9.10528351e+03],\n",
      "       [9.56290889e-01, 4.56395559e-03, 3.65346165e-02, 7.75880317e+03,\n",
      "        8.50413095e+03, 9.13891158e+03, 9.10528351e+03],\n",
      "       [9.56290889e-01, 4.56395558e-03, 3.65346165e-02, 7.75880318e+03,\n",
      "        8.50413094e+03, 9.13891158e+03, 9.10528353e+03],\n",
      "       [9.56290889e-01, 4.56395559e-03, 3.65346165e-02, 7.75880318e+03,\n",
      "        8.50413094e+03, 9.13891158e+03, 9.10528348e+03],\n",
      "       [9.56290889e-01, 4.56395561e-03, 3.65346165e-02, 7.75880314e+03,\n",
      "        8.50413095e+03, 9.13891157e+03, 9.10528342e+03],\n",
      "       [9.56290889e-01, 4.56395559e-03, 3.65346165e-02, 7.75880316e+03,\n",
      "        8.50413095e+03, 9.13891157e+03, 9.10528350e+03],\n",
      "       [9.56290889e-01, 4.56395559e-03, 3.65346165e-02, 7.75880316e+03,\n",
      "        8.50413095e+03, 9.13891157e+03, 9.10528351e+03]]), array([37451.61328125, 37451.61328125, 37451.61328125, 37451.61328125,\n",
      "       37451.61328125, 37451.61328125, 37451.61328125, 37451.61328125]))\n",
      "           fun: 37451.61328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 407\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.56290889e-01, 4.56395558e-03, 3.65346165e-02, 7.75880318e+03,\n",
      "       8.50413094e+03, 9.13891158e+03, 9.10528351e+03])\n",
      "best ll: 56537.21484375, bestParams: [tensor(0.3086), tensor(0.1811), tensor(0.0601), tensor(545.8878), tensor(7789.2207), tensor(7663.4443), tensor(12380.9023)]\n",
      "epoch 4\n",
      " final_simplex: (array([[8.30237425e-01, 1.19059818e-01, 4.70742676e-02, 6.59768606e+02,\n",
      "        5.66089734e+03, 5.67468555e+03, 6.19023191e+03],\n",
      "       [8.30237424e-01, 1.19059818e-01, 4.70742677e-02, 6.59768610e+02,\n",
      "        5.66089735e+03, 5.67468557e+03, 6.19023182e+03],\n",
      "       [8.30237425e-01, 1.19059818e-01, 4.70742675e-02, 6.59768606e+02,\n",
      "        5.66089734e+03, 5.67468557e+03, 6.19023194e+03],\n",
      "       [8.30237424e-01, 1.19059817e-01, 4.70742675e-02, 6.59768608e+02,\n",
      "        5.66089736e+03, 5.67468557e+03, 6.19023187e+03],\n",
      "       [8.30237424e-01, 1.19059818e-01, 4.70742676e-02, 6.59768609e+02,\n",
      "        5.66089733e+03, 5.67468556e+03, 6.19023186e+03],\n",
      "       [8.30237425e-01, 1.19059818e-01, 4.70742675e-02, 6.59768608e+02,\n",
      "        5.66089733e+03, 5.67468557e+03, 6.19023191e+03],\n",
      "       [8.30237424e-01, 1.19059817e-01, 4.70742674e-02, 6.59768607e+02,\n",
      "        5.66089737e+03, 5.67468558e+03, 6.19023187e+03],\n",
      "       [8.30237424e-01, 1.19059818e-01, 4.70742676e-02, 6.59768607e+02,\n",
      "        5.66089734e+03, 5.67468556e+03, 6.19023191e+03]]), array([40273.0234375, 40273.0234375, 40273.0234375, 40273.0234375,\n",
      "       40273.0234375, 40273.0234375, 40273.0234375, 40273.0234375]))\n",
      "           fun: 40273.0234375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1227\n",
      "           nit: 430\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.30237425e-01, 1.19059818e-01, 4.70742676e-02, 6.59768606e+02,\n",
      "       5.66089734e+03, 5.67468555e+03, 6.19023191e+03])\n",
      "minPrevious 37451.61328125\n",
      "best ll: 55324.2578125, bestParams: [tensor(0.3333), tensor(0.1534), tensor(0.0295), tensor(10826.6074), tensor(20631.), tensor(21409.6348), tensor(9112.3555)]\n",
      "epoch 5\n",
      " final_simplex: (array([[9.42532951e-01, 2.44399722e-02, 2.63136033e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597838e+03],\n",
      "       [9.42532951e-01, 2.44399717e-02, 2.63136034e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597838e+03],\n",
      "       [9.42532951e-01, 2.44399718e-02, 2.63136034e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597838e+03],\n",
      "       [9.42532951e-01, 2.44399716e-02, 2.63136033e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597839e+03],\n",
      "       [9.42532951e-01, 2.44399718e-02, 2.63136033e-02, 1.39364407e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597839e+03],\n",
      "       [9.42532951e-01, 2.44399716e-02, 2.63136033e-02, 1.39364407e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597839e+03],\n",
      "       [9.42532952e-01, 2.44399714e-02, 2.63136034e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597838e+03],\n",
      "       [9.42532951e-01, 2.44399717e-02, 2.63136034e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597838e+03]]), array([37319.046875, 37319.046875, 37319.046875, 37319.046875,\n",
      "       37319.046875, 37319.046875, 37319.046875, 37319.046875]))\n",
      "           fun: 37319.046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 469\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.42532951e-01, 2.44399722e-02, 2.63136033e-02, 1.39364406e+04,\n",
      "       1.61294848e+04, 1.68413028e+04, 6.40597838e+03])\n",
      "minPrevious 37451.61328125\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.42532951e-01, 2.44399722e-02, 2.63136033e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597838e+03],\n",
      "       [9.42532951e-01, 2.44399717e-02, 2.63136034e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597838e+03],\n",
      "       [9.42532951e-01, 2.44399718e-02, 2.63136034e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597838e+03],\n",
      "       [9.42532951e-01, 2.44399716e-02, 2.63136033e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597839e+03],\n",
      "       [9.42532951e-01, 2.44399718e-02, 2.63136033e-02, 1.39364407e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597839e+03],\n",
      "       [9.42532951e-01, 2.44399716e-02, 2.63136033e-02, 1.39364407e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597839e+03],\n",
      "       [9.42532952e-01, 2.44399714e-02, 2.63136034e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597838e+03],\n",
      "       [9.42532951e-01, 2.44399717e-02, 2.63136034e-02, 1.39364406e+04,\n",
      "        1.61294848e+04, 1.68413028e+04, 6.40597838e+03]]), array([37319.046875, 37319.046875, 37319.046875, 37319.046875,\n",
      "       37319.046875, 37319.046875, 37319.046875, 37319.046875]))\n",
      "           fun: 37319.046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 469\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.42532951e-01, 2.44399722e-02, 2.63136033e-02, 1.39364406e+04,\n",
      "       1.61294848e+04, 1.68413028e+04, 6.40597838e+03])\n",
      "best ll: 59677.06640625, bestParams: [tensor(0.2624), tensor(0.0848), tensor(0.2406), tensor(13389.1074), tensor(14591.9160), tensor(17227.2441), tensor(12487.9922)]\n",
      "epoch 6\n",
      " final_simplex: (array([[8.79347654e-01, 4.08475468e-02, 7.78265049e-02, 1.85162659e+04,\n",
      "        1.25712409e+04, 1.26614798e+04, 5.30861650e+03],\n",
      "       [8.79347653e-01, 4.08475470e-02, 7.78265050e-02, 1.85162659e+04,\n",
      "        1.25712409e+04, 1.26614797e+04, 5.30861649e+03],\n",
      "       [8.79347653e-01, 4.08475470e-02, 7.78265050e-02, 1.85162659e+04,\n",
      "        1.25712410e+04, 1.26614798e+04, 5.30861650e+03],\n",
      "       [8.79347653e-01, 4.08475469e-02, 7.78265050e-02, 1.85162659e+04,\n",
      "        1.25712410e+04, 1.26614798e+04, 5.30861650e+03],\n",
      "       [8.79347653e-01, 4.08475470e-02, 7.78265047e-02, 1.85162659e+04,\n",
      "        1.25712409e+04, 1.26614798e+04, 5.30861649e+03],\n",
      "       [8.79347653e-01, 4.08475470e-02, 7.78265048e-02, 1.85162659e+04,\n",
      "        1.25712410e+04, 1.26614797e+04, 5.30861652e+03],\n",
      "       [8.79347653e-01, 4.08475471e-02, 7.78265053e-02, 1.85162659e+04,\n",
      "        1.25712410e+04, 1.26614797e+04, 5.30861651e+03],\n",
      "       [8.79347653e-01, 4.08475471e-02, 7.78265050e-02, 1.85162660e+04,\n",
      "        1.25712410e+04, 1.26614797e+04, 5.30861650e+03]]), array([39081.15234375, 39081.15234375, 39081.15234375, 39081.15234375,\n",
      "       39081.15234375, 39081.15234375, 39081.15234375, 39081.15234375]))\n",
      "           fun: 39081.15234375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1302\n",
      "           nit: 471\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.79347654e-01, 4.08475468e-02, 7.78265049e-02, 1.85162659e+04,\n",
      "       1.25712409e+04, 1.26614798e+04, 5.30861650e+03])\n",
      "minPrevious 37319.046875\n",
      "best ll: 61265.515625, bestParams: [tensor(0.2361), tensor(0.2407), tensor(0.0612), tensor(16332.1631), tensor(17966.3301), tensor(13688.2275), tensor(14095.0205)]\n",
      "epoch 7\n",
      " final_simplex: (array([[9.38851223e-01, 1.55893326e-03, 5.53977108e-02, 9.83924075e+03,\n",
      "        8.58209743e+03, 8.55731355e+03, 7.72754372e+03],\n",
      "       [9.38851220e-01, 1.55893487e-03, 5.53977108e-02, 9.83924080e+03,\n",
      "        8.58209749e+03, 8.55731357e+03, 7.72754373e+03],\n",
      "       [9.38851224e-01, 1.55893288e-03, 5.53977108e-02, 9.83924081e+03,\n",
      "        8.58209741e+03, 8.55731348e+03, 7.72754375e+03],\n",
      "       [9.38851222e-01, 1.55893389e-03, 5.53977108e-02, 9.83924077e+03,\n",
      "        8.58209739e+03, 8.55731362e+03, 7.72754371e+03],\n",
      "       [9.38851225e-01, 1.55893232e-03, 5.53977107e-02, 9.83924078e+03,\n",
      "        8.58209743e+03, 8.55731347e+03, 7.72754376e+03],\n",
      "       [9.38851223e-01, 1.55893361e-03, 5.53977107e-02, 9.83924081e+03,\n",
      "        8.58209745e+03, 8.55731348e+03, 7.72754375e+03],\n",
      "       [9.38851221e-01, 1.55893404e-03, 5.53977109e-02, 9.83924077e+03,\n",
      "        8.58209752e+03, 8.55731355e+03, 7.72754373e+03],\n",
      "       [9.38851222e-01, 1.55893379e-03, 5.53977109e-02, 9.83924076e+03,\n",
      "        8.58209751e+03, 8.55731354e+03, 7.72754371e+03]]), array([37735.734375, 37735.734375, 37735.734375, 37735.734375,\n",
      "       37735.734375, 37735.734375, 37735.734375, 37735.734375]))\n",
      "           fun: 37735.734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1196\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.38851223e-01, 1.55893326e-03, 5.53977108e-02, 9.83924075e+03,\n",
      "       8.58209743e+03, 8.55731355e+03, 7.72754372e+03])\n",
      "minPrevious 37319.046875\n",
      "best ll: 59835.3125, bestParams: [tensor(0.2512), tensor(0.0163), tensor(0.1897), tensor(9952.7139), tensor(18769.3652), tensor(17683.7812), tensor(4767.8579)]\n",
      "epoch 8\n",
      " final_simplex: (array([[9.64983119e-01, 6.13443147e-03, 2.20340983e-03, 3.82163898e+02,\n",
      "        1.95079105e+04, 2.33494982e+04, 4.64480663e+03],\n",
      "       [9.64983119e-01, 6.13443150e-03, 2.20340974e-03, 3.82163870e+02,\n",
      "        1.95079105e+04, 2.33494982e+04, 4.64480663e+03],\n",
      "       [9.64983120e-01, 6.13443147e-03, 2.20340952e-03, 3.82163882e+02,\n",
      "        1.95079105e+04, 2.33494982e+04, 4.64480663e+03],\n",
      "       [9.64983120e-01, 6.13443143e-03, 2.20341026e-03, 3.82163894e+02,\n",
      "        1.95079105e+04, 2.33494982e+04, 4.64480663e+03],\n",
      "       [9.64983120e-01, 6.13443145e-03, 2.20340987e-03, 3.82163892e+02,\n",
      "        1.95079105e+04, 2.33494982e+04, 4.64480662e+03],\n",
      "       [9.64983120e-01, 6.13443146e-03, 2.20340972e-03, 3.82163884e+02,\n",
      "        1.95079104e+04, 2.33494982e+04, 4.64480663e+03],\n",
      "       [9.64983120e-01, 6.13443147e-03, 2.20340978e-03, 3.82163858e+02,\n",
      "        1.95079104e+04, 2.33494982e+04, 4.64480664e+03],\n",
      "       [9.64983120e-01, 6.13443144e-03, 2.20340984e-03, 3.82163852e+02,\n",
      "        1.95079104e+04, 2.33494982e+04, 4.64480664e+03]]), array([37223.55859375, 37223.55859375, 37223.55859375, 37223.55859375,\n",
      "       37223.55859375, 37223.55859375, 37223.55859375, 37223.55859375]))\n",
      "           fun: 37223.55859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 436\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.64983119e-01, 6.13443147e-03, 2.20340983e-03, 3.82163898e+02,\n",
      "       1.95079105e+04, 2.33494982e+04, 4.64480663e+03])\n",
      "minPrevious 37319.046875\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.64983119e-01, 6.13443147e-03, 2.20340983e-03, 3.82163898e+02,\n",
      "        1.95079105e+04, 2.33494982e+04, 4.64480663e+03],\n",
      "       [9.64983119e-01, 6.13443150e-03, 2.20340974e-03, 3.82163870e+02,\n",
      "        1.95079105e+04, 2.33494982e+04, 4.64480663e+03],\n",
      "       [9.64983120e-01, 6.13443147e-03, 2.20340952e-03, 3.82163882e+02,\n",
      "        1.95079105e+04, 2.33494982e+04, 4.64480663e+03],\n",
      "       [9.64983120e-01, 6.13443143e-03, 2.20341026e-03, 3.82163894e+02,\n",
      "        1.95079105e+04, 2.33494982e+04, 4.64480663e+03],\n",
      "       [9.64983120e-01, 6.13443145e-03, 2.20340987e-03, 3.82163892e+02,\n",
      "        1.95079105e+04, 2.33494982e+04, 4.64480662e+03],\n",
      "       [9.64983120e-01, 6.13443146e-03, 2.20340972e-03, 3.82163884e+02,\n",
      "        1.95079104e+04, 2.33494982e+04, 4.64480663e+03],\n",
      "       [9.64983120e-01, 6.13443147e-03, 2.20340978e-03, 3.82163858e+02,\n",
      "        1.95079104e+04, 2.33494982e+04, 4.64480664e+03],\n",
      "       [9.64983120e-01, 6.13443144e-03, 2.20340984e-03, 3.82163852e+02,\n",
      "        1.95079104e+04, 2.33494982e+04, 4.64480664e+03]]), array([37223.55859375, 37223.55859375, 37223.55859375, 37223.55859375,\n",
      "       37223.55859375, 37223.55859375, 37223.55859375, 37223.55859375]))\n",
      "           fun: 37223.55859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 436\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.64983119e-01, 6.13443147e-03, 2.20340983e-03, 3.82163898e+02,\n",
      "       1.95079105e+04, 2.33494982e+04, 4.64480663e+03])\n",
      "best ll: 57038.09375, bestParams: [tensor(0.3159), tensor(0.0632), tensor(0.2545), tensor(10156.5410), tensor(22925.9824), tensor(23098.1133), tensor(21403.0312)]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.69069670e-01, 2.52190947e-02, 8.68343729e-04, 9.18007733e+03,\n",
      "        1.74772714e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069671e-01, 2.52190946e-02, 8.68343987e-04, 9.18007734e+03,\n",
      "        1.74772714e+04, 1.82201120e+04, 2.06048543e+04],\n",
      "       [9.69069670e-01, 2.52190947e-02, 8.68343888e-04, 9.18007734e+03,\n",
      "        1.74772714e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069670e-01, 2.52190947e-02, 8.68343862e-04, 9.18007733e+03,\n",
      "        1.74772714e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069670e-01, 2.52190947e-02, 8.68343888e-04, 9.18007734e+03,\n",
      "        1.74772714e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069671e-01, 2.52190947e-02, 8.68343937e-04, 9.18007733e+03,\n",
      "        1.74772715e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069671e-01, 2.52190947e-02, 8.68343620e-04, 9.18007732e+03,\n",
      "        1.74772715e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069671e-01, 2.52190948e-02, 8.68343475e-04, 9.18007731e+03,\n",
      "        1.74772715e+04, 1.82201119e+04, 2.06048544e+04]]), array([36888.265625, 36888.265625, 36888.265625, 36888.265625,\n",
      "       36888.265625, 36888.265625, 36888.265625, 36888.265625]))\n",
      "           fun: 36888.265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1264\n",
      "           nit: 403\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.69069670e-01, 2.52190947e-02, 8.68343729e-04, 9.18007733e+03,\n",
      "       1.74772714e+04, 1.82201120e+04, 2.06048544e+04])\n",
      "minPrevious 37223.55859375\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.69069670e-01, 2.52190947e-02, 8.68343729e-04, 9.18007733e+03,\n",
      "        1.74772714e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069671e-01, 2.52190946e-02, 8.68343987e-04, 9.18007734e+03,\n",
      "        1.74772714e+04, 1.82201120e+04, 2.06048543e+04],\n",
      "       [9.69069670e-01, 2.52190947e-02, 8.68343888e-04, 9.18007734e+03,\n",
      "        1.74772714e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069670e-01, 2.52190947e-02, 8.68343862e-04, 9.18007733e+03,\n",
      "        1.74772714e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069670e-01, 2.52190947e-02, 8.68343888e-04, 9.18007734e+03,\n",
      "        1.74772714e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069671e-01, 2.52190947e-02, 8.68343937e-04, 9.18007733e+03,\n",
      "        1.74772715e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069671e-01, 2.52190947e-02, 8.68343620e-04, 9.18007732e+03,\n",
      "        1.74772715e+04, 1.82201120e+04, 2.06048544e+04],\n",
      "       [9.69069671e-01, 2.52190948e-02, 8.68343475e-04, 9.18007731e+03,\n",
      "        1.74772715e+04, 1.82201119e+04, 2.06048544e+04]]), array([36888.265625, 36888.265625, 36888.265625, 36888.265625,\n",
      "       36888.265625, 36888.265625, 36888.265625, 36888.265625]))\n",
      "           fun: 36888.265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1264\n",
      "           nit: 403\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.69069670e-01, 2.52190947e-02, 8.68343729e-04, 9.18007733e+03,\n",
      "       1.74772714e+04, 1.82201120e+04, 2.06048544e+04])\n",
      "best ll: 55557.9375, bestParams: [tensor(0.3556), tensor(0.1617), tensor(0.0512), tensor(19707.1230), tensor(16244.6094), tensor(23016.9375), tensor(6689.3604)]\n",
      "epoch 10\n",
      " final_simplex: (array([[8.72861878e-01, 8.86971817e-02, 3.53955295e-02, 2.24633777e+04,\n",
      "        1.26414221e+04, 1.22749430e+04, 5.45396845e+03],\n",
      "       [8.72861878e-01, 8.86971816e-02, 3.53955294e-02, 2.24633777e+04,\n",
      "        1.26414221e+04, 1.22749430e+04, 5.45396846e+03],\n",
      "       [8.72861878e-01, 8.86971814e-02, 3.53955296e-02, 2.24633777e+04,\n",
      "        1.26414221e+04, 1.22749430e+04, 5.45396845e+03],\n",
      "       [8.72861879e-01, 8.86971814e-02, 3.53955294e-02, 2.24633777e+04,\n",
      "        1.26414221e+04, 1.22749430e+04, 5.45396846e+03],\n",
      "       [8.72861879e-01, 8.86971813e-02, 3.53955294e-02, 2.24633777e+04,\n",
      "        1.26414221e+04, 1.22749430e+04, 5.45396846e+03],\n",
      "       [8.72861879e-01, 8.86971806e-02, 3.53955295e-02, 2.24633776e+04,\n",
      "        1.26414221e+04, 1.22749430e+04, 5.45396847e+03],\n",
      "       [8.72861878e-01, 8.86971815e-02, 3.53955295e-02, 2.24633777e+04,\n",
      "        1.26414221e+04, 1.22749430e+04, 5.45396846e+03],\n",
      "       [8.72861879e-01, 8.86971811e-02, 3.53955295e-02, 2.24633777e+04,\n",
      "        1.26414221e+04, 1.22749430e+04, 5.45396846e+03]]), array([39222.89453125, 39222.89453125, 39222.89453125, 39222.89453125,\n",
      "       39222.89453125, 39222.89453125, 39222.89453125, 39222.89453125]))\n",
      "           fun: 39222.89453125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1260\n",
      "           nit: 444\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.72861878e-01, 8.86971817e-02, 3.53955295e-02, 2.24633777e+04,\n",
      "       1.26414221e+04, 1.22749430e+04, 5.45396845e+03])\n",
      "minPrevious 36888.265625\n",
      "best ll: 56172.08203125, bestParams: [tensor(0.3279), tensor(0.1391), tensor(0.1226), tensor(10000.3555), tensor(22508.5000), tensor(20295.5508), tensor(10056.5684)]\n",
      "epoch 11\n",
      " final_simplex: (array([[8.68177721e-01, 2.91396537e-02, 1.01309476e-01, 7.59094487e+03,\n",
      "        1.91014560e+04, 1.83268045e+04, 8.17777530e+03],\n",
      "       [8.68177719e-01, 2.91396569e-02, 1.01309473e-01, 7.59094495e+03,\n",
      "        1.91014560e+04, 1.83268045e+04, 8.17777523e+03],\n",
      "       [8.68177721e-01, 2.91396552e-02, 1.01309473e-01, 7.59094495e+03,\n",
      "        1.91014560e+04, 1.83268045e+04, 8.17777529e+03],\n",
      "       [8.68177722e-01, 2.91396551e-02, 1.01309472e-01, 7.59094497e+03,\n",
      "        1.91014559e+04, 1.83268045e+04, 8.17777533e+03],\n",
      "       [8.68177722e-01, 2.91396547e-02, 1.01309475e-01, 7.59094490e+03,\n",
      "        1.91014559e+04, 1.83268046e+04, 8.17777527e+03],\n",
      "       [8.68177723e-01, 2.91396540e-02, 1.01309473e-01, 7.59094494e+03,\n",
      "        1.91014560e+04, 1.83268045e+04, 8.17777528e+03],\n",
      "       [8.68177720e-01, 2.91396555e-02, 1.01309474e-01, 7.59094491e+03,\n",
      "        1.91014560e+04, 1.83268045e+04, 8.17777523e+03],\n",
      "       [8.68177719e-01, 2.91396550e-02, 1.01309476e-01, 7.59094489e+03,\n",
      "        1.91014559e+04, 1.83268045e+04, 8.17777529e+03]]), array([38945.81640625, 38945.81640625, 38945.81640625, 38945.81640625,\n",
      "       38945.81640625, 38945.81640625, 38945.81640625, 38945.81640625]))\n",
      "           fun: 38945.81640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1151\n",
      "           nit: 378\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.68177721e-01, 2.91396537e-02, 1.01309476e-01, 7.59094487e+03,\n",
      "       1.91014560e+04, 1.83268045e+04, 8.17777530e+03])\n",
      "minPrevious 36888.265625\n",
      "best ll: 51973.7734375, bestParams: [tensor(0.4423), tensor(0.0438), tensor(0.0279), tensor(11141.9873), tensor(8935.4951), tensor(13978.2061), tensor(10832.5801)]\n",
      "epoch 12\n",
      " final_simplex: (array([[9.37001100e-01, 3.80547362e-02, 2.44795784e-02, 1.09541247e+04,\n",
      "        8.51122291e+03, 8.48871160e+03, 8.38362177e+03],\n",
      "       [9.37001100e-01, 3.80547362e-02, 2.44795786e-02, 1.09541246e+04,\n",
      "        8.51122289e+03, 8.48871159e+03, 8.38362182e+03],\n",
      "       [9.37001099e-01, 3.80547362e-02, 2.44795786e-02, 1.09541246e+04,\n",
      "        8.51122290e+03, 8.48871159e+03, 8.38362183e+03],\n",
      "       [9.37001099e-01, 3.80547362e-02, 2.44795784e-02, 1.09541247e+04,\n",
      "        8.51122285e+03, 8.48871166e+03, 8.38362183e+03],\n",
      "       [9.37001100e-01, 3.80547362e-02, 2.44795786e-02, 1.09541246e+04,\n",
      "        8.51122288e+03, 8.48871160e+03, 8.38362182e+03],\n",
      "       [9.37001100e-01, 3.80547362e-02, 2.44795786e-02, 1.09541246e+04,\n",
      "        8.51122288e+03, 8.48871161e+03, 8.38362181e+03],\n",
      "       [9.37001100e-01, 3.80547363e-02, 2.44795784e-02, 1.09541247e+04,\n",
      "        8.51122282e+03, 8.48871166e+03, 8.38362180e+03],\n",
      "       [9.37001100e-01, 3.80547363e-02, 2.44795785e-02, 1.09541247e+04,\n",
      "        8.51122283e+03, 8.48871166e+03, 8.38362180e+03]]), array([37863.60546875, 37863.60546875, 37863.60546875, 37863.60546875,\n",
      "       37863.60546875, 37863.60546875, 37863.60546875, 37863.60546875]))\n",
      "           fun: 37863.60546875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1190\n",
      "           nit: 399\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.37001100e-01, 3.80547362e-02, 2.44795784e-02, 1.09541247e+04,\n",
      "       8.51122291e+03, 8.48871160e+03, 8.38362177e+03])\n",
      "minPrevious 36888.265625\n",
      "best ll: 55266.875, bestParams: [tensor(0.3429), tensor(0.0194), tensor(0.2053), tensor(17009.5254), tensor(20818.7207), tensor(17724.6582), tensor(10673.4014)]\n",
      "epoch 13\n",
      " final_simplex: (array([[9.74756889e-01, 1.55007504e-02, 2.75476179e-03, 6.72558411e+03,\n",
      "        1.25852306e+04, 1.12168393e+04, 1.06617604e+04],\n",
      "       [9.74756891e-01, 1.55007505e-02, 2.75476191e-03, 6.72558401e+03,\n",
      "        1.25852306e+04, 1.12168393e+04, 1.06617604e+04],\n",
      "       [9.74756889e-01, 1.55007504e-02, 2.75476235e-03, 6.72558407e+03,\n",
      "        1.25852306e+04, 1.12168393e+04, 1.06617604e+04],\n",
      "       [9.74756891e-01, 1.55007504e-02, 2.75476149e-03, 6.72558407e+03,\n",
      "        1.25852306e+04, 1.12168393e+04, 1.06617604e+04],\n",
      "       [9.74756889e-01, 1.55007505e-02, 2.75476219e-03, 6.72558406e+03,\n",
      "        1.25852306e+04, 1.12168393e+04, 1.06617604e+04],\n",
      "       [9.74756890e-01, 1.55007504e-02, 2.75476194e-03, 6.72558409e+03,\n",
      "        1.25852306e+04, 1.12168393e+04, 1.06617604e+04],\n",
      "       [9.74756890e-01, 1.55007504e-02, 2.75476193e-03, 6.72558407e+03,\n",
      "        1.25852306e+04, 1.12168392e+04, 1.06617604e+04],\n",
      "       [9.74756890e-01, 1.55007504e-02, 2.75476203e-03, 6.72558407e+03,\n",
      "        1.25852306e+04, 1.12168393e+04, 1.06617604e+04]]), array([37044.00390625, 37044.00390625, 37044.00390625, 37044.00390625,\n",
      "       37044.00390625, 37044.00390625, 37044.00390625, 37044.00390625]))\n",
      "           fun: 37044.00390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 426\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.74756889e-01, 1.55007504e-02, 2.75476179e-03, 6.72558411e+03,\n",
      "       1.25852306e+04, 1.12168393e+04, 1.06617604e+04])\n",
      "minPrevious 36888.265625\n",
      "best ll: 55911.9296875, bestParams: [tensor(0.3434), tensor(0.0862), tensor(0.1276), tensor(17966.9219), tensor(9699.4248), tensor(13709.8115), tensor(20750.8242)]\n",
      "epoch 14\n",
      " final_simplex: (array([[8.64967616e-01, 6.17311588e-02, 7.14472007e-02, 7.79419620e+03,\n",
      "        1.13957852e+04, 1.16248338e+04, 1.80539062e+04],\n",
      "       [8.64967616e-01, 6.17311589e-02, 7.14472006e-02, 7.79419625e+03,\n",
      "        1.13957851e+04, 1.16248339e+04, 1.80539062e+04],\n",
      "       [8.64967616e-01, 6.17311589e-02, 7.14472005e-02, 7.79419621e+03,\n",
      "        1.13957851e+04, 1.16248339e+04, 1.80539062e+04],\n",
      "       [8.64967616e-01, 6.17311587e-02, 7.14472007e-02, 7.79419623e+03,\n",
      "        1.13957851e+04, 1.16248338e+04, 1.80539062e+04],\n",
      "       [8.64967616e-01, 6.17311586e-02, 7.14472007e-02, 7.79419629e+03,\n",
      "        1.13957852e+04, 1.16248338e+04, 1.80539061e+04],\n",
      "       [8.64967616e-01, 6.17311586e-02, 7.14472008e-02, 7.79419625e+03,\n",
      "        1.13957852e+04, 1.16248338e+04, 1.80539062e+04],\n",
      "       [8.64967616e-01, 6.17311588e-02, 7.14472007e-02, 7.79419624e+03,\n",
      "        1.13957851e+04, 1.16248339e+04, 1.80539062e+04],\n",
      "       [8.64967616e-01, 6.17311588e-02, 7.14472006e-02, 7.79419620e+03,\n",
      "        1.13957851e+04, 1.16248339e+04, 1.80539062e+04]]), array([39415.1015625, 39415.1015625, 39415.1015625, 39415.1015625,\n",
      "       39415.1015625, 39415.1015625, 39415.1015625, 39415.1015625]))\n",
      "           fun: 39415.1015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1302\n",
      "           nit: 419\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.64967616e-01, 6.17311588e-02, 7.14472007e-02, 7.79419620e+03,\n",
      "       1.13957852e+04, 1.16248338e+04, 1.80539062e+04])\n",
      "minPrevious 36888.265625\n",
      "best ll: 57807.50390625, bestParams: [tensor(0.2947), tensor(0.1367), tensor(0.1329), tensor(15635.4434), tensor(19820.8125), tensor(22649.2676), tensor(10701.9209)]\n",
      "epoch 15\n",
      " final_simplex: (array([[7.88926176e-01, 7.43536267e-02, 1.23281115e-01, 7.56029376e+03,\n",
      "        2.85969835e+04, 1.89118910e+04, 5.29369876e+03],\n",
      "       [7.88926176e-01, 7.43536266e-02, 1.23281116e-01, 7.56029375e+03,\n",
      "        2.85969835e+04, 1.89118910e+04, 5.29369878e+03],\n",
      "       [7.88926176e-01, 7.43536271e-02, 1.23281115e-01, 7.56029371e+03,\n",
      "        2.85969835e+04, 1.89118910e+04, 5.29369880e+03],\n",
      "       [7.88926175e-01, 7.43536267e-02, 1.23281116e-01, 7.56029377e+03,\n",
      "        2.85969835e+04, 1.89118910e+04, 5.29369879e+03],\n",
      "       [7.88926175e-01, 7.43536271e-02, 1.23281115e-01, 7.56029374e+03,\n",
      "        2.85969835e+04, 1.89118910e+04, 5.29369876e+03],\n",
      "       [7.88926176e-01, 7.43536262e-02, 1.23281115e-01, 7.56029377e+03,\n",
      "        2.85969835e+04, 1.89118910e+04, 5.29369880e+03],\n",
      "       [7.88926177e-01, 7.43536268e-02, 1.23281116e-01, 7.56029367e+03,\n",
      "        2.85969835e+04, 1.89118910e+04, 5.29369878e+03],\n",
      "       [7.88926177e-01, 7.43536263e-02, 1.23281115e-01, 7.56029376e+03,\n",
      "        2.85969835e+04, 1.89118910e+04, 5.29369879e+03]]), array([42429.20703125, 42429.20703125, 42429.20703125, 42429.20703125,\n",
      "       42429.20703125, 42429.20703125, 42429.20703125, 42429.20703125]))\n",
      "           fun: 42429.20703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1226\n",
      "           nit: 387\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.88926176e-01, 7.43536267e-02, 1.23281115e-01, 7.56029376e+03,\n",
      "       2.85969835e+04, 1.89118910e+04, 5.29369876e+03])\n",
      "minPrevious 36888.265625\n",
      "best ll: 60015.2109375, bestParams: [tensor(0.2252), tensor(0.0661), tensor(0.0248), tensor(9403.2217), tensor(19854.8340), tensor(21054.3125), tensor(16054.2148)]\n",
      "epoch 16\n",
      " final_simplex: (array([[9.83974001e-01, 3.73735319e-03, 9.28564582e-03, 7.39684463e+03,\n",
      "        8.20164735e+03, 8.38091281e+03, 7.31257914e+03],\n",
      "       [9.83974001e-01, 3.73735342e-03, 9.28564579e-03, 7.39684464e+03,\n",
      "        8.20164738e+03, 8.38091280e+03, 7.31257914e+03],\n",
      "       [9.83974000e-01, 3.73735317e-03, 9.28564586e-03, 7.39684463e+03,\n",
      "        8.20164737e+03, 8.38091289e+03, 7.31257915e+03],\n",
      "       [9.83974000e-01, 3.73735315e-03, 9.28564589e-03, 7.39684461e+03,\n",
      "        8.20164739e+03, 8.38091288e+03, 7.31257915e+03],\n",
      "       [9.83974001e-01, 3.73735328e-03, 9.28564580e-03, 7.39684466e+03,\n",
      "        8.20164729e+03, 8.38091284e+03, 7.31257914e+03],\n",
      "       [9.83974001e-01, 3.73735333e-03, 9.28564580e-03, 7.39684464e+03,\n",
      "        8.20164732e+03, 8.38091278e+03, 7.31257917e+03],\n",
      "       [9.83974000e-01, 3.73735318e-03, 9.28564582e-03, 7.39684466e+03,\n",
      "        8.20164730e+03, 8.38091290e+03, 7.31257913e+03],\n",
      "       [9.83974001e-01, 3.73735352e-03, 9.28564576e-03, 7.39684466e+03,\n",
      "        8.20164741e+03, 8.38091279e+03, 7.31257912e+03]]), array([36826.53125, 36826.53125, 36826.53125, 36826.53125, 36826.53125,\n",
      "       36826.53125, 36826.53125, 36826.53125]))\n",
      "           fun: 36826.53125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1281\n",
      "           nit: 475\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.83974001e-01, 3.73735319e-03, 9.28564582e-03, 7.39684463e+03,\n",
      "       8.20164735e+03, 8.38091281e+03, 7.31257914e+03])\n",
      "minPrevious 36888.265625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.83974001e-01, 3.73735319e-03, 9.28564582e-03, 7.39684463e+03,\n",
      "        8.20164735e+03, 8.38091281e+03, 7.31257914e+03],\n",
      "       [9.83974001e-01, 3.73735342e-03, 9.28564579e-03, 7.39684464e+03,\n",
      "        8.20164738e+03, 8.38091280e+03, 7.31257914e+03],\n",
      "       [9.83974000e-01, 3.73735317e-03, 9.28564586e-03, 7.39684463e+03,\n",
      "        8.20164737e+03, 8.38091289e+03, 7.31257915e+03],\n",
      "       [9.83974000e-01, 3.73735315e-03, 9.28564589e-03, 7.39684461e+03,\n",
      "        8.20164739e+03, 8.38091288e+03, 7.31257915e+03],\n",
      "       [9.83974001e-01, 3.73735328e-03, 9.28564580e-03, 7.39684466e+03,\n",
      "        8.20164729e+03, 8.38091284e+03, 7.31257914e+03],\n",
      "       [9.83974001e-01, 3.73735333e-03, 9.28564580e-03, 7.39684464e+03,\n",
      "        8.20164732e+03, 8.38091278e+03, 7.31257917e+03],\n",
      "       [9.83974000e-01, 3.73735318e-03, 9.28564582e-03, 7.39684466e+03,\n",
      "        8.20164730e+03, 8.38091290e+03, 7.31257913e+03],\n",
      "       [9.83974001e-01, 3.73735352e-03, 9.28564576e-03, 7.39684466e+03,\n",
      "        8.20164741e+03, 8.38091279e+03, 7.31257912e+03]]), array([36826.53125, 36826.53125, 36826.53125, 36826.53125, 36826.53125,\n",
      "       36826.53125, 36826.53125, 36826.53125]))\n",
      "           fun: 36826.53125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1281\n",
      "           nit: 475\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.83974001e-01, 3.73735319e-03, 9.28564582e-03, 7.39684463e+03,\n",
      "       8.20164735e+03, 8.38091281e+03, 7.31257914e+03])\n",
      "best ll: 55818.59375, bestParams: [tensor(0.3381), tensor(0.0013), tensor(0.2023), tensor(9469.2744), tensor(24539.8574), tensor(17747.6250), tensor(20270.8066)]\n",
      "epoch 17\n",
      " final_simplex: (array([[8.36683249e-01, 1.20271902e-03, 1.58608079e-01, 9.92867280e+03,\n",
      "        1.42978319e+04, 1.57704497e+04, 1.78529232e+04],\n",
      "       [8.36683249e-01, 1.20271902e-03, 1.58608078e-01, 9.92867276e+03,\n",
      "        1.42978319e+04, 1.57704497e+04, 1.78529232e+04],\n",
      "       [8.36683249e-01, 1.20271903e-03, 1.58608079e-01, 9.92867277e+03,\n",
      "        1.42978319e+04, 1.57704497e+04, 1.78529231e+04],\n",
      "       [8.36683248e-01, 1.20271902e-03, 1.58608079e-01, 9.92867276e+03,\n",
      "        1.42978320e+04, 1.57704497e+04, 1.78529232e+04],\n",
      "       [8.36683249e-01, 1.20271902e-03, 1.58608079e-01, 9.92867276e+03,\n",
      "        1.42978320e+04, 1.57704497e+04, 1.78529232e+04],\n",
      "       [8.36683249e-01, 1.20271902e-03, 1.58608079e-01, 9.92867277e+03,\n",
      "        1.42978320e+04, 1.57704497e+04, 1.78529232e+04],\n",
      "       [8.36683249e-01, 1.20271902e-03, 1.58608079e-01, 9.92867275e+03,\n",
      "        1.42978320e+04, 1.57704496e+04, 1.78529232e+04],\n",
      "       [8.36683248e-01, 1.20271902e-03, 1.58608079e-01, 9.92867275e+03,\n",
      "        1.42978320e+04, 1.57704496e+04, 1.78529232e+04]]), array([39826.12109375, 39826.12109375, 39826.12109375, 39826.12109375,\n",
      "       39826.12109375, 39826.12109375, 39826.12109375, 39826.12109375]))\n",
      "           fun: 39826.12109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1233\n",
      "           nit: 435\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.36683249e-01, 1.20271902e-03, 1.58608079e-01, 9.92867280e+03,\n",
      "       1.42978319e+04, 1.57704497e+04, 1.78529232e+04])\n",
      "minPrevious 36826.53125\n",
      "best ll: 57716.09765625, bestParams: [tensor(0.3102), tensor(0.3010), tensor(0.0481), tensor(11030.6045), tensor(17602.4941), tensor(22005.6152), tensor(9681.6885)]\n",
      "epoch 18\n",
      " final_simplex: (array([[9.50663870e-01, 3.10727253e-03, 3.91974223e-02, 1.36108383e+04,\n",
      "        1.13886301e+04, 1.22037363e+04, 4.53520761e+03],\n",
      "       [9.50663869e-01, 3.10727433e-03, 3.91974223e-02, 1.36108382e+04,\n",
      "        1.13886301e+04, 1.22037363e+04, 4.53520766e+03],\n",
      "       [9.50663870e-01, 3.10727266e-03, 3.91974222e-02, 1.36108383e+04,\n",
      "        1.13886301e+04, 1.22037363e+04, 4.53520761e+03],\n",
      "       [9.50663869e-01, 3.10727357e-03, 3.91974224e-02, 1.36108382e+04,\n",
      "        1.13886301e+04, 1.22037364e+04, 4.53520767e+03],\n",
      "       [9.50663870e-01, 3.10727211e-03, 3.91974222e-02, 1.36108383e+04,\n",
      "        1.13886301e+04, 1.22037364e+04, 4.53520759e+03],\n",
      "       [9.50663870e-01, 3.10727333e-03, 3.91974222e-02, 1.36108382e+04,\n",
      "        1.13886301e+04, 1.22037364e+04, 4.53520764e+03],\n",
      "       [9.50663869e-01, 3.10727462e-03, 3.91974224e-02, 1.36108382e+04,\n",
      "        1.13886301e+04, 1.22037363e+04, 4.53520771e+03],\n",
      "       [9.50663870e-01, 3.10727268e-03, 3.91974222e-02, 1.36108383e+04,\n",
      "        1.13886301e+04, 1.22037364e+04, 4.53520763e+03]]), array([37587.51171875, 37587.51171875, 37587.51171875, 37587.51171875,\n",
      "       37587.51171875, 37587.51171875, 37587.51171875, 37587.51171875]))\n",
      "           fun: 37587.51171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1301\n",
      "           nit: 450\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.50663870e-01, 3.10727253e-03, 3.91974223e-02, 1.36108383e+04,\n",
      "       1.13886301e+04, 1.22037363e+04, 4.53520761e+03])\n",
      "minPrevious 36826.53125\n",
      "best ll: 57473.51171875, bestParams: [tensor(0.3278), tensor(0.0848), tensor(0.0144), tensor(5457.6030), tensor(24148.5703), tensor(13359.1836), tensor(19708.0996)]\n",
      "epoch 19\n",
      " final_simplex: (array([[9.31085625e-01, 4.90013565e-02, 1.52297027e-02, 4.52963306e+03,\n",
      "        1.61686118e+04, 1.74715541e+04, 7.69901475e+03],\n",
      "       [9.31085625e-01, 4.90013564e-02, 1.52297026e-02, 4.52963306e+03,\n",
      "        1.61686118e+04, 1.74715542e+04, 7.69901474e+03],\n",
      "       [9.31085624e-01, 4.90013566e-02, 1.52297026e-02, 4.52963305e+03,\n",
      "        1.61686118e+04, 1.74715542e+04, 7.69901476e+03],\n",
      "       [9.31085625e-01, 4.90013567e-02, 1.52297027e-02, 4.52963305e+03,\n",
      "        1.61686117e+04, 1.74715542e+04, 7.69901476e+03],\n",
      "       [9.31085625e-01, 4.90013567e-02, 1.52297027e-02, 4.52963305e+03,\n",
      "        1.61686117e+04, 1.74715541e+04, 7.69901478e+03],\n",
      "       [9.31085626e-01, 4.90013566e-02, 1.52297027e-02, 4.52963305e+03,\n",
      "        1.61686118e+04, 1.74715542e+04, 7.69901477e+03],\n",
      "       [9.31085625e-01, 4.90013565e-02, 1.52297026e-02, 4.52963305e+03,\n",
      "        1.61686117e+04, 1.74715542e+04, 7.69901476e+03],\n",
      "       [9.31085625e-01, 4.90013567e-02, 1.52297027e-02, 4.52963305e+03,\n",
      "        1.61686117e+04, 1.74715541e+04, 7.69901478e+03]]), array([37732.01953125, 37732.01953125, 37732.01953125, 37732.01953125,\n",
      "       37732.01953125, 37732.01953125, 37732.01953125, 37732.01953125]))\n",
      "           fun: 37732.01953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1250\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.31085625e-01, 4.90013565e-02, 1.52297027e-02, 4.52963306e+03,\n",
      "       1.61686118e+04, 1.74715541e+04, 7.69901475e+03])\n",
      "minPrevious 36826.53125\n",
      "inferredPis tensor([0.9840, 0.0037, 0.0093], dtype=torch.float64)\n",
      "inferredAlphas tensor([7396.8446, 8201.6473, 8380.9128, 7312.5791], dtype=torch.float64)\n",
      "truth0 tensor(0.7519) truth1 tensor(0.1111) truth2 tensor(0.1121) truthBoth tensor(0.0250)\n",
      "params on run 3 {'lls': [58132.7578125, 61020.8984375, 62816.03125, 61310.28125, 59964.953125, 47473.921875, 47433.734375, 47816.32421875, 47210.3984375, 51822.578125, 51970.546875, 47609.4609375, 52364.7734375, 53773.0390625, 47233.921875, 36342.86328125, 36234.44921875, 36770.3828125, 36826.53125], 'inferredAlphas': [tensor([17771.7538,   267.5774,   285.4237, 19323.4289], dtype=torch.float64), tensor([17391.5067,   389.1159,   504.1465, 38945.6315], dtype=torch.float64), tensor([26599.6834,   330.5187,   522.2450, 20474.0527], dtype=torch.float64), tensor([17159.0905,   229.1438,   192.1196, 23702.7612], dtype=torch.float64), tensor([14365.2776,   353.8587,   277.5095, 36615.7416], dtype=torch.float64), tensor([4681.1768, 1514.9906,  279.5278, 6430.2365], dtype=torch.float64), tensor([11636.0228,  1941.4431,   317.7839,  2432.4090], dtype=torch.float64), tensor([3466.6976,  105.4401,  574.8790,  884.2902], dtype=torch.float64), tensor([  190.1304,   255.3843,  1367.9433, 10051.6183], dtype=torch.float64), tensor([13347.1036,  2995.2070,   679.1869,  9964.7306], dtype=torch.float64), tensor([3050.1159,  274.5893, 1270.7564, 7251.8219], dtype=torch.float64), tensor([1902.8937,  238.1495, 1249.7712, 7914.4684], dtype=torch.float64), tensor([20414.2533,  1255.3286,  5495.8171, 24486.6440], dtype=torch.float64), tensor([ 5422.4410,  1070.5042,  5035.1884, 34394.7350], dtype=torch.float64), tensor([6116.3640, 1549.1665,  277.2773, 5735.0947], dtype=torch.float64), tensor([ 3252.4160, 17197.7572, 17440.7641, 20021.9416], dtype=torch.float64), tensor([7562.1733, 8368.3120, 8779.7352, 8746.4345], dtype=torch.float64), tensor([24233.9895, 13108.5658, 12119.1812, 10209.1235], dtype=torch.float64), tensor([7396.8446, 8201.6473, 8380.9128, 7312.5791], dtype=torch.float64)], 'inferredPis': [tensor([0.2745, 0.5123, 0.0037], dtype=torch.float64), tensor([0.2424, 0.2423, 0.0335], dtype=torch.float64), tensor([0.2477, 0.1574, 0.0414], dtype=torch.float64), tensor([0.2670, 0.3576, 0.1152], dtype=torch.float64), tensor([0.4350, 0.2494, 0.0647], dtype=torch.float64), tensor([0.1319, 0.8504, 0.0173], dtype=torch.float64), tensor([0.1121, 0.8709, 0.0016], dtype=torch.float64), tensor([0.7272, 0.2531, 0.0189], dtype=torch.float64), tensor([0.8014, 0.1978, 0.0008], dtype=torch.float64), tensor([0.1527, 0.5340, 0.0406], dtype=torch.float64), tensor([4.4252e-01, 2.4141e-01, 6.9015e-05], dtype=torch.float64), tensor([0.7311, 0.2567, 0.0100], dtype=torch.float64), tensor([0.4108, 0.3023, 0.0150], dtype=torch.float64), tensor([0.4187, 0.1117, 0.0518], dtype=torch.float64), tensor([0.2033, 0.7863, 0.0045], dtype=torch.float64), tensor([0.9651, 0.0301, 0.0021], dtype=torch.float64), tensor([0.9906, 0.0041, 0.0032], dtype=torch.float64), tensor([9.9493e-01, 2.2532e-03, 5.0930e-04], dtype=torch.float64), tensor([0.9840, 0.0037, 0.0093], dtype=torch.float64)], 'inferredPDVs': [tensor([0.4720, 0.0071, 0.0076, 0.5133], dtype=torch.float64), tensor([0.3039, 0.0068, 0.0088, 0.6805], dtype=torch.float64), tensor([0.5550, 0.0069, 0.0109, 0.4272], dtype=torch.float64), tensor([0.4156, 0.0056, 0.0047, 0.5742], dtype=torch.float64), tensor([0.2783, 0.0069, 0.0054, 0.7095], dtype=torch.float64), tensor([0.3627, 0.1174, 0.0217, 0.4982], dtype=torch.float64), tensor([0.7126, 0.1189, 0.0195, 0.1490], dtype=torch.float64), tensor([0.6890, 0.0210, 0.1143, 0.1758], dtype=torch.float64), tensor([0.0160, 0.0215, 0.1153, 0.8471], dtype=torch.float64), tensor([0.4945, 0.1110, 0.0252, 0.3693], dtype=torch.float64), tensor([0.2575, 0.0232, 0.1073, 0.6120], dtype=torch.float64), tensor([0.1683, 0.0210, 0.1106, 0.7001], dtype=torch.float64), tensor([0.3952, 0.0243, 0.1064, 0.4741], dtype=torch.float64), tensor([0.1181, 0.0233, 0.1096, 0.7490], dtype=torch.float64), tensor([0.4472, 0.1133, 0.0203, 0.4192], dtype=torch.float64), tensor([0.0562, 0.2969, 0.3011, 0.3458], dtype=torch.float64), tensor([0.2260, 0.2501, 0.2624, 0.2614], dtype=torch.float64), tensor([0.4061, 0.2197, 0.2031, 0.1711], dtype=torch.float64), tensor([0.2364, 0.2621, 0.2678, 0.2337], dtype=torch.float64)], 'trueMeanPDVs': [tensor([0.7547, 0.1096, 0.1105, 0.0252]), tensor([0.7520, 0.1114, 0.1113, 0.0253]), tensor([0.7523, 0.1111, 0.1116, 0.0250]), tensor([0.7518, 0.1113, 0.1112, 0.0257]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7510, 0.1117, 0.1118, 0.0255]), tensor([0.7535, 0.1110, 0.1105, 0.0250]), tensor([0.7503, 0.1121, 0.1120, 0.0256]), tensor([0.7542, 0.1103, 0.1109, 0.0246]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250])], 'truePis': [tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500])]}\n",
      "tensor([[ 87.,   8.,   4.,   0.],\n",
      "        [ 84.,   7.,   2.,   0.],\n",
      "        [132.,  15.,   1.,   0.],\n",
      "        ...,\n",
      "        [ 73.,   1.,   0.,   0.],\n",
      "        [107.,   3.,   0.,   0.],\n",
      "        [120.,   0.,   1.,   0.]])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood4 at 0x7feb3ea4ca70>\n",
      "best ll: 55525.2421875, bestParams: [tensor(0.3472), tensor(0.1489), tensor(0.0305), tensor(17616.6465), tensor(8270.7188), tensor(5699.3169), tensor(9389.8975)]\n",
      "epoch 0\n",
      " final_simplex: (array([[9.69832238e-01, 1.88947289e-02, 1.08184452e-02, 1.15180316e+04,\n",
      "        9.03426683e+03, 8.35347903e+03, 1.24956462e+03],\n",
      "       [9.69832237e-01, 1.88947289e-02, 1.08184453e-02, 1.15180317e+04,\n",
      "        9.03426683e+03, 8.35347904e+03, 1.24956460e+03],\n",
      "       [9.69832237e-01, 1.88947290e-02, 1.08184454e-02, 1.15180317e+04,\n",
      "        9.03426683e+03, 8.35347904e+03, 1.24956460e+03],\n",
      "       [9.69832237e-01, 1.88947291e-02, 1.08184454e-02, 1.15180317e+04,\n",
      "        9.03426682e+03, 8.35347904e+03, 1.24956459e+03],\n",
      "       [9.69832237e-01, 1.88947290e-02, 1.08184454e-02, 1.15180317e+04,\n",
      "        9.03426682e+03, 8.35347904e+03, 1.24956459e+03],\n",
      "       [9.69832237e-01, 1.88947292e-02, 1.08184453e-02, 1.15180317e+04,\n",
      "        9.03426683e+03, 8.35347904e+03, 1.24956460e+03],\n",
      "       [9.69832237e-01, 1.88947292e-02, 1.08184454e-02, 1.15180317e+04,\n",
      "        9.03426682e+03, 8.35347903e+03, 1.24956461e+03],\n",
      "       [9.69832237e-01, 1.88947290e-02, 1.08184453e-02, 1.15180317e+04,\n",
      "        9.03426682e+03, 8.35347904e+03, 1.24956460e+03]]), array([37087.265625, 37087.265625, 37087.265625, 37087.265625,\n",
      "       37087.265625, 37087.265625, 37087.265625, 37087.265625]))\n",
      "           fun: 37087.265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1321\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.69832238e-01, 1.88947289e-02, 1.08184452e-02, 1.15180316e+04,\n",
      "       9.03426683e+03, 8.35347903e+03, 1.24956462e+03])\n",
      "best ll: 57578.73046875, bestParams: [tensor(0.2739), tensor(0.1012), tensor(0.0673), tensor(9177.6514), tensor(15094.5254), tensor(13532.1270), tensor(19653.5117)]\n",
      "epoch 1\n",
      " final_simplex: (array([[9.69064947e-01, 6.71827643e-03, 1.64588787e-02, 1.18237575e+04,\n",
      "        1.20683142e+04, 1.36518350e+04, 8.27550772e+03],\n",
      "       [9.69064945e-01, 6.71827662e-03, 1.64588787e-02, 1.18237575e+04,\n",
      "        1.20683142e+04, 1.36518350e+04, 8.27550782e+03],\n",
      "       [9.69064945e-01, 6.71827688e-03, 1.64588788e-02, 1.18237576e+04,\n",
      "        1.20683142e+04, 1.36518350e+04, 8.27550769e+03],\n",
      "       [9.69064947e-01, 6.71827655e-03, 1.64588788e-02, 1.18237576e+04,\n",
      "        1.20683142e+04, 1.36518350e+04, 8.27550767e+03],\n",
      "       [9.69064946e-01, 6.71827654e-03, 1.64588787e-02, 1.18237575e+04,\n",
      "        1.20683143e+04, 1.36518350e+04, 8.27550769e+03],\n",
      "       [9.69064946e-01, 6.71827653e-03, 1.64588786e-02, 1.18237575e+04,\n",
      "        1.20683143e+04, 1.36518350e+04, 8.27550776e+03],\n",
      "       [9.69064947e-01, 6.71827633e-03, 1.64588786e-02, 1.18237576e+04,\n",
      "        1.20683143e+04, 1.36518350e+04, 8.27550763e+03],\n",
      "       [9.69064946e-01, 6.71827664e-03, 1.64588788e-02, 1.18237575e+04,\n",
      "        1.20683142e+04, 1.36518350e+04, 8.27550771e+03]]), array([37116.50390625, 37116.50390625, 37116.50390625, 37116.50390625,\n",
      "       37116.50390625, 37116.50390625, 37116.50390625, 37116.50390625]))\n",
      "           fun: 37116.50390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1279\n",
      "           nit: 464\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.69064947e-01, 6.71827643e-03, 1.64588787e-02, 1.18237575e+04,\n",
      "       1.20683142e+04, 1.36518350e+04, 8.27550772e+03])\n",
      "minPrevious 37087.265625\n",
      "best ll: 58536.51171875, bestParams: [tensor(0.2524), tensor(0.0762), tensor(0.0516), tensor(14564.6924), tensor(12798.0693), tensor(15235.5117), tensor(10206.8652)]\n",
      "epoch 2\n",
      " final_simplex: (array([[9.66531705e-01, 1.37416218e-03, 2.99038226e-02, 1.33535941e+04,\n",
      "        1.01692543e+04, 9.95281549e+03, 6.96793452e+03],\n",
      "       [9.66531706e-01, 1.37416191e-03, 2.99038225e-02, 1.33535941e+04,\n",
      "        1.01692543e+04, 9.95281550e+03, 6.96793452e+03],\n",
      "       [9.66531704e-01, 1.37416232e-03, 2.99038226e-02, 1.33535940e+04,\n",
      "        1.01692543e+04, 9.95281556e+03, 6.96793453e+03],\n",
      "       [9.66531706e-01, 1.37416216e-03, 2.99038225e-02, 1.33535941e+04,\n",
      "        1.01692543e+04, 9.95281558e+03, 6.96793451e+03],\n",
      "       [9.66531705e-01, 1.37416214e-03, 2.99038225e-02, 1.33535941e+04,\n",
      "        1.01692543e+04, 9.95281552e+03, 6.96793452e+03],\n",
      "       [9.66531704e-01, 1.37416209e-03, 2.99038226e-02, 1.33535940e+04,\n",
      "        1.01692543e+04, 9.95281545e+03, 6.96793454e+03],\n",
      "       [9.66531705e-01, 1.37416217e-03, 2.99038227e-02, 1.33535941e+04,\n",
      "        1.01692542e+04, 9.95281557e+03, 6.96793450e+03],\n",
      "       [9.66531704e-01, 1.37416227e-03, 2.99038227e-02, 1.33535940e+04,\n",
      "        1.01692542e+04, 9.95281558e+03, 6.96793452e+03]]), array([37048.3203125, 37048.3203125, 37048.3203125, 37048.3203125,\n",
      "       37048.3203125, 37048.3203125, 37048.3203125, 37048.3203125]))\n",
      "           fun: 37048.3203125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 441\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.66531705e-01, 1.37416218e-03, 2.99038226e-02, 1.33535941e+04,\n",
      "       1.01692543e+04, 9.95281549e+03, 6.96793452e+03])\n",
      "minPrevious 37087.265625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.66531705e-01, 1.37416218e-03, 2.99038226e-02, 1.33535941e+04,\n",
      "        1.01692543e+04, 9.95281549e+03, 6.96793452e+03],\n",
      "       [9.66531706e-01, 1.37416191e-03, 2.99038225e-02, 1.33535941e+04,\n",
      "        1.01692543e+04, 9.95281550e+03, 6.96793452e+03],\n",
      "       [9.66531704e-01, 1.37416232e-03, 2.99038226e-02, 1.33535940e+04,\n",
      "        1.01692543e+04, 9.95281556e+03, 6.96793453e+03],\n",
      "       [9.66531706e-01, 1.37416216e-03, 2.99038225e-02, 1.33535941e+04,\n",
      "        1.01692543e+04, 9.95281558e+03, 6.96793451e+03],\n",
      "       [9.66531705e-01, 1.37416214e-03, 2.99038225e-02, 1.33535941e+04,\n",
      "        1.01692543e+04, 9.95281552e+03, 6.96793452e+03],\n",
      "       [9.66531704e-01, 1.37416209e-03, 2.99038226e-02, 1.33535940e+04,\n",
      "        1.01692543e+04, 9.95281545e+03, 6.96793454e+03],\n",
      "       [9.66531705e-01, 1.37416217e-03, 2.99038227e-02, 1.33535941e+04,\n",
      "        1.01692542e+04, 9.95281557e+03, 6.96793450e+03],\n",
      "       [9.66531704e-01, 1.37416227e-03, 2.99038227e-02, 1.33535940e+04,\n",
      "        1.01692542e+04, 9.95281558e+03, 6.96793452e+03]]), array([37048.3203125, 37048.3203125, 37048.3203125, 37048.3203125,\n",
      "       37048.3203125, 37048.3203125, 37048.3203125, 37048.3203125]))\n",
      "           fun: 37048.3203125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 441\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.66531705e-01, 1.37416218e-03, 2.99038226e-02, 1.33535941e+04,\n",
      "       1.01692543e+04, 9.95281549e+03, 6.96793452e+03])\n",
      "best ll: 55542.1640625, bestParams: [tensor(0.3254), tensor(0.0689), tensor(0.1335), tensor(15296.8711), tensor(13092.3623), tensor(11948.3281), tensor(18666.8418)]\n",
      "epoch 3\n",
      " final_simplex: (array([[8.57499019e-01, 4.50629239e-02, 9.57402103e-02, 1.76277355e+04,\n",
      "        8.07881258e+03, 8.79653619e+03, 1.38405819e+04],\n",
      "       [8.57499019e-01, 4.50629239e-02, 9.57402103e-02, 1.76277355e+04,\n",
      "        8.07881258e+03, 8.79653619e+03, 1.38405819e+04],\n",
      "       [8.57499019e-01, 4.50629239e-02, 9.57402103e-02, 1.76277355e+04,\n",
      "        8.07881258e+03, 8.79653619e+03, 1.38405819e+04],\n",
      "       [8.57499020e-01, 4.50629239e-02, 9.57402108e-02, 1.76277354e+04,\n",
      "        8.07881257e+03, 8.79653619e+03, 1.38405819e+04],\n",
      "       [8.57499020e-01, 4.50629239e-02, 9.57402108e-02, 1.76277354e+04,\n",
      "        8.07881257e+03, 8.79653618e+03, 1.38405819e+04],\n",
      "       [8.57499020e-01, 4.50629239e-02, 9.57402102e-02, 1.76277355e+04,\n",
      "        8.07881257e+03, 8.79653618e+03, 1.38405820e+04],\n",
      "       [8.57499019e-01, 4.50629238e-02, 9.57402103e-02, 1.76277355e+04,\n",
      "        8.07881258e+03, 8.79653618e+03, 1.38405819e+04],\n",
      "       [8.57499019e-01, 4.50629240e-02, 9.57402107e-02, 1.76277355e+04,\n",
      "        8.07881256e+03, 8.79653620e+03, 1.38405819e+04]]), array([39441.984375, 39441.984375, 39441.984375, 39441.984375,\n",
      "       39441.984375, 39441.984375, 39441.984375, 39441.984375]))\n",
      "           fun: 39441.984375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1246\n",
      "           nit: 389\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.57499019e-01, 4.50629239e-02, 9.57402103e-02, 1.76277355e+04,\n",
      "       8.07881258e+03, 8.79653619e+03, 1.38405819e+04])\n",
      "minPrevious 37048.3203125\n",
      "best ll: 56755.453125, bestParams: [tensor(0.3120), tensor(0.2401), tensor(0.0137), tensor(23149.6875), tensor(10570.1055), tensor(8662.9180), tensor(9037.8633)]\n",
      "epoch 4\n",
      " final_simplex: (array([[9.77556149e-01, 1.35400544e-03, 1.07105742e-02, 1.07665428e+04,\n",
      "        8.84485369e+03, 1.06806634e+04, 9.34019537e+03],\n",
      "       [9.77556151e-01, 1.35400409e-03, 1.07105742e-02, 1.07665428e+04,\n",
      "        8.84485368e+03, 1.06806634e+04, 9.34019535e+03],\n",
      "       [9.77556149e-01, 1.35400647e-03, 1.07105742e-02, 1.07665427e+04,\n",
      "        8.84485367e+03, 1.06806634e+04, 9.34019543e+03],\n",
      "       [9.77556150e-01, 1.35400613e-03, 1.07105742e-02, 1.07665428e+04,\n",
      "        8.84485363e+03, 1.06806634e+04, 9.34019542e+03],\n",
      "       [9.77556148e-01, 1.35400580e-03, 1.07105742e-02, 1.07665427e+04,\n",
      "        8.84485373e+03, 1.06806633e+04, 9.34019543e+03],\n",
      "       [9.77556148e-01, 1.35400521e-03, 1.07105742e-02, 1.07665428e+04,\n",
      "        8.84485373e+03, 1.06806634e+04, 9.34019540e+03],\n",
      "       [9.77556151e-01, 1.35400559e-03, 1.07105742e-02, 1.07665428e+04,\n",
      "        8.84485360e+03, 1.06806634e+04, 9.34019540e+03],\n",
      "       [9.77556147e-01, 1.35400577e-03, 1.07105742e-02, 1.07665428e+04,\n",
      "        8.84485374e+03, 1.06806633e+04, 9.34019543e+03]]), array([37118.3828125, 37118.3828125, 37118.3828125, 37118.3828125,\n",
      "       37118.3828125, 37118.3828125, 37118.3828125, 37118.3828125]))\n",
      "           fun: 37118.3828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1211\n",
      "           nit: 401\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.77556149e-01, 1.35400544e-03, 1.07105742e-02, 1.07665428e+04,\n",
      "       8.84485369e+03, 1.06806634e+04, 9.34019537e+03])\n",
      "minPrevious 37048.3203125\n",
      "best ll: 55302.265625, bestParams: [tensor(0.3180), tensor(0.0334), tensor(0.0082), tensor(14393.5693), tensor(7496.7793), tensor(9691.6943), tensor(22364.3730)]\n",
      "epoch 5\n",
      " final_simplex: (array([[9.77455413e-01, 1.27210147e-02, 6.35934692e-03, 1.08448358e+03,\n",
      "        1.08640022e+04, 9.79303512e+03, 1.34549088e+04],\n",
      "       [9.77455414e-01, 1.27210147e-02, 6.35934689e-03, 1.08448360e+03,\n",
      "        1.08640022e+04, 9.79303511e+03, 1.34549087e+04],\n",
      "       [9.77455414e-01, 1.27210147e-02, 6.35934690e-03, 1.08448358e+03,\n",
      "        1.08640022e+04, 9.79303512e+03, 1.34549087e+04],\n",
      "       [9.77455414e-01, 1.27210147e-02, 6.35934688e-03, 1.08448359e+03,\n",
      "        1.08640022e+04, 9.79303512e+03, 1.34549087e+04],\n",
      "       [9.77455414e-01, 1.27210147e-02, 6.35934690e-03, 1.08448362e+03,\n",
      "        1.08640021e+04, 9.79303512e+03, 1.34549087e+04],\n",
      "       [9.77455414e-01, 1.27210147e-02, 6.35934690e-03, 1.08448362e+03,\n",
      "        1.08640021e+04, 9.79303510e+03, 1.34549087e+04],\n",
      "       [9.77455413e-01, 1.27210147e-02, 6.35934690e-03, 1.08448358e+03,\n",
      "        1.08640022e+04, 9.79303513e+03, 1.34549087e+04],\n",
      "       [9.77455413e-01, 1.27210147e-02, 6.35934692e-03, 1.08448363e+03,\n",
      "        1.08640021e+04, 9.79303514e+03, 1.34549087e+04]]), array([36872.8359375, 36872.8359375, 36872.8359375, 36872.8359375,\n",
      "       36872.8359375, 36872.8359375, 36872.8359375, 36872.8359375]))\n",
      "           fun: 36872.8359375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1284\n",
      "           nit: 454\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.77455413e-01, 1.27210147e-02, 6.35934692e-03, 1.08448358e+03,\n",
      "       1.08640022e+04, 9.79303512e+03, 1.34549088e+04])\n",
      "minPrevious 37048.3203125\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.77455413e-01, 1.27210147e-02, 6.35934692e-03, 1.08448358e+03,\n",
      "        1.08640022e+04, 9.79303512e+03, 1.34549088e+04],\n",
      "       [9.77455414e-01, 1.27210147e-02, 6.35934689e-03, 1.08448360e+03,\n",
      "        1.08640022e+04, 9.79303511e+03, 1.34549087e+04],\n",
      "       [9.77455414e-01, 1.27210147e-02, 6.35934690e-03, 1.08448358e+03,\n",
      "        1.08640022e+04, 9.79303512e+03, 1.34549087e+04],\n",
      "       [9.77455414e-01, 1.27210147e-02, 6.35934688e-03, 1.08448359e+03,\n",
      "        1.08640022e+04, 9.79303512e+03, 1.34549087e+04],\n",
      "       [9.77455414e-01, 1.27210147e-02, 6.35934690e-03, 1.08448362e+03,\n",
      "        1.08640021e+04, 9.79303512e+03, 1.34549087e+04],\n",
      "       [9.77455414e-01, 1.27210147e-02, 6.35934690e-03, 1.08448362e+03,\n",
      "        1.08640021e+04, 9.79303510e+03, 1.34549087e+04],\n",
      "       [9.77455413e-01, 1.27210147e-02, 6.35934690e-03, 1.08448358e+03,\n",
      "        1.08640022e+04, 9.79303513e+03, 1.34549087e+04],\n",
      "       [9.77455413e-01, 1.27210147e-02, 6.35934692e-03, 1.08448363e+03,\n",
      "        1.08640021e+04, 9.79303514e+03, 1.34549087e+04]]), array([36872.8359375, 36872.8359375, 36872.8359375, 36872.8359375,\n",
      "       36872.8359375, 36872.8359375, 36872.8359375, 36872.8359375]))\n",
      "           fun: 36872.8359375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1284\n",
      "           nit: 454\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.77455413e-01, 1.27210147e-02, 6.35934692e-03, 1.08448358e+03,\n",
      "       1.08640022e+04, 9.79303512e+03, 1.34549088e+04])\n",
      "best ll: 59886.75, bestParams: [tensor(0.2503), tensor(0.2179), tensor(0.1026), tensor(20430.9453), tensor(19357.2695), tensor(21142.5586), tensor(19610.9590)]\n",
      "epoch 6\n",
      " final_simplex: (array([[8.63603477e-01, 1.86390846e-03, 1.32596757e-01, 1.31944748e+04,\n",
      "        1.08288822e+04, 1.12579812e+04, 1.21124852e+04],\n",
      "       [8.63603478e-01, 1.86390817e-03, 1.32596757e-01, 1.31944747e+04,\n",
      "        1.08288822e+04, 1.12579812e+04, 1.21124852e+04],\n",
      "       [8.63603478e-01, 1.86390850e-03, 1.32596757e-01, 1.31944747e+04,\n",
      "        1.08288822e+04, 1.12579812e+04, 1.21124852e+04],\n",
      "       [8.63603478e-01, 1.86390850e-03, 1.32596757e-01, 1.31944747e+04,\n",
      "        1.08288822e+04, 1.12579812e+04, 1.21124851e+04],\n",
      "       [8.63603478e-01, 1.86390811e-03, 1.32596757e-01, 1.31944748e+04,\n",
      "        1.08288822e+04, 1.12579813e+04, 1.21124852e+04],\n",
      "       [8.63603478e-01, 1.86390842e-03, 1.32596757e-01, 1.31944748e+04,\n",
      "        1.08288822e+04, 1.12579813e+04, 1.21124852e+04],\n",
      "       [8.63603478e-01, 1.86390809e-03, 1.32596757e-01, 1.31944748e+04,\n",
      "        1.08288822e+04, 1.12579813e+04, 1.21124852e+04],\n",
      "       [8.63603478e-01, 1.86390796e-03, 1.32596757e-01, 1.31944748e+04,\n",
      "        1.08288822e+04, 1.12579812e+04, 1.21124852e+04]]), array([39311.2265625, 39311.2265625, 39311.2265625, 39311.2265625,\n",
      "       39311.2265625, 39311.2265625, 39311.2265625, 39311.2265625]))\n",
      "           fun: 39311.2265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1267\n",
      "           nit: 451\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.63603477e-01, 1.86390846e-03, 1.32596757e-01, 1.31944748e+04,\n",
      "       1.08288822e+04, 1.12579812e+04, 1.21124852e+04])\n",
      "minPrevious 36872.8359375\n",
      "best ll: 53563.5703125, bestParams: [tensor(0.3978), tensor(0.0117), tensor(0.0155), tensor(10435.3857), tensor(23792.9355), tensor(14014.2588), tensor(13596.3916)]\n",
      "epoch 7\n",
      " final_simplex: (array([[9.76396812e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325939e+04, 8.88837336e+03],\n",
      "       [9.76396811e-01, 1.02869441e-02, 1.02235813e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325939e+04, 8.88837333e+03],\n",
      "       [9.76396810e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325938e+04, 8.88837340e+03],\n",
      "       [9.76396811e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325939e+04, 8.88837335e+03],\n",
      "       [9.76396810e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "        1.34300548e+04, 1.35325938e+04, 8.88837343e+03],\n",
      "       [9.76396811e-01, 1.02869441e-02, 1.02235813e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325938e+04, 8.88837335e+03],\n",
      "       [9.76396811e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325938e+04, 8.88837335e+03],\n",
      "       [9.76396812e-01, 1.02869441e-02, 1.02235813e-02, 1.15813164e+04,\n",
      "        1.34300546e+04, 1.35325938e+04, 8.88837338e+03]]), array([36796.37109375, 36796.37109375, 36796.37109375, 36796.37109375,\n",
      "       36796.37109375, 36796.37109375, 36796.37109375, 36796.37109375]))\n",
      "           fun: 36796.37109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.76396812e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "       1.34300547e+04, 1.35325939e+04, 8.88837336e+03])\n",
      "minPrevious 36872.8359375\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.76396812e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325939e+04, 8.88837336e+03],\n",
      "       [9.76396811e-01, 1.02869441e-02, 1.02235813e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325939e+04, 8.88837333e+03],\n",
      "       [9.76396810e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325938e+04, 8.88837340e+03],\n",
      "       [9.76396811e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325939e+04, 8.88837335e+03],\n",
      "       [9.76396810e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "        1.34300548e+04, 1.35325938e+04, 8.88837343e+03],\n",
      "       [9.76396811e-01, 1.02869441e-02, 1.02235813e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325938e+04, 8.88837335e+03],\n",
      "       [9.76396811e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "        1.34300547e+04, 1.35325938e+04, 8.88837335e+03],\n",
      "       [9.76396812e-01, 1.02869441e-02, 1.02235813e-02, 1.15813164e+04,\n",
      "        1.34300546e+04, 1.35325938e+04, 8.88837338e+03]]), array([36796.37109375, 36796.37109375, 36796.37109375, 36796.37109375,\n",
      "       36796.37109375, 36796.37109375, 36796.37109375, 36796.37109375]))\n",
      "           fun: 36796.37109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.76396812e-01, 1.02869441e-02, 1.02235812e-02, 1.15813164e+04,\n",
      "       1.34300547e+04, 1.35325939e+04, 8.88837336e+03])\n",
      "best ll: 55596.2109375, bestParams: [tensor(0.3330), tensor(0.0872), tensor(0.0765), tensor(14942.1357), tensor(20863.8457), tensor(15231.6943), tensor(10621.4648)]\n",
      "epoch 8\n",
      " final_simplex: (array([[8.93872392e-01, 4.42109791e-02, 5.88404423e-02, 1.26462772e+04,\n",
      "        1.23980259e+04, 1.23764006e+04, 8.56149116e+03],\n",
      "       [8.93872392e-01, 4.42109791e-02, 5.88404423e-02, 1.26462772e+04,\n",
      "        1.23980260e+04, 1.23764006e+04, 8.56149118e+03],\n",
      "       [8.93872392e-01, 4.42109793e-02, 5.88404424e-02, 1.26462772e+04,\n",
      "        1.23980259e+04, 1.23764006e+04, 8.56149118e+03],\n",
      "       [8.93872392e-01, 4.42109793e-02, 5.88404424e-02, 1.26462772e+04,\n",
      "        1.23980259e+04, 1.23764006e+04, 8.56149117e+03],\n",
      "       [8.93872391e-01, 4.42109792e-02, 5.88404426e-02, 1.26462772e+04,\n",
      "        1.23980259e+04, 1.23764006e+04, 8.56149119e+03],\n",
      "       [8.93872391e-01, 4.42109791e-02, 5.88404423e-02, 1.26462772e+04,\n",
      "        1.23980260e+04, 1.23764006e+04, 8.56149120e+03],\n",
      "       [8.93872392e-01, 4.42109793e-02, 5.88404424e-02, 1.26462772e+04,\n",
      "        1.23980260e+04, 1.23764006e+04, 8.56149116e+03],\n",
      "       [8.93872392e-01, 4.42109792e-02, 5.88404423e-02, 1.26462772e+04,\n",
      "        1.23980260e+04, 1.23764006e+04, 8.56149118e+03]]), array([38642.578125, 38642.578125, 38642.578125, 38642.578125,\n",
      "       38642.578125, 38642.578125, 38642.578125, 38642.578125]))\n",
      "           fun: 38642.578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1255\n",
      "           nit: 434\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.93872392e-01, 4.42109791e-02, 5.88404423e-02, 1.26462772e+04,\n",
      "       1.23980259e+04, 1.23764006e+04, 8.56149116e+03])\n",
      "minPrevious 36796.37109375\n",
      "best ll: 52986.58984375, bestParams: [tensor(0.3783), tensor(0.0296), tensor(0.0949), tensor(18207.6543), tensor(19851.3164), tensor(19921.7695), tensor(18286.6426)]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.46037096e-01, 1.66642667e-02, 3.61062244e-02, 1.18223512e+04,\n",
      "        2.27814588e+04, 1.94086214e+04, 1.35869070e+04],\n",
      "       [9.46037096e-01, 1.66642667e-02, 3.61062240e-02, 1.18223512e+04,\n",
      "        2.27814588e+04, 1.94086214e+04, 1.35869070e+04],\n",
      "       [9.46037096e-01, 1.66642667e-02, 3.61062242e-02, 1.18223512e+04,\n",
      "        2.27814588e+04, 1.94086213e+04, 1.35869071e+04],\n",
      "       [9.46037097e-01, 1.66642667e-02, 3.61062244e-02, 1.18223511e+04,\n",
      "        2.27814589e+04, 1.94086213e+04, 1.35869071e+04],\n",
      "       [9.46037097e-01, 1.66642667e-02, 3.61062245e-02, 1.18223511e+04,\n",
      "        2.27814589e+04, 1.94086213e+04, 1.35869071e+04],\n",
      "       [9.46037097e-01, 1.66642667e-02, 3.61062241e-02, 1.18223512e+04,\n",
      "        2.27814589e+04, 1.94086214e+04, 1.35869071e+04],\n",
      "       [9.46037096e-01, 1.66642667e-02, 3.61062242e-02, 1.18223512e+04,\n",
      "        2.27814588e+04, 1.94086213e+04, 1.35869071e+04],\n",
      "       [9.46037095e-01, 1.66642667e-02, 3.61062242e-02, 1.18223512e+04,\n",
      "        2.27814588e+04, 1.94086214e+04, 1.35869070e+04]]), array([37494.921875, 37494.921875, 37494.921875, 37494.921875,\n",
      "       37494.921875, 37494.921875, 37494.921875, 37494.921875]))\n",
      "           fun: 37494.921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1208\n",
      "           nit: 398\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.46037096e-01, 1.66642667e-02, 3.61062244e-02, 1.18223512e+04,\n",
      "       2.27814588e+04, 1.94086214e+04, 1.35869070e+04])\n",
      "minPrevious 36796.37109375\n",
      "best ll: 57111.49609375, bestParams: [tensor(0.2838), tensor(0.1297), tensor(0.0119), tensor(17231.1387), tensor(6211.8745), tensor(5494.9653), tensor(12613.2246)]\n",
      "epoch 10\n",
      " final_simplex: (array([[9.46399037e-01, 4.12685798e-02, 1.17865273e-02, 1.82132632e+04,\n",
      "        2.44831578e+03, 2.56104357e+03, 1.04384259e+04],\n",
      "       [9.46399037e-01, 4.12685802e-02, 1.17865273e-02, 1.82132633e+04,\n",
      "        2.44831578e+03, 2.56104357e+03, 1.04384259e+04],\n",
      "       [9.46399037e-01, 4.12685803e-02, 1.17865273e-02, 1.82132632e+04,\n",
      "        2.44831578e+03, 2.56104357e+03, 1.04384259e+04],\n",
      "       [9.46399037e-01, 4.12685803e-02, 1.17865274e-02, 1.82132632e+04,\n",
      "        2.44831578e+03, 2.56104357e+03, 1.04384259e+04],\n",
      "       [9.46399037e-01, 4.12685797e-02, 1.17865273e-02, 1.82132633e+04,\n",
      "        2.44831578e+03, 2.56104357e+03, 1.04384259e+04],\n",
      "       [9.46399037e-01, 4.12685801e-02, 1.17865274e-02, 1.82132632e+04,\n",
      "        2.44831578e+03, 2.56104357e+03, 1.04384259e+04],\n",
      "       [9.46399037e-01, 4.12685799e-02, 1.17865273e-02, 1.82132632e+04,\n",
      "        2.44831578e+03, 2.56104356e+03, 1.04384259e+04],\n",
      "       [9.46399037e-01, 4.12685801e-02, 1.17865273e-02, 1.82132632e+04,\n",
      "        2.44831578e+03, 2.56104356e+03, 1.04384259e+04]]), array([37590.9609375, 37590.9609375, 37590.9609375, 37590.9609375,\n",
      "       37590.9609375, 37590.9609375, 37590.9609375, 37590.9609375]))\n",
      "           fun: 37590.9609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1242\n",
      "           nit: 394\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.46399037e-01, 4.12685798e-02, 1.17865273e-02, 1.82132632e+04,\n",
      "       2.44831578e+03, 2.56104357e+03, 1.04384259e+04])\n",
      "minPrevious 36796.37109375\n",
      "best ll: 55901.1015625, bestParams: [tensor(0.3323), tensor(0.0439), tensor(0.1133), tensor(2154.4722), tensor(14528.2803), tensor(20665.6895), tensor(12823.1904)]\n",
      "epoch 11\n",
      " final_simplex: (array([[9.20114107e-01, 3.45351467e-02, 4.35608462e-02, 2.22673217e+03,\n",
      "        1.10886015e+04, 1.15311691e+04, 8.41243507e+03],\n",
      "       [9.20114103e-01, 3.45351472e-02, 4.35608484e-02, 2.22673215e+03,\n",
      "        1.10886015e+04, 1.15311691e+04, 8.41243498e+03],\n",
      "       [9.20114107e-01, 3.45351467e-02, 4.35608465e-02, 2.22673217e+03,\n",
      "        1.10886015e+04, 1.15311691e+04, 8.41243505e+03],\n",
      "       [9.20114107e-01, 3.45351467e-02, 4.35608460e-02, 2.22673218e+03,\n",
      "        1.10886015e+04, 1.15311692e+04, 8.41243509e+03],\n",
      "       [9.20114108e-01, 3.45351465e-02, 4.35608460e-02, 2.22673217e+03,\n",
      "        1.10886016e+04, 1.15311691e+04, 8.41243505e+03],\n",
      "       [9.20114106e-01, 3.45351467e-02, 4.35608469e-02, 2.22673216e+03,\n",
      "        1.10886016e+04, 1.15311691e+04, 8.41243504e+03],\n",
      "       [9.20114107e-01, 3.45351468e-02, 4.35608463e-02, 2.22673217e+03,\n",
      "        1.10886015e+04, 1.15311692e+04, 8.41243505e+03],\n",
      "       [9.20114106e-01, 3.45351468e-02, 4.35608470e-02, 2.22673216e+03,\n",
      "        1.10886016e+04, 1.15311691e+04, 8.41243503e+03]]), array([38013.3828125, 38013.3828125, 38013.3828125, 38013.3828125,\n",
      "       38013.3828125, 38013.3828125, 38013.3828125, 38013.3828125]))\n",
      "           fun: 38013.3828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1200\n",
      "           nit: 416\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.20114107e-01, 3.45351467e-02, 4.35608462e-02, 2.22673217e+03,\n",
      "       1.10886015e+04, 1.15311691e+04, 8.41243507e+03])\n",
      "minPrevious 36796.37109375\n",
      "best ll: 54474.8203125, bestParams: [tensor(0.3683), tensor(0.0238), tensor(0.0418), tensor(17209.5273), tensor(4316.0293), tensor(2748.1404), tensor(15755.0352)]\n",
      "epoch 12\n",
      " final_simplex: (array([[9.55340737e-01, 1.31247190e-02, 3.12117060e-02, 8.24244327e+03,\n",
      "        3.74767418e+03, 3.65596586e+03, 9.13619794e+03],\n",
      "       [9.55340736e-01, 1.31247190e-02, 3.12117061e-02, 8.24244329e+03,\n",
      "        3.74767416e+03, 3.65596586e+03, 9.13619795e+03],\n",
      "       [9.55340737e-01, 1.31247189e-02, 3.12117062e-02, 8.24244329e+03,\n",
      "        3.74767417e+03, 3.65596586e+03, 9.13619797e+03],\n",
      "       [9.55340736e-01, 1.31247190e-02, 3.12117062e-02, 8.24244326e+03,\n",
      "        3.74767416e+03, 3.65596585e+03, 9.13619794e+03],\n",
      "       [9.55340736e-01, 1.31247190e-02, 3.12117061e-02, 8.24244329e+03,\n",
      "        3.74767417e+03, 3.65596586e+03, 9.13619792e+03],\n",
      "       [9.55340737e-01, 1.31247190e-02, 3.12117062e-02, 8.24244331e+03,\n",
      "        3.74767416e+03, 3.65596586e+03, 9.13619794e+03],\n",
      "       [9.55340737e-01, 1.31247190e-02, 3.12117061e-02, 8.24244326e+03,\n",
      "        3.74767416e+03, 3.65596586e+03, 9.13619794e+03],\n",
      "       [9.55340737e-01, 1.31247189e-02, 3.12117061e-02, 8.24244336e+03,\n",
      "        3.74767415e+03, 3.65596588e+03, 9.13619799e+03]]), array([37409.83203125, 37409.83203125, 37409.83203125, 37409.83203125,\n",
      "       37409.83203125, 37409.83203125, 37409.83203125, 37409.83203125]))\n",
      "           fun: 37409.83203125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1242\n",
      "           nit: 434\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.55340737e-01, 1.31247190e-02, 3.12117060e-02, 8.24244327e+03,\n",
      "       3.74767418e+03, 3.65596586e+03, 9.13619794e+03])\n",
      "minPrevious 36796.37109375\n",
      "best ll: 59497.1484375, bestParams: [tensor(0.2768), tensor(0.1629), tensor(0.0154), tensor(8840.6992), tensor(15131.2822), tensor(24791.2266), tensor(12887.0400)]\n",
      "epoch 13\n",
      " final_simplex: (array([[9.23703084e-01, 6.31674612e-02, 1.19524429e-02, 6.51806987e+03,\n",
      "        1.97686663e+04, 1.82090697e+04, 1.81565239e+02],\n",
      "       [9.23703084e-01, 6.31674615e-02, 1.19524428e-02, 6.51806990e+03,\n",
      "        1.97686663e+04, 1.82090698e+04, 1.81565233e+02],\n",
      "       [9.23703083e-01, 6.31674610e-02, 1.19524430e-02, 6.51806985e+03,\n",
      "        1.97686663e+04, 1.82090697e+04, 1.81565262e+02],\n",
      "       [9.23703084e-01, 6.31674613e-02, 1.19524430e-02, 6.51806986e+03,\n",
      "        1.97686663e+04, 1.82090697e+04, 1.81565222e+02],\n",
      "       [9.23703082e-01, 6.31674618e-02, 1.19524428e-02, 6.51806991e+03,\n",
      "        1.97686664e+04, 1.82090697e+04, 1.81565252e+02],\n",
      "       [9.23703083e-01, 6.31674611e-02, 1.19524430e-02, 6.51806986e+03,\n",
      "        1.97686663e+04, 1.82090697e+04, 1.81565269e+02],\n",
      "       [9.23703083e-01, 6.31674611e-02, 1.19524430e-02, 6.51806986e+03,\n",
      "        1.97686663e+04, 1.82090697e+04, 1.81565268e+02],\n",
      "       [9.23703083e-01, 6.31674612e-02, 1.19524430e-02, 6.51806987e+03,\n",
      "        1.97686663e+04, 1.82090698e+04, 1.81565268e+02]]), array([37736.8828125, 37736.8828125, 37736.8828125, 37736.8828125,\n",
      "       37736.8828125, 37736.8828125, 37736.8828125, 37736.8828125]))\n",
      "           fun: 37736.8828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1288\n",
      "           nit: 447\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.23703084e-01, 6.31674612e-02, 1.19524429e-02, 6.51806987e+03,\n",
      "       1.97686663e+04, 1.82090697e+04, 1.81565239e+02])\n",
      "minPrevious 36796.37109375\n",
      "best ll: 56647.25390625, bestParams: [tensor(0.2940), tensor(0.0943), tensor(0.0893), tensor(15911.4199), tensor(18894.0918), tensor(17567.0137), tensor(7612.0166)]\n",
      "epoch 14\n",
      " final_simplex: (array([[8.71485106e-01, 4.75342677e-02, 7.65888066e-02, 4.49898094e+03,\n",
      "        1.71224484e+04, 2.25033758e+04, 1.07264075e+04],\n",
      "       [8.71485105e-01, 4.75342674e-02, 7.65888068e-02, 4.49898097e+03,\n",
      "        1.71224484e+04, 2.25033758e+04, 1.07264075e+04],\n",
      "       [8.71485105e-01, 4.75342678e-02, 7.65888069e-02, 4.49898103e+03,\n",
      "        1.71224484e+04, 2.25033758e+04, 1.07264074e+04],\n",
      "       [8.71485106e-01, 4.75342673e-02, 7.65888066e-02, 4.49898098e+03,\n",
      "        1.71224484e+04, 2.25033758e+04, 1.07264075e+04],\n",
      "       [8.71485108e-01, 4.75342676e-02, 7.65888071e-02, 4.49898089e+03,\n",
      "        1.71224484e+04, 2.25033758e+04, 1.07264075e+04],\n",
      "       [8.71485107e-01, 4.75342674e-02, 7.65888067e-02, 4.49898092e+03,\n",
      "        1.71224484e+04, 2.25033758e+04, 1.07264075e+04],\n",
      "       [8.71485108e-01, 4.75342676e-02, 7.65888068e-02, 4.49898094e+03,\n",
      "        1.71224484e+04, 2.25033758e+04, 1.07264075e+04],\n",
      "       [8.71485108e-01, 4.75342676e-02, 7.65888071e-02, 4.49898091e+03,\n",
      "        1.71224484e+04, 2.25033758e+04, 1.07264075e+04]]), array([39550.9921875, 39550.9921875, 39550.9921875, 39550.9921875,\n",
      "       39550.9921875, 39550.9921875, 39550.9921875, 39550.9921875]))\n",
      "           fun: 39550.9921875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1241\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.71485106e-01, 4.75342677e-02, 7.65888066e-02, 4.49898094e+03,\n",
      "       1.71224484e+04, 2.25033758e+04, 1.07264075e+04])\n",
      "minPrevious 36796.37109375\n",
      "best ll: 55692.9453125, bestParams: [tensor(0.3273), tensor(0.1631), tensor(0.0656), tensor(15402.5586), tensor(832.4813), tensor(694.9297), tensor(14363.8623)]\n",
      "epoch 15\n",
      " final_simplex: (array([[9.23757841e-01, 2.11358655e-04, 7.58165872e-02, 1.00530788e+04,\n",
      "        5.83049675e+02, 5.43693042e+02, 1.46925577e+04],\n",
      "       [9.23757842e-01, 2.11358371e-04, 7.58165872e-02, 1.00530788e+04,\n",
      "        5.83049676e+02, 5.43693042e+02, 1.46925577e+04],\n",
      "       [9.23757842e-01, 2.11358040e-04, 7.58165874e-02, 1.00530788e+04,\n",
      "        5.83049676e+02, 5.43693042e+02, 1.46925577e+04],\n",
      "       [9.23757841e-01, 2.11359732e-04, 7.58165868e-02, 1.00530788e+04,\n",
      "        5.83049675e+02, 5.43693043e+02, 1.46925577e+04],\n",
      "       [9.23757841e-01, 2.11358708e-04, 7.58165869e-02, 1.00530789e+04,\n",
      "        5.83049676e+02, 5.43693040e+02, 1.46925576e+04],\n",
      "       [9.23757841e-01, 2.11358850e-04, 7.58165872e-02, 1.00530788e+04,\n",
      "        5.83049674e+02, 5.43693042e+02, 1.46925576e+04],\n",
      "       [9.23757842e-01, 2.11358903e-04, 7.58165873e-02, 1.00530788e+04,\n",
      "        5.83049674e+02, 5.43693043e+02, 1.46925576e+04],\n",
      "       [9.23757842e-01, 2.11358832e-04, 7.58165872e-02, 1.00530787e+04,\n",
      "        5.83049676e+02, 5.43693044e+02, 1.46925577e+04]]), array([38047.34765625, 38047.34765625, 38047.34765625, 38047.34765625,\n",
      "       38047.34765625, 38047.34765625, 38047.34765625, 38047.34765625]))\n",
      "           fun: 38047.34765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1269\n",
      "           nit: 468\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.23757841e-01, 2.11358655e-04, 7.58165872e-02, 1.00530788e+04,\n",
      "       5.83049675e+02, 5.43693042e+02, 1.46925577e+04])\n",
      "minPrevious 36796.37109375\n",
      "best ll: 55219.84765625, bestParams: [tensor(0.3213), tensor(0.1555), tensor(0.0004), tensor(15791.6982), tensor(21589.1680), tensor(22243.3867), tensor(5844.9023)]\n",
      "epoch 16\n",
      " final_simplex: (array([[8.66993458e-01, 1.29883415e-01, 2.65246120e-04, 1.12922893e+04,\n",
      "        1.90111488e+04, 1.66417810e+04, 6.13266926e+03],\n",
      "       [8.66993458e-01, 1.29883414e-01, 2.65246120e-04, 1.12922893e+04,\n",
      "        1.90111487e+04, 1.66417810e+04, 6.13266929e+03],\n",
      "       [8.66993457e-01, 1.29883414e-01, 2.65246121e-04, 1.12922893e+04,\n",
      "        1.90111487e+04, 1.66417811e+04, 6.13266926e+03],\n",
      "       [8.66993456e-01, 1.29883414e-01, 2.65246122e-04, 1.12922892e+04,\n",
      "        1.90111488e+04, 1.66417810e+04, 6.13266931e+03],\n",
      "       [8.66993455e-01, 1.29883415e-01, 2.65246122e-04, 1.12922893e+04,\n",
      "        1.90111487e+04, 1.66417811e+04, 6.13266928e+03],\n",
      "       [8.66993459e-01, 1.29883415e-01, 2.65246119e-04, 1.12922893e+04,\n",
      "        1.90111488e+04, 1.66417810e+04, 6.13266928e+03],\n",
      "       [8.66993454e-01, 1.29883414e-01, 2.65246123e-04, 1.12922892e+04,\n",
      "        1.90111487e+04, 1.66417811e+04, 6.13266929e+03],\n",
      "       [8.66993456e-01, 1.29883414e-01, 2.65246122e-04, 1.12922892e+04,\n",
      "        1.90111487e+04, 1.66417810e+04, 6.13266933e+03]]), array([39080.92578125, 39080.92578125, 39080.92578125, 39080.92578125,\n",
      "       39080.92578125, 39080.92578125, 39080.92578125, 39080.92578125]))\n",
      "           fun: 39080.92578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1175\n",
      "           nit: 387\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.66993458e-01, 1.29883415e-01, 2.65246120e-04, 1.12922893e+04,\n",
      "       1.90111488e+04, 1.66417810e+04, 6.13266926e+03])\n",
      "minPrevious 36796.37109375\n",
      "best ll: 58554.43359375, bestParams: [tensor(0.2538), tensor(0.0487), tensor(0.1140), tensor(11260.0449), tensor(16984.8574), tensor(18442.8926), tensor(9168.7227)]\n",
      "epoch 17\n",
      " final_simplex: (array([[9.36432238e-01, 4.35738498e-02, 1.88980180e-02, 1.50208207e+04,\n",
      "        1.44573057e+04, 1.32009766e+04, 5.35936786e+03],\n",
      "       [9.36432240e-01, 4.35738497e-02, 1.88980169e-02, 1.50208207e+04,\n",
      "        1.44573057e+04, 1.32009766e+04, 5.35936791e+03],\n",
      "       [9.36432239e-01, 4.35738497e-02, 1.88980177e-02, 1.50208207e+04,\n",
      "        1.44573057e+04, 1.32009766e+04, 5.35936784e+03],\n",
      "       [9.36432240e-01, 4.35738497e-02, 1.88980172e-02, 1.50208207e+04,\n",
      "        1.44573057e+04, 1.32009766e+04, 5.35936790e+03],\n",
      "       [9.36432240e-01, 4.35738498e-02, 1.88980174e-02, 1.50208206e+04,\n",
      "        1.44573057e+04, 1.32009766e+04, 5.35936789e+03],\n",
      "       [9.36432239e-01, 4.35738498e-02, 1.88980181e-02, 1.50208206e+04,\n",
      "        1.44573057e+04, 1.32009766e+04, 5.35936786e+03],\n",
      "       [9.36432239e-01, 4.35738498e-02, 1.88980180e-02, 1.50208207e+04,\n",
      "        1.44573057e+04, 1.32009767e+04, 5.35936785e+03],\n",
      "       [9.36432239e-01, 4.35738498e-02, 1.88980175e-02, 1.50208207e+04,\n",
      "        1.44573057e+04, 1.32009766e+04, 5.35936787e+03]]), array([37781.1328125, 37781.1328125, 37781.1328125, 37781.1328125,\n",
      "       37781.1328125, 37781.1328125, 37781.1328125, 37781.1328125]))\n",
      "           fun: 37781.1328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1272\n",
      "           nit: 436\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.36432238e-01, 4.35738498e-02, 1.88980180e-02, 1.50208207e+04,\n",
      "       1.44573057e+04, 1.32009766e+04, 5.35936786e+03])\n",
      "minPrevious 36796.37109375\n",
      "best ll: 57387.0703125, bestParams: [tensor(0.2988), tensor(0.0593), tensor(0.2402), tensor(22645.8301), tensor(11090.8125), tensor(10798.1416), tensor(16758.7246)]\n",
      "epoch 18\n",
      " final_simplex: (array([[9.51315760e-01, 3.58772210e-02, 8.04422252e-03, 1.74257328e+04,\n",
      "        1.10883401e+04, 9.56474252e+03, 1.52633286e+04],\n",
      "       [9.51315756e-01, 3.58772214e-02, 8.04422370e-03, 1.74257328e+04,\n",
      "        1.10883401e+04, 9.56474251e+03, 1.52633286e+04],\n",
      "       [9.51315759e-01, 3.58772210e-02, 8.04422504e-03, 1.74257327e+04,\n",
      "        1.10883401e+04, 9.56474253e+03, 1.52633286e+04],\n",
      "       [9.51315758e-01, 3.58772210e-02, 8.04422525e-03, 1.74257327e+04,\n",
      "        1.10883401e+04, 9.56474253e+03, 1.52633286e+04],\n",
      "       [9.51315754e-01, 3.58772218e-02, 8.04422377e-03, 1.74257329e+04,\n",
      "        1.10883401e+04, 9.56474247e+03, 1.52633286e+04],\n",
      "       [9.51315757e-01, 3.58772215e-02, 8.04422482e-03, 1.74257328e+04,\n",
      "        1.10883401e+04, 9.56474247e+03, 1.52633286e+04],\n",
      "       [9.51315760e-01, 3.58772213e-02, 8.04422353e-03, 1.74257328e+04,\n",
      "        1.10883401e+04, 9.56474247e+03, 1.52633286e+04],\n",
      "       [9.51315759e-01, 3.58772213e-02, 8.04422346e-03, 1.74257328e+04,\n",
      "        1.10883401e+04, 9.56474247e+03, 1.52633286e+04]]), array([37517.3203125, 37517.3203125, 37517.3203125, 37517.3203125,\n",
      "       37517.3203125, 37517.3203125, 37517.3203125, 37517.3203125]))\n",
      "           fun: 37517.3203125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1191\n",
      "           nit: 395\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.51315760e-01, 3.58772210e-02, 8.04422252e-03, 1.74257328e+04,\n",
      "       1.10883401e+04, 9.56474252e+03, 1.52633286e+04])\n",
      "minPrevious 36796.37109375\n",
      "best ll: 54661.484375, bestParams: [tensor(0.3366), tensor(0.0003), tensor(0.1288), tensor(14006.4854), tensor(8059.8472), tensor(7407.6265), tensor(17942.2910)]\n",
      "epoch 19\n",
      " final_simplex: (array([[8.87125029e-01, 3.29498658e-04, 1.10004475e-01, 1.02114684e+04,\n",
      "        6.13431001e+03, 6.31108568e+03, 1.09314993e+04],\n",
      "       [8.87125030e-01, 3.29498659e-04, 1.10004475e-01, 1.02114684e+04,\n",
      "        6.13431002e+03, 6.31108567e+03, 1.09314993e+04],\n",
      "       [8.87125029e-01, 3.29498658e-04, 1.10004476e-01, 1.02114684e+04,\n",
      "        6.13431003e+03, 6.31108565e+03, 1.09314993e+04],\n",
      "       [8.87125030e-01, 3.29498659e-04, 1.10004475e-01, 1.02114684e+04,\n",
      "        6.13431004e+03, 6.31108567e+03, 1.09314993e+04],\n",
      "       [8.87125030e-01, 3.29498659e-04, 1.10004476e-01, 1.02114684e+04,\n",
      "        6.13431003e+03, 6.31108567e+03, 1.09314993e+04],\n",
      "       [8.87125031e-01, 3.29498660e-04, 1.10004475e-01, 1.02114684e+04,\n",
      "        6.13431005e+03, 6.31108567e+03, 1.09314993e+04],\n",
      "       [8.87125029e-01, 3.29498657e-04, 1.10004476e-01, 1.02114684e+04,\n",
      "        6.13431005e+03, 6.31108564e+03, 1.09314993e+04],\n",
      "       [8.87125029e-01, 3.29498658e-04, 1.10004476e-01, 1.02114684e+04,\n",
      "        6.13431002e+03, 6.31108559e+03, 1.09314993e+04]]), array([38798.8515625, 38798.8515625, 38798.8515625, 38798.8515625,\n",
      "       38798.8515625, 38798.8515625, 38798.8515625, 38798.8515625]))\n",
      "           fun: 38798.8515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1202\n",
      "           nit: 417\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.87125029e-01, 3.29498658e-04, 1.10004475e-01, 1.02114684e+04,\n",
      "       6.13431001e+03, 6.31108568e+03, 1.09314993e+04])\n",
      "minPrevious 36796.37109375\n",
      "inferredPis tensor([0.9764, 0.0103, 0.0102], dtype=torch.float64)\n",
      "inferredAlphas tensor([11581.3164, 13430.0547, 13532.5939,  8888.3734], dtype=torch.float64)\n",
      "truth0 tensor(0.7519) truth1 tensor(0.1111) truth2 tensor(0.1121) truthBoth tensor(0.0250)\n",
      "params on run 4 {'lls': [58132.7578125, 61020.8984375, 62816.03125, 61310.28125, 59964.953125, 47473.921875, 47433.734375, 47816.32421875, 47210.3984375, 51822.578125, 51970.546875, 47609.4609375, 52364.7734375, 53773.0390625, 47233.921875, 36342.86328125, 36234.44921875, 36770.3828125, 36826.53125, 36796.37109375], 'inferredAlphas': [tensor([17771.7538,   267.5774,   285.4237, 19323.4289], dtype=torch.float64), tensor([17391.5067,   389.1159,   504.1465, 38945.6315], dtype=torch.float64), tensor([26599.6834,   330.5187,   522.2450, 20474.0527], dtype=torch.float64), tensor([17159.0905,   229.1438,   192.1196, 23702.7612], dtype=torch.float64), tensor([14365.2776,   353.8587,   277.5095, 36615.7416], dtype=torch.float64), tensor([4681.1768, 1514.9906,  279.5278, 6430.2365], dtype=torch.float64), tensor([11636.0228,  1941.4431,   317.7839,  2432.4090], dtype=torch.float64), tensor([3466.6976,  105.4401,  574.8790,  884.2902], dtype=torch.float64), tensor([  190.1304,   255.3843,  1367.9433, 10051.6183], dtype=torch.float64), tensor([13347.1036,  2995.2070,   679.1869,  9964.7306], dtype=torch.float64), tensor([3050.1159,  274.5893, 1270.7564, 7251.8219], dtype=torch.float64), tensor([1902.8937,  238.1495, 1249.7712, 7914.4684], dtype=torch.float64), tensor([20414.2533,  1255.3286,  5495.8171, 24486.6440], dtype=torch.float64), tensor([ 5422.4410,  1070.5042,  5035.1884, 34394.7350], dtype=torch.float64), tensor([6116.3640, 1549.1665,  277.2773, 5735.0947], dtype=torch.float64), tensor([ 3252.4160, 17197.7572, 17440.7641, 20021.9416], dtype=torch.float64), tensor([7562.1733, 8368.3120, 8779.7352, 8746.4345], dtype=torch.float64), tensor([24233.9895, 13108.5658, 12119.1812, 10209.1235], dtype=torch.float64), tensor([7396.8446, 8201.6473, 8380.9128, 7312.5791], dtype=torch.float64), tensor([11581.3164, 13430.0547, 13532.5939,  8888.3734], dtype=torch.float64)], 'inferredPis': [tensor([0.2745, 0.5123, 0.0037], dtype=torch.float64), tensor([0.2424, 0.2423, 0.0335], dtype=torch.float64), tensor([0.2477, 0.1574, 0.0414], dtype=torch.float64), tensor([0.2670, 0.3576, 0.1152], dtype=torch.float64), tensor([0.4350, 0.2494, 0.0647], dtype=torch.float64), tensor([0.1319, 0.8504, 0.0173], dtype=torch.float64), tensor([0.1121, 0.8709, 0.0016], dtype=torch.float64), tensor([0.7272, 0.2531, 0.0189], dtype=torch.float64), tensor([0.8014, 0.1978, 0.0008], dtype=torch.float64), tensor([0.1527, 0.5340, 0.0406], dtype=torch.float64), tensor([4.4252e-01, 2.4141e-01, 6.9015e-05], dtype=torch.float64), tensor([0.7311, 0.2567, 0.0100], dtype=torch.float64), tensor([0.4108, 0.3023, 0.0150], dtype=torch.float64), tensor([0.4187, 0.1117, 0.0518], dtype=torch.float64), tensor([0.2033, 0.7863, 0.0045], dtype=torch.float64), tensor([0.9651, 0.0301, 0.0021], dtype=torch.float64), tensor([0.9906, 0.0041, 0.0032], dtype=torch.float64), tensor([9.9493e-01, 2.2532e-03, 5.0930e-04], dtype=torch.float64), tensor([0.9840, 0.0037, 0.0093], dtype=torch.float64), tensor([0.9764, 0.0103, 0.0102], dtype=torch.float64)], 'inferredPDVs': [tensor([0.4720, 0.0071, 0.0076, 0.5133], dtype=torch.float64), tensor([0.3039, 0.0068, 0.0088, 0.6805], dtype=torch.float64), tensor([0.5550, 0.0069, 0.0109, 0.4272], dtype=torch.float64), tensor([0.4156, 0.0056, 0.0047, 0.5742], dtype=torch.float64), tensor([0.2783, 0.0069, 0.0054, 0.7095], dtype=torch.float64), tensor([0.3627, 0.1174, 0.0217, 0.4982], dtype=torch.float64), tensor([0.7126, 0.1189, 0.0195, 0.1490], dtype=torch.float64), tensor([0.6890, 0.0210, 0.1143, 0.1758], dtype=torch.float64), tensor([0.0160, 0.0215, 0.1153, 0.8471], dtype=torch.float64), tensor([0.4945, 0.1110, 0.0252, 0.3693], dtype=torch.float64), tensor([0.2575, 0.0232, 0.1073, 0.6120], dtype=torch.float64), tensor([0.1683, 0.0210, 0.1106, 0.7001], dtype=torch.float64), tensor([0.3952, 0.0243, 0.1064, 0.4741], dtype=torch.float64), tensor([0.1181, 0.0233, 0.1096, 0.7490], dtype=torch.float64), tensor([0.4472, 0.1133, 0.0203, 0.4192], dtype=torch.float64), tensor([0.0562, 0.2969, 0.3011, 0.3458], dtype=torch.float64), tensor([0.2260, 0.2501, 0.2624, 0.2614], dtype=torch.float64), tensor([0.4061, 0.2197, 0.2031, 0.1711], dtype=torch.float64), tensor([0.2364, 0.2621, 0.2678, 0.2337], dtype=torch.float64), tensor([0.2442, 0.2832, 0.2853, 0.1874], dtype=torch.float64)], 'trueMeanPDVs': [tensor([0.7547, 0.1096, 0.1105, 0.0252]), tensor([0.7520, 0.1114, 0.1113, 0.0253]), tensor([0.7523, 0.1111, 0.1116, 0.0250]), tensor([0.7518, 0.1113, 0.1112, 0.0257]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7510, 0.1117, 0.1118, 0.0255]), tensor([0.7535, 0.1110, 0.1105, 0.0250]), tensor([0.7503, 0.1121, 0.1120, 0.0256]), tensor([0.7542, 0.1103, 0.1109, 0.0246]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250])], 'truePis': [tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500])]}\n",
      "tensor([[102.,  25.,   1.,   1.],\n",
      "        [ 63.,   5.,   0.,   0.],\n",
      "        [ 53.,  18.,   0.,   0.],\n",
      "        ...,\n",
      "        [105.,   4.,   1.,   1.],\n",
      "        [ 61.,   1.,   0.,   0.],\n",
      "        [145.,   0.,   1.,   0.]])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood4 at 0x7febac6c4d40>\n",
      "best ll: 52834.3828125, bestParams: [tensor(0.3800), tensor(0.0895), tensor(0.0542), tensor(17257.2090), tensor(10507.5225), tensor(11444.7891), tensor(18023.3906)]\n",
      "epoch 0\n",
      " final_simplex: (array([[9.30764495e-01, 4.01807836e-02, 2.39029790e-02, 1.87099600e+04,\n",
      "        1.02338488e+04, 8.89088366e+03, 1.56818261e+04],\n",
      "       [9.30764495e-01, 4.01807841e-02, 2.39029791e-02, 1.87099600e+04,\n",
      "        1.02338488e+04, 8.89088366e+03, 1.56818260e+04],\n",
      "       [9.30764496e-01, 4.01807836e-02, 2.39029789e-02, 1.87099601e+04,\n",
      "        1.02338489e+04, 8.89088366e+03, 1.56818260e+04],\n",
      "       [9.30764495e-01, 4.01807836e-02, 2.39029789e-02, 1.87099600e+04,\n",
      "        1.02338489e+04, 8.89088368e+03, 1.56818260e+04],\n",
      "       [9.30764495e-01, 4.01807837e-02, 2.39029789e-02, 1.87099600e+04,\n",
      "        1.02338489e+04, 8.89088367e+03, 1.56818260e+04],\n",
      "       [9.30764495e-01, 4.01807837e-02, 2.39029790e-02, 1.87099600e+04,\n",
      "        1.02338488e+04, 8.89088365e+03, 1.56818260e+04],\n",
      "       [9.30764495e-01, 4.01807840e-02, 2.39029790e-02, 1.87099600e+04,\n",
      "        1.02338488e+04, 8.89088366e+03, 1.56818261e+04],\n",
      "       [9.30764496e-01, 4.01807835e-02, 2.39029790e-02, 1.87099601e+04,\n",
      "        1.02338489e+04, 8.89088364e+03, 1.56818260e+04]]), array([37871.140625, 37871.140625, 37871.140625, 37871.140625,\n",
      "       37871.140625, 37871.140625, 37871.140625, 37871.140625]))\n",
      "           fun: 37871.140625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1266\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.30764495e-01, 4.01807836e-02, 2.39029790e-02, 1.87099600e+04,\n",
      "       1.02338488e+04, 8.89088366e+03, 1.56818261e+04])\n",
      "best ll: 58708.234375, bestParams: [tensor(0.2662), tensor(0.1980), tensor(0.0225), tensor(1198.8926), tensor(21099.5352), tensor(18408.0898), tensor(8478.1641)]\n",
      "epoch 1\n",
      " final_simplex: (array([[9.65512343e-01, 8.45473155e-03, 2.26883707e-02, 3.16522066e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299801e+03],\n",
      "       [9.65512344e-01, 8.45472933e-03, 2.26883706e-02, 3.16522158e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299798e+03],\n",
      "       [9.65512349e-01, 8.45472940e-03, 2.26883707e-02, 3.16522012e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299799e+03],\n",
      "       [9.65512346e-01, 8.45473019e-03, 2.26883707e-02, 3.16522065e+01,\n",
      "        1.42710325e+04, 1.48808658e+04, 6.98299800e+03],\n",
      "       [9.65512338e-01, 8.45473149e-03, 2.26883707e-02, 3.16522235e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299799e+03],\n",
      "       [9.65512343e-01, 8.45473020e-03, 2.26883707e-02, 3.16522109e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299799e+03],\n",
      "       [9.65512343e-01, 8.45473059e-03, 2.26883707e-02, 3.16522095e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299799e+03],\n",
      "       [9.65512344e-01, 8.45473017e-03, 2.26883707e-02, 3.16522123e+01,\n",
      "        1.42710325e+04, 1.48808658e+04, 6.98299799e+03]]), array([36735.640625, 36735.640625, 36735.640625, 36735.640625,\n",
      "       36735.640625, 36735.640625, 36735.640625, 36735.640625]))\n",
      "           fun: 36735.640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1251\n",
      "           nit: 439\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.65512343e-01, 8.45473155e-03, 2.26883707e-02, 3.16522066e+01,\n",
      "       1.42710326e+04, 1.48808658e+04, 6.98299801e+03])\n",
      "minPrevious 37871.140625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.65512343e-01, 8.45473155e-03, 2.26883707e-02, 3.16522066e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299801e+03],\n",
      "       [9.65512344e-01, 8.45472933e-03, 2.26883706e-02, 3.16522158e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299798e+03],\n",
      "       [9.65512349e-01, 8.45472940e-03, 2.26883707e-02, 3.16522012e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299799e+03],\n",
      "       [9.65512346e-01, 8.45473019e-03, 2.26883707e-02, 3.16522065e+01,\n",
      "        1.42710325e+04, 1.48808658e+04, 6.98299800e+03],\n",
      "       [9.65512338e-01, 8.45473149e-03, 2.26883707e-02, 3.16522235e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299799e+03],\n",
      "       [9.65512343e-01, 8.45473020e-03, 2.26883707e-02, 3.16522109e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299799e+03],\n",
      "       [9.65512343e-01, 8.45473059e-03, 2.26883707e-02, 3.16522095e+01,\n",
      "        1.42710326e+04, 1.48808658e+04, 6.98299799e+03],\n",
      "       [9.65512344e-01, 8.45473017e-03, 2.26883707e-02, 3.16522123e+01,\n",
      "        1.42710325e+04, 1.48808658e+04, 6.98299799e+03]]), array([36735.640625, 36735.640625, 36735.640625, 36735.640625,\n",
      "       36735.640625, 36735.640625, 36735.640625, 36735.640625]))\n",
      "           fun: 36735.640625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1251\n",
      "           nit: 439\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.65512343e-01, 8.45473155e-03, 2.26883707e-02, 3.16522066e+01,\n",
      "       1.42710326e+04, 1.48808658e+04, 6.98299801e+03])\n",
      "best ll: 58271.75, bestParams: [tensor(0.2805), tensor(0.3002), tensor(0.0160), tensor(21270.9395), tensor(14563.4023), tensor(15621.6992), tensor(16418.5352)]\n",
      "epoch 2\n",
      " final_simplex: (array([[9.44522014e-01, 4.10044038e-02, 2.23747580e-04, 3.01184933e+04,\n",
      "        9.78311184e+03, 9.22959702e+03, 1.23668005e+04],\n",
      "       [9.44522014e-01, 4.10044037e-02, 2.23747580e-04, 3.01184933e+04,\n",
      "        9.78311185e+03, 9.22959702e+03, 1.23668006e+04],\n",
      "       [9.44522014e-01, 4.10044038e-02, 2.23747588e-04, 3.01184933e+04,\n",
      "        9.78311184e+03, 9.22959703e+03, 1.23668006e+04],\n",
      "       [9.44522014e-01, 4.10044036e-02, 2.23747588e-04, 3.01184933e+04,\n",
      "        9.78311184e+03, 9.22959702e+03, 1.23668006e+04],\n",
      "       [9.44522014e-01, 4.10044040e-02, 2.23747591e-04, 3.01184933e+04,\n",
      "        9.78311184e+03, 9.22959700e+03, 1.23668005e+04],\n",
      "       [9.44522014e-01, 4.10044037e-02, 2.23747579e-04, 3.01184933e+04,\n",
      "        9.78311184e+03, 9.22959701e+03, 1.23668005e+04],\n",
      "       [9.44522014e-01, 4.10044037e-02, 2.23747581e-04, 3.01184933e+04,\n",
      "        9.78311184e+03, 9.22959701e+03, 1.23668005e+04],\n",
      "       [9.44522015e-01, 4.10044039e-02, 2.23747583e-04, 3.01184933e+04,\n",
      "        9.78311184e+03, 9.22959699e+03, 1.23668005e+04]]), array([37444.828125, 37444.828125, 37444.828125, 37444.828125,\n",
      "       37444.828125, 37444.828125, 37444.828125, 37444.828125]))\n",
      "           fun: 37444.828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1342\n",
      "           nit: 469\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.44522014e-01, 4.10044038e-02, 2.23747580e-04, 3.01184933e+04,\n",
      "       9.78311184e+03, 9.22959702e+03, 1.23668005e+04])\n",
      "minPrevious 36735.640625\n",
      "best ll: 56337.55078125, bestParams: [tensor(0.2799), tensor(0.0254), tensor(0.0081), tensor(10453.1182), tensor(13741.2119), tensor(14312.5195), tensor(8931.3896)]\n",
      "epoch 3\n",
      " final_simplex: (array([[9.78952049e-01, 1.37078006e-02, 4.71218746e-03, 7.63148277e+03,\n",
      "        9.63536044e+03, 9.44519422e+03, 6.39783327e+03],\n",
      "       [9.78952049e-01, 1.37078006e-02, 4.71218747e-03, 7.63148276e+03,\n",
      "        9.63536043e+03, 9.44519423e+03, 6.39783327e+03],\n",
      "       [9.78952050e-01, 1.37078006e-02, 4.71218749e-03, 7.63148268e+03,\n",
      "        9.63536045e+03, 9.44519422e+03, 6.39783322e+03],\n",
      "       [9.78952049e-01, 1.37078007e-02, 4.71218744e-03, 7.63148271e+03,\n",
      "        9.63536044e+03, 9.44519424e+03, 6.39783325e+03],\n",
      "       [9.78952049e-01, 1.37078005e-02, 4.71218748e-03, 7.63148279e+03,\n",
      "        9.63536045e+03, 9.44519422e+03, 6.39783328e+03],\n",
      "       [9.78952049e-01, 1.37078004e-02, 4.71218753e-03, 7.63148274e+03,\n",
      "        9.63536045e+03, 9.44519420e+03, 6.39783325e+03],\n",
      "       [9.78952050e-01, 1.37078005e-02, 4.71218746e-03, 7.63148277e+03,\n",
      "        9.63536041e+03, 9.44519425e+03, 6.39783328e+03],\n",
      "       [9.78952049e-01, 1.37078007e-02, 4.71218745e-03, 7.63148272e+03,\n",
      "        9.63536042e+03, 9.44519424e+03, 6.39783325e+03]]), array([36715.48046875, 36715.48046875, 36715.48046875, 36715.48046875,\n",
      "       36715.48046875, 36715.48046875, 36715.48046875, 36715.48046875]))\n",
      "           fun: 36715.48046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1210\n",
      "           nit: 379\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.78952049e-01, 1.37078006e-02, 4.71218746e-03, 7.63148277e+03,\n",
      "       9.63536044e+03, 9.44519422e+03, 6.39783327e+03])\n",
      "minPrevious 36735.640625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.78952049e-01, 1.37078006e-02, 4.71218746e-03, 7.63148277e+03,\n",
      "        9.63536044e+03, 9.44519422e+03, 6.39783327e+03],\n",
      "       [9.78952049e-01, 1.37078006e-02, 4.71218747e-03, 7.63148276e+03,\n",
      "        9.63536043e+03, 9.44519423e+03, 6.39783327e+03],\n",
      "       [9.78952050e-01, 1.37078006e-02, 4.71218749e-03, 7.63148268e+03,\n",
      "        9.63536045e+03, 9.44519422e+03, 6.39783322e+03],\n",
      "       [9.78952049e-01, 1.37078007e-02, 4.71218744e-03, 7.63148271e+03,\n",
      "        9.63536044e+03, 9.44519424e+03, 6.39783325e+03],\n",
      "       [9.78952049e-01, 1.37078005e-02, 4.71218748e-03, 7.63148279e+03,\n",
      "        9.63536045e+03, 9.44519422e+03, 6.39783328e+03],\n",
      "       [9.78952049e-01, 1.37078004e-02, 4.71218753e-03, 7.63148274e+03,\n",
      "        9.63536045e+03, 9.44519420e+03, 6.39783325e+03],\n",
      "       [9.78952050e-01, 1.37078005e-02, 4.71218746e-03, 7.63148277e+03,\n",
      "        9.63536041e+03, 9.44519425e+03, 6.39783328e+03],\n",
      "       [9.78952049e-01, 1.37078007e-02, 4.71218745e-03, 7.63148272e+03,\n",
      "        9.63536042e+03, 9.44519424e+03, 6.39783325e+03]]), array([36715.48046875, 36715.48046875, 36715.48046875, 36715.48046875,\n",
      "       36715.48046875, 36715.48046875, 36715.48046875, 36715.48046875]))\n",
      "           fun: 36715.48046875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1210\n",
      "           nit: 379\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.78952049e-01, 1.37078006e-02, 4.71218746e-03, 7.63148277e+03,\n",
      "       9.63536044e+03, 9.44519422e+03, 6.39783327e+03])\n",
      "best ll: 56431.625, bestParams: [tensor(0.2947), tensor(0.0923), tensor(0.0606), tensor(13147.8906), tensor(13096.7285), tensor(13650.6895), tensor(19362.8066)]\n",
      "epoch 4\n",
      " final_simplex: (array([[9.02816558e-01, 5.88968548e-02, 3.77182301e-02, 6.21629757e+03,\n",
      "        1.09123582e+04, 1.00701480e+04, 2.55476356e+04],\n",
      "       [9.02816558e-01, 5.88968547e-02, 3.77182302e-02, 6.21629755e+03,\n",
      "        1.09123582e+04, 1.00701480e+04, 2.55476355e+04],\n",
      "       [9.02816557e-01, 5.88968548e-02, 3.77182303e-02, 6.21629755e+03,\n",
      "        1.09123582e+04, 1.00701480e+04, 2.55476355e+04],\n",
      "       [9.02816558e-01, 5.88968547e-02, 3.77182302e-02, 6.21629757e+03,\n",
      "        1.09123582e+04, 1.00701480e+04, 2.55476355e+04],\n",
      "       [9.02816557e-01, 5.88968548e-02, 3.77182303e-02, 6.21629755e+03,\n",
      "        1.09123582e+04, 1.00701480e+04, 2.55476355e+04],\n",
      "       [9.02816557e-01, 5.88968548e-02, 3.77182301e-02, 6.21629757e+03,\n",
      "        1.09123582e+04, 1.00701480e+04, 2.55476355e+04],\n",
      "       [9.02816558e-01, 5.88968547e-02, 3.77182301e-02, 6.21629759e+03,\n",
      "        1.09123582e+04, 1.00701480e+04, 2.55476356e+04],\n",
      "       [9.02816558e-01, 5.88968547e-02, 3.77182302e-02, 6.21629755e+03,\n",
      "        1.09123582e+04, 1.00701480e+04, 2.55476355e+04]]), array([38366.01953125, 38366.01953125, 38366.01953125, 38366.01953125,\n",
      "       38366.01953125, 38366.01953125, 38366.01953125, 38366.01953125]))\n",
      "           fun: 38366.01953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1245\n",
      "           nit: 384\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.02816558e-01, 5.88968548e-02, 3.77182301e-02, 6.21629757e+03,\n",
      "       1.09123582e+04, 1.00701480e+04, 2.55476356e+04])\n",
      "minPrevious 36715.48046875\n",
      "best ll: 55361.7421875, bestParams: [tensor(0.3411), tensor(0.0546), tensor(0.0405), tensor(24479.9883), tensor(18767.4570), tensor(12365.8516), tensor(11743.1582)]\n",
      "epoch 5\n",
      " final_simplex: (array([[9.37837280e-01, 2.87304104e-02, 3.20987698e-02, 1.08803967e+04,\n",
      "        1.44482345e+04, 1.42445695e+04, 7.62915103e+03],\n",
      "       [9.37837281e-01, 2.87304102e-02, 3.20987696e-02, 1.08803967e+04,\n",
      "        1.44482344e+04, 1.42445695e+04, 7.62915105e+03],\n",
      "       [9.37837280e-01, 2.87304104e-02, 3.20987699e-02, 1.08803967e+04,\n",
      "        1.44482345e+04, 1.42445694e+04, 7.62915101e+03],\n",
      "       [9.37837281e-01, 2.87304103e-02, 3.20987699e-02, 1.08803966e+04,\n",
      "        1.44482345e+04, 1.42445694e+04, 7.62915099e+03],\n",
      "       [9.37837280e-01, 2.87304103e-02, 3.20987699e-02, 1.08803967e+04,\n",
      "        1.44482345e+04, 1.42445695e+04, 7.62915096e+03],\n",
      "       [9.37837281e-01, 2.87304104e-02, 3.20987698e-02, 1.08803967e+04,\n",
      "        1.44482345e+04, 1.42445694e+04, 7.62915098e+03],\n",
      "       [9.37837281e-01, 2.87304101e-02, 3.20987697e-02, 1.08803967e+04,\n",
      "        1.44482345e+04, 1.42445696e+04, 7.62915105e+03],\n",
      "       [9.37837281e-01, 2.87304103e-02, 3.20987697e-02, 1.08803967e+04,\n",
      "        1.44482344e+04, 1.42445695e+04, 7.62915106e+03]]), array([37438.0078125, 37438.0078125, 37438.0078125, 37438.0078125,\n",
      "       37438.0078125, 37438.0078125, 37438.0078125, 37438.0078125]))\n",
      "           fun: 37438.0078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1216\n",
      "           nit: 423\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.37837280e-01, 2.87304104e-02, 3.20987698e-02, 1.08803967e+04,\n",
      "       1.44482345e+04, 1.42445695e+04, 7.62915103e+03])\n",
      "minPrevious 36715.48046875\n",
      "best ll: 56806.94921875, bestParams: [tensor(0.3222), tensor(0.1223), tensor(0.1510), tensor(24982.8887), tensor(13411.4629), tensor(18341.7598), tensor(19825.4883)]\n",
      "epoch 6\n",
      " final_simplex: (array([[8.11786513e-01, 1.11860858e-01, 7.37039048e-02, 1.78494579e+04,\n",
      "        1.45499821e+04, 1.41314622e+04, 1.58521826e+04],\n",
      "       [8.11786513e-01, 1.11860859e-01, 7.37039038e-02, 1.78494578e+04,\n",
      "        1.45499821e+04, 1.41314622e+04, 1.58521827e+04],\n",
      "       [8.11786514e-01, 1.11860858e-01, 7.37039037e-02, 1.78494579e+04,\n",
      "        1.45499821e+04, 1.41314622e+04, 1.58521827e+04],\n",
      "       [8.11786514e-01, 1.11860859e-01, 7.37039039e-02, 1.78494578e+04,\n",
      "        1.45499821e+04, 1.41314622e+04, 1.58521827e+04],\n",
      "       [8.11786514e-01, 1.11860858e-01, 7.37039040e-02, 1.78494579e+04,\n",
      "        1.45499821e+04, 1.41314622e+04, 1.58521827e+04],\n",
      "       [8.11786514e-01, 1.11860857e-01, 7.37039051e-02, 1.78494579e+04,\n",
      "        1.45499821e+04, 1.41314621e+04, 1.58521827e+04],\n",
      "       [8.11786514e-01, 1.11860858e-01, 7.37039042e-02, 1.78494578e+04,\n",
      "        1.45499821e+04, 1.41314622e+04, 1.58521827e+04],\n",
      "       [8.11786514e-01, 1.11860858e-01, 7.37039042e-02, 1.78494579e+04,\n",
      "        1.45499821e+04, 1.41314621e+04, 1.58521827e+04]]), array([40351.00390625, 40351.00390625, 40351.00390625, 40351.00390625,\n",
      "       40351.00390625, 40351.00390625, 40351.00390625, 40351.00390625]))\n",
      "           fun: 40351.00390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1276\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.11786513e-01, 1.11860858e-01, 7.37039048e-02, 1.78494579e+04,\n",
      "       1.45499821e+04, 1.41314622e+04, 1.58521826e+04])\n",
      "minPrevious 36715.48046875\n",
      "best ll: 58680.73828125, bestParams: [tensor(0.3411), tensor(0.1454), tensor(0.0212), tensor(19224.2031), tensor(11443.4785), tensor(23802.1895), tensor(3056.0166)]\n",
      "epoch 7\n",
      " final_simplex: (array([[8.61514302e-01, 1.18892630e-01, 1.86222962e-02, 1.77373121e+04,\n",
      "        1.24183295e+04, 1.21438351e+04, 2.28511644e+03],\n",
      "       [8.61514303e-01, 1.18892629e-01, 1.86222963e-02, 1.77373121e+04,\n",
      "        1.24183295e+04, 1.21438351e+04, 2.28511644e+03],\n",
      "       [8.61514302e-01, 1.18892630e-01, 1.86222962e-02, 1.77373121e+04,\n",
      "        1.24183295e+04, 1.21438352e+04, 2.28511643e+03],\n",
      "       [8.61514303e-01, 1.18892629e-01, 1.86222962e-02, 1.77373121e+04,\n",
      "        1.24183296e+04, 1.21438351e+04, 2.28511645e+03],\n",
      "       [8.61514304e-01, 1.18892629e-01, 1.86222962e-02, 1.77373121e+04,\n",
      "        1.24183296e+04, 1.21438351e+04, 2.28511644e+03],\n",
      "       [8.61514303e-01, 1.18892630e-01, 1.86222962e-02, 1.77373121e+04,\n",
      "        1.24183295e+04, 1.21438351e+04, 2.28511643e+03],\n",
      "       [8.61514302e-01, 1.18892630e-01, 1.86222962e-02, 1.77373121e+04,\n",
      "        1.24183295e+04, 1.21438352e+04, 2.28511643e+03],\n",
      "       [8.61514301e-01, 1.18892631e-01, 1.86222962e-02, 1.77373121e+04,\n",
      "        1.24183295e+04, 1.21438352e+04, 2.28511642e+03]]), array([39220.4609375, 39220.4609375, 39220.4609375, 39220.4609375,\n",
      "       39220.4609375, 39220.4609375, 39220.4609375, 39220.4609375]))\n",
      "           fun: 39220.4609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1233\n",
      "           nit: 416\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.61514302e-01, 1.18892630e-01, 1.86222962e-02, 1.77373121e+04,\n",
      "       1.24183295e+04, 1.21438351e+04, 2.28511644e+03])\n",
      "minPrevious 36715.48046875\n",
      "best ll: 58962.3828125, bestParams: [tensor(0.2647), tensor(0.0024), tensor(0.2204), tensor(13814.9961), tensor(10834.6230), tensor(13213.3682), tensor(23196.8867)]\n",
      "epoch 8\n",
      " final_simplex: (array([[9.95165233e-01, 1.94814933e-03, 1.88307861e-03, 2.98540577e+03,\n",
      "        1.40508558e+04, 1.30643345e+04, 7.91451386e+03],\n",
      "       [9.95165233e-01, 1.94814936e-03, 1.88307779e-03, 2.98540571e+03,\n",
      "        1.40508558e+04, 1.30643345e+04, 7.91451385e+03],\n",
      "       [9.95165233e-01, 1.94814935e-03, 1.88307791e-03, 2.98540568e+03,\n",
      "        1.40508557e+04, 1.30643346e+04, 7.91451389e+03],\n",
      "       [9.95165232e-01, 1.94814935e-03, 1.88307811e-03, 2.98540567e+03,\n",
      "        1.40508557e+04, 1.30643345e+04, 7.91451390e+03],\n",
      "       [9.95165233e-01, 1.94814934e-03, 1.88307803e-03, 2.98540569e+03,\n",
      "        1.40508557e+04, 1.30643346e+04, 7.91451389e+03],\n",
      "       [9.95165233e-01, 1.94814935e-03, 1.88307808e-03, 2.98540569e+03,\n",
      "        1.40508557e+04, 1.30643346e+04, 7.91451389e+03],\n",
      "       [9.95165233e-01, 1.94814934e-03, 1.88307807e-03, 2.98540573e+03,\n",
      "        1.40508557e+04, 1.30643346e+04, 7.91451387e+03],\n",
      "       [9.95165233e-01, 1.94814934e-03, 1.88307824e-03, 2.98540575e+03,\n",
      "        1.40508557e+04, 1.30643346e+04, 7.91451388e+03]]), array([36452.859375, 36452.859375, 36452.859375, 36452.859375,\n",
      "       36452.859375, 36452.859375, 36452.859375, 36452.859375]))\n",
      "           fun: 36452.859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1257\n",
      "           nit: 408\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.95165233e-01, 1.94814933e-03, 1.88307861e-03, 2.98540577e+03,\n",
      "       1.40508558e+04, 1.30643345e+04, 7.91451386e+03])\n",
      "minPrevious 36715.48046875\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.95165233e-01, 1.94814933e-03, 1.88307861e-03, 2.98540577e+03,\n",
      "        1.40508558e+04, 1.30643345e+04, 7.91451386e+03],\n",
      "       [9.95165233e-01, 1.94814936e-03, 1.88307779e-03, 2.98540571e+03,\n",
      "        1.40508558e+04, 1.30643345e+04, 7.91451385e+03],\n",
      "       [9.95165233e-01, 1.94814935e-03, 1.88307791e-03, 2.98540568e+03,\n",
      "        1.40508557e+04, 1.30643346e+04, 7.91451389e+03],\n",
      "       [9.95165232e-01, 1.94814935e-03, 1.88307811e-03, 2.98540567e+03,\n",
      "        1.40508557e+04, 1.30643345e+04, 7.91451390e+03],\n",
      "       [9.95165233e-01, 1.94814934e-03, 1.88307803e-03, 2.98540569e+03,\n",
      "        1.40508557e+04, 1.30643346e+04, 7.91451389e+03],\n",
      "       [9.95165233e-01, 1.94814935e-03, 1.88307808e-03, 2.98540569e+03,\n",
      "        1.40508557e+04, 1.30643346e+04, 7.91451389e+03],\n",
      "       [9.95165233e-01, 1.94814934e-03, 1.88307807e-03, 2.98540573e+03,\n",
      "        1.40508557e+04, 1.30643346e+04, 7.91451387e+03],\n",
      "       [9.95165233e-01, 1.94814934e-03, 1.88307824e-03, 2.98540575e+03,\n",
      "        1.40508557e+04, 1.30643346e+04, 7.91451388e+03]]), array([36452.859375, 36452.859375, 36452.859375, 36452.859375,\n",
      "       36452.859375, 36452.859375, 36452.859375, 36452.859375]))\n",
      "           fun: 36452.859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1257\n",
      "           nit: 408\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.95165233e-01, 1.94814933e-03, 1.88307861e-03, 2.98540577e+03,\n",
      "       1.40508558e+04, 1.30643345e+04, 7.91451386e+03])\n",
      "best ll: 56184.9765625, bestParams: [tensor(0.3122), tensor(0.1660), tensor(0.0498), tensor(23714.3301), tensor(15146.4785), tensor(15066.9717), tensor(14444.0869)]\n",
      "epoch 9\n",
      " final_simplex: (array([[8.90765645e-01, 7.48114447e-02, 3.18052408e-02, 1.91342842e+04,\n",
      "        1.34756207e+04, 1.33173022e+04, 1.06477433e+04],\n",
      "       [8.90765644e-01, 7.48114454e-02, 3.18052408e-02, 1.91342841e+04,\n",
      "        1.34756207e+04, 1.33173022e+04, 1.06477432e+04],\n",
      "       [8.90765643e-01, 7.48114454e-02, 3.18052405e-02, 1.91342841e+04,\n",
      "        1.34756207e+04, 1.33173022e+04, 1.06477433e+04],\n",
      "       [8.90765644e-01, 7.48114451e-02, 3.18052409e-02, 1.91342841e+04,\n",
      "        1.34756207e+04, 1.33173022e+04, 1.06477432e+04],\n",
      "       [8.90765644e-01, 7.48114453e-02, 3.18052408e-02, 1.91342842e+04,\n",
      "        1.34756207e+04, 1.33173022e+04, 1.06477432e+04],\n",
      "       [8.90765643e-01, 7.48114454e-02, 3.18052406e-02, 1.91342841e+04,\n",
      "        1.34756207e+04, 1.33173022e+04, 1.06477433e+04],\n",
      "       [8.90765644e-01, 7.48114454e-02, 3.18052407e-02, 1.91342841e+04,\n",
      "        1.34756207e+04, 1.33173022e+04, 1.06477433e+04],\n",
      "       [8.90765644e-01, 7.48114453e-02, 3.18052407e-02, 1.91342841e+04,\n",
      "        1.34756207e+04, 1.33173022e+04, 1.06477433e+04]]), array([38637.7734375, 38637.7734375, 38637.7734375, 38637.7734375,\n",
      "       38637.7734375, 38637.7734375, 38637.7734375, 38637.7734375]))\n",
      "           fun: 38637.7734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1210\n",
      "           nit: 409\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.90765645e-01, 7.48114447e-02, 3.18052408e-02, 1.91342842e+04,\n",
      "       1.34756207e+04, 1.33173022e+04, 1.06477433e+04])\n",
      "minPrevious 36452.859375\n",
      "best ll: 52966.68359375, bestParams: [tensor(0.4019), tensor(0.0192), tensor(0.1351), tensor(12451.3096), tensor(16823.7090), tensor(23230.6738), tensor(4964.8633)]\n",
      "epoch 10\n",
      " final_simplex: (array([[8.64835577e-01, 1.31472684e-02, 1.07470250e-01, 1.20070157e+04,\n",
      "        1.78509295e+04, 1.62582548e+04, 3.67162582e+03],\n",
      "       [8.64835578e-01, 1.31472684e-02, 1.07470250e-01, 1.20070157e+04,\n",
      "        1.78509294e+04, 1.62582548e+04, 3.67162582e+03],\n",
      "       [8.64835576e-01, 1.31472684e-02, 1.07470250e-01, 1.20070157e+04,\n",
      "        1.78509295e+04, 1.62582548e+04, 3.67162583e+03],\n",
      "       [8.64835577e-01, 1.31472684e-02, 1.07470250e-01, 1.20070157e+04,\n",
      "        1.78509295e+04, 1.62582548e+04, 3.67162582e+03],\n",
      "       [8.64835579e-01, 1.31472683e-02, 1.07470250e-01, 1.20070157e+04,\n",
      "        1.78509294e+04, 1.62582548e+04, 3.67162581e+03],\n",
      "       [8.64835577e-01, 1.31472684e-02, 1.07470250e-01, 1.20070157e+04,\n",
      "        1.78509294e+04, 1.62582548e+04, 3.67162582e+03],\n",
      "       [8.64835577e-01, 1.31472684e-02, 1.07470250e-01, 1.20070157e+04,\n",
      "        1.78509294e+04, 1.62582548e+04, 3.67162582e+03],\n",
      "       [8.64835578e-01, 1.31472684e-02, 1.07470250e-01, 1.20070156e+04,\n",
      "        1.78509294e+04, 1.62582549e+04, 3.67162582e+03]]), array([38807.66796875, 38807.66796875, 38807.66796875, 38807.66796875,\n",
      "       38807.66796875, 38807.66796875, 38807.66796875, 38807.66796875]))\n",
      "           fun: 38807.66796875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1238\n",
      "           nit: 414\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.64835577e-01, 1.31472684e-02, 1.07470250e-01, 1.20070157e+04,\n",
      "       1.78509295e+04, 1.62582548e+04, 3.67162582e+03])\n",
      "minPrevious 36452.859375\n",
      "best ll: 58246.4609375, bestParams: [tensor(0.2770), tensor(0.0614), tensor(0.1181), tensor(16437.6777), tensor(20904.6797), tensor(15499.6660), tensor(23630.4102)]\n",
      "epoch 11\n",
      " final_simplex: (array([[8.79281802e-01, 3.55118481e-02, 8.09129390e-02, 1.13897449e+04,\n",
      "        1.40745561e+04, 1.64584132e+04, 1.68218719e+04],\n",
      "       [8.79281802e-01, 3.55118482e-02, 8.09129392e-02, 1.13897448e+04,\n",
      "        1.40745561e+04, 1.64584132e+04, 1.68218719e+04],\n",
      "       [8.79281802e-01, 3.55118481e-02, 8.09129390e-02, 1.13897448e+04,\n",
      "        1.40745560e+04, 1.64584132e+04, 1.68218719e+04],\n",
      "       [8.79281802e-01, 3.55118481e-02, 8.09129391e-02, 1.13897448e+04,\n",
      "        1.40745561e+04, 1.64584132e+04, 1.68218719e+04],\n",
      "       [8.79281801e-01, 3.55118482e-02, 8.09129391e-02, 1.13897448e+04,\n",
      "        1.40745561e+04, 1.64584132e+04, 1.68218719e+04],\n",
      "       [8.79281801e-01, 3.55118481e-02, 8.09129392e-02, 1.13897448e+04,\n",
      "        1.40745561e+04, 1.64584132e+04, 1.68218720e+04],\n",
      "       [8.79281803e-01, 3.55118482e-02, 8.09129391e-02, 1.13897448e+04,\n",
      "        1.40745561e+04, 1.64584132e+04, 1.68218718e+04],\n",
      "       [8.79281803e-01, 3.55118481e-02, 8.09129390e-02, 1.13897448e+04,\n",
      "        1.40745561e+04, 1.64584132e+04, 1.68218719e+04]]), array([38908.52734375, 38908.52734375, 38908.52734375, 38908.52734375,\n",
      "       38908.52734375, 38908.52734375, 38908.52734375, 38908.52734375]))\n",
      "           fun: 38908.52734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1280\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.79281802e-01, 3.55118481e-02, 8.09129390e-02, 1.13897449e+04,\n",
      "       1.40745561e+04, 1.64584132e+04, 1.68218719e+04])\n",
      "minPrevious 36452.859375\n",
      "best ll: 58947.6328125, bestParams: [tensor(0.2755), tensor(0.1487), tensor(0.1999), tensor(12077.7695), tensor(13481.3076), tensor(14855.7500), tensor(20141.8281)]\n",
      "epoch 12\n",
      " final_simplex: (array([[9.29705370e-01, 6.31686201e-02, 7.15149031e-04, 6.81508579e+03,\n",
      "        1.56455172e+04, 1.38900754e+04, 1.93722163e+04],\n",
      "       [9.29705367e-01, 6.31686197e-02, 7.15152514e-04, 6.81508587e+03,\n",
      "        1.56455172e+04, 1.38900754e+04, 1.93722162e+04],\n",
      "       [9.29705367e-01, 6.31686193e-02, 7.15152816e-04, 6.81508581e+03,\n",
      "        1.56455172e+04, 1.38900754e+04, 1.93722162e+04],\n",
      "       [9.29705368e-01, 6.31686204e-02, 7.15150563e-04, 6.81508581e+03,\n",
      "        1.56455172e+04, 1.38900754e+04, 1.93722163e+04],\n",
      "       [9.29705368e-01, 6.31686204e-02, 7.15150955e-04, 6.81508586e+03,\n",
      "        1.56455172e+04, 1.38900754e+04, 1.93722162e+04],\n",
      "       [9.29705368e-01, 6.31686204e-02, 7.15150291e-04, 6.81508585e+03,\n",
      "        1.56455172e+04, 1.38900754e+04, 1.93722162e+04],\n",
      "       [9.29705369e-01, 6.31686200e-02, 7.15150233e-04, 6.81508586e+03,\n",
      "        1.56455173e+04, 1.38900753e+04, 1.93722162e+04],\n",
      "       [9.29705369e-01, 6.31686200e-02, 7.15150294e-04, 6.81508587e+03,\n",
      "        1.56455172e+04, 1.38900753e+04, 1.93722162e+04]]), array([37673.50390625, 37673.50390625, 37673.50390625, 37673.50390625,\n",
      "       37673.50390625, 37673.50390625, 37673.50390625, 37673.50390625]))\n",
      "           fun: 37673.50390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1262\n",
      "           nit: 457\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.29705370e-01, 6.31686201e-02, 7.15149031e-04, 6.81508579e+03,\n",
      "       1.56455172e+04, 1.38900754e+04, 1.93722163e+04])\n",
      "minPrevious 36452.859375\n",
      "best ll: 57506.24609375, bestParams: [tensor(0.2825), tensor(0.0364), tensor(0.0580), tensor(5568.8169), tensor(13101.4443), tensor(9288.4893), tensor(106.5466)]\n",
      "epoch 13\n",
      " final_simplex: (array([[9.73303898e-01, 2.02107114e-02, 1.77979619e-03, 1.80299985e+03,\n",
      "        1.32952846e+04, 1.43976787e+04, 2.94843373e+01],\n",
      "       [9.73303899e-01, 2.02107115e-02, 1.77979574e-03, 1.80299986e+03,\n",
      "        1.32952846e+04, 1.43976788e+04, 2.94843367e+01],\n",
      "       [9.73303898e-01, 2.02107112e-02, 1.77979667e-03, 1.80299981e+03,\n",
      "        1.32952846e+04, 1.43976788e+04, 2.94843375e+01],\n",
      "       [9.73303900e-01, 2.02107113e-02, 1.77979610e-03, 1.80299983e+03,\n",
      "        1.32952846e+04, 1.43976788e+04, 2.94843370e+01],\n",
      "       [9.73303898e-01, 2.02107115e-02, 1.77979604e-03, 1.80299987e+03,\n",
      "        1.32952846e+04, 1.43976788e+04, 2.94843367e+01],\n",
      "       [9.73303899e-01, 2.02107114e-02, 1.77979609e-03, 1.80299984e+03,\n",
      "        1.32952846e+04, 1.43976788e+04, 2.94843369e+01],\n",
      "       [9.73303899e-01, 2.02107114e-02, 1.77979618e-03, 1.80299984e+03,\n",
      "        1.32952846e+04, 1.43976788e+04, 2.94843369e+01],\n",
      "       [9.73303899e-01, 2.02107114e-02, 1.77979614e-03, 1.80299984e+03,\n",
      "        1.32952846e+04, 1.43976787e+04, 2.94843371e+01]]), array([36903.67578125, 36903.67578125, 36903.67578125, 36903.67578125,\n",
      "       36903.67578125, 36903.67578125, 36903.67578125, 36903.67578125]))\n",
      "           fun: 36903.67578125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1260\n",
      "           nit: 410\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.73303898e-01, 2.02107114e-02, 1.77979619e-03, 1.80299985e+03,\n",
      "       1.32952846e+04, 1.43976787e+04, 2.94843373e+01])\n",
      "minPrevious 36452.859375\n",
      "best ll: 56522.17578125, bestParams: [tensor(0.3021), tensor(0.0793), tensor(0.1093), tensor(15420.5781), tensor(4678.1631), tensor(5288.1880), tensor(4072.0754)]\n",
      "epoch 14\n",
      " final_simplex: (array([[9.23624111e-01, 4.00589043e-02, 3.31488383e-02, 1.33499096e+04,\n",
      "        4.01985755e+03, 4.27231334e+03, 3.96083582e+03],\n",
      "       [9.23624111e-01, 4.00589044e-02, 3.31488382e-02, 1.33499095e+04,\n",
      "        4.01985755e+03, 4.27231334e+03, 3.96083583e+03],\n",
      "       [9.23624110e-01, 4.00589045e-02, 3.31488387e-02, 1.33499096e+04,\n",
      "        4.01985756e+03, 4.27231333e+03, 3.96083581e+03],\n",
      "       [9.23624110e-01, 4.00589044e-02, 3.31488386e-02, 1.33499096e+04,\n",
      "        4.01985756e+03, 4.27231333e+03, 3.96083581e+03],\n",
      "       [9.23624110e-01, 4.00589044e-02, 3.31488385e-02, 1.33499095e+04,\n",
      "        4.01985756e+03, 4.27231334e+03, 3.96083582e+03],\n",
      "       [9.23624110e-01, 4.00589046e-02, 3.31488387e-02, 1.33499095e+04,\n",
      "        4.01985756e+03, 4.27231334e+03, 3.96083582e+03],\n",
      "       [9.23624111e-01, 4.00589044e-02, 3.31488384e-02, 1.33499095e+04,\n",
      "        4.01985756e+03, 4.27231334e+03, 3.96083583e+03],\n",
      "       [9.23624111e-01, 4.00589043e-02, 3.31488381e-02, 1.33499096e+04,\n",
      "        4.01985755e+03, 4.27231334e+03, 3.96083582e+03]]), array([37989.94140625, 37989.94140625, 37989.94140625, 37989.94140625,\n",
      "       37989.94140625, 37989.94140625, 37989.94140625, 37989.94140625]))\n",
      "           fun: 37989.94140625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1293\n",
      "           nit: 455\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.23624111e-01, 4.00589043e-02, 3.31488383e-02, 1.33499096e+04,\n",
      "       4.01985755e+03, 4.27231334e+03, 3.96083582e+03])\n",
      "minPrevious 36452.859375\n",
      "best ll: 54739.1328125, bestParams: [tensor(0.3356), tensor(0.0860), tensor(0.0133), tensor(18191.0234), tensor(24530.7949), tensor(18050.4629), tensor(627.7850)]\n",
      "epoch 15\n",
      " final_simplex: (array([[8.95634726e-01, 8.92192309e-02, 1.37763785e-02, 1.00159861e+04,\n",
      "        1.88901734e+04, 2.00954174e+04, 1.94634526e+02],\n",
      "       [8.95634727e-01, 8.92192307e-02, 1.37763784e-02, 1.00159862e+04,\n",
      "        1.88901734e+04, 2.00954174e+04, 1.94634533e+02],\n",
      "       [8.95634727e-01, 8.92192311e-02, 1.37763786e-02, 1.00159861e+04,\n",
      "        1.88901734e+04, 2.00954174e+04, 1.94634526e+02],\n",
      "       [8.95634727e-01, 8.92192310e-02, 1.37763785e-02, 1.00159861e+04,\n",
      "        1.88901735e+04, 2.00954174e+04, 1.94634528e+02],\n",
      "       [8.95634726e-01, 8.92192314e-02, 1.37763785e-02, 1.00159861e+04,\n",
      "        1.88901735e+04, 2.00954174e+04, 1.94634530e+02],\n",
      "       [8.95634727e-01, 8.92192312e-02, 1.37763785e-02, 1.00159861e+04,\n",
      "        1.88901734e+04, 2.00954175e+04, 1.94634528e+02],\n",
      "       [8.95634726e-01, 8.92192314e-02, 1.37763784e-02, 1.00159861e+04,\n",
      "        1.88901735e+04, 2.00954174e+04, 1.94634533e+02],\n",
      "       [8.95634726e-01, 8.92192313e-02, 1.37763785e-02, 1.00159861e+04,\n",
      "        1.88901735e+04, 2.00954174e+04, 1.94634531e+02]]), array([38248.15625, 38248.15625, 38248.15625, 38248.15625, 38248.15625,\n",
      "       38248.15625, 38248.15625, 38248.15625]))\n",
      "           fun: 38248.15625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1153\n",
      "           nit: 388\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.95634726e-01, 8.92192309e-02, 1.37763785e-02, 1.00159861e+04,\n",
      "       1.88901734e+04, 2.00954174e+04, 1.94634526e+02])\n",
      "minPrevious 36452.859375\n",
      "best ll: 56127.4375, bestParams: [tensor(0.3126), tensor(0.0930), tensor(0.0878), tensor(11055.4268), tensor(24489.9180), tensor(18859.9043), tensor(24223.3301)]\n",
      "epoch 16\n",
      " final_simplex: (array([[8.73919242e-01, 6.85250113e-02, 5.36032734e-02, 5.09888542e+03,\n",
      "        1.80148888e+04, 1.93567480e+04, 1.95379837e+04],\n",
      "       [8.73919240e-01, 6.85250118e-02, 5.36032737e-02, 5.09888543e+03,\n",
      "        1.80148887e+04, 1.93567480e+04, 1.95379837e+04],\n",
      "       [8.73919243e-01, 6.85250113e-02, 5.36032736e-02, 5.09888537e+03,\n",
      "        1.80148887e+04, 1.93567480e+04, 1.95379837e+04],\n",
      "       [8.73919243e-01, 6.85250113e-02, 5.36032736e-02, 5.09888541e+03,\n",
      "        1.80148887e+04, 1.93567480e+04, 1.95379837e+04],\n",
      "       [8.73919240e-01, 6.85250116e-02, 5.36032735e-02, 5.09888543e+03,\n",
      "        1.80148888e+04, 1.93567479e+04, 1.95379837e+04],\n",
      "       [8.73919241e-01, 6.85250115e-02, 5.36032735e-02, 5.09888543e+03,\n",
      "        1.80148888e+04, 1.93567479e+04, 1.95379837e+04],\n",
      "       [8.73919240e-01, 6.85250118e-02, 5.36032736e-02, 5.09888544e+03,\n",
      "        1.80148888e+04, 1.93567479e+04, 1.95379837e+04],\n",
      "       [8.73919243e-01, 6.85250113e-02, 5.36032737e-02, 5.09888538e+03,\n",
      "        1.80148887e+04, 1.93567480e+04, 1.95379837e+04]]), array([38689.4296875, 38689.4296875, 38689.4296875, 38689.4296875,\n",
      "       38689.4296875, 38689.4296875, 38689.4296875, 38689.4296875]))\n",
      "           fun: 38689.4296875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1270\n",
      "           nit: 448\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.73919242e-01, 6.85250113e-02, 5.36032734e-02, 5.09888542e+03,\n",
      "       1.80148888e+04, 1.93567480e+04, 1.95379837e+04])\n",
      "minPrevious 36452.859375\n",
      "best ll: 58765.109375, bestParams: [tensor(0.2692), tensor(0.1813), tensor(0.0871), tensor(12890.2432), tensor(8230.7090), tensor(7503.1523), tensor(20913.3320)]\n",
      "epoch 17\n",
      " final_simplex: (array([[9.48203375e-01, 5.47133935e-04, 5.07834777e-02, 4.56114829e+03,\n",
      "        2.78163347e+03, 2.71336125e+03, 3.52017339e+04],\n",
      "       [9.48203375e-01, 5.47133665e-04, 5.07834775e-02, 4.56114828e+03,\n",
      "        2.78163347e+03, 2.71336125e+03, 3.52017339e+04],\n",
      "       [9.48203376e-01, 5.47133716e-04, 5.07834771e-02, 4.56114824e+03,\n",
      "        2.78163347e+03, 2.71336125e+03, 3.52017340e+04],\n",
      "       [9.48203375e-01, 5.47133832e-04, 5.07834775e-02, 4.56114828e+03,\n",
      "        2.78163347e+03, 2.71336124e+03, 3.52017339e+04],\n",
      "       [9.48203375e-01, 5.47133900e-04, 5.07834777e-02, 4.56114831e+03,\n",
      "        2.78163347e+03, 2.71336125e+03, 3.52017339e+04],\n",
      "       [9.48203374e-01, 5.47134284e-04, 5.07834780e-02, 4.56114832e+03,\n",
      "        2.78163348e+03, 2.71336125e+03, 3.52017338e+04],\n",
      "       [9.48203375e-01, 5.47133597e-04, 5.07834775e-02, 4.56114828e+03,\n",
      "        2.78163347e+03, 2.71336126e+03, 3.52017339e+04],\n",
      "       [9.48203375e-01, 5.47133651e-04, 5.07834775e-02, 4.56114828e+03,\n",
      "        2.78163347e+03, 2.71336126e+03, 3.52017339e+04]]), array([37517.609375, 37517.609375, 37517.609375, 37517.609375,\n",
      "       37517.609375, 37517.609375, 37517.609375, 37517.609375]))\n",
      "           fun: 37517.609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1396\n",
      "           nit: 499\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.48203375e-01, 5.47133935e-04, 5.07834777e-02, 4.56114829e+03,\n",
      "       2.78163347e+03, 2.71336125e+03, 3.52017339e+04])\n",
      "minPrevious 36452.859375\n",
      "best ll: 56201.40625, bestParams: [tensor(0.3126), tensor(0.0537), tensor(0.1970), tensor(21582.7930), tensor(17173.8691), tensor(18663.8555), tensor(4950.1895)]\n",
      "epoch 18\n",
      " final_simplex: (array([[8.46462301e-01, 3.19838731e-02, 1.19268091e-01, 1.79675995e+04,\n",
      "        1.84871268e+04, 1.45367221e+04, 2.41050006e+03],\n",
      "       [8.46462301e-01, 3.19838731e-02, 1.19268091e-01, 1.79675995e+04,\n",
      "        1.84871268e+04, 1.45367221e+04, 2.41050006e+03],\n",
      "       [8.46462302e-01, 3.19838732e-02, 1.19268090e-01, 1.79675994e+04,\n",
      "        1.84871268e+04, 1.45367221e+04, 2.41050005e+03],\n",
      "       [8.46462299e-01, 3.19838738e-02, 1.19268091e-01, 1.79675995e+04,\n",
      "        1.84871268e+04, 1.45367221e+04, 2.41050006e+03],\n",
      "       [8.46462302e-01, 3.19838729e-02, 1.19268090e-01, 1.79675995e+04,\n",
      "        1.84871268e+04, 1.45367221e+04, 2.41050008e+03],\n",
      "       [8.46462302e-01, 3.19838731e-02, 1.19268090e-01, 1.79675994e+04,\n",
      "        1.84871268e+04, 1.45367221e+04, 2.41050007e+03],\n",
      "       [8.46462301e-01, 3.19838731e-02, 1.19268091e-01, 1.79675995e+04,\n",
      "        1.84871268e+04, 1.45367220e+04, 2.41050005e+03],\n",
      "       [8.46462301e-01, 3.19838731e-02, 1.19268091e-01, 1.79675995e+04,\n",
      "        1.84871269e+04, 1.45367220e+04, 2.41050005e+03]]), array([39842.8828125, 39842.8828125, 39842.8828125, 39842.8828125,\n",
      "       39842.8828125, 39842.8828125, 39842.8828125, 39842.8828125]))\n",
      "           fun: 39842.8828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1215\n",
      "           nit: 426\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.46462301e-01, 3.19838731e-02, 1.19268091e-01, 1.79675995e+04,\n",
      "       1.84871268e+04, 1.45367221e+04, 2.41050006e+03])\n",
      "minPrevious 36452.859375\n",
      "best ll: 55684.67578125, bestParams: [tensor(0.3393), tensor(0.0717), tensor(0.0908), tensor(335.9926), tensor(15181.1211), tensor(10366.1777), tensor(11121.7246)]\n",
      "epoch 19\n",
      " final_simplex: (array([[9.05732424e-01, 5.52317499e-02, 3.74113721e-02, 1.35311555e+02,\n",
      "        1.20892306e+04, 1.41961865e+04, 7.63209992e+03],\n",
      "       [9.05732424e-01, 5.52317491e-02, 3.74113720e-02, 1.35311553e+02,\n",
      "        1.20892306e+04, 1.41961865e+04, 7.63210000e+03],\n",
      "       [9.05732423e-01, 5.52317491e-02, 3.74113720e-02, 1.35311553e+02,\n",
      "        1.20892306e+04, 1.41961865e+04, 7.63210002e+03],\n",
      "       [9.05732424e-01, 5.52317491e-02, 3.74113720e-02, 1.35311553e+02,\n",
      "        1.20892305e+04, 1.41961865e+04, 7.63210002e+03],\n",
      "       [9.05732425e-01, 5.52317498e-02, 3.74113721e-02, 1.35311555e+02,\n",
      "        1.20892306e+04, 1.41961865e+04, 7.63209991e+03],\n",
      "       [9.05732424e-01, 5.52317497e-02, 3.74113721e-02, 1.35311555e+02,\n",
      "        1.20892305e+04, 1.41961865e+04, 7.63209995e+03],\n",
      "       [9.05732423e-01, 5.52317499e-02, 3.74113720e-02, 1.35311556e+02,\n",
      "        1.20892305e+04, 1.41961865e+04, 7.63209994e+03],\n",
      "       [9.05732425e-01, 5.52317492e-02, 3.74113721e-02, 1.35311553e+02,\n",
      "        1.20892306e+04, 1.41961866e+04, 7.63209996e+03]]), array([38556.62109375, 38556.62109375, 38556.62109375, 38556.62109375,\n",
      "       38556.62109375, 38556.62109375, 38556.62109375, 38556.62109375]))\n",
      "           fun: 38556.62109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1218\n",
      "           nit: 401\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.05732424e-01, 5.52317499e-02, 3.74113721e-02, 1.35311555e+02,\n",
      "       1.20892306e+04, 1.41961865e+04, 7.63209992e+03])\n",
      "minPrevious 36452.859375\n",
      "inferredPis tensor([0.9952, 0.0019, 0.0019], dtype=torch.float64)\n",
      "inferredAlphas tensor([ 2985.4058, 14050.8558, 13064.3345,  7914.5139], dtype=torch.float64)\n",
      "truth0 tensor(0.7519) truth1 tensor(0.1111) truth2 tensor(0.1121) truthBoth tensor(0.0250)\n",
      "params on run 5 {'lls': [58132.7578125, 61020.8984375, 62816.03125, 61310.28125, 59964.953125, 47473.921875, 47433.734375, 47816.32421875, 47210.3984375, 51822.578125, 51970.546875, 47609.4609375, 52364.7734375, 53773.0390625, 47233.921875, 36342.86328125, 36234.44921875, 36770.3828125, 36826.53125, 36796.37109375, 36452.859375], 'inferredAlphas': [tensor([17771.7538,   267.5774,   285.4237, 19323.4289], dtype=torch.float64), tensor([17391.5067,   389.1159,   504.1465, 38945.6315], dtype=torch.float64), tensor([26599.6834,   330.5187,   522.2450, 20474.0527], dtype=torch.float64), tensor([17159.0905,   229.1438,   192.1196, 23702.7612], dtype=torch.float64), tensor([14365.2776,   353.8587,   277.5095, 36615.7416], dtype=torch.float64), tensor([4681.1768, 1514.9906,  279.5278, 6430.2365], dtype=torch.float64), tensor([11636.0228,  1941.4431,   317.7839,  2432.4090], dtype=torch.float64), tensor([3466.6976,  105.4401,  574.8790,  884.2902], dtype=torch.float64), tensor([  190.1304,   255.3843,  1367.9433, 10051.6183], dtype=torch.float64), tensor([13347.1036,  2995.2070,   679.1869,  9964.7306], dtype=torch.float64), tensor([3050.1159,  274.5893, 1270.7564, 7251.8219], dtype=torch.float64), tensor([1902.8937,  238.1495, 1249.7712, 7914.4684], dtype=torch.float64), tensor([20414.2533,  1255.3286,  5495.8171, 24486.6440], dtype=torch.float64), tensor([ 5422.4410,  1070.5042,  5035.1884, 34394.7350], dtype=torch.float64), tensor([6116.3640, 1549.1665,  277.2773, 5735.0947], dtype=torch.float64), tensor([ 3252.4160, 17197.7572, 17440.7641, 20021.9416], dtype=torch.float64), tensor([7562.1733, 8368.3120, 8779.7352, 8746.4345], dtype=torch.float64), tensor([24233.9895, 13108.5658, 12119.1812, 10209.1235], dtype=torch.float64), tensor([7396.8446, 8201.6473, 8380.9128, 7312.5791], dtype=torch.float64), tensor([11581.3164, 13430.0547, 13532.5939,  8888.3734], dtype=torch.float64), tensor([ 2985.4058, 14050.8558, 13064.3345,  7914.5139], dtype=torch.float64)], 'inferredPis': [tensor([0.2745, 0.5123, 0.0037], dtype=torch.float64), tensor([0.2424, 0.2423, 0.0335], dtype=torch.float64), tensor([0.2477, 0.1574, 0.0414], dtype=torch.float64), tensor([0.2670, 0.3576, 0.1152], dtype=torch.float64), tensor([0.4350, 0.2494, 0.0647], dtype=torch.float64), tensor([0.1319, 0.8504, 0.0173], dtype=torch.float64), tensor([0.1121, 0.8709, 0.0016], dtype=torch.float64), tensor([0.7272, 0.2531, 0.0189], dtype=torch.float64), tensor([0.8014, 0.1978, 0.0008], dtype=torch.float64), tensor([0.1527, 0.5340, 0.0406], dtype=torch.float64), tensor([4.4252e-01, 2.4141e-01, 6.9015e-05], dtype=torch.float64), tensor([0.7311, 0.2567, 0.0100], dtype=torch.float64), tensor([0.4108, 0.3023, 0.0150], dtype=torch.float64), tensor([0.4187, 0.1117, 0.0518], dtype=torch.float64), tensor([0.2033, 0.7863, 0.0045], dtype=torch.float64), tensor([0.9651, 0.0301, 0.0021], dtype=torch.float64), tensor([0.9906, 0.0041, 0.0032], dtype=torch.float64), tensor([9.9493e-01, 2.2532e-03, 5.0930e-04], dtype=torch.float64), tensor([0.9840, 0.0037, 0.0093], dtype=torch.float64), tensor([0.9764, 0.0103, 0.0102], dtype=torch.float64), tensor([0.9952, 0.0019, 0.0019], dtype=torch.float64)], 'inferredPDVs': [tensor([0.4720, 0.0071, 0.0076, 0.5133], dtype=torch.float64), tensor([0.3039, 0.0068, 0.0088, 0.6805], dtype=torch.float64), tensor([0.5550, 0.0069, 0.0109, 0.4272], dtype=torch.float64), tensor([0.4156, 0.0056, 0.0047, 0.5742], dtype=torch.float64), tensor([0.2783, 0.0069, 0.0054, 0.7095], dtype=torch.float64), tensor([0.3627, 0.1174, 0.0217, 0.4982], dtype=torch.float64), tensor([0.7126, 0.1189, 0.0195, 0.1490], dtype=torch.float64), tensor([0.6890, 0.0210, 0.1143, 0.1758], dtype=torch.float64), tensor([0.0160, 0.0215, 0.1153, 0.8471], dtype=torch.float64), tensor([0.4945, 0.1110, 0.0252, 0.3693], dtype=torch.float64), tensor([0.2575, 0.0232, 0.1073, 0.6120], dtype=torch.float64), tensor([0.1683, 0.0210, 0.1106, 0.7001], dtype=torch.float64), tensor([0.3952, 0.0243, 0.1064, 0.4741], dtype=torch.float64), tensor([0.1181, 0.0233, 0.1096, 0.7490], dtype=torch.float64), tensor([0.4472, 0.1133, 0.0203, 0.4192], dtype=torch.float64), tensor([0.0562, 0.2969, 0.3011, 0.3458], dtype=torch.float64), tensor([0.2260, 0.2501, 0.2624, 0.2614], dtype=torch.float64), tensor([0.4061, 0.2197, 0.2031, 0.1711], dtype=torch.float64), tensor([0.2364, 0.2621, 0.2678, 0.2337], dtype=torch.float64), tensor([0.2442, 0.2832, 0.2853, 0.1874], dtype=torch.float64), tensor([0.0785, 0.3696, 0.3436, 0.2082], dtype=torch.float64)], 'trueMeanPDVs': [tensor([0.7547, 0.1096, 0.1105, 0.0252]), tensor([0.7520, 0.1114, 0.1113, 0.0253]), tensor([0.7523, 0.1111, 0.1116, 0.0250]), tensor([0.7518, 0.1113, 0.1112, 0.0257]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7510, 0.1117, 0.1118, 0.0255]), tensor([0.7535, 0.1110, 0.1105, 0.0250]), tensor([0.7503, 0.1121, 0.1120, 0.0256]), tensor([0.7542, 0.1103, 0.1109, 0.0246]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250])], 'truePis': [tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500])]}\n",
      "tensor([[70., 12.,  0.,  1.],\n",
      "        [71.,  9.,  0.,  0.],\n",
      "        [76.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [92.,  0.,  2.,  0.],\n",
      "        [99.,  0.,  2.,  0.],\n",
      "        [75.,  2.,  0.,  0.]])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood4 at 0x7fed0e1aa320>\n",
      "best ll: 56194.8125, bestParams: [tensor(0.3132), tensor(0.0593), tensor(0.1870), tensor(6361.4092), tensor(17897.9844), tensor(18684.9570), tensor(23027.7305)]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.31752167e-01, 5.89563727e-02, 1.82475336e-01, 6.34779758e+03,\n",
      "        1.77848439e+04, 1.91922540e+04, 2.32955964e+04],\n",
      "       [3.31752167e-01, 5.89563729e-02, 1.82475336e-01, 6.34779758e+03,\n",
      "        1.77848439e+04, 1.91922541e+04, 2.32955965e+04],\n",
      "       [3.31752167e-01, 5.89563730e-02, 1.82475335e-01, 6.34779758e+03,\n",
      "        1.77848439e+04, 1.91922541e+04, 2.32955965e+04],\n",
      "       [3.31752167e-01, 5.89563729e-02, 1.82475336e-01, 6.34779758e+03,\n",
      "        1.77848440e+04, 1.91922540e+04, 2.32955965e+04],\n",
      "       [3.31752167e-01, 5.89563730e-02, 1.82475336e-01, 6.34779757e+03,\n",
      "        1.77848440e+04, 1.91922540e+04, 2.32955964e+04],\n",
      "       [3.31752167e-01, 5.89563732e-02, 1.82475336e-01, 6.34779757e+03,\n",
      "        1.77848440e+04, 1.91922540e+04, 2.32955964e+04],\n",
      "       [3.31752167e-01, 5.89563728e-02, 1.82475336e-01, 6.34779759e+03,\n",
      "        1.77848439e+04, 1.91922541e+04, 2.32955965e+04],\n",
      "       [3.31752167e-01, 5.89563730e-02, 1.82475335e-01, 6.34779759e+03,\n",
      "        1.77848440e+04, 1.91922541e+04, 2.32955965e+04]]), array([55083.5234375, 55083.5234375, 55083.5234375, 55083.5234375,\n",
      "       55083.5234375, 55083.5234375, 55083.5234375, 55083.5234375]))\n",
      "           fun: 55083.5234375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1077\n",
      "           nit: 329\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.31752167e-01, 5.89563727e-02, 1.82475336e-01, 6.34779758e+03,\n",
      "       1.77848439e+04, 1.91922540e+04, 2.32955964e+04])\n",
      "best ll: 56124.4921875, bestParams: [tensor(0.3105), tensor(0.1179), tensor(0.0802), tensor(17213.1914), tensor(17484.6406), tensor(20250.5508), tensor(12709.4609)]\n",
      "epoch 1\n",
      " final_simplex: (array([[8.26207831e-01, 1.07287973e-01, 6.45963464e-02, 1.80143493e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207825e-01, 1.07287973e-01, 6.45963470e-02, 1.80143492e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207826e-01, 1.07287973e-01, 6.45963469e-02, 1.80143493e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207827e-01, 1.07287974e-01, 6.45963469e-02, 1.80143492e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207826e-01, 1.07287973e-01, 6.45963467e-02, 1.80143493e+04,\n",
      "        1.05997344e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207828e-01, 1.07287973e-01, 6.45963469e-02, 1.80143493e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207828e-01, 1.07287973e-01, 6.45963466e-02, 1.80143493e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207828e-01, 1.07287973e-01, 6.45963469e-02, 1.80143492e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04]]), array([40239.0390625, 40239.0390625, 40239.0390625, 40239.0390625,\n",
      "       40239.0390625, 40239.0390625, 40239.0390625, 40239.0390625]))\n",
      "           fun: 40239.0390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1191\n",
      "           nit: 411\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.26207831e-01, 1.07287973e-01, 6.45963464e-02, 1.80143493e+04,\n",
      "       1.05997343e+04, 1.08421148e+04, 1.23073873e+04])\n",
      "minPrevious 55083.5234375\n",
      "better by at >= 1; new ll:  final_simplex: (array([[8.26207831e-01, 1.07287973e-01, 6.45963464e-02, 1.80143493e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207825e-01, 1.07287973e-01, 6.45963470e-02, 1.80143492e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207826e-01, 1.07287973e-01, 6.45963469e-02, 1.80143493e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207827e-01, 1.07287974e-01, 6.45963469e-02, 1.80143492e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207826e-01, 1.07287973e-01, 6.45963467e-02, 1.80143493e+04,\n",
      "        1.05997344e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207828e-01, 1.07287973e-01, 6.45963469e-02, 1.80143493e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207828e-01, 1.07287973e-01, 6.45963466e-02, 1.80143493e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04],\n",
      "       [8.26207828e-01, 1.07287973e-01, 6.45963469e-02, 1.80143492e+04,\n",
      "        1.05997343e+04, 1.08421148e+04, 1.23073873e+04]]), array([40239.0390625, 40239.0390625, 40239.0390625, 40239.0390625,\n",
      "       40239.0390625, 40239.0390625, 40239.0390625, 40239.0390625]))\n",
      "           fun: 40239.0390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1191\n",
      "           nit: 411\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.26207831e-01, 1.07287973e-01, 6.45963464e-02, 1.80143493e+04,\n",
      "       1.05997343e+04, 1.08421148e+04, 1.23073873e+04])\n",
      "best ll: 56343.87890625, bestParams: [tensor(0.3103), tensor(0.1650), tensor(0.0071), tensor(8870.8408), tensor(13883.3428), tensor(14591.3613), tensor(14284.6533)]\n",
      "epoch 2\n",
      " final_simplex: (array([[9.66837921e-01, 2.46152156e-02, 4.23176090e-03, 1.01142162e+04,\n",
      "        1.09429109e+04, 1.12699056e+04, 2.02268809e+03],\n",
      "       [9.66837920e-01, 2.46152156e-02, 4.23176092e-03, 1.01142162e+04,\n",
      "        1.09429109e+04, 1.12699056e+04, 2.02268809e+03],\n",
      "       [9.66837920e-01, 2.46152160e-02, 4.23176090e-03, 1.01142162e+04,\n",
      "        1.09429109e+04, 1.12699056e+04, 2.02268811e+03],\n",
      "       [9.66837920e-01, 2.46152158e-02, 4.23176092e-03, 1.01142162e+04,\n",
      "        1.09429110e+04, 1.12699056e+04, 2.02268807e+03],\n",
      "       [9.66837919e-01, 2.46152163e-02, 4.23176089e-03, 1.01142162e+04,\n",
      "        1.09429110e+04, 1.12699056e+04, 2.02268818e+03],\n",
      "       [9.66837921e-01, 2.46152162e-02, 4.23176089e-03, 1.01142162e+04,\n",
      "        1.09429110e+04, 1.12699056e+04, 2.02268810e+03],\n",
      "       [9.66837921e-01, 2.46152166e-02, 4.23176090e-03, 1.01142162e+04,\n",
      "        1.09429110e+04, 1.12699056e+04, 2.02268810e+03],\n",
      "       [9.66837920e-01, 2.46152166e-02, 4.23176087e-03, 1.01142162e+04,\n",
      "        1.09429110e+04, 1.12699056e+04, 2.02268819e+03]]), array([37111.68359375, 37111.68359375, 37111.68359375, 37111.68359375,\n",
      "       37111.68359375, 37111.68359375, 37111.68359375, 37111.68359375]))\n",
      "           fun: 37111.68359375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1235\n",
      "           nit: 424\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.66837921e-01, 2.46152156e-02, 4.23176090e-03, 1.01142162e+04,\n",
      "       1.09429109e+04, 1.12699056e+04, 2.02268809e+03])\n",
      "minPrevious 40239.0390625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.66837921e-01, 2.46152156e-02, 4.23176090e-03, 1.01142162e+04,\n",
      "        1.09429109e+04, 1.12699056e+04, 2.02268809e+03],\n",
      "       [9.66837920e-01, 2.46152156e-02, 4.23176092e-03, 1.01142162e+04,\n",
      "        1.09429109e+04, 1.12699056e+04, 2.02268809e+03],\n",
      "       [9.66837920e-01, 2.46152160e-02, 4.23176090e-03, 1.01142162e+04,\n",
      "        1.09429109e+04, 1.12699056e+04, 2.02268811e+03],\n",
      "       [9.66837920e-01, 2.46152158e-02, 4.23176092e-03, 1.01142162e+04,\n",
      "        1.09429110e+04, 1.12699056e+04, 2.02268807e+03],\n",
      "       [9.66837919e-01, 2.46152163e-02, 4.23176089e-03, 1.01142162e+04,\n",
      "        1.09429110e+04, 1.12699056e+04, 2.02268818e+03],\n",
      "       [9.66837921e-01, 2.46152162e-02, 4.23176089e-03, 1.01142162e+04,\n",
      "        1.09429110e+04, 1.12699056e+04, 2.02268810e+03],\n",
      "       [9.66837921e-01, 2.46152166e-02, 4.23176090e-03, 1.01142162e+04,\n",
      "        1.09429110e+04, 1.12699056e+04, 2.02268810e+03],\n",
      "       [9.66837920e-01, 2.46152166e-02, 4.23176087e-03, 1.01142162e+04,\n",
      "        1.09429110e+04, 1.12699056e+04, 2.02268819e+03]]), array([37111.68359375, 37111.68359375, 37111.68359375, 37111.68359375,\n",
      "       37111.68359375, 37111.68359375, 37111.68359375, 37111.68359375]))\n",
      "           fun: 37111.68359375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1235\n",
      "           nit: 424\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.66837921e-01, 2.46152156e-02, 4.23176090e-03, 1.01142162e+04,\n",
      "       1.09429109e+04, 1.12699056e+04, 2.02268809e+03])\n",
      "best ll: 58553.90625, bestParams: [tensor(0.2521), tensor(0.1238), tensor(0.0047), tensor(11599.5469), tensor(19815.1660), tensor(20303.8965), tensor(21649.5996)]\n",
      "epoch 3\n",
      " final_simplex: (array([[9.70074403e-01, 2.78217038e-02, 1.05106842e-03, 2.33708461e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074403e-01, 2.78217037e-02, 1.05106842e-03, 2.33708461e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074403e-01, 2.78217037e-02, 1.05106843e-03, 2.33708460e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074403e-01, 2.78217038e-02, 1.05106843e-03, 2.33708460e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074402e-01, 2.78217037e-02, 1.05106843e-03, 2.33708460e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074402e-01, 2.78217038e-02, 1.05106842e-03, 2.33708462e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074403e-01, 2.78217037e-02, 1.05106842e-03, 2.33708462e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605821e+04],\n",
      "       [9.70074403e-01, 2.78217039e-02, 1.05106843e-03, 2.33708463e+03,\n",
      "        1.73286425e+04, 1.92556900e+04, 1.35605822e+04]]), array([36878.4765625, 36878.4765625, 36878.4765625, 36878.4765625,\n",
      "       36878.4765625, 36878.4765625, 36878.4765625, 36878.4765625]))\n",
      "           fun: 36878.4765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1279\n",
      "           nit: 434\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.70074403e-01, 2.78217038e-02, 1.05106842e-03, 2.33708461e+03,\n",
      "       1.73286425e+04, 1.92556901e+04, 1.35605822e+04])\n",
      "minPrevious 37111.68359375\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.70074403e-01, 2.78217038e-02, 1.05106842e-03, 2.33708461e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074403e-01, 2.78217037e-02, 1.05106842e-03, 2.33708461e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074403e-01, 2.78217037e-02, 1.05106843e-03, 2.33708460e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074403e-01, 2.78217038e-02, 1.05106843e-03, 2.33708460e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074402e-01, 2.78217037e-02, 1.05106843e-03, 2.33708460e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074402e-01, 2.78217038e-02, 1.05106842e-03, 2.33708462e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605822e+04],\n",
      "       [9.70074403e-01, 2.78217037e-02, 1.05106842e-03, 2.33708462e+03,\n",
      "        1.73286425e+04, 1.92556901e+04, 1.35605821e+04],\n",
      "       [9.70074403e-01, 2.78217039e-02, 1.05106843e-03, 2.33708463e+03,\n",
      "        1.73286425e+04, 1.92556900e+04, 1.35605822e+04]]), array([36878.4765625, 36878.4765625, 36878.4765625, 36878.4765625,\n",
      "       36878.4765625, 36878.4765625, 36878.4765625, 36878.4765625]))\n",
      "           fun: 36878.4765625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1279\n",
      "           nit: 434\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.70074403e-01, 2.78217038e-02, 1.05106842e-03, 2.33708461e+03,\n",
      "       1.73286425e+04, 1.92556901e+04, 1.35605822e+04])\n",
      "best ll: 56348.5703125, bestParams: [tensor(0.3235), tensor(0.0919), tensor(0.2410), tensor(11794.6807), tensor(15278.8682), tensor(15186.5166), tensor(3864.0605)]\n",
      "epoch 4\n",
      " final_simplex: (array([[8.70731683e-01, 6.37429092e-02, 4.97092776e-02, 1.41105787e+04,\n",
      "        1.03809224e+04, 9.92007671e+03, 3.74253907e+03],\n",
      "       [8.70731683e-01, 6.37429080e-02, 4.97092756e-02, 1.41105787e+04,\n",
      "        1.03809224e+04, 9.92007672e+03, 3.74253908e+03],\n",
      "       [8.70731684e-01, 6.37429087e-02, 4.97092764e-02, 1.41105787e+04,\n",
      "        1.03809224e+04, 9.92007671e+03, 3.74253908e+03],\n",
      "       [8.70731684e-01, 6.37429085e-02, 4.97092763e-02, 1.41105787e+04,\n",
      "        1.03809224e+04, 9.92007671e+03, 3.74253908e+03],\n",
      "       [8.70731684e-01, 6.37429083e-02, 4.97092760e-02, 1.41105787e+04,\n",
      "        1.03809225e+04, 9.92007670e+03, 3.74253908e+03],\n",
      "       [8.70731685e-01, 6.37429082e-02, 4.97092757e-02, 1.41105787e+04,\n",
      "        1.03809225e+04, 9.92007669e+03, 3.74253908e+03],\n",
      "       [8.70731682e-01, 6.37429093e-02, 4.97092778e-02, 1.41105787e+04,\n",
      "        1.03809224e+04, 9.92007673e+03, 3.74253908e+03],\n",
      "       [8.70731683e-01, 6.37429088e-02, 4.97092770e-02, 1.41105787e+04,\n",
      "        1.03809224e+04, 9.92007673e+03, 3.74253908e+03]]), array([39179.828125, 39179.828125, 39179.828125, 39179.828125,\n",
      "       39179.828125, 39179.828125, 39179.828125, 39179.828125]))\n",
      "           fun: 39179.828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1267\n",
      "           nit: 472\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.70731683e-01, 6.37429092e-02, 4.97092776e-02, 1.41105787e+04,\n",
      "       1.03809224e+04, 9.92007671e+03, 3.74253907e+03])\n",
      "minPrevious 36878.4765625\n",
      "best ll: 50563.73046875, bestParams: [tensor(0.4261), tensor(0.0587), tensor(0.0137), tensor(13385.8633), tensor(23862.2773), tensor(23813.1016), tensor(13642.8115)]\n",
      "epoch 5\n",
      " final_simplex: (array([[9.25305091e-01, 5.67640442e-02, 1.16045158e-02, 9.97936617e+03,\n",
      "        1.80606488e+04, 2.04693070e+04, 8.95451008e+03],\n",
      "       [9.25305094e-01, 5.67640441e-02, 1.16045158e-02, 9.97936616e+03,\n",
      "        1.80606488e+04, 2.04693070e+04, 8.95451006e+03],\n",
      "       [9.25305094e-01, 5.67640441e-02, 1.16045159e-02, 9.97936608e+03,\n",
      "        1.80606488e+04, 2.04693070e+04, 8.95451000e+03],\n",
      "       [9.25305094e-01, 5.67640441e-02, 1.16045158e-02, 9.97936611e+03,\n",
      "        1.80606488e+04, 2.04693069e+04, 8.95451006e+03],\n",
      "       [9.25305092e-01, 5.67640442e-02, 1.16045158e-02, 9.97936615e+03,\n",
      "        1.80606488e+04, 2.04693069e+04, 8.95451012e+03],\n",
      "       [9.25305093e-01, 5.67640442e-02, 1.16045158e-02, 9.97936613e+03,\n",
      "        1.80606488e+04, 2.04693069e+04, 8.95451008e+03],\n",
      "       [9.25305094e-01, 5.67640441e-02, 1.16045159e-02, 9.97936614e+03,\n",
      "        1.80606487e+04, 2.04693070e+04, 8.95451003e+03],\n",
      "       [9.25305094e-01, 5.67640441e-02, 1.16045158e-02, 9.97936615e+03,\n",
      "        1.80606487e+04, 2.04693070e+04, 8.95451004e+03]]), array([37726.33984375, 37726.33984375, 37726.33984375, 37726.33984375,\n",
      "       37726.33984375, 37726.33984375, 37726.33984375, 37726.33984375]))\n",
      "           fun: 37726.33984375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1206\n",
      "           nit: 396\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.25305091e-01, 5.67640442e-02, 1.16045158e-02, 9.97936617e+03,\n",
      "       1.80606488e+04, 2.04693070e+04, 8.95451008e+03])\n",
      "minPrevious 36878.4765625\n",
      "best ll: 54018.63671875, bestParams: [tensor(0.3694), tensor(0.0711), tensor(0.1498), tensor(4194.5049), tensor(16258.9082), tensor(17781.8203), tensor(23944.5879)]\n",
      "epoch 6\n",
      " final_simplex: (array([[9.07191628e-01, 3.16987708e-02, 5.82444567e-02, 3.51120318e+03,\n",
      "        2.11514347e+04, 2.08138201e+04, 2.14272405e+04],\n",
      "       [9.07191627e-01, 3.16987710e-02, 5.82444567e-02, 3.51120318e+03,\n",
      "        2.11514347e+04, 2.08138201e+04, 2.14272404e+04],\n",
      "       [9.07191628e-01, 3.16987709e-02, 5.82444565e-02, 3.51120318e+03,\n",
      "        2.11514347e+04, 2.08138201e+04, 2.14272405e+04],\n",
      "       [9.07191627e-01, 3.16987708e-02, 5.82444567e-02, 3.51120318e+03,\n",
      "        2.11514347e+04, 2.08138201e+04, 2.14272405e+04],\n",
      "       [9.07191627e-01, 3.16987708e-02, 5.82444566e-02, 3.51120318e+03,\n",
      "        2.11514347e+04, 2.08138201e+04, 2.14272405e+04],\n",
      "       [9.07191627e-01, 3.16987709e-02, 5.82444568e-02, 3.51120318e+03,\n",
      "        2.11514347e+04, 2.08138201e+04, 2.14272405e+04],\n",
      "       [9.07191627e-01, 3.16987709e-02, 5.82444567e-02, 3.51120318e+03,\n",
      "        2.11514347e+04, 2.08138200e+04, 2.14272404e+04],\n",
      "       [9.07191627e-01, 3.16987709e-02, 5.82444567e-02, 3.51120318e+03,\n",
      "        2.11514347e+04, 2.08138200e+04, 2.14272405e+04]]), array([38093.3125, 38093.3125, 38093.3125, 38093.3125, 38093.3125,\n",
      "       38093.3125, 38093.3125, 38093.3125]))\n",
      "           fun: 38093.3125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1267\n",
      "           nit: 416\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.07191628e-01, 3.16987708e-02, 5.82444567e-02, 3.51120318e+03,\n",
      "       2.11514347e+04, 2.08138201e+04, 2.14272405e+04])\n",
      "minPrevious 36878.4765625\n",
      "best ll: 57733.27734375, bestParams: [tensor(0.3091), tensor(0.3079), tensor(0.0564), tensor(2408.3608), tensor(21979.2051), tensor(24497.3281), tensor(11123.7959)]\n",
      "epoch 7\n",
      " final_simplex: (array([[9.58367857e-01, 2.29310014e-03, 3.75660203e-02, 1.31220747e+03,\n",
      "        1.75073722e+04, 1.75604256e+04, 8.73127157e+03],\n",
      "       [9.58367858e-01, 2.29309970e-03, 3.75660203e-02, 1.31220748e+03,\n",
      "        1.75073722e+04, 1.75604256e+04, 8.73127156e+03],\n",
      "       [9.58367858e-01, 2.29309985e-03, 3.75660204e-02, 1.31220747e+03,\n",
      "        1.75073722e+04, 1.75604256e+04, 8.73127155e+03],\n",
      "       [9.58367857e-01, 2.29309993e-03, 3.75660204e-02, 1.31220747e+03,\n",
      "        1.75073722e+04, 1.75604256e+04, 8.73127155e+03],\n",
      "       [9.58367857e-01, 2.29309997e-03, 3.75660203e-02, 1.31220747e+03,\n",
      "        1.75073722e+04, 1.75604256e+04, 8.73127156e+03],\n",
      "       [9.58367858e-01, 2.29309974e-03, 3.75660204e-02, 1.31220747e+03,\n",
      "        1.75073722e+04, 1.75604255e+04, 8.73127155e+03],\n",
      "       [9.58367858e-01, 2.29309977e-03, 3.75660205e-02, 1.31220746e+03,\n",
      "        1.75073723e+04, 1.75604255e+04, 8.73127154e+03],\n",
      "       [9.58367858e-01, 2.29309978e-03, 3.75660204e-02, 1.31220746e+03,\n",
      "        1.75073723e+04, 1.75604255e+04, 8.73127154e+03]]), array([36924.03515625, 36924.03515625, 36924.03515625, 36924.03515625,\n",
      "       36924.03515625, 36924.03515625, 36924.03515625, 36924.03515625]))\n",
      "           fun: 36924.03515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1349\n",
      "           nit: 482\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.58367857e-01, 2.29310014e-03, 3.75660203e-02, 1.31220747e+03,\n",
      "       1.75073722e+04, 1.75604256e+04, 8.73127157e+03])\n",
      "minPrevious 36878.4765625\n",
      "best ll: 56812.703125, bestParams: [tensor(0.3069), tensor(0.0859), tensor(0.1661), tensor(23256.9629), tensor(7870.2271), tensor(9541.6719), tensor(24448.1328)]\n",
      "epoch 8\n",
      " final_simplex: (array([[8.86790967e-01, 6.45344782e-02, 4.72443779e-02, 2.00847822e+04,\n",
      "        6.51669713e+03, 7.21497520e+03, 2.89104308e+04],\n",
      "       [8.86790966e-01, 6.45344784e-02, 4.72443782e-02, 2.00847822e+04,\n",
      "        6.51669714e+03, 7.21497519e+03, 2.89104307e+04],\n",
      "       [8.86790967e-01, 6.45344780e-02, 4.72443780e-02, 2.00847822e+04,\n",
      "        6.51669713e+03, 7.21497519e+03, 2.89104308e+04],\n",
      "       [8.86790966e-01, 6.45344785e-02, 4.72443781e-02, 2.00847822e+04,\n",
      "        6.51669714e+03, 7.21497519e+03, 2.89104307e+04],\n",
      "       [8.86790967e-01, 6.45344781e-02, 4.72443778e-02, 2.00847822e+04,\n",
      "        6.51669713e+03, 7.21497519e+03, 2.89104308e+04],\n",
      "       [8.86790966e-01, 6.45344784e-02, 4.72443780e-02, 2.00847821e+04,\n",
      "        6.51669713e+03, 7.21497520e+03, 2.89104308e+04],\n",
      "       [8.86790967e-01, 6.45344783e-02, 4.72443779e-02, 2.00847822e+04,\n",
      "        6.51669713e+03, 7.21497520e+03, 2.89104307e+04],\n",
      "       [8.86790967e-01, 6.45344783e-02, 4.72443779e-02, 2.00847822e+04,\n",
      "        6.51669713e+03, 7.21497520e+03, 2.89104308e+04]]), array([38994.0703125, 38994.0703125, 38994.0703125, 38994.0703125,\n",
      "       38994.0703125, 38994.0703125, 38994.0703125, 38994.0703125]))\n",
      "           fun: 38994.0703125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1334\n",
      "           nit: 469\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.86790967e-01, 6.45344782e-02, 4.72443779e-02, 2.00847822e+04,\n",
      "       6.51669713e+03, 7.21497520e+03, 2.89104308e+04])\n",
      "minPrevious 36878.4765625\n",
      "best ll: 57309.8046875, bestParams: [tensor(0.2736), tensor(0.0321), tensor(0.0008), tensor(9364.3115), tensor(8342.5283), tensor(11029.8135), tensor(3089.7395)]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.64449615e-01, 3.40576566e-02, 3.14867629e-04, 8.95267999e+03,\n",
      "        5.54154730e+03, 5.44154147e+03, 1.52701883e+03],\n",
      "       [9.64449615e-01, 3.40576567e-02, 3.14867629e-04, 8.95267997e+03,\n",
      "        5.54154730e+03, 5.44154147e+03, 1.52701883e+03],\n",
      "       [9.64449615e-01, 3.40576567e-02, 3.14867630e-04, 8.95267998e+03,\n",
      "        5.54154730e+03, 5.44154147e+03, 1.52701882e+03],\n",
      "       [9.64449614e-01, 3.40576567e-02, 3.14867631e-04, 8.95267997e+03,\n",
      "        5.54154730e+03, 5.44154147e+03, 1.52701881e+03],\n",
      "       [9.64449614e-01, 3.40576568e-02, 3.14867630e-04, 8.95267995e+03,\n",
      "        5.54154730e+03, 5.44154146e+03, 1.52701881e+03],\n",
      "       [9.64449615e-01, 3.40576567e-02, 3.14867630e-04, 8.95267998e+03,\n",
      "        5.54154730e+03, 5.44154147e+03, 1.52701882e+03],\n",
      "       [9.64449615e-01, 3.40576568e-02, 3.14867630e-04, 8.95267995e+03,\n",
      "        5.54154729e+03, 5.44154149e+03, 1.52701882e+03],\n",
      "       [9.64449615e-01, 3.40576563e-02, 3.14867631e-04, 8.95268009e+03,\n",
      "        5.54154733e+03, 5.44154144e+03, 1.52701880e+03]]), array([37164.07421875, 37164.07421875, 37164.07421875, 37164.07421875,\n",
      "       37164.07421875, 37164.07421875, 37164.07421875, 37164.07421875]))\n",
      "           fun: 37164.07421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1224\n",
      "           nit: 409\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.64449615e-01, 3.40576566e-02, 3.14867629e-04, 8.95267999e+03,\n",
      "       5.54154730e+03, 5.44154147e+03, 1.52701883e+03])\n",
      "minPrevious 36878.4765625\n",
      "best ll: 58465.2265625, bestParams: [tensor(0.2865), tensor(0.2061), tensor(0.0838), tensor(10885.8115), tensor(15799.3408), tensor(12258.5967), tensor(13295.0176)]\n",
      "epoch 10\n",
      " final_simplex: (array([[8.71209115e-01, 5.94719886e-02, 6.50025916e-02, 7.13938447e+03,\n",
      "        1.25756917e+04, 1.21063149e+04, 7.97345959e+03],\n",
      "       [8.71209116e-01, 5.94719882e-02, 6.50025914e-02, 7.13938451e+03,\n",
      "        1.25756917e+04, 1.21063149e+04, 7.97345960e+03],\n",
      "       [8.71209116e-01, 5.94719883e-02, 6.50025915e-02, 7.13938450e+03,\n",
      "        1.25756917e+04, 1.21063149e+04, 7.97345959e+03],\n",
      "       [8.71209115e-01, 5.94719884e-02, 6.50025914e-02, 7.13938452e+03,\n",
      "        1.25756917e+04, 1.21063148e+04, 7.97345959e+03],\n",
      "       [8.71209116e-01, 5.94719885e-02, 6.50025914e-02, 7.13938452e+03,\n",
      "        1.25756917e+04, 1.21063149e+04, 7.97345959e+03],\n",
      "       [8.71209115e-01, 5.94719891e-02, 6.50025918e-02, 7.13938446e+03,\n",
      "        1.25756917e+04, 1.21063149e+04, 7.97345964e+03],\n",
      "       [8.71209117e-01, 5.94719877e-02, 6.50025909e-02, 7.13938457e+03,\n",
      "        1.25756918e+04, 1.21063149e+04, 7.97345954e+03],\n",
      "       [8.71209116e-01, 5.94719881e-02, 6.50025911e-02, 7.13938455e+03,\n",
      "        1.25756917e+04, 1.21063149e+04, 7.97345957e+03]]), array([39175.76171875, 39175.76171875, 39175.76171875, 39175.76171875,\n",
      "       39175.76171875, 39175.76171875, 39175.76171875, 39175.76171875]))\n",
      "           fun: 39175.76171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1252\n",
      "           nit: 424\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.71209115e-01, 5.94719886e-02, 6.50025916e-02, 7.13938447e+03,\n",
      "       1.25756917e+04, 1.21063149e+04, 7.97345959e+03])\n",
      "minPrevious 36878.4765625\n",
      "best ll: 57586.26953125, bestParams: [tensor(0.2935), tensor(0.2817), tensor(0.0094), tensor(1888.1998), tensor(18402.3828), tensor(19690.0820), tensor(17401.7090)]\n",
      "epoch 11\n",
      " final_simplex: (array([[8.78208086e-01, 1.16299412e-01, 2.38254583e-03, 1.29542556e+03,\n",
      "        1.92402253e+04, 2.04468934e+04, 1.39403298e+04],\n",
      "       [8.78208085e-01, 1.16299414e-01, 2.38254588e-03, 1.29542556e+03,\n",
      "        1.92402253e+04, 2.04468934e+04, 1.39403297e+04],\n",
      "       [8.78208086e-01, 1.16299413e-01, 2.38254585e-03, 1.29542556e+03,\n",
      "        1.92402253e+04, 2.04468934e+04, 1.39403298e+04],\n",
      "       [8.78208086e-01, 1.16299413e-01, 2.38254584e-03, 1.29542556e+03,\n",
      "        1.92402253e+04, 2.04468934e+04, 1.39403298e+04],\n",
      "       [8.78208086e-01, 1.16299414e-01, 2.38254586e-03, 1.29542555e+03,\n",
      "        1.92402253e+04, 2.04468934e+04, 1.39403298e+04],\n",
      "       [8.78208086e-01, 1.16299413e-01, 2.38254580e-03, 1.29542556e+03,\n",
      "        1.92402253e+04, 2.04468934e+04, 1.39403299e+04],\n",
      "       [8.78208086e-01, 1.16299413e-01, 2.38254581e-03, 1.29542556e+03,\n",
      "        1.92402254e+04, 2.04468934e+04, 1.39403298e+04],\n",
      "       [8.78208085e-01, 1.16299413e-01, 2.38254584e-03, 1.29542556e+03,\n",
      "        1.92402253e+04, 2.04468934e+04, 1.39403298e+04]]), array([38697.30859375, 38697.30859375, 38697.30859375, 38697.30859375,\n",
      "       38697.30859375, 38697.30859375, 38697.30859375, 38697.30859375]))\n",
      "           fun: 38697.30859375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1245\n",
      "           nit: 415\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.78208086e-01, 1.16299412e-01, 2.38254583e-03, 1.29542556e+03,\n",
      "       1.92402253e+04, 2.04468934e+04, 1.39403298e+04])\n",
      "minPrevious 36878.4765625\n",
      "best ll: 58358.25390625, bestParams: [tensor(0.2761), tensor(0.0406), tensor(0.2034), tensor(7860.7715), tensor(21875.5449), tensor(18886.9434), tensor(2704.6411)]\n",
      "epoch 12\n",
      " final_simplex: (array([[9.90388127e-01, 2.28472697e-03, 1.07375677e-03, 1.15045958e+04,\n",
      "        1.30231613e+04, 1.30906367e+04, 2.38842946e+03],\n",
      "       [9.90388127e-01, 2.28472701e-03, 1.07375646e-03, 1.15045958e+04,\n",
      "        1.30231613e+04, 1.30906367e+04, 2.38842946e+03],\n",
      "       [9.90388128e-01, 2.28472714e-03, 1.07375539e-03, 1.15045958e+04,\n",
      "        1.30231613e+04, 1.30906367e+04, 2.38842947e+03],\n",
      "       [9.90388128e-01, 2.28472698e-03, 1.07375513e-03, 1.15045958e+04,\n",
      "        1.30231612e+04, 1.30906367e+04, 2.38842947e+03],\n",
      "       [9.90388128e-01, 2.28472702e-03, 1.07375609e-03, 1.15045958e+04,\n",
      "        1.30231613e+04, 1.30906367e+04, 2.38842946e+03],\n",
      "       [9.90388128e-01, 2.28472712e-03, 1.07375631e-03, 1.15045958e+04,\n",
      "        1.30231612e+04, 1.30906367e+04, 2.38842946e+03],\n",
      "       [9.90388128e-01, 2.28472718e-03, 1.07375604e-03, 1.15045958e+04,\n",
      "        1.30231612e+04, 1.30906367e+04, 2.38842947e+03],\n",
      "       [9.90388128e-01, 2.28472711e-03, 1.07375610e-03, 1.15045958e+04,\n",
      "        1.30231612e+04, 1.30906367e+04, 2.38842947e+03]]), array([36562.25390625, 36562.25390625, 36562.25390625, 36562.25390625,\n",
      "       36562.25390625, 36562.25390625, 36562.25390625, 36562.25390625]))\n",
      "           fun: 36562.25390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1204\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.90388127e-01, 2.28472697e-03, 1.07375677e-03, 1.15045958e+04,\n",
      "       1.30231613e+04, 1.30906367e+04, 2.38842946e+03])\n",
      "minPrevious 36878.4765625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.90388127e-01, 2.28472697e-03, 1.07375677e-03, 1.15045958e+04,\n",
      "        1.30231613e+04, 1.30906367e+04, 2.38842946e+03],\n",
      "       [9.90388127e-01, 2.28472701e-03, 1.07375646e-03, 1.15045958e+04,\n",
      "        1.30231613e+04, 1.30906367e+04, 2.38842946e+03],\n",
      "       [9.90388128e-01, 2.28472714e-03, 1.07375539e-03, 1.15045958e+04,\n",
      "        1.30231613e+04, 1.30906367e+04, 2.38842947e+03],\n",
      "       [9.90388128e-01, 2.28472698e-03, 1.07375513e-03, 1.15045958e+04,\n",
      "        1.30231612e+04, 1.30906367e+04, 2.38842947e+03],\n",
      "       [9.90388128e-01, 2.28472702e-03, 1.07375609e-03, 1.15045958e+04,\n",
      "        1.30231613e+04, 1.30906367e+04, 2.38842946e+03],\n",
      "       [9.90388128e-01, 2.28472712e-03, 1.07375631e-03, 1.15045958e+04,\n",
      "        1.30231612e+04, 1.30906367e+04, 2.38842946e+03],\n",
      "       [9.90388128e-01, 2.28472718e-03, 1.07375604e-03, 1.15045958e+04,\n",
      "        1.30231612e+04, 1.30906367e+04, 2.38842947e+03],\n",
      "       [9.90388128e-01, 2.28472711e-03, 1.07375610e-03, 1.15045958e+04,\n",
      "        1.30231612e+04, 1.30906367e+04, 2.38842947e+03]]), array([36562.25390625, 36562.25390625, 36562.25390625, 36562.25390625,\n",
      "       36562.25390625, 36562.25390625, 36562.25390625, 36562.25390625]))\n",
      "           fun: 36562.25390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1204\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.90388127e-01, 2.28472697e-03, 1.07375677e-03, 1.15045958e+04,\n",
      "       1.30231613e+04, 1.30906367e+04, 2.38842946e+03])\n",
      "best ll: 55139.18359375, bestParams: [tensor(0.3194), tensor(0.0421), tensor(0.0092), tensor(21598.3887), tensor(14478.1064), tensor(17589.7441), tensor(20525.8848)]\n",
      "epoch 13\n",
      " final_simplex: (array([[9.49904014e-01, 4.28627204e-02, 5.16874585e-03, 2.42980055e+04,\n",
      "        1.43676794e+04, 1.33788813e+04, 3.16191847e+02],\n",
      "       [9.49904014e-01, 4.28627204e-02, 5.16874586e-03, 2.42980055e+04,\n",
      "        1.43676794e+04, 1.33788813e+04, 3.16191855e+02],\n",
      "       [9.49904014e-01, 4.28627204e-02, 5.16874585e-03, 2.42980055e+04,\n",
      "        1.43676794e+04, 1.33788813e+04, 3.16191868e+02],\n",
      "       [9.49904014e-01, 4.28627203e-02, 5.16874587e-03, 2.42980055e+04,\n",
      "        1.43676794e+04, 1.33788813e+04, 3.16191873e+02],\n",
      "       [9.49904014e-01, 4.28627203e-02, 5.16874587e-03, 2.42980056e+04,\n",
      "        1.43676794e+04, 1.33788812e+04, 3.16191879e+02],\n",
      "       [9.49904014e-01, 4.28627204e-02, 5.16874586e-03, 2.42980055e+04,\n",
      "        1.43676794e+04, 1.33788812e+04, 3.16191881e+02],\n",
      "       [9.49904014e-01, 4.28627204e-02, 5.16874587e-03, 2.42980056e+04,\n",
      "        1.43676794e+04, 1.33788812e+04, 3.16191906e+02],\n",
      "       [9.49904015e-01, 4.28627204e-02, 5.16874586e-03, 2.42980055e+04,\n",
      "        1.43676794e+04, 1.33788812e+04, 3.16191901e+02]]), array([37468.28515625, 37468.28515625, 37468.28515625, 37468.28515625,\n",
      "       37468.28515625, 37468.28515625, 37468.28515625, 37468.28515625]))\n",
      "           fun: 37468.28515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1301\n",
      "           nit: 450\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.49904014e-01, 4.28627204e-02, 5.16874585e-03, 2.42980055e+04,\n",
      "       1.43676794e+04, 1.33788813e+04, 3.16191847e+02])\n",
      "minPrevious 36562.25390625\n",
      "best ll: 57832.21875, bestParams: [tensor(0.3119), tensor(0.1356), tensor(0.0244), tensor(11821.6494), tensor(13167.1504), tensor(8132.5723), tensor(10080.7119)]\n",
      "epoch 14\n",
      " final_simplex: (array([[9.58506079e-01, 2.52812638e-02, 9.83542253e-03, 1.33464770e+04,\n",
      "        1.03490742e+04, 1.08051377e+04, 8.44716333e+02],\n",
      "       [9.58506079e-01, 2.52812635e-02, 9.83542258e-03, 1.33464770e+04,\n",
      "        1.03490742e+04, 1.08051377e+04, 8.44716312e+02],\n",
      "       [9.58506079e-01, 2.52812639e-02, 9.83542254e-03, 1.33464770e+04,\n",
      "        1.03490742e+04, 1.08051377e+04, 8.44716339e+02],\n",
      "       [9.58506079e-01, 2.52812654e-02, 9.83542218e-03, 1.33464769e+04,\n",
      "        1.03490742e+04, 1.08051378e+04, 8.44716427e+02],\n",
      "       [9.58506079e-01, 2.52812638e-02, 9.83542250e-03, 1.33464770e+04,\n",
      "        1.03490742e+04, 1.08051377e+04, 8.44716360e+02],\n",
      "       [9.58506079e-01, 2.52812633e-02, 9.83542257e-03, 1.33464770e+04,\n",
      "        1.03490742e+04, 1.08051378e+04, 8.44716346e+02],\n",
      "       [9.58506079e-01, 2.52812643e-02, 9.83542237e-03, 1.33464770e+04,\n",
      "        1.03490742e+04, 1.08051378e+04, 8.44716371e+02],\n",
      "       [9.58506079e-01, 2.52812647e-02, 9.83542231e-03, 1.33464770e+04,\n",
      "        1.03490742e+04, 1.08051378e+04, 8.44716366e+02]]), array([37279.3984375, 37279.3984375, 37279.3984375, 37279.3984375,\n",
      "       37279.3984375, 37279.3984375, 37279.3984375, 37279.3984375]))\n",
      "           fun: 37279.3984375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1268\n",
      "           nit: 433\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.58506079e-01, 2.52812638e-02, 9.83542253e-03, 1.33464770e+04,\n",
      "       1.03490742e+04, 1.08051377e+04, 8.44716333e+02])\n",
      "minPrevious 36562.25390625\n",
      "best ll: 58589.6640625, bestParams: [tensor(0.3033), tensor(0.0124), tensor(0.2642), tensor(15318.9287), tensor(6122.5063), tensor(9501.0498), tensor(6692.0928)]\n",
      "epoch 15\n",
      " final_simplex: (array([[9.81901114e-01, 1.07280537e-02, 1.07511592e-03, 1.12056595e+04,\n",
      "        8.87825713e+03, 8.39555628e+03, 2.29600556e+02],\n",
      "       [9.81901114e-01, 1.07280537e-02, 1.07511600e-03, 1.12056595e+04,\n",
      "        8.87825713e+03, 8.39555628e+03, 2.29600558e+02],\n",
      "       [9.81901114e-01, 1.07280537e-02, 1.07511611e-03, 1.12056595e+04,\n",
      "        8.87825713e+03, 8.39555628e+03, 2.29600561e+02],\n",
      "       [9.81901114e-01, 1.07280537e-02, 1.07511638e-03, 1.12056595e+04,\n",
      "        8.87825713e+03, 8.39555628e+03, 2.29600556e+02],\n",
      "       [9.81901113e-01, 1.07280537e-02, 1.07511582e-03, 1.12056596e+04,\n",
      "        8.87825713e+03, 8.39555628e+03, 2.29600546e+02],\n",
      "       [9.81901113e-01, 1.07280537e-02, 1.07511638e-03, 1.12056595e+04,\n",
      "        8.87825713e+03, 8.39555628e+03, 2.29600564e+02],\n",
      "       [9.81901113e-01, 1.07280537e-02, 1.07511663e-03, 1.12056595e+04,\n",
      "        8.87825712e+03, 8.39555629e+03, 2.29600562e+02],\n",
      "       [9.81901114e-01, 1.07280537e-02, 1.07511575e-03, 1.12056595e+04,\n",
      "        8.87825713e+03, 8.39555628e+03, 2.29600553e+02]]), array([36780.3203125, 36780.3203125, 36780.3203125, 36780.3203125,\n",
      "       36780.3203125, 36780.3203125, 36780.3203125, 36780.3203125]))\n",
      "           fun: 36780.3203125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1280\n",
      "           nit: 420\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.81901114e-01, 1.07280537e-02, 1.07511592e-03, 1.12056595e+04,\n",
      "       8.87825713e+03, 8.39555628e+03, 2.29600556e+02])\n",
      "minPrevious 36562.25390625\n",
      "best ll: 58746.19140625, bestParams: [tensor(0.3582), tensor(0.0443), tensor(0.1632), tensor(11532.6719), tensor(19745.8887), tensor(9189.0508), tensor(23982.9062)]\n",
      "epoch 16\n",
      " final_simplex: (array([[8.06395864e-01, 4.06218292e-02, 1.51046049e-01, 5.39067820e+03,\n",
      "        1.02445623e+04, 9.88587942e+03, 2.10337233e+04],\n",
      "       [8.06395864e-01, 4.06218291e-02, 1.51046049e-01, 5.39067822e+03,\n",
      "        1.02445623e+04, 9.88587942e+03, 2.10337234e+04],\n",
      "       [8.06395864e-01, 4.06218292e-02, 1.51046049e-01, 5.39067823e+03,\n",
      "        1.02445623e+04, 9.88587942e+03, 2.10337234e+04],\n",
      "       [8.06395863e-01, 4.06218293e-02, 1.51046049e-01, 5.39067820e+03,\n",
      "        1.02445623e+04, 9.88587942e+03, 2.10337234e+04],\n",
      "       [8.06395863e-01, 4.06218292e-02, 1.51046049e-01, 5.39067822e+03,\n",
      "        1.02445623e+04, 9.88587943e+03, 2.10337234e+04],\n",
      "       [8.06395863e-01, 4.06218294e-02, 1.51046049e-01, 5.39067822e+03,\n",
      "        1.02445623e+04, 9.88587942e+03, 2.10337234e+04],\n",
      "       [8.06395863e-01, 4.06218292e-02, 1.51046049e-01, 5.39067823e+03,\n",
      "        1.02445623e+04, 9.88587943e+03, 2.10337234e+04],\n",
      "       [8.06395864e-01, 4.06218292e-02, 1.51046049e-01, 5.39067820e+03,\n",
      "        1.02445623e+04, 9.88587942e+03, 2.10337233e+04]]), array([40736.03125, 40736.03125, 40736.03125, 40736.03125, 40736.03125,\n",
      "       40736.03125, 40736.03125, 40736.03125]))\n",
      "           fun: 40736.03125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1236\n",
      "           nit: 393\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.06395864e-01, 4.06218292e-02, 1.51046049e-01, 5.39067820e+03,\n",
      "       1.02445623e+04, 9.88587942e+03, 2.10337233e+04])\n",
      "minPrevious 36562.25390625\n",
      "best ll: 55985.640625, bestParams: [tensor(0.3132), tensor(0.0450), tensor(0.0505), tensor(15421.2061), tensor(23179.1699), tensor(18953.1895), tensor(7292.2686)]\n",
      "epoch 17\n",
      " final_simplex: (array([[9.32839939e-01, 2.10344247e-02, 3.70982520e-02, 1.24774729e+04,\n",
      "        1.78402429e+04, 2.05409178e+04, 1.46036234e+03],\n",
      "       [9.32839938e-01, 2.10344248e-02, 3.70982521e-02, 1.24774729e+04,\n",
      "        1.78402429e+04, 2.05409178e+04, 1.46036234e+03],\n",
      "       [9.32839938e-01, 2.10344249e-02, 3.70982521e-02, 1.24774729e+04,\n",
      "        1.78402429e+04, 2.05409178e+04, 1.46036234e+03],\n",
      "       [9.32839938e-01, 2.10344248e-02, 3.70982520e-02, 1.24774729e+04,\n",
      "        1.78402429e+04, 2.05409178e+04, 1.46036234e+03],\n",
      "       [9.32839939e-01, 2.10344248e-02, 3.70982520e-02, 1.24774729e+04,\n",
      "        1.78402429e+04, 2.05409178e+04, 1.46036233e+03],\n",
      "       [9.32839939e-01, 2.10344246e-02, 3.70982519e-02, 1.24774729e+04,\n",
      "        1.78402429e+04, 2.05409179e+04, 1.46036234e+03],\n",
      "       [9.32839939e-01, 2.10344248e-02, 3.70982521e-02, 1.24774729e+04,\n",
      "        1.78402428e+04, 2.05409178e+04, 1.46036233e+03],\n",
      "       [9.32839940e-01, 2.10344248e-02, 3.70982521e-02, 1.24774729e+04,\n",
      "        1.78402428e+04, 2.05409179e+04, 1.46036232e+03]]), array([37692.5234375, 37692.5234375, 37692.5234375, 37692.5234375,\n",
      "       37692.5234375, 37692.5234375, 37692.5234375, 37692.5234375]))\n",
      "           fun: 37692.5234375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1284\n",
      "           nit: 433\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.32839939e-01, 2.10344247e-02, 3.70982520e-02, 1.24774729e+04,\n",
      "       1.78402429e+04, 2.05409178e+04, 1.46036234e+03])\n",
      "minPrevious 36562.25390625\n",
      "best ll: 57645.1015625, bestParams: [tensor(0.2836), tensor(0.0292), tensor(0.1806), tensor(19929.3672), tensor(21062.6738), tensor(22005.6152), tensor(2812.6550)]\n",
      "epoch 18\n",
      " final_simplex: (array([[8.63814427e-01, 1.03313457e-02, 1.17035737e-01, 1.08632059e+03,\n",
      "        2.01080262e+04, 2.44911452e+04, 2.86436394e+03],\n",
      "       [8.63814426e-01, 1.03313457e-02, 1.17035737e-01, 1.08632060e+03,\n",
      "        2.01080262e+04, 2.44911452e+04, 2.86436394e+03],\n",
      "       [8.63814426e-01, 1.03313458e-02, 1.17035737e-01, 1.08632067e+03,\n",
      "        2.01080263e+04, 2.44911451e+04, 2.86436393e+03],\n",
      "       [8.63814427e-01, 1.03313457e-02, 1.17035737e-01, 1.08632065e+03,\n",
      "        2.01080263e+04, 2.44911451e+04, 2.86436393e+03],\n",
      "       [8.63814425e-01, 1.03313457e-02, 1.17035738e-01, 1.08632062e+03,\n",
      "        2.01080263e+04, 2.44911452e+04, 2.86436394e+03],\n",
      "       [8.63814427e-01, 1.03313457e-02, 1.17035737e-01, 1.08632059e+03,\n",
      "        2.01080263e+04, 2.44911452e+04, 2.86436394e+03],\n",
      "       [8.63814427e-01, 1.03313457e-02, 1.17035737e-01, 1.08632060e+03,\n",
      "        2.01080262e+04, 2.44911452e+04, 2.86436393e+03],\n",
      "       [8.63814428e-01, 1.03313456e-02, 1.17035737e-01, 1.08632053e+03,\n",
      "        2.01080262e+04, 2.44911452e+04, 2.86436394e+03]]), array([39428.7109375, 39428.7109375, 39428.7109375, 39428.7109375,\n",
      "       39428.7109375, 39428.7109375, 39428.7109375, 39428.7109375]))\n",
      "           fun: 39428.7109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1281\n",
      "           nit: 457\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.63814427e-01, 1.03313457e-02, 1.17035737e-01, 1.08632059e+03,\n",
      "       2.01080262e+04, 2.44911452e+04, 2.86436394e+03])\n",
      "minPrevious 36562.25390625\n",
      "best ll: 54994.046875, bestParams: [tensor(0.3346), tensor(0.0575), tensor(0.0881), tensor(22652.6973), tensor(24140.8691), tensor(20025.2910), tensor(24275.9746)]\n",
      "epoch 19\n",
      " final_simplex: (array([[9.24534491e-01, 2.34813270e-02, 4.69691558e-02, 1.90084500e+04,\n",
      "        1.93069611e+04, 2.08653577e+04, 2.50977048e+04],\n",
      "       [9.24534489e-01, 2.34813269e-02, 4.69691560e-02, 1.90084500e+04,\n",
      "        1.93069611e+04, 2.08653577e+04, 2.50977048e+04],\n",
      "       [9.24534489e-01, 2.34813266e-02, 4.69691560e-02, 1.90084500e+04,\n",
      "        1.93069611e+04, 2.08653577e+04, 2.50977049e+04],\n",
      "       [9.24534490e-01, 2.34813268e-02, 4.69691558e-02, 1.90084500e+04,\n",
      "        1.93069611e+04, 2.08653577e+04, 2.50977048e+04],\n",
      "       [9.24534490e-01, 2.34813269e-02, 4.69691558e-02, 1.90084500e+04,\n",
      "        1.93069610e+04, 2.08653577e+04, 2.50977048e+04],\n",
      "       [9.24534491e-01, 2.34813269e-02, 4.69691558e-02, 1.90084500e+04,\n",
      "        1.93069610e+04, 2.08653578e+04, 2.50977048e+04],\n",
      "       [9.24534489e-01, 2.34813268e-02, 4.69691558e-02, 1.90084500e+04,\n",
      "        1.93069611e+04, 2.08653577e+04, 2.50977048e+04],\n",
      "       [9.24534490e-01, 2.34813270e-02, 4.69691558e-02, 1.90084500e+04,\n",
      "        1.93069611e+04, 2.08653577e+04, 2.50977048e+04]]), array([37810.49609375, 37810.49609375, 37810.49609375, 37810.49609375,\n",
      "       37810.49609375, 37810.49609375, 37810.49609375, 37810.49609375]))\n",
      "           fun: 37810.49609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1240\n",
      "           nit: 426\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.24534491e-01, 2.34813270e-02, 4.69691558e-02, 1.90084500e+04,\n",
      "       1.93069611e+04, 2.08653577e+04, 2.50977048e+04])\n",
      "minPrevious 36562.25390625\n",
      "inferredPis tensor([0.9904, 0.0023, 0.0011], dtype=torch.float64)\n",
      "inferredAlphas tensor([11504.5958, 13023.1613, 13090.6367,  2388.4295], dtype=torch.float64)\n",
      "truth0 tensor(0.7519) truth1 tensor(0.1111) truth2 tensor(0.1121) truthBoth tensor(0.0250)\n",
      "params on run 6 {'lls': [58132.7578125, 61020.8984375, 62816.03125, 61310.28125, 59964.953125, 47473.921875, 47433.734375, 47816.32421875, 47210.3984375, 51822.578125, 51970.546875, 47609.4609375, 52364.7734375, 53773.0390625, 47233.921875, 36342.86328125, 36234.44921875, 36770.3828125, 36826.53125, 36796.37109375, 36452.859375, 36562.25390625], 'inferredAlphas': [tensor([17771.7538,   267.5774,   285.4237, 19323.4289], dtype=torch.float64), tensor([17391.5067,   389.1159,   504.1465, 38945.6315], dtype=torch.float64), tensor([26599.6834,   330.5187,   522.2450, 20474.0527], dtype=torch.float64), tensor([17159.0905,   229.1438,   192.1196, 23702.7612], dtype=torch.float64), tensor([14365.2776,   353.8587,   277.5095, 36615.7416], dtype=torch.float64), tensor([4681.1768, 1514.9906,  279.5278, 6430.2365], dtype=torch.float64), tensor([11636.0228,  1941.4431,   317.7839,  2432.4090], dtype=torch.float64), tensor([3466.6976,  105.4401,  574.8790,  884.2902], dtype=torch.float64), tensor([  190.1304,   255.3843,  1367.9433, 10051.6183], dtype=torch.float64), tensor([13347.1036,  2995.2070,   679.1869,  9964.7306], dtype=torch.float64), tensor([3050.1159,  274.5893, 1270.7564, 7251.8219], dtype=torch.float64), tensor([1902.8937,  238.1495, 1249.7712, 7914.4684], dtype=torch.float64), tensor([20414.2533,  1255.3286,  5495.8171, 24486.6440], dtype=torch.float64), tensor([ 5422.4410,  1070.5042,  5035.1884, 34394.7350], dtype=torch.float64), tensor([6116.3640, 1549.1665,  277.2773, 5735.0947], dtype=torch.float64), tensor([ 3252.4160, 17197.7572, 17440.7641, 20021.9416], dtype=torch.float64), tensor([7562.1733, 8368.3120, 8779.7352, 8746.4345], dtype=torch.float64), tensor([24233.9895, 13108.5658, 12119.1812, 10209.1235], dtype=torch.float64), tensor([7396.8446, 8201.6473, 8380.9128, 7312.5791], dtype=torch.float64), tensor([11581.3164, 13430.0547, 13532.5939,  8888.3734], dtype=torch.float64), tensor([ 2985.4058, 14050.8558, 13064.3345,  7914.5139], dtype=torch.float64), tensor([11504.5958, 13023.1613, 13090.6367,  2388.4295], dtype=torch.float64)], 'inferredPis': [tensor([0.2745, 0.5123, 0.0037], dtype=torch.float64), tensor([0.2424, 0.2423, 0.0335], dtype=torch.float64), tensor([0.2477, 0.1574, 0.0414], dtype=torch.float64), tensor([0.2670, 0.3576, 0.1152], dtype=torch.float64), tensor([0.4350, 0.2494, 0.0647], dtype=torch.float64), tensor([0.1319, 0.8504, 0.0173], dtype=torch.float64), tensor([0.1121, 0.8709, 0.0016], dtype=torch.float64), tensor([0.7272, 0.2531, 0.0189], dtype=torch.float64), tensor([0.8014, 0.1978, 0.0008], dtype=torch.float64), tensor([0.1527, 0.5340, 0.0406], dtype=torch.float64), tensor([4.4252e-01, 2.4141e-01, 6.9015e-05], dtype=torch.float64), tensor([0.7311, 0.2567, 0.0100], dtype=torch.float64), tensor([0.4108, 0.3023, 0.0150], dtype=torch.float64), tensor([0.4187, 0.1117, 0.0518], dtype=torch.float64), tensor([0.2033, 0.7863, 0.0045], dtype=torch.float64), tensor([0.9651, 0.0301, 0.0021], dtype=torch.float64), tensor([0.9906, 0.0041, 0.0032], dtype=torch.float64), tensor([9.9493e-01, 2.2532e-03, 5.0930e-04], dtype=torch.float64), tensor([0.9840, 0.0037, 0.0093], dtype=torch.float64), tensor([0.9764, 0.0103, 0.0102], dtype=torch.float64), tensor([0.9952, 0.0019, 0.0019], dtype=torch.float64), tensor([0.9904, 0.0023, 0.0011], dtype=torch.float64)], 'inferredPDVs': [tensor([0.4720, 0.0071, 0.0076, 0.5133], dtype=torch.float64), tensor([0.3039, 0.0068, 0.0088, 0.6805], dtype=torch.float64), tensor([0.5550, 0.0069, 0.0109, 0.4272], dtype=torch.float64), tensor([0.4156, 0.0056, 0.0047, 0.5742], dtype=torch.float64), tensor([0.2783, 0.0069, 0.0054, 0.7095], dtype=torch.float64), tensor([0.3627, 0.1174, 0.0217, 0.4982], dtype=torch.float64), tensor([0.7126, 0.1189, 0.0195, 0.1490], dtype=torch.float64), tensor([0.6890, 0.0210, 0.1143, 0.1758], dtype=torch.float64), tensor([0.0160, 0.0215, 0.1153, 0.8471], dtype=torch.float64), tensor([0.4945, 0.1110, 0.0252, 0.3693], dtype=torch.float64), tensor([0.2575, 0.0232, 0.1073, 0.6120], dtype=torch.float64), tensor([0.1683, 0.0210, 0.1106, 0.7001], dtype=torch.float64), tensor([0.3952, 0.0243, 0.1064, 0.4741], dtype=torch.float64), tensor([0.1181, 0.0233, 0.1096, 0.7490], dtype=torch.float64), tensor([0.4472, 0.1133, 0.0203, 0.4192], dtype=torch.float64), tensor([0.0562, 0.2969, 0.3011, 0.3458], dtype=torch.float64), tensor([0.2260, 0.2501, 0.2624, 0.2614], dtype=torch.float64), tensor([0.4061, 0.2197, 0.2031, 0.1711], dtype=torch.float64), tensor([0.2364, 0.2621, 0.2678, 0.2337], dtype=torch.float64), tensor([0.2442, 0.2832, 0.2853, 0.1874], dtype=torch.float64), tensor([0.0785, 0.3696, 0.3436, 0.2082], dtype=torch.float64), tensor([0.2876, 0.3255, 0.3272, 0.0597], dtype=torch.float64)], 'trueMeanPDVs': [tensor([0.7547, 0.1096, 0.1105, 0.0252]), tensor([0.7520, 0.1114, 0.1113, 0.0253]), tensor([0.7523, 0.1111, 0.1116, 0.0250]), tensor([0.7518, 0.1113, 0.1112, 0.0257]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7510, 0.1117, 0.1118, 0.0255]), tensor([0.7535, 0.1110, 0.1105, 0.0250]), tensor([0.7503, 0.1121, 0.1120, 0.0256]), tensor([0.7542, 0.1103, 0.1109, 0.0246]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250])], 'truePis': [tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500])]}\n",
      "tensor([[ 82.,   8.,   2.,   0.],\n",
      "        [102.,   5.,   1.,   0.],\n",
      "        [ 92.,   2.,   3.,   0.],\n",
      "        ...,\n",
      "        [ 48.,   0.,   1.,   0.],\n",
      "        [ 84.,   0.,   0.,   0.],\n",
      "        [101.,   1.,   1.,   0.]])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood4 at 0x7feb3b271170>\n",
      "best ll: 59052.51953125, bestParams: [tensor(0.2539), tensor(0.0418), tensor(0.1266), tensor(14987.9189), tensor(22138.8320), tensor(19437.7383), tensor(5936.0591)]\n",
      "epoch 0\n",
      " final_simplex: (array([[9.80748286e-01, 1.68360822e-02, 1.06172224e-03, 2.06781767e+04,\n",
      "        1.32109040e+04, 1.31398688e+04, 2.37992363e+03],\n",
      "       [9.80748286e-01, 1.68360822e-02, 1.06172229e-03, 2.06781767e+04,\n",
      "        1.32109040e+04, 1.31398688e+04, 2.37992363e+03],\n",
      "       [9.80748286e-01, 1.68360822e-02, 1.06172242e-03, 2.06781768e+04,\n",
      "        1.32109039e+04, 1.31398688e+04, 2.37992362e+03],\n",
      "       [9.80748286e-01, 1.68360822e-02, 1.06172242e-03, 2.06781767e+04,\n",
      "        1.32109039e+04, 1.31398688e+04, 2.37992362e+03],\n",
      "       [9.80748286e-01, 1.68360822e-02, 1.06172252e-03, 2.06781768e+04,\n",
      "        1.32109040e+04, 1.31398688e+04, 2.37992358e+03],\n",
      "       [9.80748286e-01, 1.68360822e-02, 1.06172252e-03, 2.06781768e+04,\n",
      "        1.32109039e+04, 1.31398689e+04, 2.37992360e+03],\n",
      "       [9.80748286e-01, 1.68360822e-02, 1.06172232e-03, 2.06781767e+04,\n",
      "        1.32109040e+04, 1.31398688e+04, 2.37992362e+03],\n",
      "       [9.80748286e-01, 1.68360822e-02, 1.06172231e-03, 2.06781767e+04,\n",
      "        1.32109040e+04, 1.31398688e+04, 2.37992363e+03]]), array([36875.5625, 36875.5625, 36875.5625, 36875.5625, 36875.5625,\n",
      "       36875.5625, 36875.5625, 36875.5625]))\n",
      "           fun: 36875.5625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1286\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.80748286e-01, 1.68360822e-02, 1.06172224e-03, 2.06781767e+04,\n",
      "       1.32109040e+04, 1.31398688e+04, 2.37992363e+03])\n",
      "best ll: 58366.34765625, bestParams: [tensor(0.3029), tensor(0.3213), tensor(0.0003), tensor(6882.6343), tensor(22861.9414), tensor(17119.6328), tensor(6000.0781)]\n",
      "epoch 1\n",
      " final_simplex: (array([[9.58013244e-01, 3.93284208e-02, 2.84627788e-04, 3.89168899e+03,\n",
      "        1.97067952e+04, 2.20168701e+04, 2.16477224e+02],\n",
      "       [9.58013246e-01, 3.93284203e-02, 2.84627788e-04, 3.89168897e+03,\n",
      "        1.97067952e+04, 2.20168701e+04, 2.16477216e+02],\n",
      "       [9.58013239e-01, 3.93284226e-02, 2.84627789e-04, 3.89168904e+03,\n",
      "        1.97067952e+04, 2.20168701e+04, 2.16477209e+02],\n",
      "       [9.58013240e-01, 3.93284226e-02, 2.84627789e-04, 3.89168902e+03,\n",
      "        1.97067952e+04, 2.20168701e+04, 2.16477228e+02],\n",
      "       [9.58013252e-01, 3.93284185e-02, 2.84627787e-04, 3.89168894e+03,\n",
      "        1.97067953e+04, 2.20168700e+04, 2.16477213e+02],\n",
      "       [9.58013249e-01, 3.93284191e-02, 2.84627788e-04, 3.89168896e+03,\n",
      "        1.97067952e+04, 2.20168700e+04, 2.16477226e+02],\n",
      "       [9.58013250e-01, 3.93284187e-02, 2.84627787e-04, 3.89168894e+03,\n",
      "        1.97067952e+04, 2.20168700e+04, 2.16477232e+02],\n",
      "       [9.58013243e-01, 3.93284215e-02, 2.84627789e-04, 3.89168902e+03,\n",
      "        1.97067953e+04, 2.20168700e+04, 2.16477199e+02]]), array([37334.97265625, 37334.97265625, 37334.97265625, 37334.97265625,\n",
      "       37334.97265625, 37334.97265625, 37334.97265625, 37334.97265625]))\n",
      "           fun: 37334.97265625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1234\n",
      "           nit: 430\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.58013244e-01, 3.93284208e-02, 2.84627788e-04, 3.89168899e+03,\n",
      "       1.97067952e+04, 2.20168701e+04, 2.16477224e+02])\n",
      "minPrevious 36875.5625\n",
      "best ll: 55283.703125, bestParams: [tensor(0.4068), tensor(0.0069), tensor(0.0184), tensor(24753.0840), tensor(10277.6064), tensor(20734.4883), tensor(23122.7598)]\n",
      "epoch 2\n",
      " final_simplex: (array([[9.86883986e-01, 5.28906661e-03, 7.07109482e-03, 2.55333608e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883987e-01, 5.28906661e-03, 7.07109491e-03, 2.55333607e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571487e+04],\n",
      "       [9.86883987e-01, 5.28906661e-03, 7.07109480e-03, 2.55333609e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883986e-01, 5.28906661e-03, 7.07109480e-03, 2.55333608e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883986e-01, 5.28906661e-03, 7.07109478e-03, 2.55333609e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883987e-01, 5.28906661e-03, 7.07109484e-03, 2.55333608e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883987e-01, 5.28906661e-03, 7.07109485e-03, 2.55333608e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883987e-01, 5.28906661e-03, 7.07109481e-03, 2.55333609e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04]]), array([36789.27734375, 36789.27734375, 36789.27734375, 36789.27734375,\n",
      "       36789.27734375, 36789.27734375, 36789.27734375, 36789.27734375]))\n",
      "           fun: 36789.27734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1272\n",
      "           nit: 428\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.86883986e-01, 5.28906661e-03, 7.07109482e-03, 2.55333608e+04,\n",
      "       1.36053226e+04, 1.36123912e+04, 1.14571486e+04])\n",
      "minPrevious 36875.5625\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.86883986e-01, 5.28906661e-03, 7.07109482e-03, 2.55333608e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883987e-01, 5.28906661e-03, 7.07109491e-03, 2.55333607e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571487e+04],\n",
      "       [9.86883987e-01, 5.28906661e-03, 7.07109480e-03, 2.55333609e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883986e-01, 5.28906661e-03, 7.07109480e-03, 2.55333608e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883986e-01, 5.28906661e-03, 7.07109478e-03, 2.55333609e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883987e-01, 5.28906661e-03, 7.07109484e-03, 2.55333608e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883987e-01, 5.28906661e-03, 7.07109485e-03, 2.55333608e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04],\n",
      "       [9.86883987e-01, 5.28906661e-03, 7.07109481e-03, 2.55333609e+04,\n",
      "        1.36053226e+04, 1.36123912e+04, 1.14571486e+04]]), array([36789.27734375, 36789.27734375, 36789.27734375, 36789.27734375,\n",
      "       36789.27734375, 36789.27734375, 36789.27734375, 36789.27734375]))\n",
      "           fun: 36789.27734375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1272\n",
      "           nit: 428\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.86883986e-01, 5.28906661e-03, 7.07109482e-03, 2.55333608e+04,\n",
      "       1.36053226e+04, 1.36123912e+04, 1.14571486e+04])\n",
      "best ll: 56440.0234375, bestParams: [tensor(0.2955), tensor(0.0423), tensor(0.0246), tensor(7519.6592), tensor(19469.9922), tensor(21779.0176), tensor(10776.2188)]\n",
      "epoch 3\n",
      " final_simplex: (array([[7.55411994e-01, 3.48232858e-02, 2.71632646e-02, 5.82170166e+01,\n",
      "        2.61461202e+04, 2.14546989e+04, 2.59593041e+03],\n",
      "       [7.55411997e-01, 3.48232858e-02, 2.71632645e-02, 5.82169970e+01,\n",
      "        2.61461202e+04, 2.14546989e+04, 2.59593035e+03],\n",
      "       [7.55411996e-01, 3.48232858e-02, 2.71632646e-02, 5.82170035e+01,\n",
      "        2.61461202e+04, 2.14546989e+04, 2.59593037e+03],\n",
      "       [7.55411997e-01, 3.48232859e-02, 2.71632646e-02, 5.82169808e+01,\n",
      "        2.61461202e+04, 2.14546989e+04, 2.59593037e+03],\n",
      "       [7.55411996e-01, 3.48232858e-02, 2.71632646e-02, 5.82170010e+01,\n",
      "        2.61461202e+04, 2.14546989e+04, 2.59593035e+03],\n",
      "       [7.55411997e-01, 3.48232858e-02, 2.71632646e-02, 5.82169959e+01,\n",
      "        2.61461202e+04, 2.14546989e+04, 2.59593035e+03],\n",
      "       [7.55411998e-01, 3.48232858e-02, 2.71632646e-02, 5.82169941e+01,\n",
      "        2.61461202e+04, 2.14546989e+04, 2.59593032e+03],\n",
      "       [7.55411995e-01, 3.48232858e-02, 2.71632646e-02, 5.82170004e+01,\n",
      "        2.61461202e+04, 2.14546989e+04, 2.59593040e+03]]), array([41576.5, 41576.5, 41576.5, 41576.5, 41576.5, 41576.5, 41576.5,\n",
      "       41576.5]))\n",
      "           fun: 41576.5\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1256\n",
      "           nit: 405\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.55411994e-01, 3.48232858e-02, 2.71632646e-02, 5.82170166e+01,\n",
      "       2.61461202e+04, 2.14546989e+04, 2.59593041e+03])\n",
      "minPrevious 36789.27734375\n",
      "best ll: 58347.71875, bestParams: [tensor(0.2650), tensor(0.0442), tensor(0.0990), tensor(21229.7812), tensor(9095.1367), tensor(10942.7354), tensor(21495.9238)]\n",
      "epoch 4\n",
      " final_simplex: (array([[9.80324014e-01, 1.21927564e-02, 7.76490464e-04, 1.80567458e+04,\n",
      "        1.40979195e+04, 1.25553282e+04, 1.49977057e+04],\n",
      "       [9.80324014e-01, 1.21927564e-02, 7.76490482e-04, 1.80567458e+04,\n",
      "        1.40979195e+04, 1.25553282e+04, 1.49977057e+04],\n",
      "       [9.80324014e-01, 1.21927564e-02, 7.76490436e-04, 1.80567459e+04,\n",
      "        1.40979195e+04, 1.25553283e+04, 1.49977056e+04],\n",
      "       [9.80324014e-01, 1.21927564e-02, 7.76490602e-04, 1.80567458e+04,\n",
      "        1.40979195e+04, 1.25553282e+04, 1.49977058e+04],\n",
      "       [9.80324014e-01, 1.21927563e-02, 7.76491066e-04, 1.80567457e+04,\n",
      "        1.40979195e+04, 1.25553282e+04, 1.49977057e+04],\n",
      "       [9.80324013e-01, 1.21927564e-02, 7.76490881e-04, 1.80567457e+04,\n",
      "        1.40979195e+04, 1.25553282e+04, 1.49977058e+04],\n",
      "       [9.80324014e-01, 1.21927565e-02, 7.76490603e-04, 1.80567458e+04,\n",
      "        1.40979196e+04, 1.25553282e+04, 1.49977057e+04],\n",
      "       [9.80324014e-01, 1.21927564e-02, 7.76490512e-04, 1.80567459e+04,\n",
      "        1.40979195e+04, 1.25553283e+04, 1.49977057e+04]]), array([37026.21875, 37026.21875, 37026.21875, 37026.21875, 37026.21875,\n",
      "       37026.21875, 37026.21875, 37026.21875]))\n",
      "           fun: 37026.21875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1270\n",
      "           nit: 433\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.80324014e-01, 1.21927564e-02, 7.76490464e-04, 1.80567458e+04,\n",
      "       1.40979195e+04, 1.25553282e+04, 1.49977057e+04])\n",
      "minPrevious 36789.27734375\n",
      "best ll: 53466.0390625, bestParams: [tensor(0.3663), tensor(0.1166), tensor(0.0202), tensor(16992.2559), tensor(893.4237), tensor(1013.7308), tensor(23481.1777)]\n",
      "epoch 5\n",
      " final_simplex: (array([[9.53878353e-01, 3.64250544e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845071e-01, 8.63449621e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845064e-01, 8.63449623e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845070e-01, 8.63449613e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845078e-01, 8.63449609e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845089e-01, 8.63449620e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845081e-01, 8.63449603e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845098e-01, 8.63449628e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845065e-01, 8.63449635e-01, 4.25097504e+04]]), array([25604.76953125, 25604.76953125, 25604.76953125, 25604.76953125,\n",
      "       25604.76953125, 25604.76953125, 25604.76953125, 25604.76953125]))\n",
      "           fun: 25604.76953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1541\n",
      "           nit: 654\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.53878353e-01, 3.64250544e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "       8.57845071e-01, 8.63449621e-01, 4.25097504e+04])\n",
      "minPrevious 36789.27734375\n",
      "better by at >= 1; new ll:  final_simplex: (array([[9.53878353e-01, 3.64250544e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845071e-01, 8.63449621e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845064e-01, 8.63449623e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845070e-01, 8.63449613e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845078e-01, 8.63449609e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845089e-01, 8.63449620e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845081e-01, 8.63449603e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845098e-01, 8.63449628e-01, 4.25097504e+04],\n",
      "       [9.53878353e-01, 3.64250543e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "        8.57845065e-01, 8.63449635e-01, 4.25097504e+04]]), array([25604.76953125, 25604.76953125, 25604.76953125, 25604.76953125,\n",
      "       25604.76953125, 25604.76953125, 25604.76953125, 25604.76953125]))\n",
      "           fun: 25604.76953125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1541\n",
      "           nit: 654\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.53878353e-01, 3.64250544e-03, 4.08982463e-02, 2.51090266e+03,\n",
      "       8.57845071e-01, 8.63449621e-01, 4.25097504e+04])\n",
      "best ll: 55263.82421875, bestParams: [tensor(0.3145), tensor(0.0302), tensor(0.0786), tensor(6067.9370), tensor(24727.1953), tensor(21795.3066), tensor(1569.9390)]\n",
      "epoch 6\n",
      " final_simplex: (array([[3.29577971e-01, 3.01701391e-02, 7.85784976e-02, 6.07044751e+03,\n",
      "        2.47313961e+04, 2.17929258e+04, 1.57123388e+03],\n",
      "       [3.29577973e-01, 3.01701393e-02, 7.85784977e-02, 6.07044745e+03,\n",
      "        2.47313961e+04, 2.17929258e+04, 1.57123387e+03],\n",
      "       [3.29577972e-01, 3.01701392e-02, 7.85784976e-02, 6.07044748e+03,\n",
      "        2.47313961e+04, 2.17929257e+04, 1.57123387e+03],\n",
      "       [3.29577972e-01, 3.01701392e-02, 7.85784976e-02, 6.07044745e+03,\n",
      "        2.47313961e+04, 2.17929257e+04, 1.57123389e+03],\n",
      "       [3.29577972e-01, 3.01701395e-02, 7.85784976e-02, 6.07044742e+03,\n",
      "        2.47313961e+04, 2.17929258e+04, 1.57123389e+03],\n",
      "       [3.29577973e-01, 3.01701391e-02, 7.85784976e-02, 6.07044744e+03,\n",
      "        2.47313961e+04, 2.17929257e+04, 1.57123389e+03],\n",
      "       [3.29577972e-01, 3.01701388e-02, 7.85784976e-02, 6.07044753e+03,\n",
      "        2.47313961e+04, 2.17929257e+04, 1.57123388e+03],\n",
      "       [3.29577973e-01, 3.01701393e-02, 7.85784977e-02, 6.07044746e+03,\n",
      "        2.47313961e+04, 2.17929258e+04, 1.57123387e+03]]), array([54430.7421875, 54430.7421875, 54430.7421875, 54430.7421875,\n",
      "       54430.7421875, 54430.7421875, 54430.7421875, 54430.7421875]))\n",
      "           fun: 54430.7421875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1034\n",
      "           nit: 267\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.29577971e-01, 3.01701391e-02, 7.85784976e-02, 6.07044751e+03,\n",
      "       2.47313961e+04, 2.17929258e+04, 1.57123388e+03])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 54207.0859375, bestParams: [tensor(0.3468), tensor(0.0995), tensor(0.0031), tensor(4166.8984), tensor(4787.5410), tensor(4041.3237), tensor(18271.9062)]\n",
      "epoch 7\n",
      " final_simplex: (array([[9.16675522e-01, 7.98620077e-02, 2.86405524e-03, 4.78010602e+03,\n",
      "        2.78489631e+03, 2.80471519e+03, 1.52691829e+04],\n",
      "       [9.16675523e-01, 7.98620082e-02, 2.86405522e-03, 4.78010603e+03,\n",
      "        2.78489631e+03, 2.80471518e+03, 1.52691829e+04],\n",
      "       [9.16675522e-01, 7.98620085e-02, 2.86405521e-03, 4.78010604e+03,\n",
      "        2.78489631e+03, 2.80471517e+03, 1.52691829e+04],\n",
      "       [9.16675522e-01, 7.98620086e-02, 2.86405520e-03, 4.78010604e+03,\n",
      "        2.78489631e+03, 2.80471518e+03, 1.52691829e+04],\n",
      "       [9.16675522e-01, 7.98620085e-02, 2.86405521e-03, 4.78010604e+03,\n",
      "        2.78489632e+03, 2.80471519e+03, 1.52691829e+04],\n",
      "       [9.16675522e-01, 7.98620079e-02, 2.86405521e-03, 4.78010603e+03,\n",
      "        2.78489631e+03, 2.80471519e+03, 1.52691830e+04],\n",
      "       [9.16675521e-01, 7.98620083e-02, 2.86405522e-03, 4.78010603e+03,\n",
      "        2.78489633e+03, 2.80471517e+03, 1.52691829e+04],\n",
      "       [9.16675523e-01, 7.98620083e-02, 2.86405519e-03, 4.78010605e+03,\n",
      "        2.78489630e+03, 2.80471520e+03, 1.52691830e+04]]), array([38352.61328125, 38352.61328125, 38352.61328125, 38352.61328125,\n",
      "       38352.61328125, 38352.61328125, 38352.61328125, 38352.61328125]))\n",
      "           fun: 38352.61328125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1165\n",
      "           nit: 363\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.16675522e-01, 7.98620077e-02, 2.86405524e-03, 4.78010602e+03,\n",
      "       2.78489631e+03, 2.80471519e+03, 1.52691829e+04])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 51697.78125, bestParams: [tensor(0.4074), tensor(0.0187), tensor(0.0511), tensor(18615.8457), tensor(18517.0469), tensor(19175.3125), tensor(9360.9336)]\n",
      "epoch 8\n",
      " final_simplex: (array([[9.52248210e-01, 1.69496380e-02, 2.88901592e-02, 1.68759073e+04,\n",
      "        1.53606423e+04, 1.47353100e+04, 8.59765032e+03],\n",
      "       [9.52248206e-01, 1.69496379e-02, 2.88901599e-02, 1.68759073e+04,\n",
      "        1.53606423e+04, 1.47353100e+04, 8.59765027e+03],\n",
      "       [9.52248207e-01, 1.69496380e-02, 2.88901598e-02, 1.68759073e+04,\n",
      "        1.53606423e+04, 1.47353100e+04, 8.59765028e+03],\n",
      "       [9.52248206e-01, 1.69496379e-02, 2.88901597e-02, 1.68759073e+04,\n",
      "        1.53606423e+04, 1.47353100e+04, 8.59765027e+03],\n",
      "       [9.52248211e-01, 1.69496380e-02, 2.88901591e-02, 1.68759073e+04,\n",
      "        1.53606423e+04, 1.47353100e+04, 8.59765033e+03],\n",
      "       [9.52248209e-01, 1.69496380e-02, 2.88901593e-02, 1.68759073e+04,\n",
      "        1.53606423e+04, 1.47353100e+04, 8.59765032e+03],\n",
      "       [9.52248209e-01, 1.69496380e-02, 2.88901594e-02, 1.68759073e+04,\n",
      "        1.53606423e+04, 1.47353099e+04, 8.59765029e+03],\n",
      "       [9.52248207e-01, 1.69496380e-02, 2.88901597e-02, 1.68759073e+04,\n",
      "        1.53606423e+04, 1.47353099e+04, 8.59765027e+03]]), array([37116.12890625, 37116.12890625, 37116.12890625, 37116.12890625,\n",
      "       37116.12890625, 37116.12890625, 37116.12890625, 37116.12890625]))\n",
      "           fun: 37116.12890625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1208\n",
      "           nit: 415\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.52248210e-01, 1.69496380e-02, 2.88901592e-02, 1.68759073e+04,\n",
      "       1.53606423e+04, 1.47353100e+04, 8.59765032e+03])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 57307.5, bestParams: [tensor(0.3005), tensor(0.1335), tensor(0.0846), tensor(18562.1230), tensor(21906.2676), tensor(18411.4297), tensor(15196.3916)]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.18055049e-01, 1.76111254e-02, 5.45627851e-02, 1.88078297e+04,\n",
      "        1.88210668e+04, 2.10560324e+04, 7.33196787e+03],\n",
      "       [9.18055048e-01, 1.76111253e-02, 5.45627851e-02, 1.88078297e+04,\n",
      "        1.88210667e+04, 2.10560324e+04, 7.33196782e+03],\n",
      "       [9.18055049e-01, 1.76111251e-02, 5.45627849e-02, 1.88078297e+04,\n",
      "        1.88210668e+04, 2.10560324e+04, 7.33196786e+03],\n",
      "       [9.18055048e-01, 1.76111251e-02, 5.45627850e-02, 1.88078297e+04,\n",
      "        1.88210668e+04, 2.10560325e+04, 7.33196783e+03],\n",
      "       [9.18055048e-01, 1.76111252e-02, 5.45627850e-02, 1.88078297e+04,\n",
      "        1.88210668e+04, 2.10560325e+04, 7.33196782e+03],\n",
      "       [9.18055049e-01, 1.76111250e-02, 5.45627849e-02, 1.88078297e+04,\n",
      "        1.88210668e+04, 2.10560325e+04, 7.33196784e+03],\n",
      "       [9.18055048e-01, 1.76111253e-02, 5.45627850e-02, 1.88078297e+04,\n",
      "        1.88210667e+04, 2.10560325e+04, 7.33196780e+03],\n",
      "       [9.18055048e-01, 1.76111254e-02, 5.45627851e-02, 1.88078297e+04,\n",
      "        1.88210667e+04, 2.10560324e+04, 7.33196783e+03]]), array([37832.62109375, 37832.62109375, 37832.62109375, 37832.62109375,\n",
      "       37832.62109375, 37832.62109375, 37832.62109375, 37832.62109375]))\n",
      "           fun: 37832.62109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1242\n",
      "           nit: 417\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.18055049e-01, 1.76111254e-02, 5.45627851e-02, 1.88078297e+04,\n",
      "       1.88210668e+04, 2.10560324e+04, 7.33196787e+03])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 53506.69921875, bestParams: [tensor(0.3708), tensor(0.0072), tensor(0.0533), tensor(22601.7715), tensor(14223.4170), tensor(18780.3496), tensor(2186.3042)]\n",
      "epoch 10\n",
      " final_simplex: (array([[9.60667864e-01, 8.15250126e-03, 3.04061409e-02, 1.89056313e+04,\n",
      "        1.39640361e+04, 1.30125027e+04, 1.26629453e+03],\n",
      "       [9.60667865e-01, 8.15250123e-03, 3.04061409e-02, 1.89056312e+04,\n",
      "        1.39640361e+04, 1.30125027e+04, 1.26629454e+03],\n",
      "       [9.60667864e-01, 8.15250124e-03, 3.04061409e-02, 1.89056312e+04,\n",
      "        1.39640360e+04, 1.30125027e+04, 1.26629454e+03],\n",
      "       [9.60667865e-01, 8.15250125e-03, 3.04061409e-02, 1.89056313e+04,\n",
      "        1.39640360e+04, 1.30125027e+04, 1.26629453e+03],\n",
      "       [9.60667864e-01, 8.15250124e-03, 3.04061409e-02, 1.89056313e+04,\n",
      "        1.39640360e+04, 1.30125027e+04, 1.26629453e+03],\n",
      "       [9.60667865e-01, 8.15250127e-03, 3.04061407e-02, 1.89056312e+04,\n",
      "        1.39640361e+04, 1.30125027e+04, 1.26629452e+03],\n",
      "       [9.60667865e-01, 8.15250122e-03, 3.04061409e-02, 1.89056312e+04,\n",
      "        1.39640361e+04, 1.30125026e+04, 1.26629454e+03],\n",
      "       [9.60667865e-01, 8.15250127e-03, 3.04061409e-02, 1.89056312e+04,\n",
      "        1.39640361e+04, 1.30125026e+04, 1.26629453e+03]]), array([37257.890625, 37257.890625, 37257.890625, 37257.890625,\n",
      "       37257.890625, 37257.890625, 37257.890625, 37257.890625]))\n",
      "           fun: 37257.890625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1227\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.60667864e-01, 8.15250126e-03, 3.04061409e-02, 1.89056313e+04,\n",
      "       1.39640361e+04, 1.30125027e+04, 1.26629453e+03])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 56618.734375, bestParams: [tensor(0.3060), tensor(0.1597), tensor(0.0761), tensor(4295.5698), tensor(16258.0547), tensor(14482.2031), tensor(5185.8438)]\n",
      "epoch 11\n",
      " final_simplex: (array([[9.08258930e-01, 3.63946099e-03, 8.35354179e-02, 9.70096567e+02,\n",
      "        1.58014884e+04, 1.49886671e+04, 2.54655584e+03],\n",
      "       [9.08258924e-01, 3.63945579e-03, 8.35354175e-02, 9.70096655e+02,\n",
      "        1.58014884e+04, 1.49886671e+04, 2.54655584e+03],\n",
      "       [9.08258930e-01, 3.63945897e-03, 8.35354184e-02, 9.70096578e+02,\n",
      "        1.58014884e+04, 1.49886671e+04, 2.54655585e+03],\n",
      "       [9.08258930e-01, 3.63945801e-03, 8.35354178e-02, 9.70096585e+02,\n",
      "        1.58014884e+04, 1.49886671e+04, 2.54655584e+03],\n",
      "       [9.08258929e-01, 3.63945771e-03, 8.35354173e-02, 9.70096608e+02,\n",
      "        1.58014884e+04, 1.49886671e+04, 2.54655585e+03],\n",
      "       [9.08258928e-01, 3.63945843e-03, 8.35354176e-02, 9.70096612e+02,\n",
      "        1.58014884e+04, 1.49886671e+04, 2.54655584e+03],\n",
      "       [9.08258931e-01, 3.63945890e-03, 8.35354180e-02, 9.70096573e+02,\n",
      "        1.58014884e+04, 1.49886671e+04, 2.54655583e+03],\n",
      "       [9.08258927e-01, 3.63945786e-03, 8.35354177e-02, 9.70096617e+02,\n",
      "        1.58014884e+04, 1.49886671e+04, 2.54655586e+03]]), array([38277.1015625, 38277.1015625, 38277.1015625, 38277.1015625,\n",
      "       38277.1015625, 38277.1015625, 38277.1015625, 38277.1015625]))\n",
      "           fun: 38277.1015625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1179\n",
      "           nit: 416\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.08258930e-01, 3.63946099e-03, 8.35354179e-02, 9.70096567e+02,\n",
      "       1.58014884e+04, 1.49886671e+04, 2.54655584e+03])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 60917.87890625, bestParams: [tensor(0.2987), tensor(0.1276), tensor(0.2251), tensor(24676.1250), tensor(15306.4023), tensor(8216.4785), tensor(24238.7871)]\n",
      "epoch 12\n",
      " final_simplex: (array([[9.39653564e-01, 5.30073440e-02, 7.03018668e-04, 1.67272514e+04,\n",
      "        1.56980772e+04, 1.42611322e+04, 1.70170707e+04],\n",
      "       [9.39653565e-01, 5.30073442e-02, 7.03018424e-04, 1.67272514e+04,\n",
      "        1.56980772e+04, 1.42611322e+04, 1.70170707e+04],\n",
      "       [9.39653565e-01, 5.30073441e-02, 7.03018577e-04, 1.67272514e+04,\n",
      "        1.56980772e+04, 1.42611322e+04, 1.70170707e+04],\n",
      "       [9.39653565e-01, 5.30073443e-02, 7.03018465e-04, 1.67272514e+04,\n",
      "        1.56980772e+04, 1.42611322e+04, 1.70170707e+04],\n",
      "       [9.39653565e-01, 5.30073443e-02, 7.03018549e-04, 1.67272514e+04,\n",
      "        1.56980772e+04, 1.42611322e+04, 1.70170707e+04],\n",
      "       [9.39653565e-01, 5.30073442e-02, 7.03018415e-04, 1.67272514e+04,\n",
      "        1.56980772e+04, 1.42611322e+04, 1.70170707e+04],\n",
      "       [9.39653565e-01, 5.30073442e-02, 7.03018321e-04, 1.67272514e+04,\n",
      "        1.56980773e+04, 1.42611322e+04, 1.70170706e+04],\n",
      "       [9.39653565e-01, 5.30073443e-02, 7.03018218e-04, 1.67272514e+04,\n",
      "        1.56980773e+04, 1.42611322e+04, 1.70170706e+04]]), array([37559.7109375, 37559.7109375, 37559.7109375, 37559.7109375,\n",
      "       37559.7109375, 37559.7109375, 37559.7109375, 37559.7109375]))\n",
      "           fun: 37559.7109375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1351\n",
      "           nit: 464\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.39653564e-01, 5.30073440e-02, 7.03018668e-04, 1.67272514e+04,\n",
      "       1.56980772e+04, 1.42611322e+04, 1.70170707e+04])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 59039.6171875, bestParams: [tensor(0.2460), tensor(0.0278), tensor(0.0649), tensor(1689.0751), tensor(19712.7480), tensor(24935.2988), tensor(4604.6455)]\n",
      "epoch 13\n",
      " final_simplex: (array([[9.85557519e-01, 1.10583491e-02, 2.18919643e-03, 4.43604879e+02,\n",
      "        4.66259420e+03, 4.64148877e+03, 5.50814132e+03],\n",
      "       [9.85557518e-01, 1.10583491e-02, 2.18919652e-03, 4.43604880e+02,\n",
      "        4.66259421e+03, 4.64148876e+03, 5.50814132e+03],\n",
      "       [9.85557519e-01, 1.10583491e-02, 2.18919637e-03, 4.43604882e+02,\n",
      "        4.66259418e+03, 4.64148877e+03, 5.50814133e+03],\n",
      "       [9.85557518e-01, 1.10583491e-02, 2.18919640e-03, 4.43604881e+02,\n",
      "        4.66259420e+03, 4.64148882e+03, 5.50814133e+03],\n",
      "       [9.85557518e-01, 1.10583491e-02, 2.18919633e-03, 4.43604879e+02,\n",
      "        4.66259422e+03, 4.64148883e+03, 5.50814133e+03],\n",
      "       [9.85557518e-01, 1.10583491e-02, 2.18919637e-03, 4.43604883e+02,\n",
      "        4.66259419e+03, 4.64148884e+03, 5.50814132e+03],\n",
      "       [9.85557517e-01, 1.10583492e-02, 2.18919636e-03, 4.43604874e+02,\n",
      "        4.66259429e+03, 4.64148883e+03, 5.50814133e+03],\n",
      "       [9.85557519e-01, 1.10583491e-02, 2.18919637e-03, 4.43604883e+02,\n",
      "        4.66259417e+03, 4.64148876e+03, 5.50814133e+03]]), array([36858.6171875, 36858.6171875, 36858.6171875, 36858.6171875,\n",
      "       36858.6171875, 36858.6171875, 36858.6171875, 36858.6171875]))\n",
      "           fun: 36858.6171875\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1406\n",
      "           nit: 548\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.85557519e-01, 1.10583491e-02, 2.18919643e-03, 4.43604879e+02,\n",
      "       4.66259420e+03, 4.64148877e+03, 5.50814132e+03])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 58927.60546875, bestParams: [tensor(0.3114), tensor(0.0229), tensor(0.2170), tensor(21168.3105), tensor(8921.6475), tensor(5104.0801), tensor(18405.7422)]\n",
      "epoch 14\n",
      " final_simplex: (array([[9.81119263e-01, 1.57302899e-02, 2.56917760e-03, 2.95354257e+04,\n",
      "        5.53651940e+03, 5.44889933e+03, 1.36488948e+03],\n",
      "       [9.81119262e-01, 1.57302898e-02, 2.56917751e-03, 2.95354258e+04,\n",
      "        5.53651940e+03, 5.44889933e+03, 1.36488944e+03],\n",
      "       [9.81119262e-01, 1.57302896e-02, 2.56917722e-03, 2.95354258e+04,\n",
      "        5.53651940e+03, 5.44889934e+03, 1.36488945e+03],\n",
      "       [9.81119262e-01, 1.57302900e-02, 2.56917817e-03, 2.95354256e+04,\n",
      "        5.53651941e+03, 5.44889934e+03, 1.36488955e+03],\n",
      "       [9.81119262e-01, 1.57302897e-02, 2.56917751e-03, 2.95354257e+04,\n",
      "        5.53651939e+03, 5.44889934e+03, 1.36488948e+03],\n",
      "       [9.81119262e-01, 1.57302899e-02, 2.56917808e-03, 2.95354257e+04,\n",
      "        5.53651939e+03, 5.44889934e+03, 1.36488951e+03],\n",
      "       [9.81119262e-01, 1.57302898e-02, 2.56917800e-03, 2.95354257e+04,\n",
      "        5.53651939e+03, 5.44889935e+03, 1.36488951e+03],\n",
      "       [9.81119262e-01, 1.57302898e-02, 2.56917721e-03, 2.95354257e+04,\n",
      "        5.53651943e+03, 5.44889932e+03, 1.36488947e+03]]), array([36932.05078125, 36932.05078125, 36932.05078125, 36932.05078125,\n",
      "       36932.05078125, 36932.05078125, 36932.05078125, 36932.05078125]))\n",
      "           fun: 36932.05078125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1248\n",
      "           nit: 449\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.81119263e-01, 1.57302899e-02, 2.56917760e-03, 2.95354257e+04,\n",
      "       5.53651940e+03, 5.44889933e+03, 1.36488948e+03])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 51539.4140625, bestParams: [tensor(0.4275), tensor(0.0355), tensor(0.0393), tensor(3378.9702), tensor(16413.2578), tensor(12186.4902), tensor(19162.9902)]\n",
      "epoch 15\n",
      " final_simplex: (array([[9.48058622e-01, 2.18507302e-02, 2.66392066e-02, 2.92665913e+03,\n",
      "        1.34293388e+04, 1.49971453e+04, 2.05271162e+04],\n",
      "       [9.48058621e-01, 2.18507303e-02, 2.66392066e-02, 2.92665914e+03,\n",
      "        1.34293388e+04, 1.49971453e+04, 2.05271161e+04],\n",
      "       [9.48058621e-01, 2.18507303e-02, 2.66392066e-02, 2.92665912e+03,\n",
      "        1.34293388e+04, 1.49971453e+04, 2.05271161e+04],\n",
      "       [9.48058622e-01, 2.18507301e-02, 2.66392066e-02, 2.92665914e+03,\n",
      "        1.34293388e+04, 1.49971453e+04, 2.05271162e+04],\n",
      "       [9.48058621e-01, 2.18507303e-02, 2.66392066e-02, 2.92665913e+03,\n",
      "        1.34293388e+04, 1.49971453e+04, 2.05271161e+04],\n",
      "       [9.48058621e-01, 2.18507304e-02, 2.66392066e-02, 2.92665912e+03,\n",
      "        1.34293388e+04, 1.49971453e+04, 2.05271162e+04],\n",
      "       [9.48058622e-01, 2.18507303e-02, 2.66392066e-02, 2.92665913e+03,\n",
      "        1.34293388e+04, 1.49971453e+04, 2.05271162e+04],\n",
      "       [9.48058621e-01, 2.18507303e-02, 2.66392066e-02, 2.92665913e+03,\n",
      "        1.34293389e+04, 1.49971453e+04, 2.05271162e+04]]), array([37646.125, 37646.125, 37646.125, 37646.125, 37646.125, 37646.125,\n",
      "       37646.125, 37646.125]))\n",
      "           fun: 37646.125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1206\n",
      "           nit: 406\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.48058622e-01, 2.18507302e-02, 2.66392066e-02, 2.92665913e+03,\n",
      "       1.34293388e+04, 1.49971453e+04, 2.05271162e+04])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 57906.9453125, bestParams: [tensor(0.2987), tensor(0.0591), tensor(0.0539), tensor(20111.7324), tensor(6444.3765), tensor(10081.1709), tensor(18429.2324)]\n",
      "epoch 16\n",
      " final_simplex: (array([[9.56097910e-01, 2.12857057e-02, 2.13427951e-02, 8.80717591e+03,\n",
      "        7.63100860e+03, 7.49913780e+03, 1.64936973e+04],\n",
      "       [9.56097911e-01, 2.12857056e-02, 2.13427950e-02, 8.80717593e+03,\n",
      "        7.63100860e+03, 7.49913780e+03, 1.64936973e+04],\n",
      "       [9.56097911e-01, 2.12857056e-02, 2.13427950e-02, 8.80717593e+03,\n",
      "        7.63100861e+03, 7.49913779e+03, 1.64936973e+04],\n",
      "       [9.56097911e-01, 2.12857056e-02, 2.13427950e-02, 8.80717592e+03,\n",
      "        7.63100860e+03, 7.49913779e+03, 1.64936973e+04],\n",
      "       [9.56097911e-01, 2.12857055e-02, 2.13427950e-02, 8.80717595e+03,\n",
      "        7.63100861e+03, 7.49913778e+03, 1.64936973e+04],\n",
      "       [9.56097911e-01, 2.12857055e-02, 2.13427950e-02, 8.80717595e+03,\n",
      "        7.63100861e+03, 7.49913778e+03, 1.64936973e+04],\n",
      "       [9.56097911e-01, 2.12857055e-02, 2.13427950e-02, 8.80717601e+03,\n",
      "        7.63100862e+03, 7.49913778e+03, 1.64936973e+04],\n",
      "       [9.56097910e-01, 2.12857056e-02, 2.13427950e-02, 8.80717600e+03,\n",
      "        7.63100862e+03, 7.49913778e+03, 1.64936973e+04]]), array([37434.4609375, 37434.4609375, 37434.4609375, 37434.4609375,\n",
      "       37434.4609375, 37434.4609375, 37434.4609375, 37434.4609375]))\n",
      "           fun: 37434.4609375\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1283\n",
      "           nit: 433\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.56097910e-01, 2.12857057e-02, 2.13427951e-02, 8.80717591e+03,\n",
      "       7.63100860e+03, 7.49913780e+03, 1.64936973e+04])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 58931.203125, bestParams: [tensor(0.2798), tensor(0.0897), tensor(0.2506), tensor(10560.1113), tensor(15546.8545), tensor(16433.2188), tensor(12440.3115)]\n",
      "epoch 17\n",
      " final_simplex: (array([[7.88100834e-01, 8.05269783e-03, 2.01887691e-01, 7.06847386e+03,\n",
      "        1.44738650e+04, 1.55360552e+04, 1.07533614e+04],\n",
      "       [7.88100832e-01, 8.05269846e-03, 2.01887689e-01, 7.06847391e+03,\n",
      "        1.44738650e+04, 1.55360552e+04, 1.07533614e+04],\n",
      "       [7.88100833e-01, 8.05269795e-03, 2.01887690e-01, 7.06847388e+03,\n",
      "        1.44738650e+04, 1.55360551e+04, 1.07533614e+04],\n",
      "       [7.88100833e-01, 8.05269779e-03, 2.01887690e-01, 7.06847388e+03,\n",
      "        1.44738651e+04, 1.55360551e+04, 1.07533615e+04],\n",
      "       [7.88100834e-01, 8.05269774e-03, 2.01887690e-01, 7.06847387e+03,\n",
      "        1.44738651e+04, 1.55360551e+04, 1.07533615e+04],\n",
      "       [7.88100833e-01, 8.05269801e-03, 2.01887690e-01, 7.06847389e+03,\n",
      "        1.44738650e+04, 1.55360551e+04, 1.07533614e+04],\n",
      "       [7.88100834e-01, 8.05269764e-03, 2.01887690e-01, 7.06847388e+03,\n",
      "        1.44738650e+04, 1.55360552e+04, 1.07533614e+04],\n",
      "       [7.88100833e-01, 8.05269791e-03, 2.01887690e-01, 7.06847388e+03,\n",
      "        1.44738651e+04, 1.55360551e+04, 1.07533615e+04]]), array([41039.25390625, 41039.25390625, 41039.25390625, 41039.25390625,\n",
      "       41039.25390625, 41039.25390625, 41039.25390625, 41039.25390625]))\n",
      "           fun: 41039.25390625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1239\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.88100834e-01, 8.05269783e-03, 2.01887691e-01, 7.06847386e+03,\n",
      "       1.44738650e+04, 1.55360552e+04, 1.07533614e+04])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 58694.18359375, bestParams: [tensor(0.3025), tensor(0.0550), tensor(0.1982), tensor(24690.5078), tensor(24995.7188), tensor(15507.8018), tensor(6770.2603)]\n",
      "epoch 18\n",
      " final_simplex: (array([[8.76804207e-01, 4.73035828e-02, 7.03966777e-02, 2.81083344e+04,\n",
      "        1.37292876e+04, 1.63514860e+04, 4.91314682e+03],\n",
      "       [8.76804207e-01, 4.73035827e-02, 7.03966781e-02, 2.81083343e+04,\n",
      "        1.37292876e+04, 1.63514860e+04, 4.91314683e+03],\n",
      "       [8.76804206e-01, 4.73035827e-02, 7.03966785e-02, 2.81083343e+04,\n",
      "        1.37292876e+04, 1.63514859e+04, 4.91314683e+03],\n",
      "       [8.76804207e-01, 4.73035827e-02, 7.03966780e-02, 2.81083344e+04,\n",
      "        1.37292877e+04, 1.63514859e+04, 4.91314682e+03],\n",
      "       [8.76804207e-01, 4.73035827e-02, 7.03966781e-02, 2.81083345e+04,\n",
      "        1.37292877e+04, 1.63514859e+04, 4.91314682e+03],\n",
      "       [8.76804205e-01, 4.73035827e-02, 7.03966783e-02, 2.81083343e+04,\n",
      "        1.37292877e+04, 1.63514859e+04, 4.91314684e+03],\n",
      "       [8.76804207e-01, 4.73035828e-02, 7.03966781e-02, 2.81083344e+04,\n",
      "        1.37292876e+04, 1.63514860e+04, 4.91314680e+03],\n",
      "       [8.76804205e-01, 4.73035826e-02, 7.03966791e-02, 2.81083344e+04,\n",
      "        1.37292877e+04, 1.63514859e+04, 4.91314682e+03]]), array([39091.48828125, 39091.48828125, 39091.48828125, 39091.48828125,\n",
      "       39091.48828125, 39091.48828125, 39091.48828125, 39091.48828125]))\n",
      "           fun: 39091.48828125\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1209\n",
      "           nit: 398\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.76804207e-01, 4.73035828e-02, 7.03966777e-02, 2.81083344e+04,\n",
      "       1.37292876e+04, 1.63514860e+04, 4.91314682e+03])\n",
      "minPrevious 25604.76953125\n",
      "best ll: 63007.875, bestParams: [tensor(0.3039), tensor(0.0413), tensor(0.1373), tensor(15812.8906), tensor(9474.6367), tensor(24025.1523), tensor(3550.7539)]\n",
      "epoch 19\n",
      " final_simplex: (array([[8.81769997e-01, 4.81541902e-02, 6.90945115e-02, 8.09668105e+03,\n",
      "        1.12537705e+04, 1.10947912e+04, 2.59586083e+03],\n",
      "       [8.81769998e-01, 4.81541902e-02, 6.90945112e-02, 8.09668104e+03,\n",
      "        1.12537705e+04, 1.10947912e+04, 2.59586083e+03],\n",
      "       [8.81769997e-01, 4.81541901e-02, 6.90945118e-02, 8.09668105e+03,\n",
      "        1.12537705e+04, 1.10947912e+04, 2.59586083e+03],\n",
      "       [8.81769997e-01, 4.81541905e-02, 6.90945101e-02, 8.09668101e+03,\n",
      "        1.12537706e+04, 1.10947912e+04, 2.59586086e+03],\n",
      "       [8.81769997e-01, 4.81541901e-02, 6.90945116e-02, 8.09668105e+03,\n",
      "        1.12537705e+04, 1.10947912e+04, 2.59586083e+03],\n",
      "       [8.81769996e-01, 4.81541903e-02, 6.90945110e-02, 8.09668103e+03,\n",
      "        1.12537705e+04, 1.10947913e+04, 2.59586085e+03],\n",
      "       [8.81769997e-01, 4.81541903e-02, 6.90945110e-02, 8.09668103e+03,\n",
      "        1.12537705e+04, 1.10947913e+04, 2.59586085e+03],\n",
      "       [8.81769999e-01, 4.81541902e-02, 6.90945111e-02, 8.09668103e+03,\n",
      "        1.12537706e+04, 1.10947912e+04, 2.59586083e+03]]), array([38984.3515625, 38984.3515625, 38984.3515625, 38984.3515625,\n",
      "       38984.3515625, 38984.3515625, 38984.3515625, 38984.3515625]))\n",
      "           fun: 38984.3515625\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1245\n",
      "           nit: 430\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.81769997e-01, 4.81541902e-02, 6.90945115e-02, 8.09668105e+03,\n",
      "       1.12537705e+04, 1.10947912e+04, 2.59586083e+03])\n",
      "minPrevious 25604.76953125\n",
      "inferredPis tensor([0.9539, 0.0036, 0.0409], dtype=torch.float64)\n",
      "inferredAlphas tensor([2.5109e+03, 8.5785e-01, 8.6345e-01, 4.2510e+04], dtype=torch.float64)\n",
      "truth0 tensor(0.7519) truth1 tensor(0.1111) truth2 tensor(0.1121) truthBoth tensor(0.0250)\n",
      "params on run 7 {'lls': [58132.7578125, 61020.8984375, 62816.03125, 61310.28125, 59964.953125, 47473.921875, 47433.734375, 47816.32421875, 47210.3984375, 51822.578125, 51970.546875, 47609.4609375, 52364.7734375, 53773.0390625, 47233.921875, 36342.86328125, 36234.44921875, 36770.3828125, 36826.53125, 36796.37109375, 36452.859375, 36562.25390625, 25604.76953125], 'inferredAlphas': [tensor([17771.7538,   267.5774,   285.4237, 19323.4289], dtype=torch.float64), tensor([17391.5067,   389.1159,   504.1465, 38945.6315], dtype=torch.float64), tensor([26599.6834,   330.5187,   522.2450, 20474.0527], dtype=torch.float64), tensor([17159.0905,   229.1438,   192.1196, 23702.7612], dtype=torch.float64), tensor([14365.2776,   353.8587,   277.5095, 36615.7416], dtype=torch.float64), tensor([4681.1768, 1514.9906,  279.5278, 6430.2365], dtype=torch.float64), tensor([11636.0228,  1941.4431,   317.7839,  2432.4090], dtype=torch.float64), tensor([3466.6976,  105.4401,  574.8790,  884.2902], dtype=torch.float64), tensor([  190.1304,   255.3843,  1367.9433, 10051.6183], dtype=torch.float64), tensor([13347.1036,  2995.2070,   679.1869,  9964.7306], dtype=torch.float64), tensor([3050.1159,  274.5893, 1270.7564, 7251.8219], dtype=torch.float64), tensor([1902.8937,  238.1495, 1249.7712, 7914.4684], dtype=torch.float64), tensor([20414.2533,  1255.3286,  5495.8171, 24486.6440], dtype=torch.float64), tensor([ 5422.4410,  1070.5042,  5035.1884, 34394.7350], dtype=torch.float64), tensor([6116.3640, 1549.1665,  277.2773, 5735.0947], dtype=torch.float64), tensor([ 3252.4160, 17197.7572, 17440.7641, 20021.9416], dtype=torch.float64), tensor([7562.1733, 8368.3120, 8779.7352, 8746.4345], dtype=torch.float64), tensor([24233.9895, 13108.5658, 12119.1812, 10209.1235], dtype=torch.float64), tensor([7396.8446, 8201.6473, 8380.9128, 7312.5791], dtype=torch.float64), tensor([11581.3164, 13430.0547, 13532.5939,  8888.3734], dtype=torch.float64), tensor([ 2985.4058, 14050.8558, 13064.3345,  7914.5139], dtype=torch.float64), tensor([11504.5958, 13023.1613, 13090.6367,  2388.4295], dtype=torch.float64), tensor([2.5109e+03, 8.5785e-01, 8.6345e-01, 4.2510e+04], dtype=torch.float64)], 'inferredPis': [tensor([0.2745, 0.5123, 0.0037], dtype=torch.float64), tensor([0.2424, 0.2423, 0.0335], dtype=torch.float64), tensor([0.2477, 0.1574, 0.0414], dtype=torch.float64), tensor([0.2670, 0.3576, 0.1152], dtype=torch.float64), tensor([0.4350, 0.2494, 0.0647], dtype=torch.float64), tensor([0.1319, 0.8504, 0.0173], dtype=torch.float64), tensor([0.1121, 0.8709, 0.0016], dtype=torch.float64), tensor([0.7272, 0.2531, 0.0189], dtype=torch.float64), tensor([0.8014, 0.1978, 0.0008], dtype=torch.float64), tensor([0.1527, 0.5340, 0.0406], dtype=torch.float64), tensor([4.4252e-01, 2.4141e-01, 6.9015e-05], dtype=torch.float64), tensor([0.7311, 0.2567, 0.0100], dtype=torch.float64), tensor([0.4108, 0.3023, 0.0150], dtype=torch.float64), tensor([0.4187, 0.1117, 0.0518], dtype=torch.float64), tensor([0.2033, 0.7863, 0.0045], dtype=torch.float64), tensor([0.9651, 0.0301, 0.0021], dtype=torch.float64), tensor([0.9906, 0.0041, 0.0032], dtype=torch.float64), tensor([9.9493e-01, 2.2532e-03, 5.0930e-04], dtype=torch.float64), tensor([0.9840, 0.0037, 0.0093], dtype=torch.float64), tensor([0.9764, 0.0103, 0.0102], dtype=torch.float64), tensor([0.9952, 0.0019, 0.0019], dtype=torch.float64), tensor([0.9904, 0.0023, 0.0011], dtype=torch.float64), tensor([0.9539, 0.0036, 0.0409], dtype=torch.float64)], 'inferredPDVs': [tensor([0.4720, 0.0071, 0.0076, 0.5133], dtype=torch.float64), tensor([0.3039, 0.0068, 0.0088, 0.6805], dtype=torch.float64), tensor([0.5550, 0.0069, 0.0109, 0.4272], dtype=torch.float64), tensor([0.4156, 0.0056, 0.0047, 0.5742], dtype=torch.float64), tensor([0.2783, 0.0069, 0.0054, 0.7095], dtype=torch.float64), tensor([0.3627, 0.1174, 0.0217, 0.4982], dtype=torch.float64), tensor([0.7126, 0.1189, 0.0195, 0.1490], dtype=torch.float64), tensor([0.6890, 0.0210, 0.1143, 0.1758], dtype=torch.float64), tensor([0.0160, 0.0215, 0.1153, 0.8471], dtype=torch.float64), tensor([0.4945, 0.1110, 0.0252, 0.3693], dtype=torch.float64), tensor([0.2575, 0.0232, 0.1073, 0.6120], dtype=torch.float64), tensor([0.1683, 0.0210, 0.1106, 0.7001], dtype=torch.float64), tensor([0.3952, 0.0243, 0.1064, 0.4741], dtype=torch.float64), tensor([0.1181, 0.0233, 0.1096, 0.7490], dtype=torch.float64), tensor([0.4472, 0.1133, 0.0203, 0.4192], dtype=torch.float64), tensor([0.0562, 0.2969, 0.3011, 0.3458], dtype=torch.float64), tensor([0.2260, 0.2501, 0.2624, 0.2614], dtype=torch.float64), tensor([0.4061, 0.2197, 0.2031, 0.1711], dtype=torch.float64), tensor([0.2364, 0.2621, 0.2678, 0.2337], dtype=torch.float64), tensor([0.2442, 0.2832, 0.2853, 0.1874], dtype=torch.float64), tensor([0.0785, 0.3696, 0.3436, 0.2082], dtype=torch.float64), tensor([0.2876, 0.3255, 0.3272, 0.0597], dtype=torch.float64), tensor([5.5758e-02, 1.9332e-05, 1.9136e-05, 9.4420e-01], dtype=torch.float64)], 'trueMeanPDVs': [tensor([0.7547, 0.1096, 0.1105, 0.0252]), tensor([0.7520, 0.1114, 0.1113, 0.0253]), tensor([0.7523, 0.1111, 0.1116, 0.0250]), tensor([0.7518, 0.1113, 0.1112, 0.0257]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7514, 0.1119, 0.1118, 0.0249]), tensor([0.7510, 0.1117, 0.1118, 0.0255]), tensor([0.7535, 0.1110, 0.1105, 0.0250]), tensor([0.7503, 0.1121, 0.1120, 0.0256]), tensor([0.7542, 0.1103, 0.1109, 0.0246]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250]), tensor([0.7519, 0.1111, 0.1121, 0.0250])], 'truePis': [tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500]), tensor([0.1000, 0.1000, 0.0500])]}\n",
      "tensor([[ 92.,   9.,   1.,   0.],\n",
      "        [ 64.,   7.,   0.,   0.],\n",
      "        [104.,  15.,   2.,   0.],\n",
      "        ...,\n",
      "        [123.,   1.,   1.,   0.],\n",
      "        [115.,   0.,   1.,   0.],\n",
      "        [103.,   2.,   3.,   0.]])\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood4 at 0x7feb3b271830>\n",
      "best ll: 56804.640625, bestParams: [tensor(0.3108), tensor(0.1461), tensor(0.1955), tensor(24214.4863), tensor(12580.4873), tensor(13942.1289), tensor(1821.3059)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if i >= len(cachedData):\n",
    "        disease1Large = Samples(1e6, 1e4)\n",
    "        disease2Large = Samples(1e6, 1e4)\n",
    "        diseaseBothLarge = Samples(1e5, 1e3)\n",
    "\n",
    "        nSamplesLarge = [disease1Large, disease2Large, diseaseBothLarge]\n",
    "        nSamplesLarge = tensor(nSamplesLarge)\n",
    "\n",
    "        pDsLarge = nSamplesLarge[:, 1]/nSamplesLarge.sum(1)\n",
    "\n",
    "        nCases = nSamplesLarge[:, 1]\n",
    "        nCtrls = tensor(disease1Large[0])\n",
    "        print(\"nCases\", nCases, \"nCtrls\", nCtrls)\n",
    "        print(\"pdS\", pDsLarge)\n",
    "        print(\"diseaseFractions\", diseaseFractions)\n",
    "        start = time.time()\n",
    "        altCountsByGenePooledCtrls, afsByGenePooledCtrls = genDataSequentialPooledCtrls(nCases=nCases, nCtrls=nCtrls, pDs=pDs, diseaseFractions=diseaseFractions, rrShape=rrShape, rrMeans=rrMeans, afMean=afMean, afShape=afShape)\n",
    "        print(\"took\", time.time() - start)\n",
    "        cachedData.append([altCountsByGenePooledCtrls, afsByGenePooledCtrls, {\n",
    "            \"nCases\": nCases,\n",
    "            \"nCtrls\": nCtrls,\n",
    "            \"pDs\": pDs,\n",
    "            \"diseaseFractions\": diseaseFractions,\n",
    "            \"rrShape\": rrShape,\n",
    "            \"rrMeans\": rrMeans,\n",
    "            \"afShape\": afShape,\n",
    "            \"afMean\": afMean\n",
    "        }])\n",
    "        \n",
    "    res = fitFnBivariate(cachedData[i][0], pDs, nEpochs=20, minLLThresholdCount=20, debug=True, costFnIdx=7)\n",
    "    bestRes = res[\"params\"][-1]\n",
    "\n",
    "    inferredPis = tensor(bestRes[0:3])\n",
    "    print(\"inferredPis\", inferredPis)\n",
    "    inferredAlphas = tensor(bestRes[3:])\n",
    "    print(\"inferredAlphas\", inferredAlphas)\n",
    "    \n",
    "    inferredPDs = Dirichlet(concentration=inferredAlphas).sample([10_000,]).mean(0)\n",
    "\n",
    "    params[\"lls\"].append(res[\"lls\"][-1])\n",
    "    params[\"inferredAlphas\"].append(inferredAlphas)\n",
    "    params[\"inferredPis\"].append(inferredPis)\n",
    "    params[\"inferredPDVs\"].append(inferredPDs)\n",
    "\n",
    "    truth1 = pDgivenV(pD[0], afsByGenePooledCtrls[0:2000, 0, 1], afsByGenePooledCtrls[0:2000, 0, 0]).mean()\n",
    "    truth2 = pDgivenV(pD[1], afsByGenePooledCtrls[2000:4000, 1, 1], afsByGenePooledCtrls[2000:4000, 0, 0]).mean()\n",
    "    truth3 = pDgivenV(pD[2], afsByGenePooledCtrls[4000:5000, 2, 1], afsByGenePooledCtrls[4000:5000, 0, 0]).mean()\n",
    "    truth0 = 1 - (truth1 + truth2 + truth3)\n",
    "    print(\"truth0\", truth0, \"truth1\", truth1, \"truth2\", truth2, \"truthBoth\", truth3)\n",
    "\n",
    "    params[\"trueMeanPDVs\"].append(tensor([truth0, truth1, truth2, truth3]))\n",
    "    params[\"truePis\"].append(tensor(diseaseFractions))\n",
    "\n",
    "    print(f\"params on run {i}\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lls': [9054.998046875, 11186.029296875],\n",
       " 'inferredAlphas': [tensor([2.4194e+04, 2.9218e+01, 1.7279e+01, 1.8945e+04], dtype=torch.float64),\n",
       "  tensor([28765.8024,   165.3189,    29.7202,   179.5943], dtype=torch.float64)],\n",
       " 'inferredPis': [tensor([5.3345e-01, 3.5364e-01, 2.4111e-04], dtype=torch.float64),\n",
       "  tensor([0.3297, 0.1839, 0.2241], dtype=torch.float64)],\n",
       " 'inferredPDs': [tensor([0.4984, 0.0058, 0.4204, 0.0754], dtype=torch.float64),\n",
       "  tensor([0.4985, 0.0058, 0.4204, 0.0754], dtype=torch.float64)],\n",
       " 'trueMeanPDs': [tensor([0.7534, 0.1109, 0.1108, 0.0249]),\n",
       "  tensor([0.7534, 0.1109, 0.1108, 0.0249])],\n",
       " 'truePis': [tensor([0.1000, 0.1000, 0.0500]),\n",
       "  tensor([0.1000, 0.1000, 0.0500])]}"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pis tensor([0.3030, 0.0015, 0.0009], dtype=torch.float64)\n",
      "alphas inferred tensor([12136.1940,   140.1476, 10237.2904,  1835.4414], dtype=torch.float64)\n",
      "truth0 tensor(0.7534) truth1 tensor(0.1109) truth2 tensor(0.1108) truthBoth tensor(0.0249)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lls': [9054.998046875, 11186.029296875, 12934.8056640625],\n",
       " 'inferredAlphas': [tensor([2.4194e+04, 2.9218e+01, 1.7279e+01, 1.8945e+04], dtype=torch.float64),\n",
       "  tensor([28765.8024,   165.3189,    29.7202,   179.5943], dtype=torch.float64),\n",
       "  tensor([3.8385e+04, 1.2326e+01, 4.7383e+02, 5.2985e+03], dtype=torch.float64)],\n",
       " 'inferredPis': [tensor([5.3345e-01, 3.5364e-01, 2.4111e-04], dtype=torch.float64),\n",
       "  tensor([0.3297, 0.1839, 0.2241], dtype=torch.float64),\n",
       "  tensor([0.2817, 0.2043, 0.0316], dtype=torch.float64)],\n",
       " 'inferredPDs': [tensor([0.4984, 0.0058, 0.4204, 0.0754], dtype=torch.float64),\n",
       "  tensor([0.4985, 0.0058, 0.4204, 0.0754], dtype=torch.float64),\n",
       "  tensor([8.6904e-01, 2.7905e-04, 1.0727e-02, 1.1996e-01], dtype=torch.float64)],\n",
       " 'trueMeanPDs': [tensor([0.7534, 0.1109, 0.1108, 0.0249]),\n",
       "  tensor([0.7534, 0.1109, 0.1108, 0.0249]),\n",
       "  tensor([0.7534, 0.1109, 0.1108, 0.0249])],\n",
       " 'truePis': [tensor([0.1000, 0.1000, 0.0500]),\n",
       "  tensor([0.1000, 0.1000, 0.0500]),\n",
       "  tensor([0.1000, 0.1000, 0.0500])]}"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9856)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(afsByGenePooledCtrls[2000:4000, 1, 1]/afsByGenePooledCtrls[2000:4000, 0, 0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2000) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-423-05ded8826d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtruth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpDgivenV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafsByGenePooledCtrls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafsByGenePooledCtrls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-325-865725e0cdf2>\u001b[0m in \u001b[0;36mpDgivenV\u001b[0;34m(pD, pVgivenD, pV)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpDgivenV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpVgivenD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpVgivenD\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpD\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# works like shit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2000) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "truth = pDgivenV(pD., afsByGenePooledCtrls[0:2000, :, 1], afsByGenePooledCtrls[0:2000, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Dirichlet(tensor(1/4.0).expand(4)).sample()\n",
    "test = test[0:3]\n",
    "r = [0,1,2,3]\n",
    "r[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitFnBivariate(altCountsByGenePooledCtrls, pDs, nEpochs=100, minLLThresholdCount=100, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3260, 0.1289, 0.0037, 0.5414])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Dirichlet(concentration=tensor([1.40625703e+04,\n",
    "         5.56195520e+03, 1.57978682e+02, 2.33518936e+04]))\n",
    "d.sample([10_000,]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3260, 0.1289, 0.0037, 0.5414])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0236)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Beta(7.74788652e+02, 2.58170768e+04 + 9.72956833e+02 + 5.18278100e+03).sample([10000]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta(3.05871723e+04, 3.25256694e+02 + 3.75135881e+03 +4.52942294e+04).sample([10000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitFnUniveriateBetaBinomial took for 100 epochs:  65.16437029838562\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "res = fitFnUniveriateBetaBinomial(altCountsByGene, pDs, nEpochs=100, minLLThresholdCount=100, debug=False)\n",
    "print(\"fitFnUniveriateBetaBinomial took for 100 epochs: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lls': [10179.8525390625,\n",
       "  9959.8681640625,\n",
       "  9946.7158203125,\n",
       "  9938.27734375,\n",
       "  9932.978515625,\n",
       "  9929.8046875,\n",
       "  9924.201171875],\n",
       " 'params': [array([2.77964201e-01, 2.18606574e+02, 4.31751964e+03]),\n",
       "  array([7.79074060e-02, 2.77695550e+02, 2.00777779e+03]),\n",
       "  array([7.90871522e-02, 1.13795631e+03, 8.14870511e+03]),\n",
       "  array([5.88937885e-02, 3.17899443e+03, 2.09100838e+04]),\n",
       "  array([9.72736620e-02, 2.22070075e+03, 1.68124937e+04]),\n",
       "  array([7.19281065e-02, 3.02731933e+03, 2.08112076e+04]),\n",
       "  array([8.41100410e-02, 2.34946912e+03, 1.83333156e+04])],\n",
       " 'llTrajectory': [10179.8525390625,\n",
       "  9959.8681640625,\n",
       "  10180.7265625,\n",
       "  9958.9736328125,\n",
       "  9997.4765625,\n",
       "  9946.7158203125,\n",
       "  9950.05859375,\n",
       "  9938.27734375,\n",
       "  10001.6162109375,\n",
       "  11135.6962890625,\n",
       "  9932.978515625,\n",
       "  9938.080078125,\n",
       "  11123.787109375,\n",
       "  9947.828125,\n",
       "  9948.4072265625,\n",
       "  9949.296875,\n",
       "  9938.4248046875,\n",
       "  9962.9306640625,\n",
       "  9948.1748046875,\n",
       "  9981.7294921875,\n",
       "  9952.494140625,\n",
       "  9957.728515625,\n",
       "  9951.97265625,\n",
       "  9938.298828125,\n",
       "  11137.48828125,\n",
       "  9929.8046875,\n",
       "  9955.20703125,\n",
       "  11137.771484375,\n",
       "  10014.1162109375,\n",
       "  9960.673828125,\n",
       "  9943.7822265625,\n",
       "  9947.4990234375,\n",
       "  9959.078125,\n",
       "  11201.9521484375,\n",
       "  9941.0966796875,\n",
       "  9949.955078125,\n",
       "  9943.4912109375,\n",
       "  9959.494140625,\n",
       "  9955.2099609375,\n",
       "  9956.6142578125,\n",
       "  11153.828125,\n",
       "  9944.29296875,\n",
       "  9950.2529296875,\n",
       "  9942.4228515625,\n",
       "  9933.5576171875,\n",
       "  9954.349609375,\n",
       "  9936.6982421875,\n",
       "  9943.3271484375,\n",
       "  9956.111328125,\n",
       "  9947.1123046875,\n",
       "  10011.5712890625,\n",
       "  9959.744140625,\n",
       "  9959.1484375,\n",
       "  9940.6259765625,\n",
       "  9948.2578125,\n",
       "  9951.75390625,\n",
       "  10000.353515625,\n",
       "  9946.85546875,\n",
       "  11173.001953125,\n",
       "  9948.328125,\n",
       "  9958.6484375,\n",
       "  9924.201171875,\n",
       "  9938.4501953125,\n",
       "  9948.1806640625,\n",
       "  9942.55859375,\n",
       "  9944.8916015625,\n",
       "  9955.2255859375,\n",
       "  9950.76953125,\n",
       "  9949.7998046875,\n",
       "  10008.12109375,\n",
       "  9952.9609375,\n",
       "  9962.4482421875,\n",
       "  9940.119140625,\n",
       "  9932.740234375,\n",
       "  9954.5458984375,\n",
       "  9973.41796875,\n",
       "  9945.658203125,\n",
       "  10172.5693359375,\n",
       "  9990.240234375,\n",
       "  9965.47265625,\n",
       "  9947.140625,\n",
       "  9949.85546875,\n",
       "  10018.66015625,\n",
       "  9950.5244140625,\n",
       "  9984.8515625,\n",
       "  9940.0791015625,\n",
       "  9961.08984375,\n",
       "  9934.591796875,\n",
       "  11163.794921875,\n",
       "  9954.720703125,\n",
       "  9946.7119140625,\n",
       "  9961.568359375,\n",
       "  9958.3720703125,\n",
       "  9956.3974609375,\n",
       "  9945.90625,\n",
       "  9946.1435546875,\n",
       "  9955.3935546875,\n",
       "  10094.2001953125,\n",
       "  9946.46484375,\n",
       "  11179.0439453125]}"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(res[\"llTrajectory\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomH0 = Binomial(total_count=tensor([1.,1]), probs=pDs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.6151, -4.6151])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binomH0.log_prob(tensor(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params are [1e-09, 1e-09]\n",
      "pDgivenV 1e-09\n",
      "pi0 0.999999999\n",
      "binomH0 at the bad place of 6780 tensor([0.9327, 0.9235, 0.1218]) where the sums are tensor([ 7.,  8., 14.]) and probs are tensor(0.0099) and altCounts are tensor([0., 0., 1.])\n",
      "component0 tensor([0.9143, 0.8963, 0.0565,  ..., 0.9235, 0.9327, 0.8963]) component1 tensor([1.0000e-09, 1.0000e-09, 7.1525e-16,  ..., 1.0000e-09, 1.0000e-09,\n",
      "        1.0000e-09]) sum tensor([0.9143, 0.8963, 0.0565,  ..., 0.9235, 0.9327, 0.8963]) log tensor([-0.0896, -0.1095, -2.8731,  ..., -0.0796, -0.0697, -0.1095])\n",
      "log sum tensor(-10964.6426)\n",
      "tensor(10964.6426)\n",
      "params are [0.08845797, 0.1109436]\n",
      "pDgivenV 0.1109436\n",
      "pi0 0.91154203\n",
      "binomH0 at the bad place of 6780 tensor([0.9327, 0.9235, 0.1218]) where the sums are tensor([ 7.,  8., 14.]) and probs are tensor(0.0099) and altCounts are tensor([0., 0., 1.])\n",
      "component0 tensor([0.8335, 0.8170, 0.0515,  ..., 0.8418, 0.8502, 0.8170]) component1 tensor([0.0307, 0.0243, 0.0327,  ..., 0.0345, 0.0388, 0.0243]) sum tensor([0.8642, 0.8413, 0.0842,  ..., 0.8763, 0.8890, 0.8413]) log tensor([-0.1460, -0.1728, -2.4742,  ..., -0.1320, -0.1176, -0.1728])\n",
      "log sum tensor(-9887.2617)\n",
      "tensor(9887.2617)\n"
     ]
    }
   ],
   "source": [
    "costFn2 = likelihoodUnivariateFast(altCountsByGene, pDs)\n",
    "# print(costFn2([1e-9, .999999]))\n",
    "print(costFn2([1e-9, 1e-9]))\n",
    "print(costFn2([0.08845797,0.11094360])) #gives ~12067 using jensen's method, and ~9887 using exponentiation of the log\n",
    "\n",
    "# best result from R\n",
    "#  0.08845797           0.11094360 , ll -10127.23, and with jensen's version, \"example -12037.4347455843\"\n",
    "# pDgivenV, pi1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costFn = likelihoodUnivariate(altCountsByGene, pDs)\n",
    "print(\"costFn1:\", costFn([.001, .01]),\"costFn2:\",costFn2([.001, .01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping 6780\n",
      "skipping 7044\n",
      "skipping 7241\n",
      "skipping 7579\n",
      "skipping 11089\n",
      "skipping 11642\n",
      "skipping 11813\n",
      "skipping 12044\n",
      "skipping 12389\n",
      "skipping 15026\n",
      "skipping 16708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(12764.8105)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costFn([0.0001,0.11094360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params are [0.0001, 0.1109436]\n",
      "pDgivenV 0.1109436\n",
      "pi0 0.9999\n",
      "binomH0 at the bad place of 6780 tensor([-0.1393, -0.0000, -0.0896]) where the sums are tensor([14.,  0.,  9.])\n",
      "components tensor([-4.9825, -7.6460, -2.4972,  ..., -0.0398, -3.0452, -0.1094]) tensor([-1.3343e-04, -1.7970e-04, -9.4227e-05,  ..., -4.7038e-05,\n",
      "        -1.0597e-04, -1.2935e-04])\n",
      "tensor(11075.9297)\n"
     ]
    }
   ],
   "source": [
    "print(costFn2([0.0001,0.11094360]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1393, -0.0000, -0.0895])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Binomial(total_count=tensor([14., 0., 9.]), probs=tensor(.0099))\n",
    "d.log_prob(tensor([0.,0.,0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params are [1e-09, 0.999999]\n",
      "pDgivenV 1e-09\n",
      "pi0 1.0000000000287557e-06\n",
      "components tensor([-6.9653e-08, -9.4742e-06, -4.8388e-06,  ..., -8.9553e-08,\n",
      "        -1.1940e-07, -4.9752e-08]) tensor([-9.5367e-07, -4.3396e+01, -2.7374e+01,  ..., -9.5367e-07,\n",
      "        -1.9073e-06, -4.7684e-07])\n",
      "ll: -51670.8515625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-51670.8515625"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costFn2([1e-9, .999999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geneSums' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8b8260b3d0e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbinomH0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneSums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbinomH1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneSums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcaseAltCounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maltCountsByGene\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaseAltCounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcomponent0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinomH0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaseAltCounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geneSums' is not defined"
     ]
    }
   ],
   "source": [
    "binomH0 = Binomial(total_count=geneSums, probs=.001)\n",
    "binomH1 = Binomial(total_count=geneSums, probs=.01)\n",
    "caseAltCounts = altCountsByGene[:, 0, 1]\n",
    "print(caseAltCounts)\n",
    "component0 = binomH0.log_prob(caseAltCounts)\n",
    "print(\"component0\", component0, .5*component0)\n",
    "component1 = binomH1.log_prob(caseAltCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0987)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pDgivenV(pDs[0], afsByGene2[0:2000, 0, 1].mean(), afMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0008)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition1 = altCountsByGene2[:, 0, :]\n",
    "condition1\n",
    "pDs[0]\n",
    "\n",
    "afsByGene2[0:2000,:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fee4a74f690>]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(afsByGene2[:, 0, 1:2].flatten())\n",
    "pyplot.plot(afsByGene2[:, 0, 0:1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feb3e8c8d90>]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 0, 0:1].flatten())\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 0, 1:2].flatten())\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 1, 1:2].flatten())\n",
    "pyplot.plot(afsByGenePooledCtrls[:, 2, 1:2].flatten())\n",
    "# pyplot.plot(afsByGeneRR2[:, 0, 1:2].flatten())\n",
    "# pyplot.plot(afsByGeneRR2[:, 0, 0:1].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattenedData = []\n",
    "\n",
    "for geneAfData in afsByGenePooledCtrls:\n",
    "    flattenedData.append([geneAfData[0][0],*geneAfData[:, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mis_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Compound distribution comprising of a dirichlet-multinomial pair. The probability of\n",
       "classes (``probs`` for the :class:`~pyro.distributions.Multinomial` distribution)\n",
       "is unknown and randomly drawn from a :class:`~pyro.distributions.Dirichlet`\n",
       "distribution prior to a certain number of Categorical trials given by\n",
       "``total_count``.\n",
       "\n",
       ":param float or torch.Tensor concentration: concentration parameter (alpha) for the\n",
       "    Dirichlet distribution.\n",
       ":param int or torch.Tensor total_count: number of Categorical trials.\n",
       ":param bool is_sparse: Whether to assume value is mostly zero when computing\n",
       "    :meth:`log_prob`, which can speed up computation when data is sparse.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DirichletMultinomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2491, 0.2539, 0.2495, 0.2475])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.Dirichlet(0.5 * torch.ones(4)).sample([10_000]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattenedData = tensor(flattenedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feb3bcff950>,\n",
       " <matplotlib.lines.Line2D at 0x7febac18d750>,\n",
       " <matplotlib.lines.Line2D at 0x7febac18d910>,\n",
       " <matplotlib.lines.Line2D at 0x7febac18dad0>]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flattenedData\n",
    "pyplot.clf()\n",
    "pyplot.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(flattenedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'altCountsByGene' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b18e642596f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mctrlCounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maltCountsByGene\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maltCountsCases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maltCountsByGene\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maltCountsFlat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgeneIdx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnGenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'altCountsByGene' is not defined"
     ]
    }
   ],
   "source": [
    "ctrlCounts = altCountsByGene[:, 0, 0]\n",
    "altCountsCases = altCountsByGene[:, :, 1]\n",
    "\n",
    "altCountsFlat = []\n",
    "for geneIdx in range(nGenes):\n",
    "    altCountsFlat.append([ctrlCounts[geneIdx], *altCountsByGene[geneIdx, :, 1].flatten()])\n",
    "altCountsFlat = tensor(altCountsFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'altCountsFlat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-436d87bed148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maltCountsFlat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'altCountsFlat' is not defined"
     ]
    }
   ],
   "source": [
    "altCountsFlat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mis_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Compound distribution comprising of a dirichlet-multinomial pair. The probability of\n",
       "classes (``probs`` for the :class:`~pyro.distributions.Multinomial` distribution)\n",
       "is unknown and randomly drawn from a :class:`~pyro.distributions.Dirichlet`\n",
       "distribution prior to a certain number of Categorical trials given by\n",
       "``total_count``.\n",
       "\n",
       ":param float or torch.Tensor concentration: concentration parameter (alpha) for the\n",
       "    Dirichlet distribution.\n",
       ":param int or torch.Tensor total_count: number of Categorical trials.\n",
       ":param bool is_sparse: Whether to assume value is mostly zero when computing\n",
       "    :meth:`log_prob`, which can speed up computation when data is sparse.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DirichletMultinomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "K = 4  # Fixed number of components.\n",
    "\n",
    "@config_enumerate\n",
    "def model(data):\n",
    "    # Global variables.\n",
    "    weights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(K)))\n",
    "\n",
    "    with pyro.plate('components', K):\n",
    "        concentrations = pyro.sample('concentrations', dist.Dirichlet(0.5 * torch.ones(K)))\n",
    "\n",
    "    with pyro.plate('data', len(data)):\n",
    "        # Local variables.\n",
    "        component = pyro.sample('assignment', dist.Categorical(weights))\n",
    "        print(f\"concentrations: {concentrations[component]}\")\n",
    "        pyro.sample('obs', DirichletMultinomial(concentration=concentrations[component], total_count=data.sum(1)), obs=data)\n",
    "\n",
    "optim = pyro.optim.Adam({'lr': 0.1, 'betas': [0.8, 0.99]})\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concentrations: tensor([0.2500, 0.2500, 0.2500,  ..., 0.2500, 0.2500, 0.2500])\n",
      "concentrations: tensor([[[0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500]]], grad_fn=<IndexBackward>)\n",
      "concentrations: tensor([0.2500, 0.2500, 0.2500,  ..., 0.2500, 0.2500, 0.2500])\n",
      "concentrations: tensor([[[0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500]]], grad_fn=<IndexBackward>)\n",
      "concentrations: tensor([0.2500, 0.2500, 0.2500,  ..., 0.2500, 0.2500, 0.2500])\n",
      "concentrations: tensor([[[0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.2500, 0.2500, 0.2500, 0.2500]]], grad_fn=<IndexBackward>)\n",
      "seed = 0, initial_loss = 67835.1484375\n"
     ]
    }
   ],
   "source": [
    "def init_loc_fn(site):\n",
    "    if site[\"name\"] == \"weights\":\n",
    "        # Initialize weights to uniform.\n",
    "        return torch.ones(K) / K\n",
    "    if site[\"name\"] == \"concentrations\":\n",
    "        return torch.ones(K) / K\n",
    "    raise ValueError(site[\"name\"])\n",
    "\n",
    "def initialize(seed):\n",
    "    global global_guide, svi\n",
    "    pyro.set_rng_seed(seed)\n",
    "    pyro.clear_param_store()\n",
    "    global_guide = AutoDelta(poutine.block(model, expose=['weights', 'concentrations']),\n",
    "                             init_loc_fn=init_loc_fn)\n",
    "    svi = SVI(model, global_guide, optim, loss=elbo)\n",
    "    return svi.loss(model, global_guide, altCountsFlat)\n",
    "\n",
    "# Choose the best among 100 random initializations.\n",
    "loss, seed = min((initialize(seed), seed) for seed in range(2))\n",
    "initialize(seed)\n",
    "print('seed = {}, initial_loss = {}'.format(seed, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...................................................................................................\n",
      "..................................................................................................."
     ]
    }
   ],
   "source": [
    "# Register hooks to monitor gradient norms.\n",
    "gradient_norms = defaultdict(list)\n",
    "for name, value in pyro.get_param_store().named_parameters():\n",
    "    value.register_hook(lambda g, name=name: gradient_norms[name].append(g.norm().item()))\n",
    "\n",
    "losses = []\n",
    "for i in range(200 if not smoke_test else 2):\n",
    "    loss = svi.step(altCountsFlat)\n",
    "    losses.append(loss)\n",
    "    print('.' if i % 100 else '\\n', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(figsize=(10,3), dpi=100).set_facecolor('white')\n",
    "pyplot.plot(losses)\n",
    "pyplot.xlabel('iters')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.yscale('log')\n",
    "pyplot.title('Convergence of SVI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, grad_norms in gradient_norms.items():\n",
    "    pyplot.plot(grad_norms, label=name)\n",
    "pyplot.xlabel('iters')\n",
    "pyplot.ylabel('gradient norm')\n",
    "pyplot.yscale('log')\n",
    "pyplot.legend(loc='best')\n",
    "pyplot.title('Gradient norms during SVI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = [0.25 0.25 0.25 0.25]\n",
      "concentrations = [[0.8973397  0.0494441  0.04917945 0.00403667]\n",
      " [0.8973397  0.0494441  0.04917945 0.00403667]\n",
      " [0.8973397  0.0494441  0.04917945 0.00403667]\n",
      " [0.8973397  0.0494441  0.04917945 0.00403667]]\n"
     ]
    }
   ],
   "source": [
    "map_estimates = global_guide(altCountsFlat)\n",
    "weights = map_estimates['weights']\n",
    "locs = map_estimates['concentrations']\n",
    "print('weights = {}'.format(weights.data.numpy()))\n",
    "print('concentrations = {}'.format(locs.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dirichlet(tensor([0.8973397  , 0.0494441,  0.04917945, 0.00403667])).sample([10_000,]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
