{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import torch.tensor as tensor\n",
    "import pyro.distributions as dist\n",
    "# from torch.distributions import Binomial, Gamma, Uniform\n",
    "from pyro.distributions import Binomial, Bernoulli, Categorical, Dirichlet, DirichletMultinomial, Beta, BetaBinomial, Uniform, Gamma, Multinomial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from skopt import gp_minimize \n",
    "from scipy.stats import binom as ScipyBinom\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from collections import namedtuple\n",
    "import time\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvl import genData, likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "resSim = {\n",
    "        \"allRes\": None,\n",
    "        \"nEpochs\": None,\n",
    "        \"bestRes\": {\n",
    "            \"pis\": None,\n",
    "            \"alphas\": None,\n",
    "            \"PDV_c1true\": None,\n",
    "            \"PDV_c2true\": None,\n",
    "            \"PDV_cBothTrue\": None,\n",
    "            \"PDV_c1inferred\": None,\n",
    "            \"PDV_c2inferred\": None,\n",
    "            \"PDV_cBothInferred\": None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cached6NormalSimRes = []\n",
    "\n",
    "rrsSim = tensor([[2, 2, 1.5]])\n",
    "pisSim = tensor([[.05, .05, .05]])\n",
    "\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(5e5)\n",
    "i = 0\n",
    "for rrsSimRun in rrsSim:\n",
    "    for pisSimRun in pisSim:\n",
    "        afMeanRun = 1e-4\n",
    "        generatingFn = genData.v6normal\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        # needs tensor for shapes, otherwise \"gamma_cpu not implemente for long\", e.g rrShape=50.0 doesn't work...\n",
    "        paramsRun = genData.genParams(rrMeans=rrsSimRun, pis=pisSimRun, afMean=afMeanRun, rrShape=tensor(50.), afShape=tensor(50.), nCases=nCases, nCtrls=nCtrls)[0]\n",
    "        \n",
    "        pDsRun = paramsRun[\"pDs\"]\n",
    "        pisRun = paramsRun[\"diseaseFractions\"]\n",
    "        print(\"params are:\", paramsRun)\n",
    "        \n",
    "        cached6NormalSimRes.append({\"params\": paramsRun, \"runs\": []})\n",
    "        for y in range(0, 10):\n",
    "            start = time.time()\n",
    "            r = generatingFn(**paramsRun)\n",
    "            print(\"took\", time.time() - start)\n",
    "            \n",
    "            resPointer = {\n",
    "                **r,\n",
    "                \"generatingFn\": generatingFn,\n",
    "                \"results\": None,\n",
    "            }\n",
    "\n",
    "            cached6NormalSimRes[i][\"runs\"].append(resPointer)\n",
    "            \n",
    "            print(f\"Run: {i}, {y}\")\n",
    "            \n",
    "            xsRun = resPointer[\"altCounts\"]\n",
    "            afsRun = resPointer[\"afs\"]\n",
    "            affectedGenesRun = resPointer[\"affectedGenes\"]\n",
    "            unaffectedGenesRun = resPointer[\"unaffectedGenes\"]\n",
    "\n",
    "            runCostFnIdx = 16\n",
    "\n",
    "            nEpochsRun = 10\n",
    "            print(\"nEpochsRun\", nEpochsRun)\n",
    "            \n",
    "            res = likelihoods.fitFnBivariate(xsRun, pDsRun, nEpochs=nEpochsRun, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "            bestRes = res[\"params\"][-1]\n",
    "\n",
    "            inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "            inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "            #### Calculate actual ###\n",
    "            component1Afs = afsRun[affectedGenesRun[0]]\n",
    "            c1true = (component1Afs / afMeanRun).mean(0)\n",
    "\n",
    "            component2Afs = afsRun[affectedGenesRun[1]]\n",
    "            c2true = (component2Afs / afMeanRun).mean(0)\n",
    "\n",
    "            componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "            cBothTrue = (componentBothAfs / afMeanRun).mean(0)\n",
    "\n",
    "            ### calculate inferred values\n",
    "            pds = tensor([1-pDsRun.sum(), *pDsRun])\n",
    "            alphas = inferredAlphas.numpy()\n",
    "            c1inferred = Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            c2inferred = Dirichlet(tensor([alphas[0], alphas[0], alphas[2], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            cBothInferred = Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0)\n",
    "\n",
    "            print(f\"\\n\\nrun {i} results for rrs: {rrsSimRun}, pis: {pisSimRun}\")\n",
    "            print(\"Inferred pis:\", inferredPis)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c1true)\n",
    "            print(\"P(D|V) inferred in component 1:\", c1inferred)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c2true)\n",
    "            print(\"P(D|V) inferred in component both:\", c2inferred)\n",
    "            print(\"\\nP(D|V) true ans in component both:\", cBothTrue)\n",
    "            print(\"P(D|V) inferred in component both:\", cBothInferred,\"\\n\\n\")\n",
    "\n",
    "            resToStore = copy.deepcopy(resSim)\n",
    "            resToStore[\"allRes\"] = res\n",
    "            resToStore[\"nEpochs\"] = nEpochsRun\n",
    "            br = resToStore[\"bestRes\"]\n",
    "            br[\"pis\"] = inferredPis\n",
    "            br[\"alphas\"] = inferredAlphas\n",
    "            br[\"PDV_c1true\"] = c1true\n",
    "            br[\"PDV_c2true\"] = c2true\n",
    "            br[\"PDV_cBothTrue\"] = cBothTrue\n",
    "            br[\"PDV_c1inferred\"] = c1inferred\n",
    "            br[\"PDV_c2inferred\"] = c2inferred\n",
    "            br[\"PDV_cBothInferred\"] = cBothInferred\n",
    "\n",
    "            resPointer[\"results\"] = resToStore\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# torch.save(\"./mvln-sim-mvn\", tensor(cached6NormalSimRes))\n",
    "# json.dumps(\"./mvln-sim-mvn.json\", cached6NormalSimRes)\n",
    "cached6NormalSimRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN\n"
     ]
    }
   ],
   "source": [
    "res = np.load(\"./mvln-sim-mvln.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "resByParams = []\n",
    "for runSet in res:\n",
    "    params = (runSet[\"params\"][\"diseaseFractions\"], runSet[\"params\"][\"rrMeans\"], runSet[\"params\"][\"rrShape\"])\n",
    "#     print(\"param\", params)\n",
    "    res = []\n",
    "#     if params not in resByParam:\n",
    "#         resByParams[params] = []\n",
    "    \n",
    "    for run in runSet[\"runs\"]:\n",
    "        if run is None or \"results\" not in run or run[\"results\"] is None:\n",
    "            print(f\"no results found for {params}\")\n",
    "            continue\n",
    "        res.append(run[\"results\"])\n",
    "    resByParams.append([params, res])\n",
    "\n",
    "np.save(\"mvln-sim-mvln-results\", resByParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resByParams = np.load(\"mvln-sim-mvln-results.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.subplot([1,len(resByParams)])\n",
    "i = 0\n",
    "with open(\"mvln-sim-mvln-res.tsv\", \"w\") as file:\n",
    "    file.write(f\"Notes: 15000 samples1, 15000 samples2, 6000 samplesBoth; rrs generated from normal distribution with. 1 variance, .4 covariance, and individual effect rr summed with shared-effect rr in genes affecting both conditions\\n\")\n",
    "    file.write(f\"\\tmean\\tstd\\n\")\n",
    "    for res in resByParams:\n",
    "        i += 1\n",
    "\n",
    "        paramsRun = res[0]\n",
    "        resRun = res[1]\n",
    "\n",
    "        pis = tensor([x[\"bestRes\"][\"pis\"].numpy() for x in resRun])\n",
    "        PDV_c1true = tensor([x[\"bestRes\"][\"PDV_c1true\"].numpy() for x in resRun])\n",
    "        PDV_c2true = tensor([x[\"bestRes\"][\"PDV_c2true\"].numpy() for x in resRun])\n",
    "        PDV_c3true = tensor([x[\"bestRes\"][\"PDV_cBothTrue\"].numpy() for x in resRun])\n",
    "        PDV_c1inferred = tensor([x[\"bestRes\"][\"PDV_c1inferred\"].numpy() for x in resRun])\n",
    "        PDV_c2inferred = tensor([x[\"bestRes\"][\"PDV_c2inferred\"].numpy() for x in resRun])\n",
    "        PDV_c3inferred = tensor([x[\"bestRes\"][\"PDV_cBothInferred\"].numpy() for x in resRun])\n",
    "\n",
    "        file.write(f\"\\n\\ntrue params: \\t{paramsRun} \\n\\n\")\n",
    "\n",
    "        file.write(f\"pi\\t {pis.mean(0).numpy()} \\t  {pis.std(0).numpy()} \\n\")\n",
    "\n",
    "        file.write(f\"PDV_c1inferred \\t {PDV_c1inferred.mean(0).numpy()}\\t {PDV_c1inferred.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c1true \\t {PDV_c1true.mean(0).numpy()} \\t {PDV_c1true.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c2inferred \\t {PDV_c2inferred.mean(0).numpy()} \\t {PDV_c2inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c2true \\t {PDV_c2true.mean(0).numpy()} \\t {PDV_c2true.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3inferred \\t {PDV_c3inferred.mean(0).numpy()} \\t {PDV_c3inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3true \\t {PDV_c3true.mean(0).numpy()} \\t {PDV_c3true.std(0).numpy()}\\n\")\n",
    "\n",
    "    #     plt.figure(i)\n",
    "    #     plt.plot(t, s1)\n",
    "    #     plt.plot(t, 2*s1)\n",
    "        # plt.subplot(222)\n",
    "        # plt.plot(t, 2*s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Tensor is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5cb54c57e780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mvln-sim-mvn.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached6NormalSimRes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Tensor is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open('./mvln-sim-mvn.json', 'w') as outfile:\n",
    "    json.dump(cached6NormalSimRes, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
