{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyro\n",
    "# import torch\n",
    "# import torch.tensor as tensor\n",
    "# import pyro.distributions as dist\n",
    "# # from torch.distributions import Binomial, Gamma, Uniform\n",
    "# from pyro.distributions import Binomial, Bernoulli, Categorical, Dirichlet, DirichletMultinomial, Beta, BetaBinomial, Uniform, Gamma, Multinomial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from skopt import gp_minimize \n",
    "from scipy.stats import binom as ScipyBinom\n",
    "from matplotlib import pyplot\n",
    "from torch import tensor\n",
    "\n",
    "from collections import namedtuple\n",
    "import time\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvl import genData, likelihoods, bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([2.0000, 2.0000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[4.3519, 2.7890, 5.5548],\n",
      "        [2.8917, 4.4436, 5.2706],\n",
      "        [3.8678, 4.4712, 5.3107],\n",
      "        ...,\n",
      "        [4.7168, 4.2715, 6.7835],\n",
      "        [4.6791, 3.9330, 4.3859],\n",
      "        [2.6210, 1.9142, 4.4797]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.120481967926025\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[39., 10.,  0.,  3.],\n",
      "        [42.,  3.,  2.,  1.],\n",
      "        [50.,  3.,  2.,  0.],\n",
      "        ...,\n",
      "        [45.,  3.,  5.,  0.],\n",
      "        [60.,  0.,  1.,  2.],\n",
      "        [40.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "n tensor([52., 48., 55.,  ..., 53., 63., 42.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([10.,  3.,  3.,  ...,  3.,  0.,  1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 2.,  ..., 5., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 0.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[39., 10.,  0.,  3.],\n",
      "        [42.,  3.,  2.,  1.],\n",
      "        [50.,  3.,  2.,  0.],\n",
      "        ...,\n",
      "        [45.,  3.,  5.,  0.],\n",
      "        [60.,  0.,  1.,  2.],\n",
      "        [40.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([4.9863e-09, 7.6293e-03, 1.8464e-02,  ..., 8.1738e-04, 6.4453e-03,\n",
      "        3.3431e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8ac3320>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91056.366085773, bestParams: [0.021506596, 0.032269087, 0.032386456, 7456.216, 13592.753, 24910.842, 18917.502]\n",
      "epoch 0\n",
      "     fun: 90678.94727806201\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18988\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.49893948e-02, 4.43790738e-02, 4.08915328e-02, 8.60818913e+03,\n",
      "       2.44622045e+04, 2.48735515e+04, 2.14801207e+04])\n",
      "best ll: 91026.39509861523, bestParams: [0.11172657, 0.090561226, 0.053274393, 6340.836, 12428.718, 19741.955, 19129.791]\n",
      "epoch 1\n",
      "     fun: 90680.17847220492\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18535\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.87069860e-02, 4.87180474e-02, 4.18491463e-02, 9.10768397e+03,\n",
      "       2.46671325e+04, 2.48377120e+04, 2.38725486e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90935.85000957745, bestParams: [0.049423933, 0.009214227, 0.066587955, 8144.4087, 14092.45, 19146.107, 19184.744]\n",
      "epoch 2\n",
      "     fun: 90679.69408391253\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24517\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.51746074e-02, 4.28823114e-02, 4.09115182e-02, 8.49052334e+03,\n",
      "       2.41057989e+04, 2.49310807e+04, 2.09977006e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90968.04260795636, bestParams: [0.04376411, 0.00947107, 0.026495688, 2897.8872, 12433.758, 12579.159, 2175.1257]\n",
      "epoch 3\n",
      "     fun: 90682.20345662584\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21464\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.62273012e-02, 4.13341282e-02, 4.08307518e-02, 7.30724926e+03,\n",
      "       2.05368423e+04, 2.18005268e+04, 1.80006693e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 91230.94646826506, bestParams: [0.027580375, 0.03263207, 0.086327404, 9526.828, 13395.509, 20715.258, 16864.232]\n",
      "epoch 4\n",
      "     fun: 90680.42392596879\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21184\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93687837e-02, 4.50462777e-02, 4.14165165e-02, 8.13320033e+03,\n",
      "       2.20223509e+04, 2.30949390e+04, 2.09459093e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90891.22837955202, bestParams: [0.022499898, 0.05500002, 0.05387609, 7606.9336, 16116.186, 22950.53, 17725.414]\n",
      "epoch 5\n",
      "     fun: 91005.564852588\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19023\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.05560857e-01, 2.51295019e-02, 6.86739003e-02, 1.10150214e+04,\n",
      "       1.19546860e+04, 2.49755966e+04, 2.49999999e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90793.50734448066, bestParams: [0.04312596, 0.061409917, 0.055109084, 7393.3057, 17826.643, 19793.965, 14590.254]\n",
      "epoch 6\n",
      "     fun: 90682.98088077307\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29244\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.58835926e-02, 4.48804886e-02, 4.12324058e-02, 7.13580347e+03,\n",
      "       1.99591999e+04, 2.03665212e+04, 1.80069887e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90774.11209833511, bestParams: [0.029333118, 0.048051648, 0.034722798, 7021.4785, 19031.883, 23899.84, 18605.693]\n",
      "epoch 7\n",
      "     fun: 90677.6685678917\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18468\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.81858369e-02, 4.78172584e-02, 4.15692111e-02, 8.98392723e+03,\n",
      "       2.45434465e+04, 2.48292644e+04, 2.33467772e+04])\n",
      "minPrevious 90678.94727806201\n",
      "better by at >= 1; new ll:      fun: 90677.6685678917\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18468\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.81858369e-02, 4.78172584e-02, 4.15692111e-02, 8.98392723e+03,\n",
      "       2.45434465e+04, 2.48292644e+04, 2.33467772e+04])\n",
      "best ll: 90875.25550642482, bestParams: [0.052991223, 0.082086444, 0.03636626, 6475.547, 23251.305, 18497.258, 20307.602]\n",
      "epoch 8\n",
      "     fun: 90682.68245423601\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23101\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.50358851e-02, 4.28777768e-02, 4.09910386e-02, 4.24521045e+03,\n",
      "       1.20207836e+04, 1.24023136e+04, 1.05078487e+04])\n",
      "minPrevious 90677.6685678917\n",
      "best ll: 91548.96528524201, bestParams: [0.10768495, 0.22162051, 0.123172745, 3700.1165, 5095.398, 5719.5654, 14934.215]\n",
      "epoch 9\n",
      "     fun: 90684.1404879048\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18986\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.07374035e-02, 5.12185329e-02, 4.29776595e-02, 9.51878104e+03,\n",
      "       2.49567942e+04, 2.49907370e+04, 2.49999993e+04])\n",
      "minPrevious 90677.6685678917\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0482, 0.0478, 0.0416], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8889, 0.0632, 0.0281, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8732, 0.0716, 0.0262, 0.0290], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8816, 0.0280, 0.0648, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8726, 0.0261, 0.0723, 0.0289], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7458, 0.0981, 0.0993, 0.0618], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7052, 0.1128, 0.1135, 0.0685], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4189, 2.2110, 5.3853],\n",
      "        [2.8835, 1.5863, 4.1315],\n",
      "        [3.3437, 2.7164, 3.9165],\n",
      "        ...,\n",
      "        [3.8215, 3.8713, 6.7122],\n",
      "        [2.9858, 2.3850, 5.4729],\n",
      "        [3.9595, 3.6556, 5.0114]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.392677068710327\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[51.,  1.,  1.,  0.],\n",
      "        [49.,  6.,  3.,  0.],\n",
      "        [51.,  3.,  4.,  2.],\n",
      "        ...,\n",
      "        [52.,  1.,  2.,  0.],\n",
      "        [40.,  2.,  1.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 58., 60.,  ..., 55., 43., 45.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 3.,  ..., 1., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 4.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 2.,  ..., 0., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[51.,  1.,  1.,  0.],\n",
      "        [49.,  6.,  3.,  0.],\n",
      "        [51.,  3.,  4.,  2.],\n",
      "        ...,\n",
      "        [52.,  1.,  2.,  0.],\n",
      "        [40.,  2.,  1.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0623, 0.0003, 0.0009,  ..., 0.0464, 0.0503, 0.0438],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc680>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91239.19500249799, bestParams: [0.07369001, 0.04880978, 0.06687576, 4858.3516, 16533.74, 12923.512, 14745.741]\n",
      "epoch 0\n",
      "     fun: 90861.78577540864\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 28688\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.39126641e-02, 4.43361706e-02, 4.16877774e-02, 6.30811938e+03,\n",
      "       1.80875402e+04, 1.85093776e+04, 1.54715766e+04])\n",
      "best ll: 91471.4697084639, bestParams: [0.015408821, 0.025966937, 0.018776404, 6470.502, 16699.875, 22305.629, 7609.0425]\n",
      "epoch 1\n",
      "     fun: 90860.74902260769\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21083\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.31587597e-02, 4.55204559e-02, 4.21324394e-02, 8.65442240e+03,\n",
      "       2.47671562e+04, 2.49529431e+04, 2.13176385e+04])\n",
      "minPrevious 90861.78577540864\n",
      "better by at >= 1; new ll:      fun: 90860.74902260769\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21083\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.31587597e-02, 4.55204559e-02, 4.21324394e-02, 8.65442240e+03,\n",
      "       2.47671562e+04, 2.49529431e+04, 2.13176385e+04])\n",
      "best ll: 91429.35879988143, bestParams: [0.036266495, 0.03656501, 0.00981962, 4553.329, 23323.432, 16778.275, 3984.7922]\n",
      "epoch 2\n",
      "     fun: 90860.63394312932\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18826\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97057539e-02, 4.15170068e-02, 4.13327845e-02, 6.41557828e+03,\n",
      "       1.93464752e+04, 1.95896200e+04, 1.48570035e+04])\n",
      "minPrevious 90860.74902260769\n",
      "best ll: 91222.69810706898, bestParams: [0.03356081, 0.050940458, 0.040049728, 7300.6055, 11934.092, 23776.432, 21303.281]\n",
      "epoch 3\n",
      "     fun: 90859.43670833748\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22341\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56721447e-02, 4.79972960e-02, 4.25334885e-02, 8.95537658e+03,\n",
      "       2.48353903e+04, 2.49872164e+04, 2.28056060e+04])\n",
      "minPrevious 90860.74902260769\n",
      "better by at >= 1; new ll:      fun: 90859.43670833748\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22341\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56721447e-02, 4.79972960e-02, 4.25334885e-02, 8.95537658e+03,\n",
      "       2.48353903e+04, 2.49872164e+04, 2.28056060e+04])\n",
      "best ll: 91364.8767937252, bestParams: [0.22571534, 0.056864273, 0.07466884, 3741.4695, 6438.2812, 5871.1465, 15020.482]\n",
      "epoch 4\n",
      "     fun: 90860.23925054408\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22079\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.20028461e-02, 4.19424135e-02, 4.15822628e-02, 5.57662948e+03,\n",
      "       1.63079514e+04, 1.68432533e+04, 1.32242383e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91071.14442199793, bestParams: [0.09720786, 0.055112377, 0.06380207, 4636.733, 11534.753, 14002.477, 10913.797]\n",
      "epoch 5\n",
      "     fun: 90860.33036181553\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24815\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.16976590e-02, 4.24385731e-02, 4.17443828e-02, 4.79041325e+03,\n",
      "       1.40148252e+04, 1.43427167e+04, 1.13953899e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91144.26979706812, bestParams: [0.08022128, 0.08162482, 0.048925202, 8952.077, 16154.056, 24275.29, 19940.611]\n",
      "epoch 6\n",
      "     fun: 90858.7804887991\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16708\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.20979808e-02, 4.37486171e-02, 4.17546498e-02, 8.45101922e+03,\n",
      "       2.46176087e+04, 2.49695229e+04, 2.03637448e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91115.36426809937, bestParams: [0.05724043, 0.021042777, 0.07642279, 6261.3833, 16376.353, 23784.773, 8266.063]\n",
      "epoch 7\n",
      "     fun: 90859.69647791091\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19043\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.34963888e-02, 4.37891214e-02, 4.20289844e-02, 8.15363124e+03,\n",
      "       2.33686949e+04, 2.39683522e+04, 1.98420756e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91651.64624185565, bestParams: [0.046107255, 0.09424183, 0.00989835, 2757.5513, 14618.052, 10251.086, 9000.875]\n",
      "epoch 8\n",
      "     fun: 90859.06008520466\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20575\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44481442e-02, 4.75969522e-02, 4.21778176e-02, 8.81335975e+03,\n",
      "       2.48539057e+04, 2.48395582e+04, 2.23569747e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91065.11635174009, bestParams: [0.0242683, 0.053031314, 0.058199123, 5144.2104, 20661.969, 15971.761, 13266.957]\n",
      "epoch 9\n",
      "     fun: 90861.08577821162\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20001\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.19851050e-02, 4.17801837e-02, 4.15084630e-02, 7.28268698e+03,\n",
      "       2.13122623e+04, 2.20660360e+04, 1.72448063e+04])\n",
      "minPrevious 90859.43670833748\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0457, 0.0480, 0.0425], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8782, 0.0624, 0.0278, 0.0249], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8721, 0.0725, 0.0262, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8817, 0.0280, 0.0644, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8718, 0.0261, 0.0729, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7358, 0.0987, 0.0983, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7057, 0.1127, 0.1130, 0.0687], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.9071, 4.0096, 5.7722],\n",
      "        [3.1442, 3.7642, 4.7613],\n",
      "        [1.9910, 3.6197, 4.2653],\n",
      "        ...,\n",
      "        [2.0181, 4.2217, 4.7949],\n",
      "        [2.6019, 2.7535, 6.2110],\n",
      "        [2.9164, 2.6361, 4.6614]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.5227882862091064\n",
      "Run: 0, 2\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[27.,  4.,  2.,  2.],\n",
      "        [48.,  1.,  1.,  0.],\n",
      "        [41.,  2.,  1.,  3.],\n",
      "        ...,\n",
      "        [48.,  3.,  0.,  1.],\n",
      "        [49.,  2.,  3.,  1.],\n",
      "        [37.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([35., 50., 47.,  ..., 52., 55., 39.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 1., 2.,  ..., 3., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 0., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 3.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[27.,  4.,  2.,  2.],\n",
      "        [48.,  1.,  1.,  0.],\n",
      "        [41.,  2.,  1.,  3.],\n",
      "        ...,\n",
      "        [48.,  3.,  0.,  1.],\n",
      "        [49.,  2.,  3.,  1.],\n",
      "        [37.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([9.1044e-05, 6.8182e-02, 1.1450e-03,  ..., 9.4407e-03, 1.1078e-02,\n",
      "        8.8612e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc290>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91007.93332294546, bestParams: [0.0857708, 0.027353209, 0.056023873, 8389.133, 21786.912, 16894.488, 17575.045]\n",
      "epoch 0\n",
      "     fun: 90741.29185131165\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16482\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.23376169e-02, 4.93065527e-02, 4.38559895e-02, 9.47084934e+03,\n",
      "       2.48940172e+04, 2.48822170e+04, 2.49999981e+04])\n",
      "best ll: 91224.73436774276, bestParams: [0.043282628, 0.04283247, 0.015615053, 3965.399, 15119.752, 11289.01, 20118.45]\n",
      "epoch 1\n",
      "     fun: 90968.17657566987\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 39572\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.99538244e-02, 2.93838522e-01, 5.58080675e-02, 5.08857742e+03,\n",
      "       9.48498524e+03, 6.15838872e+03, 1.74503829e+04])\n",
      "minPrevious 90741.29185131165\n",
      "best ll: 90881.52796996137, bestParams: [0.057814863, 0.036603197, 0.048284452, 6125.3677, 14977.148, 11782.217, 16754.512]\n",
      "epoch 2\n",
      "     fun: 90729.455342717\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19418\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.65090442e-02, 4.45915397e-02, 4.23747175e-02, 8.80405812e+03,\n",
      "       2.49621024e+04, 2.48324605e+04, 2.18698763e+04])\n",
      "minPrevious 90741.29185131165\n",
      "better by at >= 1; new ll:      fun: 90729.455342717\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19418\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.65090442e-02, 4.45915397e-02, 4.23747175e-02, 8.80405812e+03,\n",
      "       2.49621024e+04, 2.48324605e+04, 2.18698763e+04])\n",
      "best ll: 91326.07627551297, bestParams: [0.095849864, 0.09590016, 0.092939384, 7666.34, 6450.7437, 15030.143, 23817.498]\n",
      "epoch 3\n",
      "     fun: 90729.30744291696\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22517\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.37379352e-02, 4.05152351e-02, 4.17252985e-02, 8.39802978e+03,\n",
      "       2.47668799e+04, 2.49916565e+04, 1.98267634e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91016.03464464155, bestParams: [0.06892339, 0.08220619, 0.041249212, 10588.921, 24391.959, 19792.424, 22084.648]\n",
      "epoch 4\n",
      "     fun: 90959.0438262211\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19051\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.16422571e-02, 8.50540140e-01, 5.78171661e-02, 5.56689535e+03,\n",
      "       9.72820890e+03, 5.85802465e+03, 1.96208622e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91027.85668282304, bestParams: [0.03505238, 0.044490505, 0.027420068, 6133.5425, 23373.82, 13148.674, 14960.702]\n",
      "epoch 5\n",
      "     fun: 90735.7505212659\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18858\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.04506841e-02, 4.75836595e-02, 4.31450513e-02, 9.25332768e+03,\n",
      "       2.49542178e+04, 2.49510328e+04, 2.40224887e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91344.33768614761, bestParams: [0.053518336, 0.08740302, 0.067629404, 6031.661, 18487.89, 9499.573, 9493.0]\n",
      "epoch 6\n",
      "     fun: 90742.86427037211\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 15856\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.25172955e-02, 4.97425219e-02, 4.43748053e-02, 9.57142437e+03,\n",
      "       2.49836514e+04, 2.48985330e+04, 2.49999996e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91210.99558153439, bestParams: [0.015522353, 0.020422507, 0.02180805, 5947.9175, 24499.941, 23246.885, 23200.797]\n",
      "epoch 7\n",
      "     fun: 90731.14997350496\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23205\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.28252218e-02, 3.99237022e-02, 4.15478607e-02, 6.40159151e+03,\n",
      "       1.90431847e+04, 1.92309877e+04, 1.49437001e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91095.22483766638, bestParams: [0.07067214, 0.03771307, 0.054919243, 6992.266, 20875.805, 19603.213, 6386.5703]\n",
      "epoch 8\n",
      "     fun: 90730.85085085777\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20929\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.53289295e-02, 4.27071902e-02, 4.20085505e-02, 8.40268795e+03,\n",
      "       2.42169186e+04, 2.42700284e+04, 2.04402196e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91393.03288045904, bestParams: [0.017872097, 0.053617258, 0.039089, 1954.1438, 5562.4053, 1457.8615, 7767.6426]\n",
      "epoch 9\n",
      "     fun: 90733.01401258064\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 31233\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.60272951e-02, 4.06109139e-02, 4.20647643e-02, 6.14139763e+03,\n",
      "       1.75751538e+04, 1.81183570e+04, 1.47902926e+04])\n",
      "minPrevious 90729.455342717\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0465, 0.0446, 0.0424], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8839, 0.0639, 0.0280, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8704, 0.0741, 0.0261, 0.0295], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8829, 0.0280, 0.0636, 0.0254], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8708, 0.0261, 0.0737, 0.0295], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7400, 0.0995, 0.0966, 0.0611], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7060, 0.1126, 0.1124, 0.0690], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.8960, 3.3836, 5.0518],\n",
      "        [3.8514, 4.7767, 6.8971],\n",
      "        [4.0691, 2.5010, 4.6004],\n",
      "        ...,\n",
      "        [4.4449, 3.2959, 3.9365],\n",
      "        [4.3674, 3.9315, 8.1608],\n",
      "        [3.6398, 2.5625, 7.4278]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.356298923492432\n",
      "Run: 0, 3\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[48.,  2.,  1.,  0.],\n",
      "        [41.,  3.,  2.,  2.],\n",
      "        [55.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [58.,  2.,  2.,  1.],\n",
      "        [48.,  2.,  0.,  0.],\n",
      "        [35.,  2.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([51., 48., 59.,  ..., 63., 50., 39.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 3.,  ..., 2., 2., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 0.,  ..., 2., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 1.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[48.,  2.,  1.,  0.],\n",
      "        [41.,  3.,  2.,  2.],\n",
      "        [55.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [58.,  2.,  2.,  1.],\n",
      "        [48.,  2.,  0.,  0.],\n",
      "        [35.,  2.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0487, 0.0019, 0.0098,  ..., 0.0257, 0.0341, 0.0266],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad03b00>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91021.23597877396, bestParams: [0.02387655, 0.09362935, 0.0531731, 8440.324, 13937.0, 11477.793, 16246.775]\n",
      "epoch 0\n",
      "     fun: 90367.46646443212\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18738\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.85798503e-02, 3.12189972e-02, 4.14406663e-02, 7.79360605e+03,\n",
      "       2.38725780e+04, 2.46992225e+04, 1.68480061e+04])\n",
      "best ll: 90814.01155907288, bestParams: [0.092853814, 0.079595976, 0.09696471, 9648.206, 12964.165, 13710.112, 22609.943]\n",
      "epoch 1\n",
      "     fun: 90370.16992066184\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20256\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.06782851e-02, 3.05888247e-02, 4.18256058e-02, 3.30614673e+03,\n",
      "       9.80870940e+03, 1.04315332e+04, 7.28013746e+03])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90693.35079318719, bestParams: [0.05039767, 0.07389942, 0.05925788, 5015.5117, 11736.682, 7729.9805, 10372.028]\n",
      "epoch 2\n",
      "     fun: 90544.51615211637\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26660\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([1.15173636e-01, 8.27076011e-01, 5.75481400e-02, 4.88184316e+03,\n",
      "       7.22753220e+03, 5.23483166e+03, 1.76610229e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90928.8394107176, bestParams: [0.08049662, 0.08387433, 0.06717268, 7118.226, 9401.673, 19610.592, 16397.375]\n",
      "epoch 3\n",
      "     fun: 90369.26401926341\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27176\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.55837197e-02, 3.36905447e-02, 4.29108512e-02, 6.71586563e+03,\n",
      "       1.85568972e+04, 1.98110040e+04, 1.60601036e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90849.15617868747, bestParams: [0.041133363, 0.06851273, 0.07244423, 6477.3115, 20420.096, 20529.924, 4543.0527]\n",
      "epoch 4\n",
      "     fun: 90369.74538215327\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 25662\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.46136940e-02, 3.52382008e-02, 4.29644138e-02, 7.05933251e+03,\n",
      "       1.96641948e+04, 2.05584337e+04, 1.69372313e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 91003.55947153617, bestParams: [0.020014536, 0.16380043, 0.05750044, 6207.0884, 6395.382, 14223.492, 21751.719]\n",
      "epoch 5\n",
      "     fun: 90366.05074559979\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19246\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44379285e-02, 3.86546502e-02, 4.30928573e-02, 8.90523070e+03,\n",
      "       2.47945943e+04, 2.48658296e+04, 2.19264077e+04])\n",
      "minPrevious 90367.46646443212\n",
      "better by at >= 1; new ll:      fun: 90366.05074559979\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19246\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44379285e-02, 3.86546502e-02, 4.30928573e-02, 8.90523070e+03,\n",
      "       2.47945943e+04, 2.48658296e+04, 2.19264077e+04])\n",
      "best ll: 90749.3357777144, bestParams: [0.054987807, 0.042462654, 0.019732246, 3481.5046, 8180.3594, 12040.532, 16030.645]\n",
      "epoch 6\n",
      "     fun: 90370.04277355093\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19775\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13956855e-02, 2.99751012e-02, 4.19297763e-02, 3.18547370e+03,\n",
      "       9.37089224e+03, 1.01267621e+04, 6.99713684e+03])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90595.93835730849, bestParams: [0.049502358, 0.05059789, 0.035600856, 5736.8604, 11006.914, 12817.075, 13380.541]\n",
      "epoch 7\n",
      "     fun: 90369.03492576667\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29654\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.43124944e-02, 3.33712831e-02, 4.27940979e-02, 6.64796216e+03,\n",
      "       1.85760876e+04, 1.98131480e+04, 1.58021285e+04])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90746.22974235666, bestParams: [0.111383274, 0.080073506, 0.042195205, 10159.44, 15388.807, 19346.172, 23211.58]\n",
      "epoch 8\n",
      "     fun: 90366.30277732995\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19017\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.62580895e-02, 3.77157167e-02, 4.32366444e-02, 8.81877383e+03,\n",
      "       2.40797226e+04, 2.47941350e+04, 2.18330276e+04])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90855.43160734844, bestParams: [0.07542367, 0.05570492, 0.015105497, 9331.249, 23335.158, 21321.234, 19561.578]\n",
      "epoch 9\n",
      "     fun: 90554.8816047398\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19215\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.37802480e-01, 6.55243135e-02, 5.54580874e-02, 5.84354058e+03,\n",
      "       6.36484808e+03, 1.06079831e+04, 2.04911301e+04])\n",
      "minPrevious 90366.05074559979\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0444, 0.0387, 0.0431], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8801, 0.0644, 0.0279, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8718, 0.0728, 0.0261, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8782, 0.0278, 0.0636, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8716, 0.0262, 0.0730, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7428, 0.0992, 0.0988, 0.0623], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7085, 0.1115, 0.1117, 0.0683], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7070, 3.3558, 5.7385],\n",
      "        [6.1712, 4.8968, 6.0728],\n",
      "        [5.5908, 6.0105, 9.0300],\n",
      "        ...,\n",
      "        [3.5412, 2.9084, 6.2405],\n",
      "        [4.0371, 3.8411, 6.2719],\n",
      "        [4.3172, 3.5554, 6.5065]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.310091972351074\n",
      "Run: 0, 4\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[46.,  3.,  2.,  2.],\n",
      "        [45.,  3.,  0.,  3.],\n",
      "        [54.,  5.,  1.,  4.],\n",
      "        ...,\n",
      "        [48.,  1.,  0.,  0.],\n",
      "        [40.,  2.,  1.,  1.],\n",
      "        [40.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 51., 64.,  ..., 49., 44., 42.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 5.,  ..., 1., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 1.,  ..., 0., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 4.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[46.,  3.,  2.,  2.],\n",
      "        [45.,  3.,  0.,  3.],\n",
      "        [54.,  5.,  1.,  4.],\n",
      "        ...,\n",
      "        [48.,  1.,  0.,  0.],\n",
      "        [40.,  2.,  1.,  1.],\n",
      "        [40.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.8431e-03, 4.8473e-04, 3.3705e-05,  ..., 4.8727e-02, 2.4768e-02,\n",
      "        8.3579e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc950>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91345.08023811383, bestParams: [0.06884586, 0.015770206, 0.08335171, 3087.4746, 10631.862, 13740.989, 2484.048]\n",
      "epoch 0\n",
      "     fun: 90879.9946159658\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23081\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.24280571e-02, 4.00968936e-02, 3.89581658e-02, 6.72886260e+03,\n",
      "       2.08850194e+04, 2.07802951e+04, 1.66012855e+04])\n",
      "best ll: 90987.4655751705, bestParams: [0.028817432, 0.02610038, 0.034790974, 7775.3364, 23897.207, 21864.736, 15247.122]\n",
      "epoch 1\n",
      "     fun: 90879.06292379234\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19756\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.14930094e-02, 3.82729929e-02, 3.86535609e-02, 7.50684449e+03,\n",
      "       2.37203578e+04, 2.38252110e+04, 1.80371150e+04])\n",
      "minPrevious 90879.9946159658\n",
      "best ll: 91464.60088640705, bestParams: [0.07165316, 0.0929115, 0.01606413, 4874.1367, 14892.382, 17925.348, 7632.4253]\n",
      "epoch 2\n",
      "     fun: 90879.14375478897\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27109\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.03898485e-02, 3.80772820e-02, 3.84634180e-02, 6.62194224e+03,\n",
      "       2.12415051e+04, 2.11538949e+04, 1.57061265e+04])\n",
      "minPrevious 90879.9946159658\n",
      "best ll: 91336.19074409138, bestParams: [0.029090187, 0.039958116, 0.025319178, 4308.908, 9381.063, 14304.205, 7759.76]\n",
      "epoch 3\n",
      "     fun: 90878.55891398477\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20515\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.09047276e-02, 3.79882333e-02, 3.86226516e-02, 5.33505945e+03,\n",
      "       1.69919902e+04, 1.70332626e+04, 1.26987930e+04])\n",
      "minPrevious 90879.9946159658\n",
      "better by at >= 1; new ll:      fun: 90878.55891398477\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20515\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.09047276e-02, 3.79882333e-02, 3.86226516e-02, 5.33505945e+03,\n",
      "       1.69919902e+04, 1.70332626e+04, 1.26987930e+04])\n",
      "best ll: 91335.93185690074, bestParams: [0.035876945, 0.06610922, 0.025485078, 4390.421, 22124.35, 10895.839, 7541.019]\n",
      "epoch 4\n",
      "     fun: 90880.92135410193\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 17484\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.59090218e-02, 4.33322652e-02, 3.96535940e-02, 8.43861685e+03,\n",
      "       2.49337275e+04, 2.48150587e+04, 2.19508901e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91250.95231934264, bestParams: [0.115218244, 0.048142098, 0.051294174, 6320.828, 14317.023, 12362.9, 13260.78]\n",
      "epoch 5\n",
      "     fun: 90878.97808052332\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19609\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.07574831e-02, 3.74625089e-02, 3.83613486e-02, 6.68112794e+03,\n",
      "       2.13446230e+04, 2.15390941e+04, 1.58039078e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91213.35925044058, bestParams: [0.15606245, 0.072391056, 0.046264574, 6354.5464, 13673.771, 19265.758, 22482.443]\n",
      "epoch 6\n",
      "     fun: 90883.28559989628\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19491\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93288901e-02, 4.60300073e-02, 4.03575042e-02, 8.80576916e+03,\n",
      "       2.49172318e+04, 2.48990628e+04, 2.38112812e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91046.46063479605, bestParams: [0.03268646, 0.011289387, 0.026305977, 6561.8726, 20767.113, 23554.947, 11815.014]\n",
      "epoch 7\n",
      "     fun: 90881.05394528931\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18450\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26334934e-02, 3.93476535e-02, 3.90612840e-02, 2.50669000e+03,\n",
      "       7.75529940e+03, 7.77798697e+03, 6.15010134e+03])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91213.77202473817, bestParams: [0.12363709, 0.07303361, 0.03884344, 5911.851, 10551.361, 9712.845, 17378.764]\n",
      "epoch 8\n",
      "     fun: 90879.20283692765\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19674\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.23063429e-02, 3.91398095e-02, 3.88485271e-02, 6.98045708e+03,\n",
      "       2.17313652e+04, 2.18296056e+04, 1.70652713e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91373.61481849875, bestParams: [0.119453534, 0.015104396, 0.048940077, 3980.3694, 9912.681, 20019.787, 4480.772]\n",
      "epoch 9\n",
      "     fun: 90964.70890373456\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16833\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.88640777e-02, 5.48396144e-02, 4.41396663e-02, 7.52303449e+03,\n",
      "       1.61309726e+04, 1.82623724e+04, 2.37081847e+04])\n",
      "minPrevious 90878.55891398477\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0409, 0.0380, 0.0386], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8845, 0.0643, 0.0281, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8593, 0.0821, 0.0257, 0.0329], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8793, 0.0279, 0.0645, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8591, 0.0257, 0.0823, 0.0329], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7472, 0.0997, 0.1000, 0.0626], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6948, 0.1160, 0.1162, 0.0730], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.2669, 1.9767, 5.1363],\n",
      "        [3.5628, 2.9073, 6.2435],\n",
      "        [3.7832, 3.7930, 6.8343],\n",
      "        ...,\n",
      "        [1.9421, 1.4840, 5.1770],\n",
      "        [4.2826, 3.2783, 5.4505],\n",
      "        [3.5943, 2.8795, 6.1372]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.476979970932007\n",
      "Run: 0, 5\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[42.,  5.,  3.,  3.],\n",
      "        [39.,  4.,  0.,  3.],\n",
      "        [43.,  1.,  3.,  0.],\n",
      "        ...,\n",
      "        [54.,  2.,  1.,  1.],\n",
      "        [47.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 46., 47.,  ..., 58., 49., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 4., 1.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 3.,  ..., 1., 1., 3.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 0.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[42.,  5.,  3.,  3.],\n",
      "        [39.,  4.,  0.,  3.],\n",
      "        [43.,  1.,  3.,  0.],\n",
      "        ...,\n",
      "        [54.,  2.,  1.,  1.],\n",
      "        [47.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.0043e-05, 1.0708e-04, 2.2014e-02,  ..., 2.9246e-02, 7.0167e-02,\n",
      "        1.6781e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdcdd0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90857.78330615468, bestParams: [0.065798305, 0.01862657, 0.08375965, 6535.119, 18724.98, 18402.521, 23863.832]\n",
      "epoch 0\n",
      "     fun: 90574.54329233595\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16861\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([8.85348671e-01, 5.79907422e-02, 5.65029340e-02, 4.43107258e+03,\n",
      "       4.70193766e+03, 8.01621143e+03, 1.52672211e+04])\n",
      "best ll: 90647.02931454076, bestParams: [0.006345086, 0.025668247, 0.041042943, 3689.1306, 14496.478, 9464.404, 3974.9004]\n",
      "epoch 1\n",
      "     fun: 90346.79818100025\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22437\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.38988240e-02, 3.73832477e-02, 4.08481269e-02, 5.29178931e+03,\n",
      "       1.53774819e+04, 1.54631092e+04, 1.26597146e+04])\n",
      "minPrevious 90574.54329233595\n",
      "better by at >= 1; new ll:      fun: 90346.79818100025\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22437\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.38988240e-02, 3.73832477e-02, 4.08481269e-02, 5.29178931e+03,\n",
      "       1.53774819e+04, 1.54631092e+04, 1.26597146e+04])\n",
      "best ll: 90701.66978014109, bestParams: [0.051171403, 0.004164878, 0.037289176, 9557.071, 24102.58, 17367.414, 20774.168]\n",
      "epoch 2\n",
      "     fun: 90346.5671615596\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19326\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93206864e-02, 4.19921320e-02, 4.19359552e-02, 9.13554443e+03,\n",
      "       2.47502305e+04, 2.48801472e+04, 2.34591945e+04])\n",
      "minPrevious 90346.79818100025\n",
      "best ll: 91283.78536810011, bestParams: [0.10908244, 0.048394613, 0.10494098, 7852.6562, 4134.3623, 18254.262, 22675.844]\n",
      "epoch 3\n",
      "     fun: 90350.25783864367\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.12992497e-02, 4.44887911e-02, 4.23193013e-02, 9.43948030e+03,\n",
      "       2.49271977e+04, 2.48737002e+04, 2.48733863e+04])\n",
      "minPrevious 90346.79818100025\n",
      "best ll: 90471.10462045555, bestParams: [0.0154586835, 0.069063015, 0.03530776, 5670.462, 21156.191, 15531.642, 14583.196]\n",
      "epoch 4\n",
      "     fun: 90343.67707197007\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21977\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.74123918e-02, 4.08289397e-02, 4.13656120e-02, 8.98044189e+03,\n",
      "       2.49493444e+04, 2.49868195e+04, 2.25900515e+04])\n",
      "minPrevious 90346.79818100025\n",
      "better by at >= 1; new ll:      fun: 90343.67707197007\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21977\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.74123918e-02, 4.08289397e-02, 4.13656120e-02, 8.98044189e+03,\n",
      "       2.49493444e+04, 2.49868195e+04, 2.25900515e+04])\n",
      "best ll: 90477.84335776992, bestParams: [0.04298072, 0.021439154, 0.036853362, 3680.7407, 9893.799, 10063.484, 6246.7983]\n",
      "epoch 5\n",
      "     fun: 90343.78822780929\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19929\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.27018839e-02, 3.55948896e-02, 4.04254643e-02, 8.00020766e+03,\n",
      "       2.37514479e+04, 2.40988899e+04, 1.86050897e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90690.74806032187, bestParams: [0.05707956, 0.04165197, 0.05212749, 5306.5737, 9165.7705, 7847.644, 21851.729]\n",
      "epoch 6\n",
      "     fun: 90347.22406009762\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27937\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.34300152e-02, 3.88849780e-02, 4.11301663e-02, 5.86526976e+03,\n",
      "       1.70700458e+04, 1.67733265e+04, 1.41632998e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90533.48503693526, bestParams: [0.05087774, 0.042099502, 0.04017582, 8607.724, 23974.309, 19314.508, 15243.791]\n",
      "epoch 7\n",
      "     fun: 90344.29825837338\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18976\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.23100412e-02, 3.51282897e-02, 4.02434122e-02, 8.19614332e+03,\n",
      "       2.44955698e+04, 2.49282104e+04, 1.89051281e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 91039.73336329563, bestParams: [0.010360104, 0.0056551113, 0.017288163, 4754.299, 16049.336, 10335.417, 10871.316]\n",
      "epoch 8\n",
      "     fun: 90605.03752168667\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 15852\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.06037770e-01, 3.14303850e-02, 6.25201762e-02, 9.78926227e+03,\n",
      "       1.04937148e+04, 2.09762757e+04, 2.49999997e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90869.42943766556, bestParams: [0.058097538, 0.054223366, 0.0151370205, 7250.6963, 17291.744, 14349.171, 17670.531]\n",
      "epoch 9\n",
      "     fun: 90346.44614650698\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21311\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.12671383e-02, 3.59230494e-02, 4.02898373e-02, 5.12029022e+03,\n",
      "       1.54464584e+04, 1.53887553e+04, 1.18023848e+04])\n",
      "minPrevious 90343.67707197007\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0474, 0.0408, 0.0414], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8833, 0.0641, 0.0280, 0.0256], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8721, 0.0726, 0.0261, 0.0291], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8836, 0.0280, 0.0633, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8720, 0.0262, 0.0728, 0.0291], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7439, 0.0981, 0.0983, 0.0618], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7069, 0.1122, 0.1124, 0.0685], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.5321, 2.1588, 5.2563],\n",
      "        [3.0922, 2.8446, 5.8659],\n",
      "        [2.4312, 3.2523, 5.2012],\n",
      "        ...,\n",
      "        [5.0824, 4.3565, 4.4788],\n",
      "        [1.8716, 3.1835, 5.8296],\n",
      "        [4.0581, 4.7861, 4.6592]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.654811859130859\n",
      "Run: 0, 6\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[38.,  1.,  2.,  0.],\n",
      "        [53.,  2.,  1.,  1.],\n",
      "        [45.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [52.,  1.,  1.,  0.],\n",
      "        [49.,  1.,  2.,  1.],\n",
      "        [55.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([41., 57., 49.,  ..., 54., 53., 58.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 3.,  ..., 1., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 0.,  ..., 1., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 0., 1., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[38.,  1.,  2.,  0.],\n",
      "        [53.,  2.,  1.,  1.],\n",
      "        [45.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [52.,  1.,  1.,  0.],\n",
      "        [49.,  1.,  2.,  1.],\n",
      "        [55.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0499, 0.0292, 0.0091,  ..., 0.0603, 0.0286, 0.0355],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdcef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91089.27396093101, bestParams: [0.0075157364, 0.016659165, 0.0528355, 6167.8413, 16675.133, 23120.914, 2626.2808]\n",
      "epoch 0\n",
      "     fun: 90528.09146807808\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21301\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.22089041e-02, 4.04911316e-02, 4.09398703e-02, 7.87634233e+03,\n",
      "       2.31800900e+04, 2.34644446e+04, 1.90780530e+04])\n",
      "best ll: 90732.33126287756, bestParams: [0.025354784, 0.034044795, 0.03233444, 3831.9717, 18235.803, 15221.045, 8825.367]\n",
      "epoch 1\n",
      "     fun: 90527.19937601546\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19413\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.15413749e-02, 3.99949216e-02, 4.07060772e-02, 7.98855681e+03,\n",
      "       2.37755273e+04, 2.40322552e+04, 1.91271434e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 91108.88783821915, bestParams: [0.086679004, 0.067132905, 0.09949029, 7799.4536, 21237.266, 20044.95, 20242.219]\n",
      "epoch 2\n",
      "     fun: 90528.26860756558\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19659\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26203286e-02, 3.91555797e-02, 4.07703934e-02, 7.61654461e+03,\n",
      "       2.23785640e+04, 2.30843006e+04, 1.83011955e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 90664.09878557731, bestParams: [0.07736944, 0.06300846, 0.045417767, 1886.3728, 4232.271, 3625.2512, 6741.4614]\n",
      "epoch 3\n",
      "     fun: 90748.34990709391\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16844\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.70603984e-02, 8.70443592e-01, 5.24885454e-02, 5.72624408e+03,\n",
      "       1.07173118e+04, 6.06026139e+03, 2.05226559e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 91160.88386263404, bestParams: [0.033290174, 0.055628516, 0.014551205, 3497.17, 22058.719, 12795.54, 5477.151]\n",
      "epoch 4\n",
      "     fun: 90526.43683545549\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18563\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.91724795e-02, 3.97801077e-02, 4.02951177e-02, 8.10570623e+03,\n",
      "       2.49413083e+04, 2.46312383e+04, 1.89534248e+04])\n",
      "minPrevious 90528.09146807808\n",
      "better by at >= 1; new ll:      fun: 90526.43683545549\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18563\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.91724795e-02, 3.97801077e-02, 4.02951177e-02, 8.10570623e+03,\n",
      "       2.49413083e+04, 2.46312383e+04, 1.89534248e+04])\n",
      "best ll: 91032.47008508065, bestParams: [0.12150022, 0.06901591, 0.044288684, 6986.347, 7713.5996, 20299.445, 23289.34]\n",
      "epoch 5\n",
      "     fun: 90527.10680973373\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19381\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.03379565e-02, 3.91045966e-02, 4.04755411e-02, 7.92413194e+03,\n",
      "       2.40087260e+04, 2.41783579e+04, 1.86340368e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 91151.68239117, bestParams: [0.02094275, 0.085978635, 0.05017864, 8948.37, 7969.455, 22098.55, 24430.57]\n",
      "epoch 6\n",
      "     fun: 90532.97349945629\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21698\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.71214153e-02, 4.57389432e-02, 4.20915576e-02, 9.02832071e+03,\n",
      "       2.47487861e+04, 2.49622212e+04, 2.35201731e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90674.02727068722, bestParams: [0.03838533, 0.010670561, 0.028407924, 4872.6216, 17658.736, 17240.87, 10353.156]\n",
      "epoch 7\n",
      "     fun: 90530.28907951455\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20557\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13376010e-02, 4.08275025e-02, 4.08953581e-02, 6.64909977e+03,\n",
      "       1.97295238e+04, 1.97269175e+04, 1.60526526e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90743.39248618434, bestParams: [0.04231918, 0.031651355, 0.027624661, 2601.6572, 11065.2, 12116.015, 5007.5166]\n",
      "epoch 8\n",
      "     fun: 90527.06941824801\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20300\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.10153887e-02, 4.13760606e-02, 4.07297194e-02, 8.06086496e+03,\n",
      "       2.41232330e+04, 2.38660672e+04, 1.94393666e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90981.63954946902, bestParams: [0.05607572, 0.03384001, 0.036304813, 11815.16, 23425.008, 23078.727, 23863.035]\n",
      "epoch 9\n",
      "     fun: 90528.45840234167\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20521\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.11606709e-02, 4.21507169e-02, 4.10246844e-02, 8.36091333e+03,\n",
      "       2.48268749e+04, 2.44381077e+04, 2.03805812e+04])\n",
      "minPrevious 90526.43683545549\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0392, 0.0398, 0.0403], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8763, 0.0643, 0.0278, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8630, 0.0796, 0.0259, 0.0315], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8857, 0.0281, 0.0657, 0.0263], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8639, 0.0259, 0.0787, 0.0315], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7398, 0.0976, 0.0982, 0.0613], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7016, 0.1140, 0.1132, 0.0712], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9121, 3.6197, 4.2672],\n",
      "        [2.9923, 3.6857, 6.1465],\n",
      "        [3.8417, 2.6237, 5.0056],\n",
      "        ...,\n",
      "        [3.7917, 3.6148, 4.5259],\n",
      "        [3.2769, 4.1533, 5.7003],\n",
      "        [4.0090, 3.2273, 4.1458]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.512847900390625\n",
      "Run: 0, 7\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[50.,  5.,  1.,  4.],\n",
      "        [45.,  2.,  2.,  1.],\n",
      "        [38.,  4.,  1.,  5.],\n",
      "        ...,\n",
      "        [56.,  2.,  2.,  0.],\n",
      "        [42.,  3.,  0.,  0.],\n",
      "        [51.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "n tensor([60., 50., 48.,  ..., 60., 45., 55.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 2., 4.,  ..., 2., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 1.,  ..., 2., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 1., 5.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[50.,  5.,  1.,  4.],\n",
      "        [45.,  2.,  2.,  1.],\n",
      "        [38.,  4.,  1.,  5.],\n",
      "        ...,\n",
      "        [56.,  2.,  2.,  0.],\n",
      "        [42.,  3.,  0.,  0.],\n",
      "        [51.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.2155e-05, 1.9104e-02, 1.7708e-06,  ..., 3.6563e-02, 1.6772e-02,\n",
      "        2.8963e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bccef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91243.91071417881, bestParams: [0.040498573, 0.039992083, 0.033642173, 6753.6836, 15692.065, 21096.775, 11753.506]\n",
      "epoch 0\n",
      "     fun: 91035.2144862661\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21164\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56112050e-02, 5.15920592e-02, 4.19819102e-02, 8.88284249e+03,\n",
      "       2.49907590e+04, 2.48726630e+04, 2.23069026e+04])\n",
      "best ll: 91357.54566372334, bestParams: [0.040997185, 0.04618633, 0.0838608, 10846.453, 19839.768, 20632.074, 23618.115]\n",
      "epoch 1\n",
      "     fun: 91032.30772549672\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26802\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.40870682e-02, 4.61593746e-02, 4.11538469e-02, 8.28519028e+03,\n",
      "       2.40384533e+04, 2.47662828e+04, 1.98040363e+04])\n",
      "minPrevious 91035.2144862661\n",
      "better by at >= 1; new ll:      fun: 91032.30772549672\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26802\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.40870682e-02, 4.61593746e-02, 4.11538469e-02, 8.28519028e+03,\n",
      "       2.40384533e+04, 2.47662828e+04, 1.98040363e+04])\n",
      "best ll: 91302.02347668094, bestParams: [0.072848134, 0.03889845, 0.056128502, 6435.528, 21272.988, 18763.773, 8352.756]\n",
      "epoch 2\n",
      "     fun: 91031.9209379922\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24570\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.36019089e-02, 4.66654380e-02, 4.10921218e-02, 7.96267313e+03,\n",
      "       2.31950003e+04, 2.36841385e+04, 1.90482360e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91338.92905650586, bestParams: [0.07102878, 0.008142718, 0.04293678, 6779.5894, 16760.775, 23199.021, 24335.203]\n",
      "epoch 3\n",
      "     fun: 91033.0256424332\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19511\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.05025247e-02, 4.48221899e-02, 4.04081393e-02, 5.73947926e+03,\n",
      "       1.73768584e+04, 1.75574538e+04, 1.31654564e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91237.5362622957, bestParams: [0.04897804, 0.02517828, 0.053476565, 6121.2505, 24571.582, 21428.121, 6433.1235]\n",
      "epoch 4\n",
      "     fun: 91033.0525860195\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20408\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13719928e-02, 4.36648545e-02, 4.02826805e-02, 6.16702916e+03,\n",
      "       1.86390630e+04, 1.91395485e+04, 1.41040120e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91642.97852024857, bestParams: [0.002547079, 0.031438496, 0.04191702, 10740.871, 20333.883, 15887.142, 24783.443]\n",
      "epoch 5\n",
      "     fun: 91034.54627224465\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23137\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26251794e-02, 4.60197835e-02, 4.10425927e-02, 6.91119423e+03,\n",
      "       2.02861702e+04, 2.07257963e+04, 1.63576711e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91317.27160636887, bestParams: [0.08740924, 0.015501036, 0.038114674, 9618.194, 22194.303, 20528.768, 23597.967]\n",
      "epoch 6\n",
      "     fun: 91034.88282504663\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20439\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.59857350e-02, 5.16670146e-02, 4.19960060e-02, 8.87733643e+03,\n",
      "       2.48689759e+04, 2.48395651e+04, 2.23461119e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91663.3816547386, bestParams: [0.11510229, 0.022979988, 0.07719361, 4350.521, 11100.692, 16230.497, 16443.652]\n",
      "epoch 7\n",
      "     fun: 91033.37773956737\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19850\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.01523012e-02, 4.31942038e-02, 4.02496093e-02, 4.25476136e+03,\n",
      "       1.30677735e+04, 1.33156742e+04, 9.56380154e+03])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91600.56161983634, bestParams: [0.021486541, 0.04493397, 0.05444471, 8626.893, 24781.225, 17456.62, 8928.072]\n",
      "epoch 8\n",
      "     fun: 91033.31471153395\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 31986\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.08887799e-02, 4.39664510e-02, 4.02960859e-02, 4.10381194e+03,\n",
      "       1.24499251e+04, 1.26908510e+04, 9.37283927e+03])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91558.65006552348, bestParams: [0.13935027, 0.023656605, 0.10880936, 7721.089, 14432.105, 18207.133, 15296.897]\n",
      "epoch 9\n",
      "     fun: 91034.43093651239\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19058\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.61504895e-02, 5.08239462e-02, 4.18637993e-02, 8.83570464e+03,\n",
      "       2.47664960e+04, 2.49518926e+04, 2.21539923e+04])\n",
      "minPrevious 91032.30772549672\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0441, 0.0462, 0.0412], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8834, 0.0644, 0.0280, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8673, 0.0756, 0.0260, 0.0311], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8760, 0.0278, 0.0650, 0.0260], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8654, 0.0259, 0.0776, 0.0311], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7375, 0.0976, 0.0992, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7045, 0.1118, 0.1137, 0.0700], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[5.3702, 4.2106, 6.4728],\n",
      "        [2.3497, 1.9903, 3.4842],\n",
      "        [3.2499, 2.2078, 5.5362],\n",
      "        ...,\n",
      "        [2.0072, 3.2786, 5.4871],\n",
      "        [4.0390, 2.2470, 6.6010],\n",
      "        [3.4164, 3.2387, 5.0540]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.588237047195435\n",
      "Run: 0, 8\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  2.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [58.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [51.,  1.,  0.,  0.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([47., 54., 61.,  ..., 52., 54., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 5., 0.,  ..., 1., 5., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 2.,  ..., 0., 2., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  2.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [58.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [51.,  1.,  0.,  0.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0106, 0.0011, 0.0168,  ..., 0.0420, 0.0011, 0.0503],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bcce60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91167.15270193382, bestParams: [0.014420534, 0.012763254, 0.08490746, 10409.463, 14869.195, 12726.8955, 24758.049]\n",
      "epoch 0\n",
      "     fun: 90664.13815521165\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18871\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.50519321e-02, 4.80974897e-02, 4.37722990e-02, 9.33124432e+03,\n",
      "       2.49952647e+04, 2.48946095e+04, 2.44922474e+04])\n",
      "best ll: 91064.46507395245, bestParams: [0.13599314, 0.0092406655, 0.06631607, 5395.3354, 13053.832, 21606.041, 11194.925]\n",
      "epoch 1\n",
      "     fun: 90658.51054391943\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21778\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97539028e-02, 3.85180081e-02, 4.21989798e-02, 5.29648514e+03,\n",
      "       1.53948253e+04, 1.60815565e+04, 1.24519796e+04])\n",
      "minPrevious 90664.13815521165\n",
      "better by at >= 1; new ll:      fun: 90658.51054391943\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21778\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97539028e-02, 3.85180081e-02, 4.21989798e-02, 5.29648514e+03,\n",
      "       1.53948253e+04, 1.60815565e+04, 1.24519796e+04])\n",
      "best ll: 91161.8533601003, bestParams: [0.034372266, 0.032068986, 0.05270397, 8083.9736, 19698.992, 9210.703, 19556.129]\n",
      "epoch 2\n",
      "     fun: 90657.06766549514\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.92766030e-02, 4.08158908e-02, 4.23739920e-02, 7.79916973e+03,\n",
      "       2.27167344e+04, 2.30158405e+04, 1.86388333e+04])\n",
      "minPrevious 90658.51054391943\n",
      "better by at >= 1; new ll:      fun: 90657.06766549514\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.92766030e-02, 4.08158908e-02, 4.23739920e-02, 7.79916973e+03,\n",
      "       2.27167344e+04, 2.30158405e+04, 1.86388333e+04])\n",
      "best ll: 91063.24965752647, bestParams: [0.021735504, 0.06495616, 0.022336451, 6890.512, 21746.352, 12447.272, 18961.99]\n",
      "epoch 3\n",
      "     fun: 90659.63845924352\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29426\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.96169439e-02, 4.09057274e-02, 4.24696771e-02, 5.79042445e+03,\n",
      "       1.67475000e+04, 1.69853353e+04, 1.39198936e+04])\n",
      "minPrevious 90657.06766549514\n",
      "best ll: 90977.47848692283, bestParams: [0.059151612, 0.05514521, 0.0882875, 7970.9907, 15740.975, 12443.312, 21263.242]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8d3d1ca8ed6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[0;31m#         fnArgs = [probs[0], probs[1], probs[2], *alphas]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m         \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mdual_annealing\u001b[0;34m(func, bounds, args, maxiter, local_search_options, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;31m# Possible local search at the end of the strategy chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_local_search\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mlocal_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;31m# Global energy has improved, let's see if LS improves further\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             e, x = self.minimizer_wrapper.local_search(self.energy_state.xbest,\n\u001b[0;32m--> 318\u001b[0;31m                                                        self.energy_state.ebest)\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mebest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_improved_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mlocal_search\u001b[0;34m(self, x, e)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Run local search from the given x location where energy value is e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mx_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mmres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'njev'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnjev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 600\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0ma1Both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1Both\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0ma21\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "resSim = {\n",
    "        \"allRes\": None,\n",
    "        \"nEpochs\": None,\n",
    "        \"bestRes\": {\n",
    "            \"pis\": None,\n",
    "            \"alphas\": None,\n",
    "            \"PDV_c1true\": None,\n",
    "            \"PDV_c2true\": None,\n",
    "            \"PDV_cBothTrue\": None,\n",
    "            \"PDV_c1inferred\": None,\n",
    "            \"PDV_c2inferred\": None,\n",
    "            \"PDV_cBothInferred\": None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cached6NormalSimRes = []\n",
    "\n",
    "rrsSim = tensor([[2, 2, 1.5]])\n",
    "pisSim = tensor([[.05, .05, .05]])\n",
    "\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(5e5)\n",
    "i = 0\n",
    "for rrsSimRun in rrsSim:\n",
    "    for pisSimRun in pisSim:\n",
    "        afMeanRun = 1e-4\n",
    "        generatingFn = genData.v6normal\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        # needs tensor for shapes, otherwise \"gamma_cpu not implemente for long\", e.g rrShape=50.0 doesn't work...\n",
    "        paramsRun = genData.genParams(rrMeans=rrsSimRun, pis=pisSimRun, afMean=afMeanRun, rrShape=tensor(50.), afShape=tensor(50.), nCases=nCases, nCtrls=nCtrls)[0]\n",
    "        \n",
    "        pDsRun = paramsRun[\"pDs\"]\n",
    "        pisRun = paramsRun[\"diseaseFractions\"]\n",
    "        print(\"params are:\", paramsRun)\n",
    "        \n",
    "        cached6NormalSimRes.append({\"params\": paramsRun, \"runs\": []})\n",
    "        for y in range(0, 10):\n",
    "            start = time.time()\n",
    "            r = generatingFn(**paramsRun)\n",
    "            print(\"took\", time.time() - start)\n",
    "            \n",
    "            resPointer = {\n",
    "                **r,\n",
    "                \"generatingFn\": generatingFn,\n",
    "                \"results\": None,\n",
    "            }\n",
    "\n",
    "            cached6NormalSimRes[i][\"runs\"].append(resPointer)\n",
    "            \n",
    "            print(f\"Run: {i}, {y}\")\n",
    "            \n",
    "            xsRun = resPointer[\"altCounts\"]\n",
    "            afsRun = resPointer[\"afs\"]\n",
    "            affectedGenesRun = resPointer[\"affectedGenes\"]\n",
    "            unaffectedGenesRun = resPointer[\"unaffectedGenes\"]\n",
    "\n",
    "            runCostFnIdx = 16\n",
    "\n",
    "            nEpochsRun = 10\n",
    "            print(\"nEpochsRun\", nEpochsRun)\n",
    "            \n",
    "            res = likelihoods.fitFnBivariateAnnealing(xsRun, pDsRun, nEpochs=nEpochsRun, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "            bestRes = res[\"params\"][-1]\n",
    "\n",
    "            inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "            inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "            #### Calculate actual ###\n",
    "            component1Afs = afsRun[affectedGenesRun[0]]\n",
    "            c1true = (component1Afs / afMeanRun).mean(0)\n",
    "\n",
    "            component2Afs = afsRun[affectedGenesRun[1]]\n",
    "            c2true = (component2Afs / afMeanRun).mean(0)\n",
    "\n",
    "            componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "            cBothTrue = (componentBothAfs / afMeanRun).mean(0)\n",
    "\n",
    "            ### calculate inferred values\n",
    "            pds = tensor([1-pDsRun.sum(), *pDsRun])\n",
    "            alphas = inferredAlphas.numpy()\n",
    "            c1inferred = Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            c2inferred = Dirichlet(tensor([alphas[0], alphas[0], alphas[2], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            cBothInferred = Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0)\n",
    "\n",
    "            print(f\"\\n\\nrun {i} results for rrs: {rrsSimRun}, pis: {pisSimRun}\")\n",
    "            print(\"Inferred pis:\", inferredPis)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c1true)\n",
    "            print(\"P(D|V) inferred in component 1:\", c1inferred)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c2true)\n",
    "            print(\"P(D|V) inferred in component both:\", c2inferred)\n",
    "            print(\"\\nP(D|V) true ans in component both:\", cBothTrue)\n",
    "            print(\"P(D|V) inferred in component both:\", cBothInferred,\"\\n\\n\")\n",
    "\n",
    "            resToStore = copy.deepcopy(resSim)\n",
    "            resToStore[\"allRes\"] = res\n",
    "            resToStore[\"nEpochs\"] = nEpochsRun\n",
    "            br = resToStore[\"bestRes\"]\n",
    "            br[\"pis\"] = inferredPis\n",
    "            br[\"alphas\"] = inferredAlphas\n",
    "            br[\"PDV_c1true\"] = c1true\n",
    "            br[\"PDV_c2true\"] = c2true\n",
    "            br[\"PDV_cBothTrue\"] = cBothTrue\n",
    "            br[\"PDV_c1inferred\"] = c1inferred\n",
    "            br[\"PDV_c2inferred\"] = c2inferred\n",
    "            br[\"PDV_cBothInferred\"] = cBothInferred\n",
    "\n",
    "            resPointer[\"results\"] = resToStore\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([2.0000, 2.0000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.0478, 2.3230, 4.9419],\n",
      "        [1.1123, 3.1260, 6.4751],\n",
      "        [3.7432, 4.8883, 4.0865],\n",
      "        ...,\n",
      "        [2.3440, 2.6389, 4.7504],\n",
      "        [3.1413, 3.7973, 5.2277],\n",
      "        [2.2387, 4.0079, 4.0649]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.850098848342896\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[45.,  5.,  3.,  2.],\n",
      "        [41.,  4.,  3.,  1.],\n",
      "        [37.,  7.,  1.,  0.],\n",
      "        ...,\n",
      "        [74.,  1.,  4.,  0.],\n",
      "        [34.,  0.,  0.,  1.],\n",
      "        [47.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([55., 49., 45.,  ..., 79., 35., 47.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 4., 7.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 1.,  ..., 4., 0., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 0.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[45.,  5.,  3.,  2.],\n",
      "        [41.,  4.,  3.,  1.],\n",
      "        [37.,  7.,  1.,  0.],\n",
      "        ...,\n",
      "        [74.,  1.,  4.,  0.],\n",
      "        [34.,  0.,  0.,  1.],\n",
      "        [47.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([1.5210e-04, 1.0985e-03, 4.9528e-05,  ..., 1.1274e-02, 3.6850e-02,\n",
      "        3.8093e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3eef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91172.32504614866, bestParams: [0.013028687, 0.04237689, 0.055741724, 11929.878, 23005.342, 24812.355, 19184.58]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.44827568e-02, 4.20886696e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886697e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204496e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886697e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204496e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886694e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04]]), array([90708.23269808, 90708.23269813, 90708.23269813, 90708.23269813,\n",
      "       90708.23269818, 90708.2326982 , 90708.23269824, 90708.23269824]))\n",
      "           fun: 90708.2326980827\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1318\n",
      "           nit: 493\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.44827568e-02, 4.20886696e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "       2.80864800e+04, 2.54391201e+04, 1.98356475e+04])\n",
      "best ll: 90890.87945008784, bestParams: [0.02896374, 0.014520663, 0.032099355, 7064.519, 15548.0, 21440.451, 23799.553]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528250e+04],\n",
      "       [3.38261325e-02, 1.79584957e-02, 3.97524944e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528248e+04],\n",
      "       [3.38261324e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519285e+04, 2.19081534e+04, 1.22528248e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524946e-02, 6.01717407e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04]]), array([90656.19387572, 90656.19387581, 90656.19387586, 90656.19387586,\n",
      "       90656.19387591, 90656.19387599, 90656.19387611, 90656.19387612]))\n",
      "           fun: 90656.19387571645\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1376\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "       1.88519284e+04, 2.19081534e+04, 1.22528249e+04])\n",
      "minPrevious 90708.2326980827\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528250e+04],\n",
      "       [3.38261325e-02, 1.79584957e-02, 3.97524944e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528248e+04],\n",
      "       [3.38261324e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519285e+04, 2.19081534e+04, 1.22528248e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524946e-02, 6.01717407e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04]]), array([90656.19387572, 90656.19387581, 90656.19387586, 90656.19387586,\n",
      "       90656.19387591, 90656.19387599, 90656.19387611, 90656.19387612]))\n",
      "           fun: 90656.19387571645\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1376\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "       1.88519284e+04, 2.19081534e+04, 1.22528249e+04])\n",
      "best ll: 91084.1192014738, bestParams: [0.09653744, 0.018029423, 0.09406014, 7974.054, 10447.645, 17449.232, 18952.387]\n",
      "epoch 2\n",
      " final_simplex: (array([[9.36961198e-02, 2.15226793e-02, 4.20764994e-02, 6.46469647e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961197e-02, 2.15226793e-02, 4.20764980e-02, 6.46469647e+03,\n",
      "        1.42865571e+04, 1.95487746e+04, 1.90451599e+04],\n",
      "       [9.36961201e-02, 2.15226793e-02, 4.20765002e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451600e+04],\n",
      "       [9.36961203e-02, 2.15226793e-02, 4.20764994e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487746e+04, 1.90451598e+04],\n",
      "       [9.36961203e-02, 2.15226792e-02, 4.20764988e-02, 6.46469647e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961206e-02, 2.15226793e-02, 4.20765004e-02, 6.46469645e+03,\n",
      "        1.42865569e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961209e-02, 2.15226792e-02, 4.20765011e-02, 6.46469645e+03,\n",
      "        1.42865569e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961205e-02, 2.15226792e-02, 4.20764990e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04]]), array([90681.43851664, 90681.43851693, 90681.43851704, 90681.43851723,\n",
      "       90681.43851748, 90681.43851752, 90681.43851769, 90681.43851779]))\n",
      "           fun: 90681.43851663727\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.36961198e-02, 2.15226793e-02, 4.20764994e-02, 6.46469647e+03,\n",
      "       1.42865570e+04, 1.95487745e+04, 1.90451599e+04])\n",
      "minPrevious 90656.19387571645\n",
      "best ll: 91034.65410804498, bestParams: [0.027997645, 0.11145982, 0.04767258, 7647.5757, 20896.21, 12109.757, 15794.455]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.29898119e-02, 8.95420892e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420892e-02, 4.67567476e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898118e-02, 8.95420892e-02, 4.67567477e-02, 6.32456128e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420894e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816320e+04, 1.92698622e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567478e-02, 6.32456126e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698622e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567478e-02, 6.32456125e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420898e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698622e+04]]), array([90716.56485695, 90716.56485706, 90716.56485719, 90716.56485742,\n",
      "       90716.56485758, 90716.56485805, 90716.56485833, 90716.56487249]))\n",
      "           fun: 90716.56485695229\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1182\n",
      "           nit: 442\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.29898119e-02, 8.95420892e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "       1.68206514e+04, 1.47816319e+04, 1.92698623e+04])\n",
      "minPrevious 90656.19387571645\n",
      "best ll: 90939.13863356014, bestParams: [0.07707118, 0.018570729, 0.07501205, 5894.602, 8311.181, 11558.4, 19163.01]\n",
      "epoch 4\n",
      " final_simplex: (array([[6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350208e-02, 2.24385760e-02, 3.93378972e-02, 4.60124344e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539976e+04],\n",
      "       [6.84350208e-02, 2.24385761e-02, 3.93378969e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350213e-02, 2.24385761e-02, 3.93378970e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539976e+04],\n",
      "       [6.84350210e-02, 2.24385763e-02, 3.93378962e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350214e-02, 2.24385761e-02, 3.93378967e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350228e-02, 2.24385758e-02, 3.93378974e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350233e-02, 2.24385756e-02, 3.93378983e-02, 4.60124348e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04]]), array([90648.44593427, 90648.44593435, 90648.44593449, 90648.44593476,\n",
      "       90648.44593506, 90648.4459351 , 90648.44593574, 90648.4459358 ]))\n",
      "           fun: 90648.44593427246\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1147\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "       1.17104156e+04, 1.52903364e+04, 1.15539975e+04])\n",
      "minPrevious 90656.19387571645\n",
      "better by at >= 1; new ll:  final_simplex: (array([[6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350208e-02, 2.24385760e-02, 3.93378972e-02, 4.60124344e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539976e+04],\n",
      "       [6.84350208e-02, 2.24385761e-02, 3.93378969e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350213e-02, 2.24385761e-02, 3.93378970e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539976e+04],\n",
      "       [6.84350210e-02, 2.24385763e-02, 3.93378962e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350214e-02, 2.24385761e-02, 3.93378967e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350228e-02, 2.24385758e-02, 3.93378974e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350233e-02, 2.24385756e-02, 3.93378983e-02, 4.60124348e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04]]), array([90648.44593427, 90648.44593435, 90648.44593449, 90648.44593476,\n",
      "       90648.44593506, 90648.4459351 , 90648.44593574, 90648.4459358 ]))\n",
      "           fun: 90648.44593427246\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1147\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "       1.17104156e+04, 1.52903364e+04, 1.15539975e+04])\n",
      "best ll: 91166.87153988995, bestParams: [0.068626955, 0.11146803, 0.06459778, 7812.6924, 19519.297, 9904.601, 17612.63]\n",
      "epoch 5\n",
      " final_simplex: (array([[7.59170859e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170857e-02, 1.01934340e-01, 4.47969147e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170858e-02, 1.01934340e-01, 4.47969150e-02, 6.65456055e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170859e-02, 1.01934340e-01, 4.47969144e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628879e+04, 2.17700551e+04],\n",
      "       [7.59170856e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934341e-01, 4.47969147e-02, 6.65456053e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934341e-01, 4.47969147e-02, 6.65456053e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04]]), array([90735.31638244, 90735.31638259, 90735.31638261, 90735.31638276,\n",
      "       90735.31638288, 90735.31638291, 90735.31638307, 90735.31638314]))\n",
      "           fun: 90735.31638244262\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1236\n",
      "           nit: 471\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.59170859e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "       1.49096890e+04, 1.34628878e+04, 2.17700551e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90917.66287739587, bestParams: [0.13892789, 0.10014813, 0.035001487, 4701.4688, 7708.276, 10219.709, 22012.11]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.36648091e-01, 9.30464598e-02, 3.80847363e-02, 4.89947091e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648091e-01, 9.30464598e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464601e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151964e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464605e-02, 3.80847362e-02, 4.89947092e+03,\n",
      "        8.76151962e+03, 1.02069802e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464605e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151957e+03, 1.02069801e+04, 1.80163115e+04],\n",
      "       [1.36648090e-01, 9.30464604e-02, 3.80847362e-02, 4.89947091e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464608e-02, 3.80847361e-02, 4.89947093e+03,\n",
      "        8.76151964e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464607e-02, 3.80847360e-02, 4.89947093e+03,\n",
      "        8.76151961e+03, 1.02069801e+04, 1.80163114e+04]]), array([90782.8870678 , 90782.88706813, 90782.88706825, 90782.88706835,\n",
      "       90782.88706844, 90782.8870687 , 90782.88706913, 90782.88706914]))\n",
      "           fun: 90782.88706779895\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1239\n",
      "           nit: 485\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.36648091e-01, 9.30464598e-02, 3.80847363e-02, 4.89947091e+03,\n",
      "       8.76151963e+03, 1.02069801e+04, 1.80163114e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90921.60896941471, bestParams: [0.039651427, 0.066044815, 0.0449088, 8883.905, 17105.955, 21929.596, 18417.646]\n",
      "epoch 7\n",
      " final_simplex: (array([[4.04578591e-02, 6.31349507e-02, 4.17312360e-02, 7.30683351e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349508e-02, 4.17312359e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349506e-02, 4.17312361e-02, 7.30683352e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130547e+04],\n",
      "       [4.04578590e-02, 6.31349505e-02, 4.17312361e-02, 7.30683351e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578592e-02, 6.31349508e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130547e+04],\n",
      "       [4.04578590e-02, 6.31349507e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349509e-02, 4.17312359e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349508e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04]]), array([90653.65813487, 90653.65813493, 90653.65813495, 90653.65813495,\n",
      "       90653.65813502, 90653.65813511, 90653.65813513, 90653.65813515]))\n",
      "           fun: 90653.65813486525\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1328\n",
      "           nit: 534\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.04578591e-02, 6.31349507e-02, 4.17312360e-02, 7.30683351e+03,\n",
      "       2.06655049e+04, 1.98816064e+04, 2.07130546e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90906.03571837083, bestParams: [0.046865396, 0.021055793, 0.022448916, 5707.723, 14474.583, 22354.312, 23248.088]\n",
      "epoch 8\n",
      " final_simplex: (array([[4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083142e-02, 2.66136979e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04]]), array([90636.62833643, 90636.62833654, 90636.6283387 , 90636.62833873,\n",
      "       90636.62833876, 90636.62833878, 90636.628347  , 90636.62834702]))\n",
      "           fun: 90636.62833642976\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1308\n",
      "           nit: 446\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "       1.71687415e+04, 1.90909270e+04, 1.19123748e+04])\n",
      "minPrevious 90648.44593427246\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083142e-02, 2.66136979e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04]]), array([90636.62833643, 90636.62833654, 90636.6283387 , 90636.62833873,\n",
      "       90636.62833876, 90636.62833878, 90636.628347  , 90636.62834702]))\n",
      "           fun: 90636.62833642976\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1308\n",
      "           nit: 446\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "       1.71687415e+04, 1.90909270e+04, 1.19123748e+04])\n",
      "best ll: 91011.59666077793, bestParams: [0.1238161, 0.015511246, 0.058201686, 9525.396, 21616.701, 17512.54, 22892.9]\n",
      "epoch 9\n",
      " final_simplex: (array([[1.03603268e-01, 1.67256257e-02, 5.42323187e-02, 8.78604866e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256257e-02, 5.42323187e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603268e-01, 1.67256256e-02, 5.42323188e-02, 8.78604868e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603268e-01, 1.67256256e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256256e-02, 5.42323188e-02, 8.78604866e+03,\n",
      "        1.78020607e+04, 2.35306881e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256256e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020608e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603269e-01, 1.67256255e-02, 5.42323190e-02, 8.78604870e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256255e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306881e+04, 2.62310912e+04]]), array([90724.66721506, 90724.66721543, 90724.66721548, 90724.66721562,\n",
      "       90724.66721583, 90724.6672159 , 90724.667216  , 90724.66721622]))\n",
      "           fun: 90724.66721505724\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1140\n",
      "           nit: 379\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.03603268e-01, 1.67256257e-02, 5.42323187e-02, 8.78604866e+03,\n",
      "       1.78020607e+04, 2.35306880e+04, 2.62310912e+04])\n",
      "minPrevious 90636.62833642976\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0405, 0.0266, 0.0348], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8832, 0.0633, 0.0280, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8564, 0.0816, 0.0256, 0.0363], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8810, 0.0279, 0.0632, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8486, 0.0255, 0.0899, 0.0360], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7405, 0.0996, 0.0999, 0.0624], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6942, 0.1121, 0.1194, 0.0742], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[1.7906, 2.9352, 4.7581],\n",
      "        [3.0976, 2.9503, 4.8961],\n",
      "        [3.5549, 4.4150, 6.2209],\n",
      "        ...,\n",
      "        [3.0932, 3.6773, 5.4842],\n",
      "        [4.8924, 3.0446, 5.1291],\n",
      "        [3.6147, 3.7954, 6.7355]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.719698190689087\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[39.,  1.,  0.,  3.],\n",
      "        [52.,  5.,  1.,  1.],\n",
      "        [48.,  1.,  0.,  3.],\n",
      "        ...,\n",
      "        [56.,  1.,  2.,  2.],\n",
      "        [43.,  4.,  0.,  1.],\n",
      "        [47.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([43., 59., 52.,  ..., 61., 48., 49.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 5., 1.,  ..., 1., 4., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 0.,  ..., 2., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 3.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[39.,  1.,  0.,  3.],\n",
      "        [52.,  5.,  1.,  1.],\n",
      "        [48.,  1.,  0.,  3.],\n",
      "        ...,\n",
      "        [56.,  1.,  2.,  2.],\n",
      "        [43.,  4.,  0.,  1.],\n",
      "        [47.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0013, 0.0021, 0.0015,  ..., 0.0100, 0.0030, 0.0702],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3ea70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90741.90852394194, bestParams: [0.07122339, 0.0030399286, 0.054159407, 10150.92, 21346.87, 23431.73, 21332.012]\n",
      "epoch 0\n",
      " final_simplex: (array([[6.75587190e-02, 3.35212914e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212913e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587193e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587193e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212914e-03, 5.38820011e-02, 8.95523095e+03,\n",
      "        2.17844697e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587194e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587194e-02, 3.35212913e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139825e+04]]), array([90648.67312646, 90648.6731265 , 90648.67312653, 90648.67312653,\n",
      "       90648.6731266 , 90648.67312662, 90648.67312669, 90648.67312672]))\n",
      "           fun: 90648.67312645877\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1299\n",
      "           nit: 485\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.75587190e-02, 3.35212914e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "       2.17844698e+04, 2.55800586e+04, 2.21139824e+04])\n",
      "best ll: 90681.83730196144, bestParams: [0.009099581, 0.0579189, 0.04930118, 3433.2517, 15866.488, 10614.559, 6043.5835]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482751e+03],\n",
      "       [3.97041955e-02, 3.83571503e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482756e+03],\n",
      "       [3.97041953e-02, 3.83571506e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482753e+03],\n",
      "       [3.97041955e-02, 3.83571505e-02, 4.01668990e-02, 1.65787189e+03,\n",
      "        5.10452657e+03, 4.99800959e+03, 3.89482751e+03],\n",
      "       [3.97041957e-02, 3.83571504e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452653e+03, 4.99800953e+03, 3.89482757e+03],\n",
      "       [3.97041957e-02, 3.83571501e-02, 4.01668989e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482757e+03],\n",
      "       [3.97041956e-02, 3.83571500e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452651e+03, 4.99800959e+03, 3.89482750e+03],\n",
      "       [3.97041950e-02, 3.83571509e-02, 4.01668988e-02, 1.65787188e+03,\n",
      "        5.10452655e+03, 4.99800972e+03, 3.89482750e+03]]), array([90476.89262346, 90476.89262354, 90476.89262355, 90476.89262356,\n",
      "       90476.89262359, 90476.89262365, 90476.89262374, 90476.89262375]))\n",
      "           fun: 90476.89262346049\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1303\n",
      "           nit: 537\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "       5.10452656e+03, 4.99800963e+03, 3.89482751e+03])\n",
      "minPrevious 90648.67312645877\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482751e+03],\n",
      "       [3.97041955e-02, 3.83571503e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482756e+03],\n",
      "       [3.97041953e-02, 3.83571506e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482753e+03],\n",
      "       [3.97041955e-02, 3.83571505e-02, 4.01668990e-02, 1.65787189e+03,\n",
      "        5.10452657e+03, 4.99800959e+03, 3.89482751e+03],\n",
      "       [3.97041957e-02, 3.83571504e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452653e+03, 4.99800953e+03, 3.89482757e+03],\n",
      "       [3.97041957e-02, 3.83571501e-02, 4.01668989e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482757e+03],\n",
      "       [3.97041956e-02, 3.83571500e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452651e+03, 4.99800959e+03, 3.89482750e+03],\n",
      "       [3.97041950e-02, 3.83571509e-02, 4.01668988e-02, 1.65787188e+03,\n",
      "        5.10452655e+03, 4.99800972e+03, 3.89482750e+03]]), array([90476.89262346, 90476.89262354, 90476.89262355, 90476.89262356,\n",
      "       90476.89262359, 90476.89262365, 90476.89262374, 90476.89262375]))\n",
      "           fun: 90476.89262346049\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1303\n",
      "           nit: 537\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "       5.10452656e+03, 4.99800963e+03, 3.89482751e+03])\n",
      "best ll: 90717.3162355351, bestParams: [0.06359781, 0.10405803, 0.046771917, 7625.652, 24112.361, 18915.994, 16105.375]\n",
      "epoch 2\n",
      " final_simplex: (array([[5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102427e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102420e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102419e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102418e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102419e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04]]), array([90500.47796516, 90500.47796518, 90500.47796518, 90500.47796519,\n",
      "       90500.47796527, 90500.47796527, 90500.47796527, 90500.47796528]))\n",
      "           fun: 90500.47796516292\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 4652\n",
      "           nit: 2308\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "       2.04976104e+04, 2.06011943e+04, 2.24340928e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90929.14797453234, bestParams: [0.021989336, 0.024018025, 0.07503793, 7889.689, 16223.559, 6951.5303, 24633.479]\n",
      "epoch 3\n",
      " final_simplex: (array([[2.99085125e-02, 2.41263715e-02, 4.27982693e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577086e+03],\n",
      "       [2.99085127e-02, 2.41263716e-02, 4.27982671e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577085e+03],\n",
      "       [2.99085125e-02, 2.41263714e-02, 4.27982700e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577081e+03],\n",
      "       [2.99085123e-02, 2.41263714e-02, 4.27982701e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577087e+03],\n",
      "       [2.99085125e-02, 2.41263713e-02, 4.27982700e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577081e+03],\n",
      "       [2.99085124e-02, 2.41263712e-02, 4.27982710e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577083e+03],\n",
      "       [2.99085124e-02, 2.41263713e-02, 4.27982702e-02, 4.40451852e+03,\n",
      "        1.47346393e+04, 1.45226304e+04, 8.34577086e+03],\n",
      "       [2.99085123e-02, 2.41263713e-02, 4.27982702e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577086e+03]]), array([90495.8006795 , 90495.80067955, 90495.80067955, 90495.8006796 ,\n",
      "       90495.80067963, 90495.80067969, 90495.80067975, 90495.80067979]))\n",
      "           fun: 90495.80067950126\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1186\n",
      "           nit: 463\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.99085125e-02, 2.41263715e-02, 4.27982693e-02, 4.40451852e+03,\n",
      "       1.47346392e+04, 1.45226304e+04, 8.34577086e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90864.35112277341, bestParams: [0.018510455, 0.058447286, 0.035942793, 6684.6064, 20323.559, 21613.281, 5399.623]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.43113091e-02, 2.92079757e-02, 4.39142700e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673893e+03],\n",
      "       [2.43113090e-02, 2.92079759e-02, 4.39142701e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03],\n",
      "       [2.43113090e-02, 2.92079760e-02, 4.39142702e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673896e+03],\n",
      "       [2.43113090e-02, 2.92079757e-02, 4.39142702e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905713e+04, 9.04673895e+03],\n",
      "       [2.43113090e-02, 2.92079757e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673892e+03],\n",
      "       [2.43113090e-02, 2.92079756e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03],\n",
      "       [2.43113090e-02, 2.92079758e-02, 4.39142706e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905711e+04, 9.04673894e+03],\n",
      "       [2.43113091e-02, 2.92079753e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03]]), array([90498.99775909, 90498.99775912, 90498.99775917, 90498.99775926,\n",
      "       90498.99775931, 90498.99775936, 90498.9977594 , 90498.99775941]))\n",
      "           fun: 90498.99775908835\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1218\n",
      "           nit: 417\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.43113091e-02, 2.92079757e-02, 4.39142700e-02, 4.97417025e+03,\n",
      "       1.72363324e+04, 1.66905712e+04, 9.04673893e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90989.41744427223, bestParams: [0.030847164, 0.029215563, 0.034289706, 2947.6792, 13085.451, 7149.294, 2870.779]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.08771419e-02, 3.15990099e-02, 4.33952910e-02, 2.10684217e+03,\n",
      "        6.80498898e+03, 6.67304328e+03, 4.34566725e+03],\n",
      "       [3.08771419e-02, 3.15990095e-02, 4.33952911e-02, 2.10684218e+03,\n",
      "        6.80498898e+03, 6.67304328e+03, 4.34566732e+03],\n",
      "       [3.08771415e-02, 3.15990100e-02, 4.33952912e-02, 2.10684217e+03,\n",
      "        6.80498897e+03, 6.67304334e+03, 4.34566724e+03],\n",
      "       [3.08771414e-02, 3.15990099e-02, 4.33952914e-02, 2.10684218e+03,\n",
      "        6.80498901e+03, 6.67304327e+03, 4.34566729e+03],\n",
      "       [3.08771412e-02, 3.15990097e-02, 4.33952913e-02, 2.10684219e+03,\n",
      "        6.80498900e+03, 6.67304332e+03, 4.34566733e+03],\n",
      "       [3.08771411e-02, 3.15990098e-02, 4.33952915e-02, 2.10684219e+03,\n",
      "        6.80498896e+03, 6.67304328e+03, 4.34566735e+03],\n",
      "       [3.08771410e-02, 3.15990097e-02, 4.33952914e-02, 2.10684220e+03,\n",
      "        6.80498899e+03, 6.67304331e+03, 4.34566735e+03],\n",
      "       [3.08771408e-02, 3.15990100e-02, 4.33952916e-02, 2.10684219e+03,\n",
      "        6.80498897e+03, 6.67304330e+03, 4.34566733e+03]]), array([90484.77045382, 90484.77045403, 90484.77045422, 90484.77045436,\n",
      "       90484.77045459, 90484.77045473, 90484.77045477, 90484.77045493]))\n",
      "           fun: 90484.7704538244\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1185\n",
      "           nit: 456\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.08771419e-02, 3.15990099e-02, 4.33952910e-02, 2.10684217e+03,\n",
      "       6.80498898e+03, 6.67304328e+03, 4.34566725e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90880.97895039347, bestParams: [0.024393914, 0.062279228, 0.049727906, 4949.1357, 22385.908, 15643.343, 17572.701]\n",
      "epoch 6\n",
      " final_simplex: (array([[3.06168610e-02, 4.95983339e-02, 4.25957054e-02, 6.09077079e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168609e-02, 4.95983338e-02, 4.25957054e-02, 6.09077077e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168610e-02, 4.95983339e-02, 4.25957053e-02, 6.09077077e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168608e-02, 4.95983342e-02, 4.25957057e-02, 6.09077079e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168608e-02, 4.95983345e-02, 4.25957059e-02, 6.09077080e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168606e-02, 4.95983349e-02, 4.25957058e-02, 6.09077083e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168607e-02, 4.95983349e-02, 4.25957063e-02, 6.09077083e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168606e-02, 4.95983351e-02, 4.25957061e-02, 6.09077086e+03,\n",
      "        1.90729034e+04, 1.73021239e+04, 1.45279573e+04]]), array([90486.75336569, 90486.75336575, 90486.75336577, 90486.75336609,\n",
      "       90486.75336629, 90486.75336661, 90486.75336662, 90486.75336664]))\n",
      "           fun: 90486.75336568736\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1230\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.06168610e-02, 4.95983339e-02, 4.25957054e-02, 6.09077079e+03,\n",
      "       1.90729035e+04, 1.73021239e+04, 1.45279573e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 91497.65906267175, bestParams: [0.054666173, 0.09095881, 0.06649772, 5459.7817, 5106.5513, 5879.891, 11712.161]\n",
      "epoch 7\n",
      " final_simplex: (array([[4.30860784e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "        9.78249630e+03, 9.13774297e+03, 7.77570167e+03],\n",
      "       [4.30860784e-02, 4.05039918e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249625e+03, 9.13774294e+03, 7.77570159e+03],\n",
      "       [4.30860785e-02, 4.05039917e-02, 4.19283439e-02, 3.17918518e+03,\n",
      "        9.78249632e+03, 9.13774297e+03, 7.77570168e+03],\n",
      "       [4.30860788e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "        9.78249631e+03, 9.13774300e+03, 7.77570166e+03],\n",
      "       [4.30860793e-02, 4.05039921e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249629e+03, 9.13774301e+03, 7.77570167e+03],\n",
      "       [4.30860797e-02, 4.05039928e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249627e+03, 9.13774295e+03, 7.77570175e+03],\n",
      "       [4.30860799e-02, 4.05039931e-02, 4.19283442e-02, 3.17918518e+03,\n",
      "        9.78249625e+03, 9.13774295e+03, 7.77570174e+03],\n",
      "       [4.30860800e-02, 4.05039930e-02, 4.19283442e-02, 3.17918518e+03,\n",
      "        9.78249624e+03, 9.13774295e+03, 7.77570174e+03]]), array([90480.57137342, 90480.57137345, 90480.57137348, 90480.57137366,\n",
      "       90480.57137391, 90480.571374  , 90480.57137409, 90480.57137411]))\n",
      "           fun: 90480.57137341992\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1357\n",
      "           nit: 569\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.30860784e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "       9.78249630e+03, 9.13774297e+03, 7.77570167e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90748.30062683142, bestParams: [0.07419606, 0.039394133, 0.028832112, 6168.2896, 21175.932, 24372.55, 6964.5005]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.83425215e-02, 3.05141356e-02, 4.41328425e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425210e-02, 3.05141358e-02, 4.41328427e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425213e-02, 3.05141355e-02, 4.41328426e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425204e-02, 3.05141360e-02, 4.41328427e-02, 6.29920487e+03,\n",
      "        2.23644696e+04, 2.12074130e+04, 1.02575861e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644696e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425206e-02, 3.05141358e-02, 4.41328426e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575861e+04]]), array([90499.4328383 , 90499.43283833, 90499.43283834, 90499.4328384 ,\n",
      "       90499.43283843, 90499.43283848, 90499.43283849, 90499.43283851]))\n",
      "           fun: 90499.43283829854\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1204\n",
      "           nit: 459\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.83425215e-02, 3.05141356e-02, 4.41328425e-02, 6.29920489e+03,\n",
      "       2.23644697e+04, 2.12074130e+04, 1.02575860e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 91296.27290015653, bestParams: [0.11290184, 0.13054714, 0.1386694, 5181.501, 8365.07, 8362.464, 14073.521]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.02097583e-02, 1.10225090e-01, 5.28885652e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097588e-02, 1.10225090e-01, 5.28885651e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097587e-02, 1.10225090e-01, 5.28885651e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097504e-02, 1.10225090e-01, 5.28885671e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099462e+04],\n",
      "       [9.02097550e-02, 1.10225090e-01, 5.28885660e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097555e-02, 1.10225090e-01, 5.28885659e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097559e-02, 1.10225090e-01, 5.28885658e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097561e-02, 1.10225090e-01, 5.28885658e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04]]), array([90626.40935142, 90626.40935145, 90626.40935145, 90626.40935773,\n",
      "       90626.40935794, 90626.40935797, 90626.40935799, 90626.40935799]))\n",
      "           fun: 90626.40935142341\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2984\n",
      "           nit: 1336\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.02097583e-02, 1.10225090e-01, 5.28885652e-02, 5.25880194e+03,\n",
      "       1.01009865e+04, 1.00144483e+04, 1.76099461e+04])\n",
      "minPrevious 90476.89262346049\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0397, 0.0384, 0.0402], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8799, 0.0645, 0.0279, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8632, 0.0797, 0.0259, 0.0312], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8797, 0.0279, 0.0630, 0.0252], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8646, 0.0259, 0.0782, 0.0313], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7380, 0.0977, 0.0978, 0.0611], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7017, 0.1143, 0.1130, 0.0710], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7900, 4.1484, 4.0321],\n",
      "        [3.0761, 4.3315, 6.6560],\n",
      "        [2.8822, 3.3881, 5.3680],\n",
      "        ...,\n",
      "        [2.3470, 2.6197, 4.9254],\n",
      "        [1.9785, 2.4099, 3.6386],\n",
      "        [2.8596, 1.1003, 4.5087]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.632166147232056\n",
      "Run: 0, 2\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[38.,  5.,  3.,  2.],\n",
      "        [46.,  6.,  0.,  4.],\n",
      "        [42.,  5.,  3.,  4.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [53.,  2.,  3.,  2.],\n",
      "        [47.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([48., 56., 54.,  ..., 70., 60., 50.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 6., 5.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 3.,  ..., 2., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 4., 4.,  ..., 2., 2., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[38.,  5.,  3.,  2.],\n",
      "        [46.,  6.,  0.,  4.],\n",
      "        [42.,  5.,  3.,  4.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [53.,  2.,  3.,  2.],\n",
      "        [47.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([5.5336e-05, 2.3030e-06, 3.0288e-06,  ..., 5.4883e-03, 4.3785e-03,\n",
      "        3.9273e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3eb90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90729.31401045548, bestParams: [0.04714876, 0.012392071, 0.053447075, 7013.6914, 12085.93, 22692.54, 17837.424]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.33117250e-02, 2.04074664e-02, 4.59170420e-02, 5.82361142e+03,\n",
      "        1.80858056e+04, 2.06137097e+04, 9.83484979e+03],\n",
      "       [3.33117247e-02, 2.04074666e-02, 4.59170423e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484977e+03],\n",
      "       [3.33117250e-02, 2.04074665e-02, 4.59170422e-02, 5.82361140e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484981e+03],\n",
      "       [3.33117246e-02, 2.04074667e-02, 4.59170427e-02, 5.82361135e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484984e+03],\n",
      "       [3.33117235e-02, 2.04074668e-02, 4.59170428e-02, 5.82361134e+03,\n",
      "        1.80858056e+04, 2.06137097e+04, 9.83484973e+03],\n",
      "       [3.33117244e-02, 2.04074666e-02, 4.59170425e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484982e+03],\n",
      "       [3.33117253e-02, 2.04074665e-02, 4.59170425e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484977e+03],\n",
      "       [3.33117247e-02, 2.04074666e-02, 4.59170427e-02, 5.82361137e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484979e+03]]), array([90493.42080322, 90493.42080323, 90493.42080334, 90493.42080338,\n",
      "       90493.4208034 , 90493.42080347, 90493.42080347, 90493.42080351]))\n",
      "           fun: 90493.42080322158\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1276\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.33117250e-02, 2.04074664e-02, 4.59170420e-02, 5.82361142e+03,\n",
      "       1.80858056e+04, 2.06137097e+04, 9.83484979e+03])\n",
      "best ll: 90732.75782383714, bestParams: [0.026286537, 0.090551235, 0.06254556, 6272.722, 16600.713, 17853.037, 18413.832]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379185e-02, 3.65881725e-02, 4.13337161e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379184e-02, 3.65881725e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379192e-02, 3.65881712e-02, 4.13337149e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379215e-02, 3.65881670e-02, 4.13337104e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379220e-02, 3.65881662e-02, 4.13337095e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04]]), array([90476.45793291, 90476.45793291, 90476.45793292, 90476.45793292,\n",
      "       90476.45793305, 90476.45793305, 90476.45793305, 90476.45793306]))\n",
      "           fun: 90476.45793290669\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2009\n",
      "           nit: 867\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "       2.20264360e+04, 2.27778555e+04, 1.56540855e+04])\n",
      "minPrevious 90493.42080322158\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379185e-02, 3.65881725e-02, 4.13337161e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379184e-02, 3.65881725e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379192e-02, 3.65881712e-02, 4.13337149e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379215e-02, 3.65881670e-02, 4.13337104e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379220e-02, 3.65881662e-02, 4.13337095e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04]]), array([90476.45793291, 90476.45793291, 90476.45793292, 90476.45793292,\n",
      "       90476.45793305, 90476.45793305, 90476.45793305, 90476.45793306]))\n",
      "           fun: 90476.45793290669\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2009\n",
      "           nit: 867\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "       2.20264360e+04, 2.27778555e+04, 1.56540855e+04])\n",
      "best ll: 90768.5476276376, bestParams: [0.035219885, 0.09352289, 0.08136546, 7144.487, 12225.303, 11796.263, 16765.65]\n",
      "epoch 2\n",
      " final_simplex: (array([[4.65238400e-02, 6.44146076e-02, 4.12197981e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146078e-02, 4.12197982e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146078e-02, 4.12197982e-02, 5.96552759e+03,\n",
      "        1.68314529e+04, 1.52391460e+04, 1.52451012e+04],\n",
      "       [4.65238401e-02, 6.44146081e-02, 4.12197979e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238401e-02, 6.44146082e-02, 4.12197980e-02, 5.96552759e+03,\n",
      "        1.68314529e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146084e-02, 4.12197976e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451012e+04],\n",
      "       [4.65238401e-02, 6.44146083e-02, 4.12197978e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146084e-02, 4.12197976e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451012e+04]]), array([90515.26528606, 90515.26528614, 90515.26528617, 90515.26528672,\n",
      "       90515.26528676, 90515.26528692, 90515.26528698, 90515.26528702]))\n",
      "           fun: 90515.26528606444\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1692\n",
      "           nit: 718\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.65238400e-02, 6.44146076e-02, 4.12197981e-02, 5.96552759e+03,\n",
      "       1.68314530e+04, 1.52391460e+04, 1.52451011e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 91066.53966861677, bestParams: [0.074466266, 0.08731467, 0.05386589, 5332.576, 21387.4, 14033.31, 14331.92]\n",
      "epoch 3\n",
      " final_simplex: (array([[6.01747648e-02, 4.74827058e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747647e-02, 4.74827060e-02, 4.25113519e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747646e-02, 4.74827057e-02, 4.25113525e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267154e+04],\n",
      "       [6.01747648e-02, 4.74827057e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747647e-02, 4.74827060e-02, 4.25113524e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267154e+04],\n",
      "       [6.01747649e-02, 4.74827058e-02, 4.25113522e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747649e-02, 4.74827055e-02, 4.25113523e-02, 6.63523070e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267156e+04],\n",
      "       [6.01747651e-02, 4.74827060e-02, 4.25113520e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04]]), array([90504.39416636, 90504.39416637, 90504.39416639, 90504.3941664 ,\n",
      "       90504.39416647, 90504.39416659, 90504.39416662, 90504.39416662]))\n",
      "           fun: 90504.39416636349\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1256\n",
      "           nit: 502\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.01747648e-02, 4.74827058e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "       1.67311435e+04, 1.85195322e+04, 1.85267155e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90970.57307666962, bestParams: [0.0472617, 0.06842829, 0.05356198, 8647.348, 17162.938, 13426.564, 15939.611]\n",
      "epoch 4\n",
      " final_simplex: (array([[4.82379986e-02, 6.64176122e-02, 5.29707453e-02, 6.53249533e+03,\n",
      "        1.67371434e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379985e-02, 6.64176126e-02, 5.29707455e-02, 6.53249532e+03,\n",
      "        1.67371435e+04, 1.62008374e+04, 1.69415655e+04],\n",
      "       [4.82379985e-02, 6.64176125e-02, 5.29707455e-02, 6.53249531e+03,\n",
      "        1.67371435e+04, 1.62008374e+04, 1.69415655e+04],\n",
      "       [4.82379987e-02, 6.64176129e-02, 5.29707456e-02, 6.53249531e+03,\n",
      "        1.67371434e+04, 1.62008374e+04, 1.69415654e+04],\n",
      "       [4.82379989e-02, 6.64176128e-02, 5.29707456e-02, 6.53249531e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379995e-02, 6.64176129e-02, 5.29707460e-02, 6.53249531e+03,\n",
      "        1.67371434e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379992e-02, 6.64176132e-02, 5.29707460e-02, 6.53249530e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415654e+04],\n",
      "       [4.82379995e-02, 6.64176132e-02, 5.29707461e-02, 6.53249529e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415655e+04]]), array([90529.94631074, 90529.94631171, 90529.94631177, 90529.94631258,\n",
      "       90529.9463127 , 90529.94631417, 90529.94631475, 90529.94631492]))\n",
      "           fun: 90529.94631074075\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1416\n",
      "           nit: 580\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.82379986e-02, 6.64176122e-02, 5.29707453e-02, 6.53249533e+03,\n",
      "       1.67371434e+04, 1.62008373e+04, 1.69415655e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90676.96857508212, bestParams: [0.019758662, 0.040811747, 0.07994546, 5986.399, 18685.148, 19524.918, 7057.7544]\n",
      "epoch 5\n",
      " final_simplex: (array([[2.16419345e-02, 3.82889994e-02, 4.21537846e-02, 5.67924004e+03,\n",
      "        1.92461813e+04, 1.89292301e+04, 9.56055409e+03],\n",
      "       [2.16419346e-02, 3.82889993e-02, 4.21537843e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292300e+04, 9.56055415e+03],\n",
      "       [2.16419345e-02, 3.82889994e-02, 4.21537847e-02, 5.67924006e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055411e+03],\n",
      "       [2.16419346e-02, 3.82889994e-02, 4.21537843e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055413e+03],\n",
      "       [2.16419346e-02, 3.82889995e-02, 4.21537839e-02, 5.67924004e+03,\n",
      "        1.92461813e+04, 1.89292300e+04, 9.56055416e+03],\n",
      "       [2.16419345e-02, 3.82889994e-02, 4.21537847e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055411e+03],\n",
      "       [2.16419346e-02, 3.82889994e-02, 4.21537842e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055413e+03],\n",
      "       [2.16419345e-02, 3.82889995e-02, 4.21537854e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292302e+04, 9.56055403e+03]]), array([90489.89028648, 90489.89028649, 90489.8902865 , 90489.89028651,\n",
      "       90489.89028664, 90489.89029371, 90489.89029371, 90489.89029372]))\n",
      "           fun: 90489.89028647794\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1144\n",
      "           nit: 370\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.16419345e-02, 3.82889994e-02, 4.21537846e-02, 5.67924004e+03,\n",
      "       1.92461813e+04, 1.89292301e+04, 9.56055409e+03])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90614.04184293446, bestParams: [0.045280494, 0.037793145, 0.059227735, 7774.5674, 18537.154, 16869.389, 16223.571]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.63254603e-02, 4.03578762e-02, 4.26819493e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254605e-02, 4.03578763e-02, 4.26819491e-02, 6.80712184e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04],\n",
      "       [4.63254611e-02, 4.03578752e-02, 4.26819506e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254615e-02, 4.03578750e-02, 4.26819507e-02, 6.80712185e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254623e-02, 4.03578738e-02, 4.26819521e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254625e-02, 4.03578735e-02, 4.26819527e-02, 6.80712185e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04],\n",
      "       [4.63254627e-02, 4.03578731e-02, 4.26819533e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254631e-02, 4.03578727e-02, 4.26819538e-02, 6.80712185e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04]]), array([90481.01067873, 90481.01067887, 90481.01067918, 90481.01067943,\n",
      "       90481.01067984, 90481.01068004, 90481.01068014, 90481.01068039]))\n",
      "           fun: 90481.0106787277\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1407\n",
      "           nit: 591\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.63254603e-02, 4.03578762e-02, 4.26819493e-02, 6.80712183e+03,\n",
      "       1.93045360e+04, 2.10435576e+04, 1.53310997e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 91118.26744689574, bestParams: [0.16203003, 0.019491551, 0.10167087, 9075.078, 17631.64, 23901.205, 12888.103]\n",
      "epoch 7\n",
      " final_simplex: (array([[5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136007e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136009e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136009e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136010e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136010e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04]]), array([90512.80037146, 90512.80037147, 90512.80037148, 90512.80037158,\n",
      "       90512.80037168, 90512.80037168, 90512.8003717 , 90512.80037172]))\n",
      "           fun: 90512.80037145794\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2992\n",
      "           nit: 1354\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "       2.06886979e+04, 2.46288633e+04, 2.07469199e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90838.88955760052, bestParams: [0.01900933, 0.062275536, 0.047462903, 11755.048, 22521.502, 21961.916, 23298.01]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299854e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299854e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219301e-02, 5.02727421e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727421e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04],\n",
      "       [2.01924312e-02, 6.12219301e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04]]), array([90532.29920238, 90532.29920238, 90532.2992024 , 90532.29920254,\n",
      "       90532.29920259, 90532.2992027 , 90532.2992027 , 90532.29920271]))\n",
      "           fun: 90532.2992023793\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2184\n",
      "           nit: 1013\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "       2.50541339e+04, 2.34886631e+04, 2.30431254e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90645.41395072266, bestParams: [0.03879742, 0.05967664, 0.0748788, 9502.963, 20872.686, 20331.674, 22603.602]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04],\n",
      "       [4.06434334e-02, 5.88736021e-02, 5.93604534e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04],\n",
      "       [4.06434335e-02, 5.88736021e-02, 5.93604534e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434334e-02, 5.88736020e-02, 5.93604535e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434335e-02, 5.88736020e-02, 5.93604536e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434334e-02, 5.88736019e-02, 5.93604537e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434333e-02, 5.88736020e-02, 5.93604536e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04]]), array([90534.19459469, 90534.19459469, 90534.19459501, 90534.19459519,\n",
      "       90534.1945955 , 90534.19459563, 90534.19459592, 90534.19459592]))\n",
      "           fun: 90534.1945946857\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1561\n",
      "           nit: 650\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "       2.27999522e+04, 2.37345303e+04, 2.21734048e+04])\n",
      "minPrevious 90476.45793290669\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0330, 0.0366, 0.0413], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8823, 0.0643, 0.0280, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8625, 0.0789, 0.0259, 0.0327], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8854, 0.0280, 0.0632, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8602, 0.0258, 0.0814, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7355, 0.0985, 0.0995, 0.0613], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7058, 0.1106, 0.1127, 0.0709], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4515, 3.4402, 6.3490],\n",
      "        [3.4732, 3.5567, 6.1192],\n",
      "        [2.5983, 1.4514, 4.2065],\n",
      "        ...,\n",
      "        [2.9968, 3.2012, 6.9698],\n",
      "        [3.0024, 3.0444, 5.9488],\n",
      "        [3.8132, 4.7613, 6.0924]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.432267189025879\n",
      "Run: 0, 3\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  0.],\n",
      "        [45.,  6.,  2.,  3.],\n",
      "        [35.,  6.,  2.,  3.],\n",
      "        ...,\n",
      "        [52.,  0.,  0.,  0.],\n",
      "        [49.,  2.,  0.,  0.],\n",
      "        [45.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "n tensor([45., 56., 46.,  ..., 52., 51., 49.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 6.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 2.,  ..., 0., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 3., 3.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  0.],\n",
      "        [45.,  6.,  2.,  3.],\n",
      "        [35.,  6.,  2.,  3.],\n",
      "        ...,\n",
      "        [52.,  0.,  0.,  0.],\n",
      "        [49.,  2.,  0.,  0.],\n",
      "        [45.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([7.8009e-02, 1.5891e-05, 2.8535e-06,  ..., 2.6907e-02, 3.3099e-02,\n",
      "        2.7306e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3e8c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90687.73814175435, bestParams: [0.020037124, 0.0016247494, 0.040445533, 5294.021, 10814.926, 12456.389, 21372.918]\n",
      "epoch 0\n",
      " final_simplex: (array([[6.23123949e-02, 6.27163447e-03, 4.18681284e-02, 1.50217719e+03,\n",
      "        4.00664783e+03, 5.09986993e+03, 3.23227687e+03],\n",
      "       [6.23123948e-02, 6.27163447e-03, 4.18681283e-02, 1.50217718e+03,\n",
      "        4.00664785e+03, 5.09986989e+03, 3.23227688e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681282e-02, 1.50217718e+03,\n",
      "        4.00664787e+03, 5.09986996e+03, 3.23227683e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681282e-02, 1.50217718e+03,\n",
      "        4.00664788e+03, 5.09986997e+03, 3.23227683e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681281e-02, 1.50217718e+03,\n",
      "        4.00664789e+03, 5.09986998e+03, 3.23227682e+03],\n",
      "       [6.23123947e-02, 6.27163449e-03, 4.18681278e-02, 1.50217718e+03,\n",
      "        4.00664791e+03, 5.09986998e+03, 3.23227682e+03],\n",
      "       [6.23123950e-02, 6.27163449e-03, 4.18681283e-02, 1.50217718e+03,\n",
      "        4.00664785e+03, 5.09986993e+03, 3.23227683e+03],\n",
      "       [6.23123948e-02, 6.27163449e-03, 4.18681280e-02, 1.50217718e+03,\n",
      "        4.00664789e+03, 5.09986997e+03, 3.23227682e+03]]), array([90272.52946674, 90272.52946678, 90272.52946686, 90272.52946687,\n",
      "       90272.52946696, 90272.52946701, 90272.52946703, 90272.52946704]))\n",
      "           fun: 90272.52946674361\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1461\n",
      "           nit: 666\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.23123949e-02, 6.27163447e-03, 4.18681284e-02, 1.50217719e+03,\n",
      "       4.00664783e+03, 5.09986993e+03, 3.23227687e+03])\n",
      "best ll: 90497.28227752695, bestParams: [0.06955907, 0.049383625, 0.019450903, 993.1664, 3395.9521, 4111.0713, 3434.7034]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "        3.48913750e+03, 3.62500697e+03, 2.81886087e+03],\n",
      "       [4.14664508e-02, 3.51992356e-02, 3.96515439e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500699e+03, 2.81886085e+03],\n",
      "       [4.14664512e-02, 3.51992344e-02, 3.96515438e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500696e+03, 2.81886087e+03],\n",
      "       [4.14664522e-02, 3.51992339e-02, 3.96515431e-02, 1.18685429e+03,\n",
      "        3.48913748e+03, 3.62500698e+03, 2.81886091e+03],\n",
      "       [4.14664516e-02, 3.51992308e-02, 3.96515449e-02, 1.18685428e+03,\n",
      "        3.48913748e+03, 3.62500705e+03, 2.81886082e+03],\n",
      "       [4.14664515e-02, 3.51992312e-02, 3.96515447e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500707e+03, 2.81886080e+03],\n",
      "       [4.14664519e-02, 3.51992301e-02, 3.96515453e-02, 1.18685429e+03,\n",
      "        3.48913751e+03, 3.62500700e+03, 2.81886079e+03],\n",
      "       [4.14664531e-02, 3.51992354e-02, 3.96515419e-02, 1.18685429e+03,\n",
      "        3.48913745e+03, 3.62500700e+03, 2.81886093e+03]]), array([90173.52423769, 90173.52423776, 90173.52423781, 90173.52423785,\n",
      "       90173.52423792, 90173.52423796, 90173.52423814, 90173.52423952]))\n",
      "           fun: 90173.52423769064\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1084\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "       3.48913750e+03, 3.62500697e+03, 2.81886087e+03])\n",
      "minPrevious 90272.52946674361\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "        3.48913750e+03, 3.62500697e+03, 2.81886087e+03],\n",
      "       [4.14664508e-02, 3.51992356e-02, 3.96515439e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500699e+03, 2.81886085e+03],\n",
      "       [4.14664512e-02, 3.51992344e-02, 3.96515438e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500696e+03, 2.81886087e+03],\n",
      "       [4.14664522e-02, 3.51992339e-02, 3.96515431e-02, 1.18685429e+03,\n",
      "        3.48913748e+03, 3.62500698e+03, 2.81886091e+03],\n",
      "       [4.14664516e-02, 3.51992308e-02, 3.96515449e-02, 1.18685428e+03,\n",
      "        3.48913748e+03, 3.62500705e+03, 2.81886082e+03],\n",
      "       [4.14664515e-02, 3.51992312e-02, 3.96515447e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500707e+03, 2.81886080e+03],\n",
      "       [4.14664519e-02, 3.51992301e-02, 3.96515453e-02, 1.18685429e+03,\n",
      "        3.48913751e+03, 3.62500700e+03, 2.81886079e+03],\n",
      "       [4.14664531e-02, 3.51992354e-02, 3.96515419e-02, 1.18685429e+03,\n",
      "        3.48913745e+03, 3.62500700e+03, 2.81886093e+03]]), array([90173.52423769, 90173.52423776, 90173.52423781, 90173.52423785,\n",
      "       90173.52423792, 90173.52423796, 90173.52423814, 90173.52423952]))\n",
      "           fun: 90173.52423769064\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1084\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "       3.48913750e+03, 3.62500697e+03, 2.81886087e+03])\n",
      "best ll: 90579.49768806256, bestParams: [0.03288942, 0.02397951, 0.07897693, 8103.033, 16135.493, 20025.127, 11541.397]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.42412644e-02, 2.66188892e-02, 4.06631400e-02, 6.36961886e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707348e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631401e-02, 6.36961884e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631400e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412646e-02, 2.66188891e-02, 4.06631403e-02, 6.36961884e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631402e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631403e-02, 6.36961883e+03,\n",
      "        1.97342763e+04, 2.11661146e+04, 1.37707349e+04],\n",
      "       [3.42412646e-02, 2.66188891e-02, 4.06631406e-02, 6.36961883e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412644e-02, 2.66188891e-02, 4.06631404e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707348e+04]]), array([90179.97233838, 90179.9723385 , 90179.97233857, 90179.97233863,\n",
      "       90179.97233866, 90179.97233875, 90179.97233881, 90179.97233886]))\n",
      "           fun: 90179.97233838026\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1185\n",
      "           nit: 451\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.42412644e-02, 2.66188892e-02, 4.06631400e-02, 6.36961886e+03,\n",
      "       1.97342764e+04, 2.11661147e+04, 1.37707348e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90290.6061973017, bestParams: [0.03196858, 0.025042191, 0.034106273, 8508.276, 24321.596, 20359.771, 22960.518]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.41951284e-02, 2.69611168e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757822e+04],\n",
      "       [3.41951285e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951284e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951286e-02, 2.69611168e-02, 3.76004125e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04]]), array([90177.91638654, 90177.91638655, 90177.91638656, 90177.91638657,\n",
      "       90177.91638659, 90177.9163866 , 90177.9163866 , 90177.91638661]))\n",
      "           fun: 90177.91638654124\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1191\n",
      "           nit: 457\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.41951284e-02, 2.69611168e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "       2.34625869e+04, 2.45893096e+04, 1.64757822e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90575.35435100387, bestParams: [0.0060032983, 0.026933348, 0.054366462, 7137.234, 10640.545, 9179.854, 21404.568]\n",
      "epoch 4\n",
      " final_simplex: (array([[8.03986655e-03, 2.82214893e-02, 4.14128756e-02, 4.25668422e+03,\n",
      "        1.54685785e+04, 1.41980696e+04, 6.95569755e+03],\n",
      "       [8.03986660e-03, 2.82214881e-02, 4.14128762e-02, 4.25668422e+03,\n",
      "        1.54685784e+04, 1.41980697e+04, 6.95569753e+03],\n",
      "       [8.03986647e-03, 2.82214902e-02, 4.14128754e-02, 4.25668422e+03,\n",
      "        1.54685786e+04, 1.41980695e+04, 6.95569755e+03],\n",
      "       [8.03986655e-03, 2.82214896e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569747e+03],\n",
      "       [8.03986653e-03, 2.82214897e-02, 4.14128750e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569756e+03],\n",
      "       [8.03986652e-03, 2.82214897e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685786e+04, 1.41980696e+04, 6.95569756e+03],\n",
      "       [8.03986652e-03, 2.82214894e-02, 4.14128750e-02, 4.25668422e+03,\n",
      "        1.54685785e+04, 1.41980696e+04, 6.95569755e+03],\n",
      "       [8.03986650e-03, 2.82214895e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569751e+03]]), array([90268.35024825, 90268.35024842, 90268.35024844, 90268.35024859,\n",
      "       90268.3502486 , 90268.3502487 , 90268.35024901, 90268.35024905]))\n",
      "           fun: 90268.35024824677\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1183\n",
      "           nit: 456\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.03986655e-03, 2.82214893e-02, 4.14128756e-02, 4.25668422e+03,\n",
      "       1.54685785e+04, 1.41980696e+04, 6.95569755e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90520.96658633223, bestParams: [0.006762284, 0.055848576, 0.053748373, 5909.411, 13514.936, 18434.523, 10014.059]\n",
      "epoch 5\n",
      " final_simplex: (array([[8.16848907e-03, 4.04653276e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848907e-03, 4.04653277e-02, 4.27240406e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848906e-03, 4.04653277e-02, 4.27240406e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751150e+04],\n",
      "       [8.16848904e-03, 4.04653280e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848902e-03, 4.04653284e-02, 4.27240407e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848900e-03, 4.04653289e-02, 4.27240411e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453744e+04, 1.08751149e+04],\n",
      "       [8.16848899e-03, 4.04653285e-02, 4.27240409e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751150e+04],\n",
      "       [8.16848898e-03, 4.04653292e-02, 4.27240411e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453744e+04, 1.08751149e+04]]), array([90267.56486031, 90267.56486033, 90267.5648605 , 90267.56486061,\n",
      "       90267.56486088, 90267.56486105, 90267.56486109, 90267.56486112]))\n",
      "           fun: 90267.56486031177\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1342\n",
      "           nit: 543\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.16848907e-03, 4.04653276e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "       1.78493877e+04, 1.54453745e+04, 1.08751149e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90581.20782424859, bestParams: [0.10886746, 0.06707341, 0.07024887, 10999.218, 23754.08, 24885.004, 19561.732]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.83275297e-02, 5.67416707e-02, 3.65272603e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573896e+04, 3.13480199e+04],\n",
      "       [4.83275299e-02, 5.67416707e-02, 3.65272602e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573896e+04, 3.13480199e+04],\n",
      "       [4.83275332e-02, 5.67416700e-02, 3.65272598e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480198e+04],\n",
      "       [4.83275290e-02, 5.67416709e-02, 3.65272605e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275295e-02, 5.67416707e-02, 3.65272600e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275297e-02, 5.67416707e-02, 3.65272600e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275298e-02, 5.67416707e-02, 3.65272599e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480200e+04],\n",
      "       [4.83275303e-02, 5.67416706e-02, 3.65272598e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04]]), array([90189.04135044, 90189.04135049, 90189.0413505 , 90189.04135052,\n",
      "       90189.04135053, 90189.04135054, 90189.04135061, 90189.04135062]))\n",
      "           fun: 90189.04135044114\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1331\n",
      "           nit: 546\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83275297e-02, 5.67416707e-02, 3.65272603e-02, 1.05765347e+04,\n",
      "       2.91787862e+04, 2.91573896e+04, 3.13480199e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90555.35314912771, bestParams: [0.075666025, 0.008240507, 0.07280902, 4451.4316, 14403.895, 18652.873, 7124.4673]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.75345528e-02, 1.18217802e-02, 4.36060567e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302072e+03],\n",
      "       [3.75345531e-02, 1.18217801e-02, 4.36060564e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302069e+03],\n",
      "       [3.75345538e-02, 1.18217800e-02, 4.36060561e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249052e+04, 8.93302064e+03],\n",
      "       [3.75345535e-02, 1.18217800e-02, 4.36060565e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249052e+04, 8.93302072e+03],\n",
      "       [3.75345529e-02, 1.18217799e-02, 4.36060556e-02, 4.78113062e+03,\n",
      "        1.46175004e+04, 1.68249053e+04, 8.93302074e+03],\n",
      "       [3.75345543e-02, 1.18217799e-02, 4.36060568e-02, 4.78113064e+03,\n",
      "        1.46175002e+04, 1.68249052e+04, 8.93302079e+03],\n",
      "       [3.75345536e-02, 1.18217798e-02, 4.36060554e-02, 4.78113063e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302072e+03],\n",
      "       [3.75345542e-02, 1.18217797e-02, 4.36060553e-02, 4.78113064e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302075e+03]]), array([90221.61895767, 90221.61895817, 90221.61895843, 90221.61895862,\n",
      "       90221.61895898, 90221.61895898, 90221.61895918, 90221.61895972]))\n",
      "           fun: 90221.61895766677\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1194\n",
      "           nit: 489\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.75345528e-02, 1.18217802e-02, 4.36060567e-02, 4.78113062e+03,\n",
      "       1.46175003e+04, 1.68249053e+04, 8.93302072e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90395.4796038286, bestParams: [0.06134892, 0.003452808, 0.03632547, 3497.0854, 10186.098, 13472.928, 3790.0637]\n",
      "epoch 8\n",
      " final_simplex: (array([[3.49284716e-02, 4.18222349e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580012e+03],\n",
      "       [3.49284732e-02, 4.18222342e-03, 4.69575910e-02, 3.10646349e+03,\n",
      "        9.64244548e+03, 1.13777085e+04, 4.91580008e+03],\n",
      "       [3.49284699e-02, 4.18222349e-03, 4.69575907e-02, 3.10646349e+03,\n",
      "        9.64244538e+03, 1.13777085e+04, 4.91580018e+03],\n",
      "       [3.49284715e-02, 4.18222344e-03, 4.69575909e-02, 3.10646349e+03,\n",
      "        9.64244541e+03, 1.13777085e+04, 4.91580014e+03],\n",
      "       [3.49284719e-02, 4.18222343e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "        9.64244541e+03, 1.13777085e+04, 4.91580014e+03],\n",
      "       [3.49284714e-02, 4.18222340e-03, 4.69575908e-02, 3.10646349e+03,\n",
      "        9.64244538e+03, 1.13777086e+04, 4.91580016e+03],\n",
      "       [3.49284753e-02, 4.18222328e-03, 4.69575913e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580006e+03],\n",
      "       [3.49284752e-02, 4.18222327e-03, 4.69575913e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580007e+03]]), array([90285.22832312, 90285.22832343, 90285.22832362, 90285.22832367,\n",
      "       90285.22832372, 90285.22832417, 90285.22832441, 90285.22832463]))\n",
      "           fun: 90285.22832312356\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 492\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.49284716e-02, 4.18222349e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "       9.64244544e+03, 1.13777085e+04, 4.91580012e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90804.47701967844, bestParams: [0.02829881, 0.04583288, 0.060337245, 3230.8723, 12052.119, 7720.8174, 1496.0844]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809893e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809893e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809891e+03, 5.06995532e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809891e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167376e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995534e+03, 3.69568086e+03]]), array([90177.73267181, 90177.73267182, 90177.73267233, 90177.73267234,\n",
      "       90177.73267234, 90177.73267235, 90177.73267237, 90177.73267239]))\n",
      "           fun: 90177.73267181247\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1430\n",
      "           nit: 545\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "       5.11809893e+03, 5.06995534e+03, 3.69568086e+03])\n",
      "minPrevious 90173.52423769064\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0415, 0.0352, 0.0397], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8723, 0.0624, 0.0276, 0.0250], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8661, 0.0763, 0.0259, 0.0318], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8843, 0.0280, 0.0639, 0.0256], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8633, 0.0259, 0.0792, 0.0316], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7430, 0.0978, 0.0982, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7028, 0.1122, 0.1146, 0.0705], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4822, 2.8212, 6.3377],\n",
      "        [4.2235, 4.4837, 6.1296],\n",
      "        [1.2765, 2.0591, 4.8962],\n",
      "        ...,\n",
      "        [4.5062, 4.2377, 5.8085],\n",
      "        [1.4207, 1.4554, 5.4347],\n",
      "        [4.4840, 3.6525, 6.3723]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.543172121047974\n",
      "Run: 0, 4\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[49., 11.,  0.,  0.],\n",
      "        [39.,  2.,  1.,  1.],\n",
      "        [35.,  3.,  1.,  4.],\n",
      "        ...,\n",
      "        [42.,  4.,  2.,  0.],\n",
      "        [43.,  0.,  1.,  4.],\n",
      "        [55.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([60., 43., 43.,  ..., 48., 48., 57.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([11.,  2.,  3.,  ...,  4.,  0.,  1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 4.,  ..., 0., 4., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[49., 11.,  0.,  0.],\n",
      "        [39.,  2.,  1.,  1.],\n",
      "        [35.,  3.,  1.,  4.],\n",
      "        ...,\n",
      "        [42.,  4.,  2.,  0.],\n",
      "        [43.,  0.,  1.,  4.],\n",
      "        [55.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([9.3661e-08, 2.4138e-02, 3.4307e-05,  ..., 4.7683e-03, 1.8925e-04,\n",
      "        5.4601e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3ed40>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91158.47332401684, bestParams: [0.014721362, 0.040411327, 0.04527418, 4070.2559, 20366.186, 16429.271, 14589.068]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.72872707e-02, 4.17161449e-02, 4.35534533e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534529e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514173e+04, 1.15286872e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534536e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514175e+04, 1.15286870e+04],\n",
      "       [1.72872708e-02, 4.17161450e-02, 4.35534534e-02, 5.36272838e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161450e-02, 4.35534530e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534535e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514175e+04, 1.15286871e+04],\n",
      "       [1.72872706e-02, 4.17161451e-02, 4.35534529e-02, 5.36272841e+03,\n",
      "        1.76994581e+04, 1.59514173e+04, 1.15286872e+04],\n",
      "       [1.72872706e-02, 4.17161446e-02, 4.35534535e-02, 5.36272842e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04]]), array([90634.76874514, 90634.76874517, 90634.7687452 , 90634.76874525,\n",
      "       90634.76874526, 90634.76874527, 90634.76874536, 90634.76874539]))\n",
      "           fun: 90634.76874513857\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1217\n",
      "           nit: 489\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.72872707e-02, 4.17161449e-02, 4.35534533e-02, 5.36272840e+03,\n",
      "       1.76994581e+04, 1.59514174e+04, 1.15286871e+04])\n",
      "best ll: 91029.49863072427, bestParams: [0.000116868476, 0.083636425, 0.05230697, 6775.021, 20220.621, 12728.145, 23588.809]\n",
      "epoch 1\n",
      " final_simplex: (array([[1.18818834e-04, 8.64093273e-02, 5.59627736e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818831e-04, 8.64093286e-02, 5.59627736e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818831e-04, 8.64093282e-02, 5.59627739e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008582e+04],\n",
      "       [1.18818830e-04, 8.64093284e-02, 5.59627741e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818829e-04, 8.64093286e-02, 5.59627741e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008582e+04],\n",
      "       [1.18818827e-04, 8.64093296e-02, 5.59627742e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818824e-04, 8.64093300e-02, 5.59627745e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008580e+04],\n",
      "       [1.18818824e-04, 8.64093304e-02, 5.59627745e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04]]), array([90829.02245938, 90829.02246006, 90829.02246008, 90829.02246026,\n",
      "       90829.02246044, 90829.02246087, 90829.02246132, 90829.02246156]))\n",
      "           fun: 90829.02245937861\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1663\n",
      "           nit: 713\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.18818834e-04, 8.64093273e-02, 5.59627736e-02, 7.16703301e+03,\n",
      "       1.82555166e+04, 1.55257759e+04, 1.81008581e+04])\n",
      "minPrevious 90634.76874513857\n",
      "best ll: 90847.93749848523, bestParams: [0.07447942, 0.020183373, 0.01751763, 5548.3296, 16806.486, 18398.387, 15708.237]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368230e+03],\n",
      "       [3.32608952e-02, 2.91607544e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786958e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598481e+04, 9.34368237e+03],\n",
      "       [3.32608968e-02, 2.91607543e-02, 3.74786956e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368236e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786957e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368233e+03],\n",
      "       [3.32608950e-02, 2.91607544e-02, 3.74786960e-02, 4.76599757e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608951e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117015e+04, 1.59598482e+04, 9.34368238e+03],\n",
      "       [3.32608951e-02, 2.91607543e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03]]), array([90610.2728004 , 90610.27280042, 90610.27280048, 90610.27280051,\n",
      "       90610.27280056, 90610.27280063, 90610.27280069, 90610.27280072]))\n",
      "           fun: 90610.27280040468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "       1.59117016e+04, 1.59598482e+04, 9.34368230e+03])\n",
      "minPrevious 90634.76874513857\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368230e+03],\n",
      "       [3.32608952e-02, 2.91607544e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786958e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598481e+04, 9.34368237e+03],\n",
      "       [3.32608968e-02, 2.91607543e-02, 3.74786956e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368236e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786957e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368233e+03],\n",
      "       [3.32608950e-02, 2.91607544e-02, 3.74786960e-02, 4.76599757e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608951e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117015e+04, 1.59598482e+04, 9.34368238e+03],\n",
      "       [3.32608951e-02, 2.91607543e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03]]), array([90610.2728004 , 90610.27280042, 90610.27280048, 90610.27280051,\n",
      "       90610.27280056, 90610.27280063, 90610.27280069, 90610.27280072]))\n",
      "           fun: 90610.27280040468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "       1.59117016e+04, 1.59598482e+04, 9.34368230e+03])\n",
      "best ll: 90890.4621477907, bestParams: [0.028222447, 0.017594956, 0.0381772, 3712.175, 18208.807, 12144.222, 4784.1777]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.32745082e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086204e+03],\n",
      "       [3.32745080e-02, 2.12040114e-02, 4.29595582e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595581e-02, 3.36413636e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086202e+03],\n",
      "       [3.32745081e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086205e+03],\n",
      "       [3.32745080e-02, 2.12040113e-02, 4.29595581e-02, 3.36413636e+03,\n",
      "        1.12159341e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595582e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086205e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595583e-02, 3.36413636e+03,\n",
      "        1.12159339e+04, 1.19742536e+04, 5.79086203e+03]]), array([90628.72181675, 90628.72181677, 90628.72181677, 90628.72181681,\n",
      "       90628.72181681, 90628.72181685, 90628.7218169 , 90628.7218169 ]))\n",
      "           fun: 90628.72181674631\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1181\n",
      "           nit: 436\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32745082e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "       1.12159340e+04, 1.19742536e+04, 5.79086204e+03])\n",
      "minPrevious 90610.27280040468\n",
      "best ll: 90804.34225338264, bestParams: [0.023374725, 0.09260894, 0.04005881, 8117.6123, 16497.006, 16204.368, 24964.37]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274795e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190240e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819772e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190242e-02, 3.86819771e-02, 6.92017778e+03,\n",
      "        2.38232316e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190238e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274795e+04],\n",
      "       [2.53037902e-02, 4.64190240e-02, 3.86819774e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472489e+04, 1.47274796e+04]]), array([90610.97812776, 90610.97812779, 90610.9781278 , 90610.9781278 ,\n",
      "       90610.97812784, 90610.97812801, 90610.97814434, 90610.97814438]))\n",
      "           fun: 90610.97812776301\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1231\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "       2.38232317e+04, 2.13472490e+04, 1.47274795e+04])\n",
      "minPrevious 90610.27280040468\n",
      "best ll: 91012.84705452244, bestParams: [0.06232762, 0.034690365, 0.038248792, 3659.6003, 12318.186, 6756.515, 8484.942]\n",
      "epoch 5\n",
      " final_simplex: (array([[4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861992e+03],\n",
      "       [4.83273467e-02, 4.23176213e-02, 4.03140866e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861993e+03],\n",
      "       [4.83273481e-02, 4.23176224e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273481e-02, 4.23176225e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273487e-02, 4.23176230e-02, 4.03140823e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862000e+03],\n",
      "       [4.83273490e-02, 4.23176232e-02, 4.03140817e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273491e-02, 4.23176233e-02, 4.03140815e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273494e-02, 4.23176235e-02, 4.03140810e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862002e+03]]), array([90604.5572683 , 90604.55726843, 90604.55726955, 90604.55726956,\n",
      "       90604.55727007, 90604.55727031, 90604.55727036, 90604.55727057]))\n",
      "           fun: 90604.5572682951\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 3106\n",
      "           nit: 1429\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "       9.51034532e+03, 9.65504541e+03, 7.93861992e+03])\n",
      "minPrevious 90610.27280040468\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861992e+03],\n",
      "       [4.83273467e-02, 4.23176213e-02, 4.03140866e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861993e+03],\n",
      "       [4.83273481e-02, 4.23176224e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273481e-02, 4.23176225e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273487e-02, 4.23176230e-02, 4.03140823e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862000e+03],\n",
      "       [4.83273490e-02, 4.23176232e-02, 4.03140817e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273491e-02, 4.23176233e-02, 4.03140815e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273494e-02, 4.23176235e-02, 4.03140810e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862002e+03]]), array([90604.5572683 , 90604.55726843, 90604.55726955, 90604.55726956,\n",
      "       90604.55727007, 90604.55727031, 90604.55727036, 90604.55727057]))\n",
      "           fun: 90604.5572682951\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 3106\n",
      "           nit: 1429\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "       9.51034532e+03, 9.65504541e+03, 7.93861992e+03])\n",
      "best ll: 90973.150105765, bestParams: [0.0043483237, 0.1723103, 0.063694075, 5563.539, 10523.814, 9726.051, 20610.318]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.48004476e-03, 1.69499920e-01, 6.10019645e-02, 5.98757017e+03,\n",
      "        1.11423656e+04, 9.44868017e+03, 1.84977817e+04],\n",
      "       [4.48004475e-03, 1.69499920e-01, 6.10019649e-02, 5.98757013e+03,\n",
      "        1.11423657e+04, 9.44868016e+03, 1.84977817e+04],\n",
      "       [4.48004478e-03, 1.69499921e-01, 6.10019649e-02, 5.98757011e+03,\n",
      "        1.11423657e+04, 9.44868014e+03, 1.84977817e+04],\n",
      "       [4.48004476e-03, 1.69499921e-01, 6.10019650e-02, 5.98757014e+03,\n",
      "        1.11423657e+04, 9.44868013e+03, 1.84977817e+04],\n",
      "       [4.48004475e-03, 1.69499922e-01, 6.10019654e-02, 5.98757014e+03,\n",
      "        1.11423656e+04, 9.44868012e+03, 1.84977818e+04],\n",
      "       [4.48004474e-03, 1.69499924e-01, 6.10019654e-02, 5.98757012e+03,\n",
      "        1.11423656e+04, 9.44868008e+03, 1.84977818e+04],\n",
      "       [4.48004471e-03, 1.69499924e-01, 6.10019651e-02, 5.98757016e+03,\n",
      "        1.11423657e+04, 9.44868010e+03, 1.84977816e+04],\n",
      "       [4.48004469e-03, 1.69499924e-01, 6.10019655e-02, 5.98757013e+03,\n",
      "        1.11423657e+04, 9.44868009e+03, 1.84977817e+04]]), array([90875.20110852, 90875.2011087 , 90875.20110879, 90875.20110889,\n",
      "       90875.20110966, 90875.20111022, 90875.2011103 , 90875.20111065]))\n",
      "           fun: 90875.20110852493\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1082\n",
      "           nit: 377\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.48004476e-03, 1.69499920e-01, 6.10019645e-02, 5.98757017e+03,\n",
      "       1.11423656e+04, 9.44868017e+03, 1.84977817e+04])\n",
      "minPrevious 90604.5572682951\n",
      "best ll: 91007.53714748367, bestParams: [0.03484704, 0.027896117, 0.062791444, 4148.296, 18361.578, 16205.281, 10942.79]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529420e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334977e+04],\n",
      "       [3.58243337e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111420e+04, 1.57094699e+04, 1.04334975e+04]]), array([90602.51359827, 90602.51359829, 90602.51359829, 90602.51359829,\n",
      "       90602.51359833, 90602.51359836, 90602.51359864, 90602.51360201]))\n",
      "           fun: 90602.51359826833\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1241\n",
      "           nit: 441\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "       1.57111421e+04, 1.57094699e+04, 1.04334976e+04])\n",
      "minPrevious 90604.5572682951\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529420e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334977e+04],\n",
      "       [3.58243337e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111420e+04, 1.57094699e+04, 1.04334975e+04]]), array([90602.51359827, 90602.51359829, 90602.51359829, 90602.51359829,\n",
      "       90602.51359833, 90602.51359836, 90602.51359864, 90602.51360201]))\n",
      "           fun: 90602.51359826833\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1241\n",
      "           nit: 441\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "       1.57111421e+04, 1.57094699e+04, 1.04334976e+04])\n",
      "best ll: 91015.41612460106, bestParams: [0.12024945, 0.09470742, 0.06604782, 6515.7124, 9441.274, 11384.588, 14921.515]\n",
      "epoch 8\n",
      " final_simplex: (array([[1.15905749e-01, 8.86839476e-02, 6.41709445e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839473e-02, 6.41709447e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839465e-02, 6.41709450e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181450e+04, 1.75717270e+04],\n",
      "       [1.15905750e-01, 8.86839466e-02, 6.41709449e-02, 5.67383150e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839466e-02, 6.41709453e-02, 5.67383149e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839466e-02, 6.41709455e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181452e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839461e-02, 6.41709455e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717270e+04],\n",
      "       [1.15905749e-01, 8.86839464e-02, 6.41709457e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04]]), array([90791.50925081, 90791.50925131, 90791.509252  , 90791.50925231,\n",
      "       90791.50925269, 90791.50925337, 90791.50925357, 90791.50925369]))\n",
      "           fun: 90791.50925081424\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1149\n",
      "           nit: 380\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.15905749e-01, 8.86839476e-02, 6.41709445e-02, 5.67383148e+03,\n",
      "       1.04222081e+04, 1.12181451e+04, 1.75717269e+04])\n",
      "minPrevious 90602.51359826833\n",
      "best ll: 91011.46463348175, bestParams: [0.06312266, 0.029164523, 0.039597854, 8029.851, 24910.959, 18420.938, 11092.687]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093559e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093560e-02, 3.06041703e-02, 4.03519653e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04]]), array([90610.3734693 , 90610.37346932, 90610.37346938, 90610.37346949,\n",
      "       90610.3734696 , 90610.37346963, 90610.37346964, 90610.37346966]))\n",
      "           fun: 90610.37346929763\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2680\n",
      "           nit: 1248\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "       2.11833428e+04, 2.21593122e+04, 1.38361985e+04])\n",
      "minPrevious 90602.51359826833\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0358, 0.0335, 0.0445], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8858, 0.0647, 0.0281, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8600, 0.0815, 0.0258, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8860, 0.0281, 0.0646, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8600, 0.0258, 0.0816, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7406, 0.0995, 0.0989, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7059, 0.1114, 0.1115, 0.0713], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.0054, 3.8620, 6.9140],\n",
      "        [2.8371, 3.1236, 4.0172],\n",
      "        [3.2060, 4.0941, 6.7157],\n",
      "        ...,\n",
      "        [2.7681, 3.9681, 4.6108],\n",
      "        [2.3565, 2.2976, 6.9109],\n",
      "        [2.9001, 2.6971, 4.8654]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.674013376235962\n",
      "Run: 0, 5\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  1.],\n",
      "        [51.,  2.,  1.,  1.],\n",
      "        [47.,  3.,  1.,  1.],\n",
      "        ...,\n",
      "        [48.,  2.,  3.,  1.],\n",
      "        [59.,  2.,  0.,  1.],\n",
      "        [63.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "n tensor([44., 55., 52.,  ..., 54., 62., 66.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 3.,  ..., 2., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 3., 0., 3.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 1., 1.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  1.],\n",
      "        [51.,  2.,  1.,  1.],\n",
      "        [47.,  3.,  1.,  1.],\n",
      "        ...,\n",
      "        [48.,  2.,  3.,  1.],\n",
      "        [59.,  2.,  0.,  1.],\n",
      "        [63.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0248, 0.0290, 0.0136,  ..., 0.0106, 0.0165, 0.0126],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad035f0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91090.3604514042, bestParams: [0.043571133, 0.095463604, 0.0505203, 5832.7603, 16079.994, 12313.426, 8391.266]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.59893537e-02, 5.64996138e-02, 4.31957835e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996138e-02, 4.31957836e-02, 5.33859644e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893539e-02, 5.64996138e-02, 4.31957834e-02, 5.33859642e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996138e-02, 4.31957836e-02, 5.33859643e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996140e-02, 4.31957838e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996140e-02, 4.31957838e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893535e-02, 5.64996143e-02, 4.31957837e-02, 5.33859643e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028398e+04],\n",
      "       [3.59893536e-02, 5.64996143e-02, 4.31957839e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028398e+04]]), array([90799.07161255, 90799.07161264, 90799.07161274, 90799.07161275,\n",
      "       90799.07161278, 90799.0716128 , 90799.07161297, 90799.07161297]))\n",
      "           fun: 90799.07161254974\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.59893537e-02, 5.64996138e-02, 4.31957835e-02, 5.33859643e+03,\n",
      "       1.57706471e+04, 1.39949641e+04, 1.36028399e+04])\n",
      "best ll: 91093.57377619602, bestParams: [0.04420233, 0.06357479, 0.03340114, 4500.3525, 14206.233, 8924.385, 19454.049]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.49744082e-02, 6.21665645e-02, 4.15310181e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744086e-02, 6.21665646e-02, 4.15310186e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128040e+04],\n",
      "       [4.49744083e-02, 6.21665648e-02, 4.15310179e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128040e+04],\n",
      "       [4.49744083e-02, 6.21665651e-02, 4.15310180e-02, 4.61027368e+03,\n",
      "        1.30328999e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744086e-02, 6.21665651e-02, 4.15310186e-02, 4.61027367e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744088e-02, 6.21665655e-02, 4.15310183e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128039e+04],\n",
      "       [4.49744091e-02, 6.21665658e-02, 4.15310189e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744092e-02, 6.21665660e-02, 4.15310189e-02, 4.61027367e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128039e+04]]), array([90804.01018453, 90804.01018466, 90804.01018486, 90804.01018504,\n",
      "       90804.01018508, 90804.01018544, 90804.01018563, 90804.0101859 ]))\n",
      "           fun: 90804.01018452992\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1264\n",
      "           nit: 490\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.49744082e-02, 6.21665645e-02, 4.15310181e-02, 4.61027368e+03,\n",
      "       1.30329000e+04, 1.18758442e+04, 1.20128039e+04])\n",
      "minPrevious 90799.07161254974\n",
      "best ll: 91258.20962960232, bestParams: [0.0017469097, 0.01823081, 0.084255494, 10602.629, 13127.086, 18705.941, 23800.89]\n",
      "epoch 2\n",
      " final_simplex: (array([[2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294313e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864185e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864181e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864183e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864184e+03],\n",
      "       [2.11020782e-03, 2.95814602e-02, 5.19149978e-02, 6.74294313e+03,\n",
      "        2.45263191e+04, 2.07048135e+04, 9.00864183e+03]]), array([90955.06447395, 90955.06447396, 90955.06447396, 90955.06447397,\n",
      "       90955.06447398, 90955.06447399, 90955.06447401, 90955.06447402]))\n",
      "           fun: 90955.06447394771\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1358\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294313e+03,\n",
      "       2.45263190e+04, 2.07048135e+04, 9.00864185e+03])\n",
      "minPrevious 90799.07161254974\n",
      "best ll: 91230.90592004443, bestParams: [0.1362636, 0.18482453, 0.031719703, 2449.1853, 4716.1143, 3088.015, 11587.606]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "        7.21950271e+03, 6.88453503e+03, 5.45878630e+03],\n",
      "       [3.67651936e-02, 4.28943901e-02, 4.23365698e-02, 2.39682393e+03,\n",
      "        7.21950274e+03, 6.88453506e+03, 5.45878628e+03],\n",
      "       [3.67651929e-02, 4.28943907e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950270e+03, 6.88453500e+03, 5.45878628e+03],\n",
      "       [3.67651926e-02, 4.28943908e-02, 4.23365705e-02, 2.39682392e+03,\n",
      "        7.21950270e+03, 6.88453498e+03, 5.45878633e+03],\n",
      "       [3.67651912e-02, 4.28943931e-02, 4.23365699e-02, 2.39682394e+03,\n",
      "        7.21950278e+03, 6.88453496e+03, 5.45878628e+03],\n",
      "       [3.67651901e-02, 4.28943919e-02, 4.23365704e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453499e+03, 5.45878620e+03],\n",
      "       [3.67651903e-02, 4.28943912e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453498e+03, 5.45878626e+03],\n",
      "       [3.67651909e-02, 4.28943884e-02, 4.23365714e-02, 2.39682393e+03,\n",
      "        7.21950273e+03, 6.88453499e+03, 5.45878636e+03]]), array([90793.71585391, 90793.71585413, 90793.71585419, 90793.71585449,\n",
      "       90793.71585464, 90793.71585486, 90793.7158549 , 90793.7158549 ]))\n",
      "           fun: 90793.71585391468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1238\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "       7.21950271e+03, 6.88453503e+03, 5.45878630e+03])\n",
      "minPrevious 90799.07161254974\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "        7.21950271e+03, 6.88453503e+03, 5.45878630e+03],\n",
      "       [3.67651936e-02, 4.28943901e-02, 4.23365698e-02, 2.39682393e+03,\n",
      "        7.21950274e+03, 6.88453506e+03, 5.45878628e+03],\n",
      "       [3.67651929e-02, 4.28943907e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950270e+03, 6.88453500e+03, 5.45878628e+03],\n",
      "       [3.67651926e-02, 4.28943908e-02, 4.23365705e-02, 2.39682392e+03,\n",
      "        7.21950270e+03, 6.88453498e+03, 5.45878633e+03],\n",
      "       [3.67651912e-02, 4.28943931e-02, 4.23365699e-02, 2.39682394e+03,\n",
      "        7.21950278e+03, 6.88453496e+03, 5.45878628e+03],\n",
      "       [3.67651901e-02, 4.28943919e-02, 4.23365704e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453499e+03, 5.45878620e+03],\n",
      "       [3.67651903e-02, 4.28943912e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453498e+03, 5.45878626e+03],\n",
      "       [3.67651909e-02, 4.28943884e-02, 4.23365714e-02, 2.39682393e+03,\n",
      "        7.21950273e+03, 6.88453499e+03, 5.45878636e+03]]), array([90793.71585391, 90793.71585413, 90793.71585419, 90793.71585449,\n",
      "       90793.71585464, 90793.71585486, 90793.7158549 , 90793.7158549 ]))\n",
      "           fun: 90793.71585391468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1238\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "       7.21950271e+03, 6.88453503e+03, 5.45878630e+03])\n",
      "best ll: 91326.84358438406, bestParams: [0.02248766, 0.032484304, 0.052385617, 8575.685, 11063.958, 10108.009, 22795.377]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.84420417e-02, 3.46959567e-02, 4.26539702e-02, 4.46333716e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539702e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930251e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539704e-02, 4.46333716e+03,\n",
      "        1.44521197e+04, 1.37119075e+04, 9.14930251e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539703e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930248e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539703e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930251e+03],\n",
      "       [2.84420416e-02, 3.46959568e-02, 4.26539705e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420416e-02, 3.46959568e-02, 4.26539705e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420418e-02, 3.46959566e-02, 4.26539705e-02, 4.46333716e+03,\n",
      "        1.44521198e+04, 1.37119075e+04, 9.14930237e+03]]), array([90801.40632214, 90801.40632216, 90801.40632217, 90801.40632218,\n",
      "       90801.40632219, 90801.40632224, 90801.40632224, 90801.40632478]))\n",
      "           fun: 90801.40632214482\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1364\n",
      "           nit: 549\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.84420417e-02, 3.46959567e-02, 4.26539702e-02, 4.46333716e+03,\n",
      "       1.44521197e+04, 1.37119076e+04, 9.14930242e+03])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91152.77248384545, bestParams: [0.029007705, 0.047266837, 0.042739347, 3103.6965, 9688.097, 14387.982, 6064.706]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.05385898e-02, 4.40237968e-02, 4.16521419e-02, 3.36519154e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03],\n",
      "       [3.05385899e-02, 4.40237969e-02, 4.16521414e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845911e+03],\n",
      "       [3.05385899e-02, 4.40237970e-02, 4.16521414e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845912e+03],\n",
      "       [3.05385898e-02, 4.40237970e-02, 4.16521415e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845910e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521424e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845895e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521419e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845903e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521421e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03],\n",
      "       [3.05385892e-02, 4.40237968e-02, 4.16521421e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03]]), array([90798.38403306, 90798.3840331 , 90798.38403313, 90798.38403316,\n",
      "       90798.38403323, 90798.38403329, 90798.3840333 , 90798.38403332]))\n",
      "           fun: 90798.38403306226\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1259\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.05385898e-02, 4.40237968e-02, 4.16521419e-02, 3.36519154e+03,\n",
      "       1.10735933e+04, 1.00880013e+04, 6.82845902e+03])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91270.70408583432, bestParams: [0.015127707, 0.041919302, 0.03150278, 4334.455, 22769.922, 24498.379, 190.21886]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.75785932e-02, 1.95895246e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895245e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233751e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895247e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895246e-02, 4.58603911e-02, 5.09205005e+03,\n",
      "        2.27880383e+04, 2.20233750e+04, 2.36272117e+02],\n",
      "       [1.75785931e-02, 1.95895251e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895251e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895247e-02, 4.58603912e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895250e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02]]), array([90949.33571342, 90949.33571344, 90949.33571346, 90949.33571348,\n",
      "       90949.33571358, 90949.3357136 , 90949.3357136 , 90949.33571367]))\n",
      "           fun: 90949.33571342296\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1312\n",
      "           nit: 515\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.75785932e-02, 1.95895246e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "       2.27880384e+04, 2.20233750e+04, 2.36272116e+02])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91344.40237445639, bestParams: [0.03907052, 0.037808415, 0.034087338, 9922.918, 22659.93, 13472.755, 21920.426]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.74444807e-02, 4.19909125e-02, 4.05683430e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04],\n",
      "       [3.74444808e-02, 4.19909125e-02, 4.05683430e-02, 6.81299451e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909126e-02, 4.05683430e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444807e-02, 4.19909125e-02, 4.05683429e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04],\n",
      "       [3.74444808e-02, 4.19909127e-02, 4.05683430e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909127e-02, 4.05683429e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909126e-02, 4.05683429e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444807e-02, 4.19909125e-02, 4.05683428e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04]]), array([90794.23716006, 90794.23716007, 90794.23716007, 90794.23716008,\n",
      "       90794.23716009, 90794.23716009, 90794.2371601 , 90794.23716011]))\n",
      "           fun: 90794.2371600552\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1301\n",
      "           nit: 543\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.74444807e-02, 4.19909125e-02, 4.05683430e-02, 6.81299449e+03,\n",
      "       2.13149873e+04, 2.03928135e+04, 1.47412558e+04])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91361.03540276109, bestParams: [0.045425393, 0.07026239, 0.050605606, 5734.493, 18005.092, 5601.4487, 22472.11]\n",
      "epoch 8\n",
      " final_simplex: (array([[5.31215249e-02, 7.05228155e-02, 4.47838949e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215248e-02, 7.05228156e-02, 4.47838951e-02, 4.51425556e+03,\n",
      "        1.17898264e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228154e-02, 4.47838952e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215251e-02, 7.05228153e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228152e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215250e-02, 7.05228154e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898264e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215251e-02, 7.05228155e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228155e-02, 4.47838958e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939907e+04]]), array([90817.22476695, 90817.22476704, 90817.22476722, 90817.22476724,\n",
      "       90817.22476725, 90817.22476726, 90817.22476734, 90817.22476763]))\n",
      "           fun: 90817.22476694567\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1196\n",
      "           nit: 465\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.31215249e-02, 7.05228155e-02, 4.47838949e-02, 4.51425556e+03,\n",
      "       1.17898265e+04, 1.08016156e+04, 1.24939908e+04])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91309.75771624263, bestParams: [0.02029038, 0.014870982, 0.010115627, 4392.174, 19204.947, 19952.209, 9782.406]\n",
      "epoch 9\n",
      " final_simplex: (array([[2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587151e+02,\n",
      "        8.13689375e+02, 7.66991520e+02, 4.17404243e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689369e+02, 7.66991516e+02, 4.17404245e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689365e+02, 7.66991513e+02, 4.17404247e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689378e+02, 7.66991522e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587148e+02,\n",
      "        8.13689380e+02, 7.66991520e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587147e+02,\n",
      "        8.13689364e+02, 7.66991510e+02, 4.17404239e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587146e+02,\n",
      "        8.13689362e+02, 7.66991506e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587146e+02,\n",
      "        8.13689362e+02, 7.66991507e+02, 4.17404237e+02]]), array([90811.60778462, 90811.60778465, 90811.60778467, 90811.60778474,\n",
      "       90811.60778501, 90811.60778518, 90811.60778533, 90811.60778536]))\n",
      "           fun: 90811.60778462133\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1301\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587151e+02,\n",
      "       8.13689375e+02, 7.66991520e+02, 4.17404243e+02])\n",
      "minPrevious 90793.71585391468\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0368, 0.0429, 0.0423], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8815, 0.0637, 0.0279, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8660, 0.0782, 0.0259, 0.0299], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8880, 0.0282, 0.0649, 0.0260], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8691, 0.0260, 0.0749, 0.0299], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7411, 0.0987, 0.0971, 0.0616], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7086, 0.1125, 0.1095, 0.0694], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9130, 3.9638, 4.5806],\n",
      "        [4.8477, 3.1204, 4.6859],\n",
      "        [2.5043, 3.4648, 5.4998],\n",
      "        ...,\n",
      "        [2.2138, 3.9310, 6.0372],\n",
      "        [3.0004, 1.5042, 4.5456],\n",
      "        [3.2652, 3.3443, 5.2215]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.484266996383667\n",
      "Run: 0, 6\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[51.,  4.,  1.,  2.],\n",
      "        [40.,  2.,  0.,  0.],\n",
      "        [55.,  3.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  1.,  2.,  1.],\n",
      "        [59.,  0.,  4.,  0.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([58., 42., 61.,  ..., 52., 63., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 2., 3.,  ..., 1., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 0., 2.,  ..., 2., 4., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 1.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[51.,  4.,  1.,  2.],\n",
      "        [40.,  2.,  0.,  0.],\n",
      "        [55.,  3.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  1.,  2.,  1.],\n",
      "        [59.,  0.,  4.,  0.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0020, 0.0418, 0.0140,  ..., 0.0283, 0.0060, 0.0503],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad03950>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90705.78630343798, bestParams: [0.042797178, 0.03189743, 0.0427665, 7865.0444, 19529.307, 18785.924, 20957.984]\n",
      "epoch 0\n",
      " final_simplex: (array([[4.53094590e-02, 3.29430425e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289733e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675401e-02, 7.16461646e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718439e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718441e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04]]), array([90617.68016446, 90617.68016449, 90617.68016451, 90617.68016452,\n",
      "       90617.68016454, 90617.68016455, 90617.68016455, 90617.68016455]))\n",
      "           fun: 90617.68016446201\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1139\n",
      "           nit: 416\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.53094590e-02, 3.29430425e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "       2.07289734e+04, 2.24192353e+04, 1.77718440e+04])\n",
      "best ll: 91238.05435765057, bestParams: [0.05948744, 0.04102097, 0.013038766, 4660.9634, 18500.773, 21041.572, 23418.262]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.42696088e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799659e+03],\n",
      "       [3.42696092e-02, 3.41024516e-02, 3.87974592e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799652e+03],\n",
      "       [3.42696087e-02, 3.41024514e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799661e+03],\n",
      "       [3.42696086e-02, 3.41024513e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799663e+03],\n",
      "       [3.42696086e-02, 3.41024513e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799663e+03],\n",
      "       [3.42696085e-02, 3.41024512e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799664e+03],\n",
      "       [3.42696089e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799657e+03],\n",
      "       [3.42696082e-02, 3.41024511e-02, 3.87974589e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799669e+03]]), array([90618.91761162, 90618.91761169, 90618.91761169, 90618.91761183,\n",
      "       90618.91761185, 90618.91761194, 90618.91761205, 90618.91761219]))\n",
      "           fun: 90618.91761162136\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1909\n",
      "           nit: 848\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.42696088e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "       1.46360708e+04, 1.49596490e+04, 9.92799659e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90799.13652237343, bestParams: [0.08314967, 0.07155339, 0.06358579, 7604.4014, 13512.055, 14740.179, 23051.545]\n",
      "epoch 2\n",
      " final_simplex: (array([[8.04633027e-02, 7.18090937e-02, 5.02449341e-02, 7.23852176e+03,\n",
      "        1.58024603e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633030e-02, 7.18090935e-02, 5.02449344e-02, 7.23852175e+03,\n",
      "        1.58024603e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633039e-02, 7.18090933e-02, 5.02449343e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286440e+04],\n",
      "       [8.04633037e-02, 7.18090932e-02, 5.02449345e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286440e+04],\n",
      "       [8.04633047e-02, 7.18090929e-02, 5.02449349e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633055e-02, 7.18090926e-02, 5.02449354e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633062e-02, 7.18090923e-02, 5.02449354e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840773e+04, 2.23286441e+04],\n",
      "       [8.04633062e-02, 7.18090921e-02, 5.02449357e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04]]), array([90698.9332218 , 90698.93322237, 90698.93322263, 90698.93322275,\n",
      "       90698.933224  , 90698.93322516, 90698.93322544, 90698.93322595]))\n",
      "           fun: 90698.93322179955\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1389\n",
      "           nit: 554\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.04633027e-02, 7.18090937e-02, 5.02449341e-02, 7.23852176e+03,\n",
      "       1.58024603e+04, 1.67840772e+04, 2.23286441e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91004.02822016623, bestParams: [0.16847368, 0.006867244, 0.057000216, 9718.201, 20643.424, 24615.924, 21438.463]\n",
      "epoch 3\n",
      " final_simplex: (array([[1.02033897e-01, 7.74125429e-03, 5.54624499e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125427e-03, 5.54624498e-02, 9.58666804e+03,\n",
      "        1.95816961e+04, 2.80791649e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033898e-01, 7.74125426e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624499e-02, 9.58666804e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624498e-02, 9.58666805e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624498e-02, 9.58666804e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04]]), array([90777.40346946, 90777.40346956, 90777.40346965, 90777.40347029,\n",
      "       90777.40348193, 90777.40348194, 90777.40348196, 90777.40348204]))\n",
      "           fun: 90777.40346946282\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1171\n",
      "           nit: 404\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.02033897e-01, 7.74125429e-03, 5.54624499e-02, 9.58666803e+03,\n",
      "       1.95816962e+04, 2.80791648e+04, 2.53911261e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91187.95797366982, bestParams: [0.025342675, 0.00792712, 0.07620231, 7194.6675, 7506.416, 14323.318, 16886.123]\n",
      "epoch 4\n",
      " final_simplex: (array([[4.70038040e-02, 1.84890042e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "        7.18730002e+03, 8.35538060e+03, 5.06572632e+03],\n",
      "       [4.70038039e-02, 1.84890042e-02, 4.10251852e-02, 2.37962911e+03,\n",
      "        7.18730004e+03, 8.35538056e+03, 5.06572636e+03],\n",
      "       [4.70038041e-02, 1.84890043e-02, 4.10251854e-02, 2.37962910e+03,\n",
      "        7.18729996e+03, 8.35538056e+03, 5.06572631e+03],\n",
      "       [4.70038043e-02, 1.84890043e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "        7.18729999e+03, 8.35538061e+03, 5.06572625e+03],\n",
      "       [4.70038041e-02, 1.84890041e-02, 4.10251853e-02, 2.37962912e+03,\n",
      "        7.18730005e+03, 8.35538060e+03, 5.06572628e+03],\n",
      "       [4.70038039e-02, 1.84890042e-02, 4.10251854e-02, 2.37962909e+03,\n",
      "        7.18730002e+03, 8.35538059e+03, 5.06572628e+03],\n",
      "       [4.70038044e-02, 1.84890041e-02, 4.10251855e-02, 2.37962911e+03,\n",
      "        7.18729996e+03, 8.35538050e+03, 5.06572636e+03],\n",
      "       [4.70038042e-02, 1.84890042e-02, 4.10251853e-02, 2.37962910e+03,\n",
      "        7.18729999e+03, 8.35538054e+03, 5.06572629e+03]]), array([90641.67199394, 90641.67199403, 90641.6719941 , 90641.67199412,\n",
      "       90641.67199429, 90641.67199461, 90641.67199472, 90641.67199474]))\n",
      "           fun: 90641.67199393519\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1292\n",
      "           nit: 503\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.70038040e-02, 1.84890042e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "       7.18730002e+03, 8.35538060e+03, 5.06572632e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90934.9975112686, bestParams: [0.059806045, 0.055613108, 0.043168016, 2348.8328, 6146.4946, 8322.338, 10317.607]\n",
      "epoch 5\n",
      " final_simplex: (array([[5.42056891e-02, 4.70911906e-02, 4.19282268e-02, 2.83251915e+03,\n",
      "        7.79437423e+03, 8.19122192e+03, 7.15410411e+03],\n",
      "       [5.42056896e-02, 4.70911906e-02, 4.19282266e-02, 2.83251915e+03,\n",
      "        7.79437421e+03, 8.19122190e+03, 7.15410413e+03],\n",
      "       [5.42056846e-02, 4.70911897e-02, 4.19282289e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122191e+03, 7.15410401e+03],\n",
      "       [5.42056853e-02, 4.70911896e-02, 4.19282286e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122192e+03, 7.15410403e+03],\n",
      "       [5.42056859e-02, 4.70911898e-02, 4.19282282e-02, 2.83251916e+03,\n",
      "        7.79437423e+03, 8.19122191e+03, 7.15410403e+03],\n",
      "       [5.42056850e-02, 4.70911905e-02, 4.19282288e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122186e+03, 7.15410404e+03],\n",
      "       [5.42056864e-02, 4.70911897e-02, 4.19282281e-02, 2.83251916e+03,\n",
      "        7.79437420e+03, 8.19122190e+03, 7.15410405e+03],\n",
      "       [5.42056863e-02, 4.70911901e-02, 4.19282281e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122190e+03, 7.15410405e+03]]), array([90626.22011514, 90626.22011537, 90626.22012032, 90626.22012065,\n",
      "       90626.22012113, 90626.22012132, 90626.22012138, 90626.22012175]))\n",
      "           fun: 90626.22011513563\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1256\n",
      "           nit: 501\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.42056891e-02, 4.70911906e-02, 4.19282268e-02, 2.83251915e+03,\n",
      "       7.79437423e+03, 8.19122192e+03, 7.15410411e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90970.36604372214, bestParams: [0.054490186, 0.02661631, 0.0485164, 5726.952, 16087.912, 22577.627, 24207.025]\n",
      "epoch 6\n",
      " final_simplex: (array([[5.10958411e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958412e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636176e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958411e-02, 3.04632786e-02, 4.19672827e-02, 7.06673511e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958418e-02, 3.04632787e-02, 4.19672826e-02, 7.06673511e+03,\n",
      "        1.98636178e+04, 2.25615731e+04, 1.60116670e+04],\n",
      "       [5.10958411e-02, 3.04632785e-02, 4.19672830e-02, 7.06673513e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116672e+04],\n",
      "       [5.10958419e-02, 3.04632787e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636176e+04, 2.25615731e+04, 1.60116671e+04],\n",
      "       [5.10958414e-02, 3.04632786e-02, 4.19672828e-02, 7.06673512e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958415e-02, 3.04632785e-02, 4.19672829e-02, 7.06673512e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04]]), array([90621.57495985, 90621.57495994, 90621.57496008, 90621.57496039,\n",
      "       90621.5749604 , 90621.57496041, 90621.57496041, 90621.57496047]))\n",
      "           fun: 90621.57495984525\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1245\n",
      "           nit: 492\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.10958411e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "       1.98636177e+04, 2.25615730e+04, 1.60116671e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90804.903153182, bestParams: [0.014491759, 0.01909757, 0.026884345, 5839.411, 24984.732, 21505.56, 5679.6772]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.54264133e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "        8.02301535e+03, 8.15135230e+03, 5.64047497e+03],\n",
      "       [3.54264126e-02, 3.62265995e-02, 4.01003738e-02, 2.57159949e+03,\n",
      "        8.02301536e+03, 8.15135231e+03, 5.64047505e+03],\n",
      "       [3.54264131e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "        8.02301538e+03, 8.15135232e+03, 5.64047498e+03],\n",
      "       [3.54264143e-02, 3.62266000e-02, 4.01003715e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047488e+03],\n",
      "       [3.54264139e-02, 3.62266001e-02, 4.01003719e-02, 2.57159949e+03,\n",
      "        8.02301538e+03, 8.15135232e+03, 5.64047489e+03],\n",
      "       [3.54264141e-02, 3.62266000e-02, 4.01003716e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047490e+03],\n",
      "       [3.54264137e-02, 3.62265999e-02, 4.01003720e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047495e+03],\n",
      "       [3.54264137e-02, 3.62266000e-02, 4.01003719e-02, 2.57159949e+03,\n",
      "        8.02301537e+03, 8.15135233e+03, 5.64047494e+03]]), array([90617.76238034, 90617.76238038, 90617.76238043, 90617.76238056,\n",
      "       90617.76238057, 90617.7623806 , 90617.76238062, 90617.7623807 ]))\n",
      "           fun: 90617.76238033785\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1396\n",
      "           nit: 595\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.54264133e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "       8.02301535e+03, 8.15135230e+03, 5.64047497e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91071.9845670912, bestParams: [0.031488296, 0.07208441, 0.074685715, 6185.3647, 13709.426, 18131.521, 23476.797]\n",
      "epoch 8\n",
      " final_simplex: (array([[4.05461957e-02, 6.34717350e-02, 4.05830887e-02, 6.92152710e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461958e-02, 6.34717351e-02, 4.05830884e-02, 6.92152710e+03,\n",
      "        1.97748038e+04, 1.88326454e+04, 1.90989072e+04],\n",
      "       [4.05461960e-02, 6.34717351e-02, 4.05830884e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989071e+04],\n",
      "       [4.05461959e-02, 6.34717351e-02, 4.05830885e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461962e-02, 6.34717354e-02, 4.05830879e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989071e+04],\n",
      "       [4.05461953e-02, 6.34717350e-02, 4.05830889e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461959e-02, 6.34717353e-02, 4.05830882e-02, 6.92152708e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461954e-02, 6.34717352e-02, 4.05830887e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326454e+04, 1.90989073e+04]]), array([90642.89946052, 90642.89946059, 90642.8994606 , 90642.89946067,\n",
      "       90642.89946078, 90642.89946086, 90642.89946098, 90642.899461  ]))\n",
      "           fun: 90642.89946051945\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1339\n",
      "           nit: 563\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05461957e-02, 6.34717350e-02, 4.05830887e-02, 6.92152710e+03,\n",
      "       1.97748038e+04, 1.88326455e+04, 1.90989072e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90978.47709523376, bestParams: [0.052268486, 0.059164874, 0.029479917, 3384.196, 9466.865, 13828.556, 13715.061]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228951e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202685e+03],\n",
      "       [4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202684e+03],\n",
      "       [4.94145725e-02, 3.66047327e-02, 4.05901828e-02, 4.08228951e+03,\n",
      "        1.18931871e+04, 1.29963842e+04, 9.45202687e+03],\n",
      "       [4.94145723e-02, 3.66047329e-02, 4.05901829e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202687e+03],\n",
      "       [4.94145725e-02, 3.66047330e-02, 4.05901828e-02, 4.08228951e+03,\n",
      "        1.18931871e+04, 1.29963842e+04, 9.45202685e+03],\n",
      "       [4.94145724e-02, 3.66047332e-02, 4.05901828e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202689e+03],\n",
      "       [4.94145725e-02, 3.66047332e-02, 4.05901829e-02, 4.08228951e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202689e+03],\n",
      "       [4.94145724e-02, 3.66047334e-02, 4.05901830e-02, 4.08228952e+03,\n",
      "        1.18931871e+04, 1.29963843e+04, 9.45202682e+03]]), array([90618.74920601, 90618.74920613, 90618.74920624, 90618.74920633,\n",
      "       90618.74920639, 90618.74920644, 90618.74920651, 90618.7492066 ]))\n",
      "           fun: 90618.74920601156\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1229\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228951e+03,\n",
      "       1.18931870e+04, 1.29963842e+04, 9.45202685e+03])\n",
      "minPrevious 90617.68016446201\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0453, 0.0329, 0.0414], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8794, 0.0631, 0.0279, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8663, 0.0752, 0.0260, 0.0325], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8795, 0.0279, 0.0647, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8611, 0.0258, 0.0808, 0.0323], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7352, 0.0984, 0.0988, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6986, 0.1126, 0.1175, 0.0713], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.1919, 3.2663, 5.4709],\n",
      "        [4.1986, 3.8897, 7.2400],\n",
      "        [3.3917, 2.4035, 5.7041],\n",
      "        ...,\n",
      "        [4.9667, 4.5339, 5.2203],\n",
      "        [3.8287, 3.7274, 4.9386],\n",
      "        [3.6731, 2.6413, 5.4393]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 17.216406106948853\n",
      "Run: 0, 7\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[57.,  3.,  2.,  0.],\n",
      "        [54.,  1.,  1.,  0.],\n",
      "        [40.,  2.,  2.,  3.],\n",
      "        ...,\n",
      "        [59.,  0.,  1.,  0.],\n",
      "        [57.,  2.,  0.,  2.],\n",
      "        [46.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([62., 56., 47.,  ..., 60., 61., 48.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 2.,  ..., 0., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 2.,  ..., 1., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 3.,  ..., 0., 2., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[57.,  3.,  2.,  0.],\n",
      "        [54.,  1.,  1.,  0.],\n",
      "        [40.,  2.,  2.,  3.],\n",
      "        ...,\n",
      "        [59.,  0.,  1.,  0.],\n",
      "        [57.,  2.,  0.,  2.],\n",
      "        [46.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0211, 0.0565, 0.0007,  ..., 0.0278, 0.0058, 0.0361],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7d8437830>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90698.00966445002, bestParams: [0.03601381, 0.05376842, 0.037697803, 4858.81, 17559.475, 15117.588, 10296.187]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695246e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397107e-02, 5.12695245e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708269e-02, 4.24062757e-02, 4.20397107e-02, 5.12695246e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498577e+04],\n",
      "       [3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695247e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498577e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397106e-02, 5.12695245e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062758e-02, 4.20397103e-02, 5.12695247e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397105e-02, 5.12695248e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062755e-02, 4.20397105e-02, 5.12695246e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04]]), array([90642.85781501, 90642.85781503, 90642.85781505, 90642.85781506,\n",
      "       90642.85781507, 90642.8578153 , 90642.85781912, 90642.85781919]))\n",
      "           fun: 90642.85781500832\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 451\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695246e+03,\n",
      "       1.55116198e+04, 1.47037155e+04, 1.20498578e+04])\n",
      "best ll: 90989.10931874896, bestParams: [0.055018455, 0.058657233, 0.013274319, 6479.689, 24181.266, 18899.627, 20080.443]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.85959234e-02, 2.70830341e-02, 3.75888685e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959248e-02, 2.70830345e-02, 3.75888666e-02, 5.60836646e+03,\n",
      "        1.79338975e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959256e-02, 2.70830349e-02, 3.75888652e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959263e-02, 2.70830352e-02, 3.75888641e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154940e+04],\n",
      "       [3.85959273e-02, 2.70830354e-02, 3.75888626e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959274e-02, 2.70830356e-02, 3.75888624e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959275e-02, 2.70830356e-02, 3.75888623e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959273e-02, 2.70830360e-02, 3.75888620e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154940e+04]]), array([90650.21241961, 90650.21242353, 90650.21242637, 90650.21242847,\n",
      "       90650.21243156, 90650.21243183, 90650.21243221, 90650.2124325 ]))\n",
      "           fun: 90650.21241961051\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1903\n",
      "           nit: 830\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.85959234e-02, 2.70830341e-02, 3.75888685e-02, 5.60836646e+03,\n",
      "       1.79338974e+04, 1.86206826e+04, 1.15154939e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91231.4553234166, bestParams: [0.0892526, 0.12577815, 0.064923555, 8575.71, 16426.484, 17164.031, 13682.164]\n",
      "epoch 2\n",
      " final_simplex: (array([[6.24537414e-02, 6.15992439e-02, 4.87048961e-02, 8.10050348e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666122e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537410e-02, 6.15992442e-02, 4.87048963e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537408e-02, 6.15992444e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385009e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537410e-02, 6.15992443e-02, 4.87048963e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537413e-02, 6.15992439e-02, 4.87048963e-02, 8.10050348e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666121e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048965e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666122e+04]]), array([90678.49280484, 90678.49280488, 90678.49280488, 90678.4928049 ,\n",
      "       90678.49280491, 90678.49280492, 90678.49280495, 90678.49280495]))\n",
      "           fun: 90678.49280484293\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1336\n",
      "           nit: 527\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.24537414e-02, 6.15992439e-02, 4.87048961e-02, 8.10050348e+03,\n",
      "       1.87385010e+04, 1.77667491e+04, 2.46666122e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91162.11827079224, bestParams: [0.028731208, 0.08052614, 0.038748782, 6678.704, 9787.624, 20217.812, 20754.006]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.70904892e-02, 3.81834950e-02, 4.32858909e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550785e+04, 1.31698874e+04],\n",
      "       [3.70904891e-02, 3.81834947e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550785e+04, 1.31698875e+04],\n",
      "       [3.70904891e-02, 3.81834950e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550784e+04, 1.31698875e+04],\n",
      "       [3.70904892e-02, 3.81834948e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698873e+04],\n",
      "       [3.70904892e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698874e+04],\n",
      "       [3.70904891e-02, 3.81834949e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698875e+04],\n",
      "       [3.70904891e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550784e+04, 1.31698874e+04],\n",
      "       [3.70904890e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550784e+04, 1.31698875e+04]]), array([90642.60568465, 90642.60568466, 90642.60568467, 90642.60568468,\n",
      "       90642.60568469, 90642.60568473, 90642.60568474, 90642.60568475]))\n",
      "           fun: 90642.60568464609\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1275\n",
      "           nit: 507\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.70904892e-02, 3.81834950e-02, 4.32858909e-02, 5.98454029e+03,\n",
      "       1.81339736e+04, 1.72550785e+04, 1.31698874e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91382.86227142713, bestParams: [0.061809793, 0.19442773, 0.026268564, 4953.1294, 21892.15, 9520.106, 16782.123]\n",
      "epoch 4\n",
      " final_simplex: (array([[6.27800301e-02, 1.23767454e-01, 3.50697812e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800298e-02, 1.23767455e-01, 3.50697812e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800299e-02, 1.23767454e-01, 3.50697811e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604067e+04],\n",
      "       [6.27800297e-02, 1.23767455e-01, 3.50697811e-02, 5.48175073e+03,\n",
      "        1.28766665e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767454e-01, 3.50697811e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767455e-01, 3.50697810e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604065e+04],\n",
      "       [6.27800302e-02, 1.23767454e-01, 3.50697809e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767455e-01, 3.50697810e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04]]), array([90777.06158995, 90777.06159034, 90777.06159078, 90777.0615909 ,\n",
      "       90777.06159123, 90777.06159134, 90777.06159178, 90777.06159179]))\n",
      "           fun: 90777.06158994799\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 491\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.27800301e-02, 1.23767454e-01, 3.50697812e-02, 5.48175072e+03,\n",
      "       1.28766666e+04, 1.04008147e+04, 1.94604066e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91244.41189886695, bestParams: [0.10861425, 0.073448956, 0.058375053, 7751.9844, 24126.418, 15650.825, 13502.183]\n",
      "epoch 5\n",
      " final_simplex: (array([[4.98106413e-02, 4.31442532e-02, 4.55770178e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106415e-02, 4.31442537e-02, 4.55770179e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106417e-02, 4.31442545e-02, 4.55770180e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106419e-02, 4.31442552e-02, 4.55770181e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106422e-02, 4.31442562e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106423e-02, 4.31442564e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106423e-02, 4.31442564e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106424e-02, 4.31442567e-02, 4.55770184e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04]]), array([90645.14444341, 90645.14444347, 90645.14444356, 90645.14444367,\n",
      "       90645.14444379, 90645.14444382, 90645.14444382, 90645.14444386]))\n",
      "           fun: 90645.14444341193\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 4867\n",
      "           nit: 2501\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.98106413e-02, 4.31442532e-02, 4.55770178e-02, 8.17344313e+03,\n",
      "       2.22304248e+04, 2.16693584e+04, 2.17261576e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 90929.83437789878, bestParams: [0.042998888, 0.0036338635, 0.08923576, 6261.846, 20105.752, 21534.959, 8484.541]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.07350802e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004541e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790768e-03, 4.90472196e-02, 6.49933175e+03,\n",
      "        1.96476728e+04, 2.31004541e+04, 1.06442170e+04],\n",
      "       [4.07350803e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350800e-02, 4.32790766e-03, 4.90472198e-02, 6.49933176e+03,\n",
      "        1.96476727e+04, 2.31004541e+04, 1.06442172e+04],\n",
      "       [4.07350800e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476727e+04, 2.31004541e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790766e-03, 4.90472196e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790766e-03, 4.90472196e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350801e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04]]), array([90729.51111848, 90729.51111852, 90729.51111854, 90729.51111854,\n",
      "       90729.51111856, 90729.51111859, 90729.51111859, 90729.51111861]))\n",
      "           fun: 90729.51111847878\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1384\n",
      "           nit: 534\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.07350802e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "       1.96476728e+04, 2.31004541e+04, 1.06442171e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91338.66029620953, bestParams: [0.029967176, 0.105418496, 0.045315336, 5352.596, 2545.1953, 7796.2197, 16043.894]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.44726379e-02, 3.49043068e-02, 4.37101311e-02, 2.02821194e+03,\n",
      "        6.23612173e+03, 6.14653739e+03, 4.45542382e+03],\n",
      "       [3.44726355e-02, 3.49043034e-02, 4.37101328e-02, 2.02821196e+03,\n",
      "        6.23612174e+03, 6.14653748e+03, 4.45542375e+03],\n",
      "       [3.44726365e-02, 3.49043101e-02, 4.37101292e-02, 2.02821195e+03,\n",
      "        6.23612173e+03, 6.14653742e+03, 4.45542384e+03],\n",
      "       [3.44726357e-02, 3.49043114e-02, 4.37101301e-02, 2.02821195e+03,\n",
      "        6.23612168e+03, 6.14653744e+03, 4.45542382e+03],\n",
      "       [3.44726353e-02, 3.49043095e-02, 4.37101309e-02, 2.02821194e+03,\n",
      "        6.23612172e+03, 6.14653741e+03, 4.45542374e+03],\n",
      "       [3.44726354e-02, 3.49043147e-02, 4.37101280e-02, 2.02821196e+03,\n",
      "        6.23612170e+03, 6.14653740e+03, 4.45542391e+03],\n",
      "       [3.44726344e-02, 3.49043115e-02, 4.37101279e-02, 2.02821195e+03,\n",
      "        6.23612180e+03, 6.14653744e+03, 4.45542372e+03],\n",
      "       [3.44726337e-02, 3.49043122e-02, 4.37101303e-02, 2.02821194e+03,\n",
      "        6.23612172e+03, 6.14653737e+03, 4.45542377e+03]]), array([90642.45046539, 90642.45046608, 90642.45046658, 90642.45046711,\n",
      "       90642.45046727, 90642.45046771, 90642.45046814, 90642.45046855]))\n",
      "           fun: 90642.45046539283\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1428\n",
      "           nit: 638\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.44726379e-02, 3.49043068e-02, 4.37101311e-02, 2.02821194e+03,\n",
      "       6.23612173e+03, 6.14653739e+03, 4.45542382e+03])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 90822.19754322112, bestParams: [0.010888182, 0.014153072, 0.046646245, 3893.9783, 13470.374, 10266.924, 8581.38]\n",
      "epoch 8\n",
      " final_simplex: (array([[3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "        1.12126544e+03, 1.14623685e+03, 8.33927990e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580955e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623686e+03, 8.33927984e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903620e+02,\n",
      "        1.12126543e+03, 1.14623683e+03, 8.33927991e+02],\n",
      "       [3.82086249e-02, 3.13148454e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623682e+03, 8.33927983e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623684e+03, 8.33927993e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903611e+02,\n",
      "        1.12126540e+03, 1.14623683e+03, 8.33927973e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903626e+02,\n",
      "        1.12126544e+03, 1.14623684e+03, 8.33928033e+02],\n",
      "       [3.82086251e-02, 3.13148453e-02, 4.25580949e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623685e+03, 8.33928012e+02]]), array([90635.50396325, 90635.5039651 , 90635.5039652 , 90635.50396555,\n",
      "       90635.50396556, 90635.50396586, 90635.50397008, 90635.50397061]))\n",
      "           fun: 90635.50396325192\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 561\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "       1.12126544e+03, 1.14623685e+03, 8.33927990e+02])\n",
      "minPrevious 90642.85781500832\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "        1.12126544e+03, 1.14623685e+03, 8.33927990e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580955e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623686e+03, 8.33927984e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903620e+02,\n",
      "        1.12126543e+03, 1.14623683e+03, 8.33927991e+02],\n",
      "       [3.82086249e-02, 3.13148454e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623682e+03, 8.33927983e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623684e+03, 8.33927993e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903611e+02,\n",
      "        1.12126540e+03, 1.14623683e+03, 8.33927973e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903626e+02,\n",
      "        1.12126544e+03, 1.14623684e+03, 8.33928033e+02],\n",
      "       [3.82086251e-02, 3.13148453e-02, 4.25580949e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623685e+03, 8.33928012e+02]]), array([90635.50396325, 90635.5039651 , 90635.5039652 , 90635.50396555,\n",
      "       90635.50396556, 90635.50396586, 90635.50397008, 90635.50397061]))\n",
      "           fun: 90635.50396325192\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 561\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "       1.12126544e+03, 1.14623685e+03, 8.33927990e+02])\n",
      "best ll: 90795.9848434706, bestParams: [0.023895113, 0.04085701, 0.05497067, 7981.157, 15722.58, 17191.658, 21199.53]\n",
      "epoch 9\n",
      " final_simplex: (array([[2.82889394e-02, 4.02806717e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889394e-02, 4.02806719e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889396e-02, 4.02806716e-02, 4.32251584e-02, 6.71342930e+03,\n",
      "        2.14952765e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889396e-02, 4.02806717e-02, 4.32251585e-02, 6.71342930e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889395e-02, 4.02806717e-02, 4.32251589e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889396e-02, 4.02806717e-02, 4.32251583e-02, 6.71342930e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889395e-02, 4.02806718e-02, 4.32251588e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889395e-02, 4.02806717e-02, 4.32251587e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04]]), array([90649.70138782, 90649.70138796, 90649.70139572, 90649.70139578,\n",
      "       90649.70139578, 90649.70139579, 90649.7013958 , 90649.7013958 ]))\n",
      "           fun: 90649.70138781719\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1123\n",
      "           nit: 377\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.82889394e-02, 4.02806717e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "       2.14952764e+04, 1.98861867e+04, 1.47146669e+04])\n",
      "minPrevious 90635.50396325192\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0382, 0.0313, 0.0426], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8729, 0.0646, 0.0277, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8656, 0.0769, 0.0261, 0.0314], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8894, 0.0282, 0.0649, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8639, 0.0260, 0.0787, 0.0314], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7354, 0.0989, 0.0981, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7093, 0.1098, 0.1113, 0.0696], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.0017, 4.0782, 5.5325],\n",
      "        [2.8935, 2.9939, 5.7539],\n",
      "        [3.9443, 2.9939, 5.9781],\n",
      "        ...,\n",
      "        [4.9808, 4.8651, 7.1442],\n",
      "        [3.4877, 2.3421, 6.7752],\n",
      "        [2.0068, 2.9318, 5.2629]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.899680852890015\n",
      "Run: 0, 8\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[32.,  4.,  0.,  2.],\n",
      "        [48.,  2.,  2.,  0.],\n",
      "        [50.,  7.,  1.,  3.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [49.,  0.,  1.,  1.],\n",
      "        [50.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([38., 52., 61.,  ..., 70., 51., 53.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 2., 7.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 1.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 3.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[32.,  4.,  0.,  2.],\n",
      "        [48.,  2.,  2.,  0.],\n",
      "        [50.,  7.,  1.,  3.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [49.,  0.,  1.,  1.],\n",
      "        [50.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([3.4400e-04, 3.5403e-02, 9.0049e-06,  ..., 5.4883e-03, 2.6479e-02,\n",
      "        3.8102e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7d8437680>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90866.38670202054, bestParams: [0.04227104, 0.043204933, 0.035604723, 4999.505, 6446.358, 10356.963, 18687.867]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.78586233e-02, 4.97323902e-02, 4.39350770e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147190e+04, 8.49245920e+03],\n",
      "       [3.78586235e-02, 4.97323902e-02, 4.39350773e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147190e+04, 8.49245919e+03],\n",
      "       [3.78586232e-02, 4.97323905e-02, 4.39350767e-02, 3.58313190e+03,\n",
      "        1.04477020e+04, 1.02147190e+04, 8.49245911e+03],\n",
      "       [3.78586227e-02, 4.97323902e-02, 4.39350774e-02, 3.58313190e+03,\n",
      "        1.04477020e+04, 1.02147191e+04, 8.49245916e+03],\n",
      "       [3.78586228e-02, 4.97323899e-02, 4.39350782e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245925e+03],\n",
      "       [3.78586223e-02, 4.97323901e-02, 4.39350782e-02, 3.58313191e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245913e+03],\n",
      "       [3.78586225e-02, 4.97323904e-02, 4.39350773e-02, 3.58313189e+03,\n",
      "        1.04477020e+04, 1.02147191e+04, 8.49245911e+03],\n",
      "       [3.78586225e-02, 4.97323902e-02, 4.39350780e-02, 3.58313191e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245913e+03]]), array([90487.06109292, 90487.06109304, 90487.06109312, 90487.06109314,\n",
      "       90487.06109322, 90487.06109331, 90487.06109333, 90487.06109339]))\n",
      "           fun: 90487.06109292197\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1122\n",
      "           nit: 395\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.78586233e-02, 4.97323902e-02, 4.39350770e-02, 3.58313192e+03,\n",
      "       1.04477019e+04, 1.02147190e+04, 8.49245920e+03])\n",
      "best ll: 90778.79449381144, bestParams: [0.08165928, 0.087960355, 0.063273296, 6014.191, 7127.5513, 11117.987, 22590.318]\n",
      "epoch 1\n",
      " final_simplex: (array([[8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994274e-02, 7.17538081e-02, 4.81073032e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994274e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994276e-02, 7.17538080e-02, 4.81073031e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04],\n",
      "       [8.64994276e-02, 7.17538083e-02, 4.81073030e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04],\n",
      "       [8.64994279e-02, 7.17538081e-02, 4.81073029e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04]]), array([90562.47709194, 90562.47709201, 90562.47709202, 90562.47709211,\n",
      "       90562.47709213, 90562.47709218, 90562.47709236, 90562.47709241]))\n",
      "           fun: 90562.47709193993\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1227\n",
      "           nit: 471\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "       1.14898833e+04, 1.26010591e+04, 1.55118784e+04])\n",
      "minPrevious 90487.06109292197\n",
      "best ll: 90970.5610899757, bestParams: [0.09997445, 0.12198489, 0.051259637, 7826.5796, 23443.818, 14464.848, 18766.902]\n",
      "epoch 2\n",
      " final_simplex: (array([[8.71740907e-02, 9.11163488e-02, 5.16494257e-02, 8.27206657e+03,\n",
      "        1.61201928e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740909e-02, 9.11163489e-02, 5.16494256e-02, 8.27206655e+03,\n",
      "        1.61201928e+04, 1.78121709e+04, 2.57831929e+04],\n",
      "       [8.71740908e-02, 9.11163492e-02, 5.16494255e-02, 8.27206658e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740912e-02, 9.11163500e-02, 5.16494251e-02, 8.27206657e+03,\n",
      "        1.61201928e+04, 1.78121709e+04, 2.57831930e+04],\n",
      "       [8.71740911e-02, 9.11163504e-02, 5.16494251e-02, 8.27206659e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740911e-02, 9.11163502e-02, 5.16494252e-02, 8.27206659e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740914e-02, 9.11163510e-02, 5.16494248e-02, 8.27206657e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740915e-02, 9.11163513e-02, 5.16494247e-02, 8.27206658e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831931e+04]]), array([90589.73553078, 90589.73553096, 90589.73553098, 90589.73553157,\n",
      "       90589.73553194, 90589.73553196, 90589.73553245, 90589.73553278]))\n",
      "           fun: 90589.73553077558\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1493\n",
      "           nit: 613\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.71740907e-02, 9.11163488e-02, 5.16494257e-02, 8.27206657e+03,\n",
      "       1.61201928e+04, 1.78121708e+04, 2.57831930e+04])\n",
      "minPrevious 90487.06109292197\n",
      "best ll: 90702.98167128472, bestParams: [0.03473026, 0.046426747, 0.061863348, 9696.083, 24623.559, 19582.648, 17360.992]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639317e-02, 4.45271009e-02, 4.57781923e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639318e-02, 4.45271006e-02, 4.57781931e-02, 8.53728467e+03,\n",
      "        2.49527256e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639319e-02, 4.45271002e-02, 4.57781944e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639321e-02, 4.45270995e-02, 4.57781964e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639323e-02, 4.45270990e-02, 4.57781979e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639324e-02, 4.45270989e-02, 4.57781981e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966649e+04, 1.98905847e+04],\n",
      "       [3.66639324e-02, 4.45270987e-02, 4.57781989e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04]]), array([90482.69509499, 90482.69509598, 90482.69509679, 90482.69509802,\n",
      "       90482.69510007, 90482.69510157, 90482.69510186, 90482.69510255]))\n",
      "           fun: 90482.69509499139\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1646\n",
      "           nit: 743\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "       2.49527257e+04, 2.45966650e+04, 1.98905847e+04])\n",
      "minPrevious 90487.06109292197\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639317e-02, 4.45271009e-02, 4.57781923e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639318e-02, 4.45271006e-02, 4.57781931e-02, 8.53728467e+03,\n",
      "        2.49527256e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639319e-02, 4.45271002e-02, 4.57781944e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639321e-02, 4.45270995e-02, 4.57781964e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639323e-02, 4.45270990e-02, 4.57781979e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639324e-02, 4.45270989e-02, 4.57781981e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966649e+04, 1.98905847e+04],\n",
      "       [3.66639324e-02, 4.45270987e-02, 4.57781989e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04]]), array([90482.69509499, 90482.69509598, 90482.69509679, 90482.69509802,\n",
      "       90482.69510007, 90482.69510157, 90482.69510186, 90482.69510255]))\n",
      "           fun: 90482.69509499139\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1646\n",
      "           nit: 743\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "       2.49527257e+04, 2.45966650e+04, 1.98905847e+04])\n",
      "best ll: 90867.56193183556, bestParams: [0.0098387115, 0.062886804, 0.053461675, 6239.042, 23488.914, 22569.387, 434.96948]\n",
      "epoch 4\n",
      " final_simplex: (array([[1.15378583e-02, 2.04791823e-02, 4.61124020e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670302e+04, 6.11843483e+02],\n",
      "       [1.15378583e-02, 2.04791820e-02, 4.61124014e-02, 5.84323512e+03,\n",
      "        2.64481986e+04, 2.49670302e+04, 6.11843490e+02],\n",
      "       [1.15378582e-02, 2.04791827e-02, 4.61124012e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843491e+02],\n",
      "       [1.15378581e-02, 2.04791822e-02, 4.61124010e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843498e+02],\n",
      "       [1.15378580e-02, 2.04791818e-02, 4.61124008e-02, 5.84323512e+03,\n",
      "        2.64481986e+04, 2.49670302e+04, 6.11843501e+02],\n",
      "       [1.15378578e-02, 2.04791817e-02, 4.61124003e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843513e+02],\n",
      "       [1.15378578e-02, 2.04791814e-02, 4.61124005e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843513e+02],\n",
      "       [1.15378578e-02, 2.04791806e-02, 4.61124008e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670302e+04, 6.11843515e+02]]), array([90612.29504722, 90612.29504755, 90612.29504758, 90612.29504799,\n",
      "       90612.29504825, 90612.29504873, 90612.29504883, 90612.29504907]))\n",
      "           fun: 90612.29504722435\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1277\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.15378583e-02, 2.04791823e-02, 4.61124020e-02, 5.84323512e+03,\n",
      "       2.64481985e+04, 2.49670302e+04, 6.11843483e+02])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90725.9879271773, bestParams: [0.043563887, 0.012296107, 0.08686379, 4552.979, 12478.696, 12336.921, 8655.909]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.38270526e-02, 2.14812023e-02, 4.24158900e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403708e+03],\n",
      "       [3.38270531e-02, 2.14812022e-02, 4.24158901e-02, 4.15356910e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403705e+03],\n",
      "       [3.38270544e-02, 2.14812014e-02, 4.24158909e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212583e+04, 6.94403701e+03],\n",
      "       [3.38270549e-02, 2.14812012e-02, 4.24158914e-02, 4.15356913e+03,\n",
      "        1.34924801e+04, 1.44212583e+04, 6.94403698e+03],\n",
      "       [3.38270561e-02, 2.14812008e-02, 4.24158918e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403707e+03],\n",
      "       [3.38270559e-02, 2.14812006e-02, 4.24158918e-02, 4.15356913e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403715e+03],\n",
      "       [3.38270568e-02, 2.14812003e-02, 4.24158922e-02, 4.15356911e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403715e+03],\n",
      "       [3.38270567e-02, 2.14812002e-02, 4.24158924e-02, 4.15356912e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403709e+03]]), array([90506.88456244, 90506.8845628 , 90506.88456515, 90506.88456571,\n",
      "       90506.88456661, 90506.8845673 , 90506.8845681 , 90506.88456827]))\n",
      "           fun: 90506.88456243879\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1294\n",
      "           nit: 525\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38270526e-02, 2.14812023e-02, 4.24158900e-02, 4.15356911e+03,\n",
      "       1.34924801e+04, 1.44212582e+04, 6.94403708e+03])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90707.96802735567, bestParams: [0.01074106, 0.056317706, 0.062326808, 6906.7803, 14660.881, 12282.025, 20889.7]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948854e-02, 4.49989146e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948855e-02, 4.49989148e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948855e-02, 4.49989147e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778318e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948857e-02, 4.49989150e-02, 5.80778323e+03,\n",
      "        1.99696317e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948856e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948856e-02, 4.49989148e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04]]), array([90513.85897781, 90513.85897782, 90513.85897782, 90513.8589779 ,\n",
      "       90513.85897801, 90513.85897812, 90513.85897819, 90513.85897819]))\n",
      "           fun: 90513.85897780894\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1223\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "       1.99696318e+04, 1.68266749e+04, 1.13317168e+04])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 91208.12679174251, bestParams: [0.018939186, 0.13372447, 0.09658249, 7547.9326, 16754.46, 12379.46, 9450.32]\n",
      "epoch 7\n",
      " final_simplex: (array([[2.38771336e-02, 4.86939481e-02, 4.37289625e-02, 6.16011838e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658889e+04],\n",
      "       [2.38771335e-02, 4.86939479e-02, 4.37289625e-02, 6.16011839e+03,\n",
      "        1.88306626e+04, 1.72063936e+04, 1.41658889e+04],\n",
      "       [2.38771332e-02, 4.86939487e-02, 4.37289632e-02, 6.16011841e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771331e-02, 4.86939495e-02, 4.37289634e-02, 6.16011841e+03,\n",
      "        1.88306626e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771334e-02, 4.86939500e-02, 4.37289621e-02, 6.16011839e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771332e-02, 4.86939498e-02, 4.37289632e-02, 6.16011840e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771332e-02, 4.86939496e-02, 4.37289630e-02, 6.16011839e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771331e-02, 4.86939479e-02, 4.37289631e-02, 6.16011840e+03,\n",
      "        1.88306626e+04, 1.72063937e+04, 1.41658888e+04]]), array([90493.66767072, 90493.66767083, 90493.667671  , 90493.66767111,\n",
      "       90493.66767112, 90493.66767118, 90493.66767124, 90493.66767134]))\n",
      "           fun: 90493.6676707186\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1261\n",
      "           nit: 515\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.38771336e-02, 4.86939481e-02, 4.37289625e-02, 6.16011838e+03,\n",
      "       1.88306625e+04, 1.72063936e+04, 1.41658889e+04])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90946.33073211275, bestParams: [0.06552671, 0.03858188, 0.027416045, 5274.589, 17153.447, 15913.322, 3718.8213]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.66046495e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111184e+03],\n",
      "       [2.66046496e-02, 3.30193378e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046496e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046495e-02, 3.30193379e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111182e+03],\n",
      "       [2.66046494e-02, 3.30193379e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046494e-02, 3.30193379e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314351e+04, 1.28060088e+04, 6.71111184e+03],\n",
      "       [2.66046493e-02, 3.30193377e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060087e+04, 6.71111188e+03],\n",
      "       [2.66046494e-02, 3.30193377e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060087e+04, 6.71111185e+03]]), array([90491.11260967, 90491.11260969, 90491.1126097 , 90491.11260972,\n",
      "       90491.11260973, 90491.11260974, 90491.11260981, 90491.11260981]))\n",
      "           fun: 90491.11260967342\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1209\n",
      "           nit: 424\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.66046495e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "       1.31314350e+04, 1.28060088e+04, 6.71111184e+03])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90979.13690442877, bestParams: [0.03663157, 0.05130152, 0.088229544, 6370.648, 15553.35, 12778.411, 7697.9907]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.97788087e-02, 4.67508439e-02, 4.20900894e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412336e+04],\n",
      "       [3.97788089e-02, 4.67508438e-02, 4.20900895e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412336e+04],\n",
      "       [3.97788088e-02, 4.67508436e-02, 4.20900896e-02, 5.37312917e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412336e+04],\n",
      "       [3.97788087e-02, 4.67508442e-02, 4.20900896e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412335e+04],\n",
      "       [3.97788087e-02, 4.67508442e-02, 4.20900894e-02, 5.37312917e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412335e+04],\n",
      "       [3.97788085e-02, 4.67508446e-02, 4.20900899e-02, 5.37312915e+03,\n",
      "        1.61818613e+04, 1.60830102e+04, 1.16412335e+04],\n",
      "       [3.97788087e-02, 4.67508439e-02, 4.20900892e-02, 5.37312918e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412336e+04],\n",
      "       [3.97788084e-02, 4.67508448e-02, 4.20900899e-02, 5.37312916e+03,\n",
      "        1.61818613e+04, 1.60830102e+04, 1.16412335e+04]]), array([90485.31169553, 90485.31169555, 90485.31169556, 90485.31169564,\n",
      "       90485.31169573, 90485.31169573, 90485.31169582, 90485.31169587]))\n",
      "           fun: 90485.31169552742\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1246\n",
      "           nit: 478\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97788087e-02, 4.67508439e-02, 4.20900894e-02, 5.37312916e+03,\n",
      "       1.61818614e+04, 1.60830103e+04, 1.16412336e+04])\n",
      "minPrevious 90482.69509499139\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0367, 0.0445, 0.0458], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8773, 0.0628, 0.0278, 0.0251], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8679, 0.0761, 0.0260, 0.0300], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8874, 0.0282, 0.0652, 0.0261], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8687, 0.0261, 0.0751, 0.0301], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7379, 0.0985, 0.0987, 0.0616], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7085, 0.1116, 0.1107, 0.0692], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7394, 3.1648, 4.3888],\n",
      "        [3.2083, 2.9599, 5.7800],\n",
      "        [2.2675, 2.0366, 4.9875],\n",
      "        ...,\n",
      "        [3.8538, 3.8462, 5.9722],\n",
      "        [3.6667, 5.0235, 5.9005],\n",
      "        [5.0420, 4.6122, 7.5952]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.200846195220947\n",
      "Run: 0, 9\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[50.,  1.,  1.,  2.],\n",
      "        [61.,  3.,  1.,  1.],\n",
      "        [52.,  2.,  1.,  1.],\n",
      "        ...,\n",
      "        [53.,  0.,  1.,  1.],\n",
      "        [56.,  1.,  1.,  0.],\n",
      "        [47.,  2.,  1.,  2.]], dtype=torch.float64)\n",
      "n tensor([54., 66., 56.,  ..., 55., 58., 52.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 2.,  ..., 0., 1., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 1., 0., 2.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[50.,  1.,  1.,  2.],\n",
      "        [61.,  3.,  1.,  1.],\n",
      "        [52.,  2.,  1.,  1.],\n",
      "        ...,\n",
      "        [53.,  0.,  1.,  1.],\n",
      "        [56.,  1.,  1.,  0.],\n",
      "        [47.,  2.,  1.,  2.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0115, 0.0177, 0.0291,  ..., 0.0234, 0.0528, 0.0082],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3f200>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90761.7781549094, bestParams: [0.04600825, 0.034627862, 0.03320431, 3705.6182, 7804.2446, 11532.189, 11376.845]\n",
      "epoch 0\n",
      " final_simplex: (array([[4.79401002e-02, 3.59860707e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126223e+03],\n",
      "       [4.79401001e-02, 3.59860709e-02, 4.02713562e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126223e+03],\n",
      "       [4.79401002e-02, 3.59860711e-02, 4.02713562e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126226e+03],\n",
      "       [4.79401004e-02, 3.59860708e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043620e+04, 7.70126228e+03],\n",
      "       [4.79401003e-02, 3.59860708e-02, 4.02713564e-02, 3.34189612e+03,\n",
      "        9.83545166e+03, 1.05043621e+04, 7.70126227e+03],\n",
      "       [4.79401006e-02, 3.59860705e-02, 4.02713567e-02, 3.34189612e+03,\n",
      "        9.83545165e+03, 1.05043620e+04, 7.70126230e+03],\n",
      "       [4.79401005e-02, 3.59860707e-02, 4.02713564e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126229e+03],\n",
      "       [4.79401005e-02, 3.59860705e-02, 4.02713563e-02, 3.34189612e+03,\n",
      "        9.83545165e+03, 1.05043621e+04, 7.70126227e+03]]), array([90616.66706736, 90616.66706748, 90616.66706754, 90616.66706756,\n",
      "       90616.66706758, 90616.66706764, 90616.66706774, 90616.66706778]))\n",
      "           fun: 90616.66706735565\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1129\n",
      "           nit: 411\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.79401002e-02, 3.59860707e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "       9.83545164e+03, 1.05043621e+04, 7.70126223e+03])\n",
      "best ll: 91516.6859835903, bestParams: [0.026306985, 0.08133267, 0.024871472, 6414.625, 13429.396, 3964.474, 20765.12]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.28815934e-02, 8.33975562e-02, 4.81044641e-02, 2.66958385e+03,\n",
      "        7.24460965e+03, 6.30083680e+03, 7.38755573e+03],\n",
      "       [3.28815935e-02, 8.33975565e-02, 4.81044639e-02, 2.66958386e+03,\n",
      "        7.24460964e+03, 6.30083682e+03, 7.38755570e+03],\n",
      "       [3.28815934e-02, 8.33975568e-02, 4.81044637e-02, 2.66958386e+03,\n",
      "        7.24460973e+03, 6.30083679e+03, 7.38755579e+03],\n",
      "       [3.28815934e-02, 8.33975564e-02, 4.81044642e-02, 2.66958386e+03,\n",
      "        7.24460969e+03, 6.30083679e+03, 7.38755583e+03],\n",
      "       [3.28815934e-02, 8.33975567e-02, 4.81044638e-02, 2.66958386e+03,\n",
      "        7.24460967e+03, 6.30083680e+03, 7.38755576e+03],\n",
      "       [3.28815935e-02, 8.33975571e-02, 4.81044636e-02, 2.66958386e+03,\n",
      "        7.24460967e+03, 6.30083682e+03, 7.38755564e+03],\n",
      "       [3.28815934e-02, 8.33975570e-02, 4.81044637e-02, 2.66958386e+03,\n",
      "        7.24460966e+03, 6.30083681e+03, 7.38755572e+03],\n",
      "       [3.28815934e-02, 8.33975569e-02, 4.81044638e-02, 2.66958385e+03,\n",
      "        7.24460973e+03, 6.30083679e+03, 7.38755575e+03]]), array([90672.74759503, 90672.74759516, 90672.74759536, 90672.74759546,\n",
      "       90672.7475955 , 90672.74759568, 90672.74759569, 90672.74759581]))\n",
      "           fun: 90672.74759502892\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1175\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.28815934e-02, 8.33975562e-02, 4.81044641e-02, 2.66958385e+03,\n",
      "       7.24460965e+03, 6.30083680e+03, 7.38755573e+03])\n",
      "minPrevious 90616.66706735565\n",
      "best ll: 91198.52576890608, bestParams: [0.06617981, 0.0026062375, 0.052282184, 5632.2466, 15811.634, 23665.295, 21685.236]\n",
      "epoch 2\n",
      " final_simplex: (array([[5.97788174e-02, 2.86239567e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788175e-02, 2.86239567e-03, 5.14519103e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788175e-02, 2.86239566e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766147e+04, 1.54040265e+04],\n",
      "       [5.97788177e-02, 2.86239567e-03, 5.14519102e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766145e+04, 1.54040266e+04],\n",
      "       [5.97788177e-02, 2.86239565e-03, 5.14519106e-02, 7.10048604e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04],\n",
      "       [5.97788175e-02, 2.86239568e-03, 5.14519099e-02, 7.10048600e+03,\n",
      "        1.78954599e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788178e-02, 2.86239566e-03, 5.14519104e-02, 7.10048604e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04],\n",
      "       [5.97788177e-02, 2.86239566e-03, 5.14519103e-02, 7.10048602e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04]]), array([90761.99558966, 90761.99558975, 90761.99558987, 90761.99558988,\n",
      "       90761.99558996, 90761.99559001, 90761.99559002, 90761.99559008]))\n",
      "           fun: 90761.99558965943\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1259\n",
      "           nit: 478\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.97788174e-02, 2.86239567e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "       1.78954598e+04, 2.16766146e+04, 1.54040265e+04])\n",
      "minPrevious 90616.66706735565\n",
      "best ll: 90782.52717622745, bestParams: [0.028903035, 0.05556211, 0.03673761, 6341.9014, 12760.6875, 16858.322, 19627.572]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5c67a24bbe10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    586\u001b[0m                       callback=callback, **options)\n\u001b[1;32m    587\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mxbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxbar\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mfxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mdoshrink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0ma1Both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1Both\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0ma21\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "resSim = {\n",
    "        \"allRes\": None,\n",
    "        \"nEpochs\": None,\n",
    "        \"bestRes\": {\n",
    "            \"pis\": None,\n",
    "            \"alphas\": None,\n",
    "            \"PDV_c1true\": None,\n",
    "            \"PDV_c2true\": None,\n",
    "            \"PDV_cBothTrue\": None,\n",
    "            \"PDV_c1inferred\": None,\n",
    "            \"PDV_c2inferred\": None,\n",
    "            \"PDV_cBothInferred\": None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cached6NormalSimResNonAnnealing = []\n",
    "\n",
    "rrsSim = tensor([[2, 2, 1.5]])\n",
    "pisSim = tensor([[.05, .05, .05]])\n",
    "\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(5e5)\n",
    "i = 0\n",
    "for rrsSimRun in rrsSim:\n",
    "    for pisSimRun in pisSim:\n",
    "        afMeanRun = 1e-4\n",
    "        generatingFn = genData.v6normal\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        # needs tensor for shapes, otherwise \"gamma_cpu not implemente for long\", e.g rrShape=50.0 doesn't work...\n",
    "        paramsRun = genData.genParams(rrMeans=rrsSimRun, pis=pisSimRun, afMean=afMeanRun, rrShape=tensor(50.), afShape=tensor(50.), nCases=nCases, nCtrls=nCtrls)[0]\n",
    "        \n",
    "        pDsRun = paramsRun[\"pDs\"]\n",
    "        pisRun = paramsRun[\"diseaseFractions\"]\n",
    "        print(\"params are:\", paramsRun)\n",
    "        \n",
    "        cached6NormalSimResNonAnnealing.append({\"params\": paramsRun, \"runs\": []})\n",
    "        for y in range(0, 10):\n",
    "            start = time.time()\n",
    "            r = generatingFn(**paramsRun)\n",
    "            print(\"took\", time.time() - start)\n",
    "            \n",
    "            resPointer = {\n",
    "                **r,\n",
    "                \"generatingFn\": generatingFn,\n",
    "                \"results\": None,\n",
    "            }\n",
    "\n",
    "            cached6NormalSimResNonAnnealing[i][\"runs\"].append(resPointer)\n",
    "            \n",
    "            print(f\"Run: {i}, {y}\")\n",
    "            \n",
    "            xsRun = resPointer[\"altCounts\"]\n",
    "            afsRun = resPointer[\"afs\"]\n",
    "            affectedGenesRun = resPointer[\"affectedGenes\"]\n",
    "            unaffectedGenesRun = resPointer[\"unaffectedGenes\"]\n",
    "\n",
    "            runCostFnIdx = 16\n",
    "\n",
    "            nEpochsRun = 10\n",
    "            print(\"nEpochsRun\", nEpochsRun)\n",
    "            \n",
    "            res = likelihoods.fitFnBivariate(xsRun, pDsRun, nEpochs=nEpochsRun, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "            bestRes = res[\"params\"][-1]\n",
    "\n",
    "            inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "            inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "            #### Calculate actual ###\n",
    "            component1Afs = afsRun[affectedGenesRun[0]]\n",
    "            c1true = (component1Afs / afMeanRun).mean(0)\n",
    "\n",
    "            component2Afs = afsRun[affectedGenesRun[1]]\n",
    "            c2true = (component2Afs / afMeanRun).mean(0)\n",
    "\n",
    "            componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "            cBothTrue = (componentBothAfs / afMeanRun).mean(0)\n",
    "\n",
    "            ### calculate inferred values\n",
    "            pds = tensor([1-pDsRun.sum(), *pDsRun])\n",
    "            alphas = inferredAlphas.numpy()\n",
    "            c1inferred = Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            c2inferred = Dirichlet(tensor([alphas[0], alphas[0], alphas[2], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            cBothInferred = Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0)\n",
    "\n",
    "            print(f\"\\n\\nrun {i} results for rrs: {rrsSimRun}, pis: {pisSimRun}\")\n",
    "            print(\"Inferred pis:\", inferredPis)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c1true)\n",
    "            print(\"P(D|V) inferred in component 1:\", c1inferred)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c2true)\n",
    "            print(\"P(D|V) inferred in component both:\", c2inferred)\n",
    "            print(\"\\nP(D|V) true ans in component both:\", cBothTrue)\n",
    "            print(\"P(D|V) inferred in component both:\", cBothInferred,\"\\n\\n\")\n",
    "\n",
    "            resToStore = copy.deepcopy(resSim)\n",
    "            resToStore[\"allRes\"] = res\n",
    "            resToStore[\"nEpochs\"] = nEpochsRun\n",
    "            br = resToStore[\"bestRes\"]\n",
    "            br[\"pis\"] = inferredPis\n",
    "            br[\"alphas\"] = inferredAlphas\n",
    "            br[\"PDV_c1true\"] = c1true\n",
    "            br[\"PDV_c2true\"] = c2true\n",
    "            br[\"PDV_cBothTrue\"] = cBothTrue\n",
    "            br[\"PDV_c1inferred\"] = c1inferred\n",
    "            br[\"PDV_c2inferred\"] = c2inferred\n",
    "            br[\"PDV_cBothInferred\"] = cBothInferred\n",
    "\n",
    "            resPointer[\"results\"] = resToStore\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([1.5000, 1.5000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.8293, 2.6289, 3.8956],\n",
      "        [2.4995, 2.3651, 2.9228],\n",
      "        [2.9986, 3.1782, 5.7793],\n",
      "        ...,\n",
      "        [1.6170, 2.4270, 3.9871],\n",
      "        [2.6860, 2.5748, 3.5131],\n",
      "        [3.5057, 4.4161, 3.9715]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.05718994140625\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  0.],\n",
      "        [44.,  6.,  1.,  1.],\n",
      "        [50.,  2.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  3.,  2.,  0.],\n",
      "        [53.,  1.,  1.,  3.],\n",
      "        [53.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "n tensor([50., 52., 55.,  ..., 53., 58., 55.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 6., 2.,  ..., 3., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 2.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 0., 3., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  0.],\n",
      "        [44.,  6.,  1.,  1.],\n",
      "        [50.,  2.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  3.,  2.,  0.],\n",
      "        [53.,  1.,  1.,  3.],\n",
      "        [53.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0164, 0.0003, 0.0222,  ..., 0.0175, 0.0025, 0.0234],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa6304e8440>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89254.57939981687, bestParams: [0.09598137, 0.18161891, 0.066081025, 8628.348, 19064.254, 11141.051, 24336.697]\n",
      "epoch 0\n",
      "     fun: 89087.15867372246\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 17512\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.06655157e-01, 8.05196165e-03, 8.52313234e-02, 1.51882047e+04,\n",
      "       1.59563997e+04, 2.49997166e+04, 2.49999993e+04])\n",
      "took 263.1990089416504\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([1.5000, 1.5000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.9067, 0.0081, 0.0852], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8974, 0.0550, 0.0281, 0.0220], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.9248, 0.0291, 0.0277, 0.0183], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8934, 0.0280, 0.0558, 0.0223], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.9098, 0.0273, 0.0449, 0.0180], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7746, 0.0863, 0.0874, 0.0510], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8119, 0.0657, 0.0802, 0.0423], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.0191, 2.4042, 5.8232],\n",
      "        [1.0840, 2.3261, 4.9498],\n",
      "        [3.7891, 1.8827, 4.6055],\n",
      "        ...,\n",
      "        [4.0709, 3.3965, 6.2600],\n",
      "        [1.4524, 3.2465, 4.9516],\n",
      "        [2.2135, 1.7095, 4.1531]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.519060134887695\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  2.],\n",
      "        [45.,  6.,  4.,  3.],\n",
      "        [54.,  5.,  1.,  0.],\n",
      "        ...,\n",
      "        [59.,  3.,  2.,  3.],\n",
      "        [44.,  1.,  3.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([45., 58., 60.,  ..., 67., 48., 45.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 5.,  ..., 3., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 4., 1.,  ..., 2., 3., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 0.,  ..., 3., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  2.],\n",
      "        [45.,  6.,  4.,  3.],\n",
      "        [54.,  5.,  1.,  0.],\n",
      "        ...,\n",
      "        [59.,  3.,  2.,  3.],\n",
      "        [44.,  1.,  3.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([6.2383e-03, 3.4287e-06, 3.3784e-03,  ..., 1.4544e-03, 2.2402e-02,\n",
      "        4.3776e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa6411153b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89545.34098332483, bestParams: [0.019650858, 0.005765289, 0.015805295, 8096.601, 15435.601, 23816.336, 12740.194]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-087714822751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunSim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1387c87bde79>\u001b[0m in \u001b[0;36mrunSim\u001b[0;34m(rrs, pis, nCases, nCtrls, afMean, rrShape, afShape, generatingFn, fitMethod)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitMethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx, method)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Nelder-Mead'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adaptive\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"annealing\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"basinhopping\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasinhopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mdual_annealing\u001b[0;34m(func, bounds, args, maxiter, local_search_options, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0)\u001b[0m\n\u001b[1;32m    663\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;31m# starting strategy chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, step, temperature)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 self.energy_state.current_location, j, temperature)\n\u001b[1;32m    290\u001b[0m             \u001b[0;31m# Calling the objective function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_visit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_energy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;31m# We have got a better energy value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0maBothBoth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malphaBoth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mh3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBoth1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBoth2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBothBoth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mh0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runSim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN\n",
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([1.5000, 1.5000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9334, 2.5262, 4.5972],\n",
      "        [2.9295, 2.6827, 4.2659],\n",
      "        [3.4033, 4.0980, 4.6098],\n",
      "        ...,\n",
      "        [3.2606, 1.8734, 3.4271],\n",
      "        [2.4874, 2.7894, 4.5732],\n",
      "        [3.8228, 2.9923, 4.2592]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.798516273498535\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  1.],\n",
      "        [51.,  0.,  2.,  3.],\n",
      "        [41.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [55.,  1.,  4.,  0.],\n",
      "        [40.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([51., 56., 44.,  ..., 60., 42., 43.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 0.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 2.,  ..., 4., 1., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 1.,  ..., 0., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  1.],\n",
      "        [51.,  0.,  2.,  3.],\n",
      "        [41.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [55.,  1.,  4.,  0.],\n",
      "        [40.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0093, 0.0012, 0.0201,  ..., 0.0102, 0.0836, 0.0409],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa60809c050>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89504.27484045511, bestParams: [0.01460946, 0.02944035, 0.03863643, 3142.4583, 3569.245, 5062.629, 6662.2]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112738e+03,\n",
      "        5.21052634e+03, 4.99263541e+03, 2.62354673e+03],\n",
      "       [1.98604401e-02, 3.41540280e-02, 3.55878742e-02, 1.65112738e+03,\n",
      "        5.21052633e+03, 4.99263546e+03, 2.62354667e+03],\n",
      "       [1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112737e+03,\n",
      "        5.21052636e+03, 4.99263542e+03, 2.62354672e+03],\n",
      "       [1.98604400e-02, 3.41540281e-02, 3.55878741e-02, 1.65112738e+03,\n",
      "        5.21052634e+03, 4.99263542e+03, 2.62354670e+03],\n",
      "       [1.98604401e-02, 3.41540283e-02, 3.55878742e-02, 1.65112737e+03,\n",
      "        5.21052638e+03, 4.99263537e+03, 2.62354673e+03],\n",
      "       [1.98604401e-02, 3.41540280e-02, 3.55878744e-02, 1.65112737e+03,\n",
      "        5.21052634e+03, 4.99263546e+03, 2.62354667e+03],\n",
      "       [1.98604400e-02, 3.41540281e-02, 3.55878747e-02, 1.65112738e+03,\n",
      "        5.21052627e+03, 4.99263541e+03, 2.62354677e+03],\n",
      "       [1.98604400e-02, 3.41540282e-02, 3.55878745e-02, 1.65112738e+03,\n",
      "        5.21052630e+03, 4.99263539e+03, 2.62354675e+03]]), array([89097.20969999, 89097.20970001, 89097.20970011, 89097.20970015,\n",
      "       89097.20970023, 89097.20970029, 89097.2097003 , 89097.20970032]))\n",
      "           fun: 89097.20969998793\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1187\n",
      "           nit: 474\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112738e+03,\n",
      "       5.21052634e+03, 4.99263541e+03, 2.62354673e+03])\n",
      "best ll: 89661.97322291948, bestParams: [0.03616922, 0.032769334, 0.045829535, 10727.266, 24210.703, 12838.759, 15205.117]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514215e-02, 7.07864376e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259062e+04],\n",
      "       [4.19236529e-02, 3.25639602e-02, 3.48514220e-02, 7.07864378e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236527e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514220e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041261e+04, 2.08219659e+04, 1.43259061e+04]]), array([89076.07821087, 89076.07821088, 89076.07821092, 89076.07821098,\n",
      "       89076.07821101, 89076.07821117, 89076.07821118, 89076.07821121]))\n",
      "           fun: 89076.07821086713\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1248\n",
      "           nit: 473\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "       1.96041260e+04, 2.08219659e+04, 1.43259061e+04])\n",
      "minPrevious 89097.20969998793\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514215e-02, 7.07864376e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259062e+04],\n",
      "       [4.19236529e-02, 3.25639602e-02, 3.48514220e-02, 7.07864378e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236527e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514220e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041261e+04, 2.08219659e+04, 1.43259061e+04]]), array([89076.07821087, 89076.07821088, 89076.07821092, 89076.07821098,\n",
      "       89076.07821101, 89076.07821117, 89076.07821118, 89076.07821121]))\n",
      "           fun: 89076.07821086713\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1248\n",
      "           nit: 473\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "       1.96041260e+04, 2.08219659e+04, 1.43259061e+04])\n",
      "best ll: 89396.0603735198, bestParams: [0.02752898, 0.02535716, 0.018690322, 5718.255, 12018.066, 19256.404, 19616.584]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.03046914e-02, 2.79128625e-02, 2.73070996e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259645e+03],\n",
      "       [3.03046915e-02, 2.79128625e-02, 2.73070995e-02, 4.82605052e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259643e+03],\n",
      "       [3.03046916e-02, 2.79128625e-02, 2.73070995e-02, 4.82605052e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259641e+03],\n",
      "       [3.03046916e-02, 2.79128625e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259646e+03],\n",
      "       [3.03046915e-02, 2.79128626e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259648e+03],\n",
      "       [3.03046916e-02, 2.79128626e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259646e+03],\n",
      "       [3.03046918e-02, 2.79128627e-02, 2.73070993e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259651e+03],\n",
      "       [3.03046916e-02, 2.79128624e-02, 2.73070996e-02, 4.82605052e+03,\n",
      "        1.52177117e+04, 1.57090374e+04, 7.96259636e+03]]), array([89090.52106561, 89090.52106562, 89090.52106564, 89090.52106565,\n",
      "       89090.52106566, 89090.52106567, 89090.52106586, 89090.52107062]))\n",
      "           fun: 89090.52106561436\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1246\n",
      "           nit: 440\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.03046914e-02, 2.79128625e-02, 2.73070996e-02, 4.82605053e+03,\n",
      "       1.52177116e+04, 1.57090374e+04, 7.96259645e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89159.98797501124, bestParams: [0.07087075, 0.035208993, 0.046770897, 7998.9688, 20401.977, 21096.521, 20626.426]\n",
      "epoch 3\n",
      " final_simplex: (array([[6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623725e+04],\n",
      "       [6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730239e+04, 1.97623725e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623724e+04],\n",
      "       [6.71874810e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874810e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874811e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623724e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04]]), array([89100.40359353, 89100.40359355, 89100.40359361, 89100.40359362,\n",
      "       89100.40359366, 89100.40359367, 89100.40359371, 89100.40359375]))\n",
      "           fun: 89100.40359352919\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1309\n",
      "           nit: 496\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "       1.97499805e+04, 2.14730240e+04, 1.97623725e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89266.87360477714, bestParams: [0.02102224, 0.0073940502, 0.04933069, 9835.428, 20614.709, 23006.111, 24559.834]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.81792183e-02, 1.00385350e-02, 4.10791068e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436391e+03],\n",
      "       [2.81792178e-02, 1.00385350e-02, 4.10791081e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436387e+03],\n",
      "       [2.81792169e-02, 1.00385350e-02, 4.10791109e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436386e+03],\n",
      "       [2.81792169e-02, 1.00385350e-02, 4.10791111e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436397e+03],\n",
      "       [2.81792162e-02, 1.00385350e-02, 4.10791133e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436397e+03],\n",
      "       [2.81792161e-02, 1.00385351e-02, 4.10791135e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436386e+03],\n",
      "       [2.81792156e-02, 1.00385350e-02, 4.10791151e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436393e+03],\n",
      "       [2.81792146e-02, 1.00385351e-02, 4.10791183e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436391e+03]]), array([89131.49405002, 89131.49405098, 89131.49405308, 89131.49405339,\n",
      "       89131.49405506, 89131.49405509, 89131.4940564 , 89131.4940588 ]))\n",
      "           fun: 89131.49405001549\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2322\n",
      "           nit: 1097\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.81792183e-02, 1.00385350e-02, 4.10791068e-02, 7.92193726e+03,\n",
      "       2.46257826e+04, 2.70287627e+04, 8.82436391e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89362.65263565104, bestParams: [0.012687951, 0.011631452, 0.07809705, 6797.328, 13523.173, 17862.2, 14069.145]\n",
      "epoch 5\n",
      " final_simplex: (array([[1.84218776e-02, 1.37973849e-02, 3.77607203e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083500e+03],\n",
      "       [1.84218775e-02, 1.37973850e-02, 3.77607202e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083503e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607205e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083504e+03],\n",
      "       [1.84218776e-02, 1.37973850e-02, 3.77607202e-02, 5.59975530e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083499e+03],\n",
      "       [1.84218777e-02, 1.37973848e-02, 3.77607207e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083490e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607205e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083495e+03],\n",
      "       [1.84218776e-02, 1.37973850e-02, 3.77607202e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083502e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607204e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083499e+03]]), array([89133.97795553, 89133.97795554, 89133.97795572, 89133.9779627 ,\n",
      "       89133.97796275, 89133.97796276, 89133.97796276, 89133.97796277]))\n",
      "           fun: 89133.97795552979\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1228\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.84218776e-02, 1.37973849e-02, 3.77607203e-02, 5.59975531e+03,\n",
      "       1.89100468e+04, 1.95686277e+04, 5.99083500e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89212.69924155968, bestParams: [0.025522236, 0.07102064, 0.04095869, 6469.978, 23772.977, 16247.678, 7731.7466]\n",
      "epoch 6\n",
      " final_simplex: (array([[2.70476141e-02, 4.01468282e-02, 3.26248241e-02, 6.48001244e+03,\n",
      "        1.99119150e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476140e-02, 4.01468277e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394004e+04],\n",
      "       [2.70476141e-02, 4.01468286e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476141e-02, 4.01468292e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394002e+04],\n",
      "       [2.70476141e-02, 4.01468287e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394003e+04],\n",
      "       [2.70476141e-02, 4.01468291e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394002e+04],\n",
      "       [2.70476141e-02, 4.01468290e-02, 3.26248239e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476142e-02, 4.01468298e-02, 3.26248239e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394002e+04]]), array([89083.15977387, 89083.15977388, 89083.15977389, 89083.15977391,\n",
      "       89083.15977393, 89083.15977395, 89083.15977396, 89083.15977396]))\n",
      "           fun: 89083.15977387255\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 540\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.70476141e-02, 4.01468282e-02, 3.26248241e-02, 6.48001244e+03,\n",
      "       1.99119150e+04, 1.85927180e+04, 1.18394003e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89330.68493643744, bestParams: [0.082257316, 0.027428642, 0.07051255, 7407.681, 12604.67, 11728.0625, 22984.412]\n",
      "epoch 7\n",
      " final_simplex: (array([[7.22722643e-02, 4.08138975e-02, 3.35494221e-02, 6.23642624e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722643e-02, 4.08138976e-02, 3.35494214e-02, 6.23642621e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722637e-02, 4.08138975e-02, 3.35494209e-02, 6.23642626e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722640e-02, 4.08138976e-02, 3.35494211e-02, 6.23642624e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722644e-02, 4.08138975e-02, 3.35494216e-02, 6.23642623e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722642e-02, 4.08138974e-02, 3.35494214e-02, 6.23642625e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722651e-02, 4.08138974e-02, 3.35494229e-02, 6.23642620e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722644e-02, 4.08138975e-02, 3.35494217e-02, 6.23642623e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04]]), array([89092.78697749, 89092.78697752, 89092.78697752, 89092.78697755,\n",
      "       89092.78697766, 89092.78697766, 89092.78697766, 89092.78697769]))\n",
      "           fun: 89092.78697748706\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1211\n",
      "           nit: 458\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.22722643e-02, 4.08138975e-02, 3.35494221e-02, 6.23642624e+03,\n",
      "       1.45974907e+04, 1.66629287e+04, 1.42103738e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89389.45489296163, bestParams: [0.060271375, 0.042252373, 0.050650936, 6876.2065, 11556.726, 21871.658, 21758.736]\n",
      "epoch 8\n",
      " final_simplex: (array([[6.51869746e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869748e-02, 5.30897589e-02, 3.51516079e-02, 7.05962329e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869746e-02, 5.30897590e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869746e-02, 5.30897590e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869748e-02, 5.30897588e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123699e+04, 1.75684742e+04],\n",
      "       [6.51869746e-02, 5.30897591e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869747e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869747e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04]]), array([89093.22690281, 89093.22690282, 89093.22690284, 89093.22690284,\n",
      "       89093.22690285, 89093.22690287, 89093.22690287, 89093.2269029 ]))\n",
      "           fun: 89093.22690280867\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1255\n",
      "           nit: 513\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.51869746e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "       1.66074072e+04, 1.75123700e+04, 1.75684742e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89479.24696850716, bestParams: [0.0029611788, 0.048730392, 0.018831836, 9358.529, 19040.064, 23882.67, 18005.031]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.08114659e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147293e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532136e-02, 3.99157607e-02, 6.77894951e+03,\n",
      "        2.23243264e+04, 1.88557299e+04, 9.53147285e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147293e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157607e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147291e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147294e+03]]), array([89195.54214277, 89195.54214282, 89195.54214284, 89195.54214284,\n",
      "       89195.54214303, 89195.54216626, 89195.54216627, 89195.54216628]))\n",
      "           fun: 89195.5421427736\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1323\n",
      "           nit: 487\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.08114659e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "       2.23243264e+04, 1.88557300e+04, 9.53147293e+03])\n",
      "minPrevious 89076.07821086713\n",
      "took 407.44111680984497\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([1.5000, 1.5000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0419, 0.0326, 0.0349], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8933, 0.0569, 0.0280, 0.0227], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8708, 0.0723, 0.0261, 0.0307], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8975, 0.0281, 0.0563, 0.0225], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8670, 0.0260, 0.0765, 0.0305], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7772, 0.0856, 0.0853, 0.0511], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7218, 0.1037, 0.1075, 0.0670], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[4.4937, 4.8385, 5.2157],\n",
      "        [3.3180, 2.5832, 3.6836],\n",
      "        [4.3122, 2.5246, 4.8452],\n",
      "        ...,\n",
      "        [2.7396, 4.5652, 3.7115],\n",
      "        [1.9112, 3.0687, 5.9062],\n",
      "        [1.3352, 2.5593, 3.5319]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-879fdf1954c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunSim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitMethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1387c87bde79>\u001b[0m in \u001b[0;36mrunSim\u001b[0;34m(rrs, pis, nCases, nCtrls, afMean, rrShape, afShape, generatingFn, fitMethod)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneratingFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparamsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/genData.py\u001b[0m in \u001b[0;36mv6normal\u001b[0;34m(nCases, nCtrls, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mmarginalAlleleCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalProbability\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotalSamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0maltCountsGene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarginalAlleleCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0maltCounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsGene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/distributions/multinomial.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# samples.shape is (total_count, sample_shape, batch_shape), need to change it to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# (sample_shape, batch_shape, total_count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mshifted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mshifted_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshifted_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshifted_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runSim(fitMethod='nelder-mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f646b1ec66d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./mvln-sim-mvln.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf_should_read_directly\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = np.load(\"./mvln-sim-mvln.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resByParams = []\n",
    "for runSet in res:\n",
    "    params = (runSet[\"params\"][\"diseaseFractions\"], runSet[\"params\"][\"rrMeans\"], runSet[\"params\"][\"rrShape\"])\n",
    "#     print(\"param\", params)\n",
    "    res = []\n",
    "#     if params not in resByParam:\n",
    "#         resByParams[params] = []\n",
    "    \n",
    "    for run in runSet[\"runs\"]:\n",
    "        if run is None or \"results\" not in run or run[\"results\"] is None:\n",
    "            print(f\"no results found for {params}\")\n",
    "            continue\n",
    "        res.append(run[\"results\"])\n",
    "    resByParams.append([params, res])\n",
    "\n",
    "np.save(\"mvln-sim-mvln-results2\", resByParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resByParams = np.load(\"mvln-sim-mvln-results.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[(tensor([0.0500, 0.0500, 0.0500]), tensor([2.0000, 2.0000, 1.5000]), tensor(50.)),\n",
       "        list([{'allRes': {'lls': [90916.4783589971, 90708.31368424412, 90689.04874179952, 90677.23983613223], 'params': [array([3.87333861e-02, 1.40812486e-01, 7.59025824e-02, 9.31141067e+03,\n",
       "       2.18500134e+04, 1.68652588e+04, 2.63598593e+04]), array([1.67543257e-02, 3.13060638e-02, 4.29277051e-02, 2.50496081e+03,\n",
       "       8.64518025e+03, 8.37694873e+03, 4.74332877e+03]), array([4.07980539e-02, 5.92690249e-02, 4.06981218e-02, 4.76417261e+03,\n",
       "       1.30584069e+04, 1.28133394e+04, 1.26034808e+04]), array([3.56317955e-02, 3.20989858e-02, 4.08777915e-02, 5.02625412e+03,\n",
       "       1.52388589e+04, 1.62573997e+04, 1.10763793e+04])], 'llTrajectory': [90916.4783589971, 90708.31368424412, 90727.26669070916, 90689.04874179952, 90677.23983613223, 90676.96371994552, 90738.01226968745, 90784.31279984681, 90787.42281897092, 90677.4934384852]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0356, 0.0321, 0.0409], dtype=torch.float64), 'alphas': tensor([ 5026.2541, 15238.8589, 16257.3997, 11076.3793], dtype=torch.float64), 'PDV_c1true': tensor([0.8812, 0.0628, 0.0279, 0.0251], dtype=torch.float64), 'PDV_c2true': tensor([0.8833, 0.0281, 0.0651, 0.0261], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7405, 0.0993, 0.0996, 0.0623], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8622, 0.0785, 0.0259, 0.0335], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8577, 0.0257, 0.0832, 0.0333], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7032, 0.1105, 0.1148, 0.0715], dtype=torch.float64)}}, {'allRes': {'lls': [90645.57342181327, 90644.31351623876, 90641.27069583946], 'params': [array([3.63755073e-02, 4.57749896e-02, 4.18899664e-02, 1.42087064e+03,\n",
       "       4.35121665e+03, 4.00355358e+03, 3.50070375e+03]), array([4.66029047e-02, 4.53761282e-02, 4.29744549e-02, 6.07873461e+03,\n",
       "       1.78237112e+04, 1.71242042e+04, 1.58362642e+04]), array([4.33810405e-02, 4.52988838e-02, 4.13633647e-02, 6.96476709e+02,\n",
       "       2.04656915e+03, 1.91605097e+03, 1.77271015e+03])], 'llTrajectory': [90645.57342181327, 90651.2118646526, 90719.94317753878, 90644.31351623876, 90666.92657482934, 90653.34651654988, 90641.27069583946, 90651.3464135098, 90680.92933323765, 90792.21030335355]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0434, 0.0453, 0.0414], dtype=torch.float64), 'alphas': tensor([ 696.4767, 2046.5691, 1916.0510, 1772.7101], dtype=torch.float64), 'PDV_c1true': tensor([0.8797, 0.0642, 0.0279, 0.0257], dtype=torch.float64), 'PDV_c2true': tensor([0.8793, 0.0278, 0.0627, 0.0251], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7303, 0.0996, 0.0971, 0.0614], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8686, 0.0767, 0.0261, 0.0286], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8730, 0.0261, 0.0721, 0.0288], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7034, 0.1153, 0.1118, 0.0695], dtype=torch.float64)}}, {'allRes': {'lls': [90748.6465155581, 90711.14503326186], 'params': [array([6.27341823e-02, 4.63341146e-02, 3.75087980e-02, 6.10706763e+03,\n",
       "       1.62508186e+04, 1.74873704e+04, 1.57440691e+04]), array([3.54220726e-02, 4.85500888e-02, 4.49141211e-02, 2.28821775e+02,\n",
       "       6.42604102e+02, 6.38308739e+02, 5.08927552e+02])], 'llTrajectory': [90748.6465155581, 90711.14503326186, 90744.77986211523, 90876.14512541448, 90742.77190618007, 90800.03142956684, 90875.49917612775, 90747.52190318814, 90775.94721973015, 90878.82993506195]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0354, 0.0486, 0.0449], dtype=torch.float64), 'alphas': tensor([228.8218, 642.6041, 638.3087, 508.9276], dtype=torch.float64), 'PDV_c1true': tensor([0.8907, 0.0641, 0.0282, 0.0257], dtype=torch.float64), 'PDV_c2true': tensor([0.8856, 0.0281, 0.0643, 0.0257], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7492, 0.0969, 0.0963, 0.0615], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8712, 0.0735, 0.0262, 0.0291], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8716, 0.0263, 0.0729, 0.0293], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7170, 0.1081, 0.1075, 0.0673], dtype=torch.float64)}}, {'allRes': {'lls': [90933.72918146176, 90838.29602316262], 'params': [array([9.06864522e-02, 6.50148984e-02, 5.37885695e-02, 7.24642505e+03,\n",
       "       1.56345132e+04, 1.71235809e+04, 2.05677764e+04]), array([3.85649052e-02, 4.20795687e-02, 4.01053337e-02, 1.89342510e+03,\n",
       "       5.93866294e+03, 5.77638420e+03, 4.21878917e+03])], 'llTrajectory': [90933.72918146176, 90838.29602316262, 90868.60640369028, 90882.07712309291, 90847.74550284173, 90896.76813160375, 91157.13067761659, 90877.09566313706, 90838.3988977742, 90894.50289291705]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0386, 0.0421, 0.0401], dtype=torch.float64), 'alphas': tensor([1893.4251, 5938.6629, 5776.3842, 4218.7892], dtype=torch.float64), 'PDV_c1true': tensor([0.8888, 0.0641, 0.0282, 0.0256], dtype=torch.float64), 'PDV_c2true': tensor([0.8769, 0.0278, 0.0635, 0.0254], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7435, 0.0972, 0.0976, 0.0616], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8615, 0.0811, 0.0258, 0.0315], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8636, 0.0258, 0.0790, 0.0316], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7040, 0.1134, 0.1116, 0.0710], dtype=torch.float64)}}, {'allRes': {'lls': [90747.7696123132, 90585.67194419992, 90566.73709957347], 'params': [array([5.91826890e-02, 1.44589234e-01, 6.69387920e-02, 7.98395162e+03,\n",
       "       1.52393288e+04, 1.31918445e+04, 2.25971498e+04]), array([3.23620186e-02, 2.38361870e-02, 3.69261663e-02, 6.10035669e+03,\n",
       "       2.08475809e+04, 2.21919581e+04, 9.74581440e+03]), array([3.78255556e-02, 3.46743998e-02, 4.08244155e-02, 3.95583458e+03,\n",
       "       1.26977546e+04, 1.28829457e+04, 7.45632495e+03])], 'llTrajectory': [90747.7696123132, 90749.95843612179, 90585.67194419992, 90878.04322170046, 90566.73709957347, 90566.96453252305, 90861.6203819377, 90571.64204209404, 90615.46630737893, 90606.66331600855]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0378, 0.0347, 0.0408], dtype=torch.float64), 'alphas': tensor([ 3955.8346, 12697.7546, 12882.9457,  7456.3249], dtype=torch.float64), 'PDV_c1true': tensor([0.8825, 0.0635, 0.0280, 0.0254], dtype=torch.float64), 'PDV_c2true': tensor([0.8835, 0.0280, 0.0631, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7426, 0.0973, 0.0990, 0.0610], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8581, 0.0826, 0.0257, 0.0336], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8570, 0.0257, 0.0838, 0.0335], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7106, 0.1086, 0.1096, 0.0712], dtype=torch.float64)}}, {'allRes': {'lls': [90830.07972194639, 90562.237920496], 'params': [array([1.69463338e-01, 1.98575139e-01, 6.22025970e-02, 4.41316805e+03,\n",
       "       6.28159370e+03, 5.39738695e+03, 1.63099014e+04]), array([4.85819986e-02, 4.43267999e-02, 4.25625903e-02, 2.84641270e+02,\n",
       "       7.71902383e+02, 7.79988251e+02, 7.35633621e+02])], 'llTrajectory': [90830.07972194639, 90562.237920496, 90774.41540520656, 90774.76133135978, 90857.23196144999, 90587.14554848513, 90638.69745056726, 90581.18297009883, 90642.92672963747, 90596.53639301992]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0486, 0.0443, 0.0426], dtype=torch.float64), 'alphas': tensor([284.6413, 771.9024, 779.9883, 735.6336], dtype=torch.float64), 'PDV_c1true': tensor([0.8809, 0.0633, 0.0279, 0.0253], dtype=torch.float64), 'PDV_c2true': tensor([0.8849, 0.0280, 0.0629, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7376, 0.1000, 0.0991, 0.0615], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8736, 0.0712, 0.0264, 0.0288], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8738, 0.0261, 0.0714, 0.0286], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7067, 0.1122, 0.1130, 0.0681], dtype=torch.float64)}}, {'allRes': {'lls': [90541.19690546543, 90485.83852292394, 90450.04864336646], 'params': [array([1.05198885e-01, 5.61385155e-02, 4.30683468e-02, 7.16649842e+03,\n",
       "       1.50831749e+04, 1.90234287e+04, 2.11213115e+04]), array([1.45415926e-02, 3.60020275e-02, 4.32792564e-02, 5.79867892e+03,\n",
       "       2.10841845e+04, 1.86303955e+04, 1.00095742e+04]), array([4.04756141e-02, 2.69877192e-02, 4.02918327e-02, 5.89913599e+03,\n",
       "       1.83048623e+04, 1.99880264e+04, 1.21531034e+04])], 'llTrajectory': [90541.19690546543, 90485.83852292394, 90640.86004954319, 90450.04864336646, 90702.5564634097, 90557.9040388632, 90460.6229193173, 90467.91167992419, 90520.90760929213, 90557.50718726793]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0405, 0.0270, 0.0403], dtype=torch.float64), 'alphas': tensor([ 5899.1360, 18304.8623, 19988.0264, 12153.1034], dtype=torch.float64), 'PDV_c1true': tensor([0.8760, 0.0640, 0.0278, 0.0256], dtype=torch.float64), 'PDV_c2true': tensor([0.8838, 0.0280, 0.0630, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7420, 0.0999, 0.0992, 0.0621], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8593, 0.0800, 0.0258, 0.0349], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8530, 0.0256, 0.0868, 0.0346], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7038, 0.1090, 0.1150, 0.0722], dtype=torch.float64)}}, {'allRes': {'lls': [90757.56968553299, 90527.69242737578, 90521.27001448293], 'params': [array([1.61995075e-03, 1.05690047e-01, 5.31147218e-02, 7.83678126e+03,\n",
       "       2.34720398e+04, 1.67885869e+04, 1.81920206e+04]), array([3.75891039e-02, 3.93849894e-02, 4.27479940e-02, 3.83229961e+03,\n",
       "       1.20099977e+04, 1.13342312e+04, 9.03855526e+03]), array([3.71189801e-02, 3.75458264e-02, 4.12923202e-02, 9.18698687e+02,\n",
       "       2.84332494e+03, 2.78552088e+03, 2.18573783e+03])], 'llTrajectory': [90757.56968553299, 90527.69242737578, 90711.2276505137, 90521.27001448293, 90578.02820961754, 90562.84654239606, 90559.02988606176, 90559.19154174202, 90661.38357505882, 90574.89262462722]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0371, 0.0375, 0.0413], dtype=torch.float64), 'alphas': tensor([ 918.6987, 2843.3249, 2785.5209, 2185.7378], dtype=torch.float64), 'PDV_c1true': tensor([0.8806, 0.0645, 0.0280, 0.0258], dtype=torch.float64), 'PDV_c2true': tensor([0.8815, 0.0279, 0.0636, 0.0254], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7461, 0.1002, 0.0990, 0.0622], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8627, 0.0800, 0.0259, 0.0314], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8642, 0.0259, 0.0785, 0.0314], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.6999, 0.1150, 0.1135, 0.0715], dtype=torch.float64)}}, {'allRes': {'lls': [90897.96160983646, 90822.30100460075, 90813.7933164202], 'params': [array([4.94523337e-02, 8.98534427e-02, 5.08059703e-02, 9.33431412e+03,\n",
       "       2.31980772e+04, 2.01782677e+04, 2.67851825e+04]), array([5.22288505e-02, 3.94783721e-02, 3.29460235e-02, 6.27854966e+03,\n",
       "       1.81322217e+04, 2.01847985e+04, 1.56110186e+04]), array([4.59210324e-02, 3.17754408e-02, 3.75392591e-02, 2.79599712e+03,\n",
       "       8.37452682e+03, 9.36512056e+03, 6.22258891e+03])], 'llTrajectory': [90897.96160983646, 90822.30100460075, 90813.7933164202, 91195.13795952266, 90824.4409889472, 90948.83020724998, 90833.29153831744, 90914.45047672343, 90828.49674330515, 90894.21608835603]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0459, 0.0318, 0.0375], dtype=torch.float64), 'alphas': tensor([2795.9971, 8374.5268, 9365.1206, 6222.5889], dtype=torch.float64), 'PDV_c1true': tensor([0.8817, 0.0646, 0.0280, 0.0258], dtype=torch.float64), 'PDV_c2true': tensor([0.8855, 0.0281, 0.0642, 0.0257], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7387, 0.0989, 0.0991, 0.0620], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8621, 0.0774, 0.0258, 0.0346], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8541, 0.0256, 0.0859, 0.0344], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7009, 0.1097, 0.1173, 0.0721], dtype=torch.float64)}}, {'allRes': {'lls': [90674.24682333917, 90639.08503812845, 90635.38566081121], 'params': [array([8.25512430e-02, 4.47077237e-02, 3.81560217e-02, 4.85958175e+03,\n",
       "       1.15702661e+04, 1.34392115e+04, 1.46426684e+04]), array([3.22876832e-02, 3.94240441e-02, 4.00764617e-02, 7.08816185e+03,\n",
       "       2.15671201e+04, 2.13042256e+04, 1.77545086e+04]), array([4.38503233e-02, 4.14981181e-02, 4.02783387e-02, 4.39219918e+03,\n",
       "       1.27983245e+04, 1.36739819e+04, 1.11025385e+04])], 'llTrajectory': [90674.24682333917, 90639.08503812845, 90824.46248323756, 90645.51300320614, 90877.98499150135, 90635.38566081121, 90641.18017866093, 90640.17212894236, 90647.75311221162, 90634.58400619372]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0439, 0.0415, 0.0403], dtype=torch.float64), 'alphas': tensor([ 4392.1992, 12798.3245, 13673.9819, 11102.5385], dtype=torch.float64), 'PDV_c1true': tensor([0.8838, 0.0650, 0.0281, 0.0260], dtype=torch.float64), 'PDV_c2true': tensor([0.8842, 0.0280, 0.0629, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7435, 0.0991, 0.0996, 0.0620], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8659, 0.0758, 0.0260, 0.0323], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8616, 0.0258, 0.0804, 0.0322], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.6969, 0.1137, 0.1179, 0.0715], dtype=torch.float64)}}])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resByParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.subplot([1,len(resByParams)])\n",
    "i = 0\n",
    "with open(\"mvln-sim-mvln-res.tsv\", \"w\") as file:\n",
    "    file.write(f\"Notes: 15000 samples1, 15000 samples2, 6000 samplesBoth; rrs generated from normal distribution with. 1 variance, .4 covariance, and individual effect rr summed with shared-effect rr in genes affecting both conditions\\n\")\n",
    "    file.write(f\"\\tmean\\tstd\\n\")\n",
    "    for res in resByParams:\n",
    "        i += 1\n",
    "\n",
    "        paramsRun = res[0]\n",
    "        resRun = res[1]\n",
    "\n",
    "        pis = tensor([x[\"bestRes\"][\"pis\"].numpy() for x in resRun])\n",
    "        PDV_c1true = tensor([x[\"bestRes\"][\"PDV_c1true\"].numpy() for x in resRun])\n",
    "        PDV_c2true = tensor([x[\"bestRes\"][\"PDV_c2true\"].numpy() for x in resRun])\n",
    "        PDV_c3true = tensor([x[\"bestRes\"][\"PDV_cBothTrue\"].numpy() for x in resRun])\n",
    "        PDV_c1inferred = tensor([x[\"bestRes\"][\"PDV_c1inferred\"].numpy() for x in resRun])\n",
    "        PDV_c2inferred = tensor([x[\"bestRes\"][\"PDV_c2inferred\"].numpy() for x in resRun])\n",
    "        PDV_c3inferred = tensor([x[\"bestRes\"][\"PDV_cBothInferred\"].numpy() for x in resRun])\n",
    "\n",
    "        file.write(f\"\\n\\ntrue params: \\t{paramsRun} \\n\\n\")\n",
    "\n",
    "        file.write(f\"pi\\t {pis.mean(0).numpy()} \\t  {pis.std(0).numpy()} \\n\")\n",
    "\n",
    "        file.write(f\"PDV_c1inferred \\t {PDV_c1inferred.mean(0).numpy()}\\t {PDV_c1inferred.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c1true \\t {PDV_c1true.mean(0).numpy()} \\t {PDV_c1true.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c2inferred \\t {PDV_c2inferred.mean(0).numpy()} \\t {PDV_c2inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c2true \\t {PDV_c2true.mean(0).numpy()} \\t {PDV_c2true.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3inferred \\t {PDV_c3inferred.mean(0).numpy()} \\t {PDV_c3inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3true \\t {PDV_c3true.mean(0).numpy()} \\t {PDV_c3true.std(0).numpy()}\\n\")\n",
    "\n",
    "    #     plt.figure(i)\n",
    "    #     plt.plot(t, s1)\n",
    "    #     plt.plot(t, 2*s1)\n",
    "        # plt.subplot(222)\n",
    "        # plt.plot(t, 2*s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Tensor is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5cb54c57e780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mvln-sim-mvn.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached6NormalSimRes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Tensor is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open('./mvln-sim-mvn.json', 'w') as outfile:\n",
    "    json.dump(cached6NormalSimRes, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 5\n"
     ]
    }
   ],
   "source": [
    "def one(a, b, c, d = 5):\n",
    "    print(a, b, c, d)\n",
    "    \n",
    "def two(*args, **kwargs):\n",
    "    one(*args, **kwargs)\n",
    "    \n",
    "two(1, 2, c = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size = multiprocessing.cpu_count()\n",
    "os.system('taskset -cp 0-%d %s' % (pool_size, os.getpid()))\n",
    "\n",
    "genData.runSim(fitMethod=\"nelder-mead\", mt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('taskset -p %s' %os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "def compute_something(t):\n",
    "    a = 0.\n",
    "    for i in range(10000000):\n",
    "        a = math.sqrt(t)\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Pool size:\", pool_size)\n",
    "pool = multiprocessing.Pool(processes=pool_size)\n",
    "\n",
    "inputs = range(10)\n",
    "\n",
    "tic = time.time()\n",
    "builtin_outputs = map(compute_something, inputs)\n",
    "print('Built-in:', time.time() - tic)\n",
    "\n",
    "tic = time.time()\n",
    "pool_outputs = pool.map(compute_something, inputs)\n",
    "print('Pool    :', time.time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    "# import pyro\n",
    "# from torch.multiprocessing import Process\n",
    "# from torch.distributions import Uniform\n",
    "# import time\n",
    "# import numpy as np\n",
    "# def writer():\n",
    "#     message = f\"I am Process {i}\"\n",
    "#     print(torch.utils.data.get_worker_info())\n",
    "#     x = np.random.seed()\n",
    "#     x = np.random.randint(1000)\n",
    "#     print('seed', x)\n",
    "#     torch.manual_seed(x)\n",
    "#     pis = Uniform(1/100, .5).rsample([3])\n",
    "#     print(\"r is\", pis)\n",
    "#     time.sleep(1)\n",
    "\n",
    "# def reader(i,q):\n",
    "#     message = q.get()\n",
    "#     print(\"got message\", message)\n",
    "\n",
    "# for i in range(10):\n",
    "   \n",
    "#     Process(target=writer, args=()).start()\n",
    "#     time.sleep(.5)\n",
    "#    # Create multiprocessing pool\n",
    "#     p = Pool(10)\n",
    "#    # Create a group of parallel readers and start them\n",
    "#    # Number of readers is matching the number of writers\n",
    "#    # However, the number of simultaneously running\n",
    "#    # readers is constrained to the pool size\n",
    "#     readers = []\n",
    "#     for i in range(10):\n",
    "#         readers.append(p.apply_async(reader, (i,q,)))\n",
    "#     # Wait for the asynchrounous reader threads to finish\n",
    "#     [r.get() for r in readers]\n",
    "    \n",
    "    \n",
    "#     # Establish communication queues\n",
    "#     tasks = torch.multiprocessing.JoinableQueue()\n",
    "#     results = torch.multiprocessing.Queue()\n",
    "    \n",
    "#     # Start consumers\n",
    "#     num_consumers = torch.multiprocessing.cpu_count()\n",
    "#     print('Creating %d consumers' % num_consumers)\n",
    "#     consumers = [ Consumer(tasks, results)\n",
    "#                   for i in range(num_consumers) ]\n",
    "#     for w in consumers:\n",
    "#         w.start()\n",
    "    \n",
    "#     # Enqueue jobs\n",
    "#     for i in range(nEpochs):\n",
    "#         tasks.put(Task(altCountsByGene, pDs, 1, minLLThresholdCount, K, debug, costFnIdx, method))\n",
    "    \n",
    "#     # Add a poison pill for each consumer\n",
    "#     for i in range(nEpochs):\n",
    "#         tasks.put(None)\n",
    "\n",
    "#     # Wait for all of the tasks to finish\n",
    "#     tasks.join()\n",
    "    \n",
    "#     # Start printing results\n",
    "#     while nEpochs:\n",
    "#         result = results.get()\n",
    "#         print('Result:', result)\n",
    "#         num_jobs -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e0d0c7993644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msmoke_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'CI'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.3.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genData.runSim(fitMethod=\"nelder-mead\", mt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.distributions import DirichletMultinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c19e38a749ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, concentration, total_count, is_sparse, validate_args)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtotal_count_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "DirichletMultinomial(total_count=1000, concentration=[1, 1, 1, 1]).log_prob([10, 10, 10, 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0446, 0.0446, 0.0179])\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(300000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0446, 0.0446, 0.0179]) covShared tensor([[1.0000, 0.4000, 0.4000],\n",
      "        [0.4000, 1.0000, 0.4000],\n",
      "        [0.4000, 0.4000, 1.0000]]) covSingle tensor([[1, 0],\n",
      "        [0, 1]])\n",
      "\n",
      "\n",
      "test tensor 1.0,0.4,0.4,0.4,1.0,0.4,0.4,0.4,1.0\n",
      "tensor([[3.8911, 4.3012, 4.9429],\n",
      "        [3.5095, 3.8114, 5.0887],\n",
      "        [1.4753, 3.1997, 6.0978],\n",
      "        ...,\n",
      "        [3.5758, 2.5359, 5.1694],\n",
      "        [3.7204, 3.0271, 3.6657],\n",
      "        [3.6032, 3.8470, 4.7421]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 336000\n"
     ]
    }
   ],
   "source": [
    "rrs = tensor([1.5, 1.5, 1.5])\n",
    "pis = tensor([.05, .05, .05])\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(3e5)\n",
    "afMean = 1e-4\n",
    "rrShape=tensor(50.)\n",
    "afShape=tensor(50.)\n",
    "generatingFn =  genData.v6normal\n",
    "fitMethod = 'nelder-mead'\n",
    "nEpochs=20\n",
    "mt = True\n",
    "covShared=tensor([[1,.4,.4], [.4, 1, .4], [.4, .4, 1]])\n",
    "covSingle=tensor([[1, 0], [0, 1]])\n",
    "\n",
    "params = genData.genParams(rrMeans=rrs, pis=pis, afMean=afMean, rrShape=rrShape, afShape=afShape, nCases=nCases, nCtrls=nCtrls)[0]\n",
    "testData = generatingFn(**params, covShared=covShared, covSingle=covSingle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nGenes': 20000,\n",
       " 'nCases': tensor([15000., 15000.,  6000.]),\n",
       " 'nCtrls': tensor(300000.),\n",
       " 'pDs': tensor([0.0446, 0.0446, 0.0179]),\n",
       " 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]),\n",
       " 'rrShape': tensor(50.),\n",
       " 'rrMeans': tensor([1.5000, 1.5000, 1.5000]),\n",
       " 'afShape': tensor(50.),\n",
       " 'afMean': 0.0001}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdCtrl, pd1, pd2, pdBoth:  tensor([0.8929, 0.0446, 0.0446, 0.0179], dtype=torch.float64)\n",
      "DOING IT\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ffb131a3dd0>\n",
      "best ll: 88870.30258883575, bestParams: [0.046318885, 0.010737355, 0.039105527, 6095.37, 22289.193, 23849.473, 7651.473]\n",
      "Epoch took 70.15880513191223\n"
     ]
    }
   ],
   "source": [
    "testFit = likelihoods.fitFnBivariate(testData[\"altCounts\"], params[\"pDs\"], nEpochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.80034960e-02, 5.06226849e-02, 4.08778335e-02, 1.39208014e+02,\n",
       "        3.32159605e+02, 3.14389955e+02, 3.62098777e+02])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFit[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdCtrl, pd1, pd2, pdBoth:  tensor([0.8929, 0.0446, 0.0446, 0.0179], dtype=torch.float64)\n",
      "DOING IT\n",
      "method annealing costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ffb00a66a70>\n",
      "Epoch took 860.3144640922546\n"
     ]
    }
   ],
   "source": [
    "testFit2 = likelihoods.fitFnBivariate(testData[\"altCounts\"], params[\"pDs\"], nEpochs=1,method=\"annealing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.40492863e-02, 4.49347770e-02, 3.71856771e-02, 2.71023054e+03,\n",
       "        7.28987257e+03, 6.95473597e+03, 6.89301047e+03])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFit2[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFit3 = likelihoods.fitFnBivariateMT(testData[\"altCounts\"], params[\"pDs\"], nEpochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFit3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.40492863e-02, 4.49347770e-02, 3.71856771e-02, 2.71023054e+03,\n",
       "        7.28987257e+03, 6.95473597e+03, 6.89301047e+03])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFit2[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFit3 = testFit3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lls', 'llsAll', 'params', 'trajectoryLLs', 'trajectoryPi', 'trajectoryAlphas'])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFit.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-853204ceb2a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestFit3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trajectoryLLs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "pyplot.plot(testFit3[\"trajectoryLLs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tensor(testFit3[\"trajectoryAlphas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestLL = None\n",
    "bestParams = None\n",
    "for x in testFit3:\n",
    "    if bestLL is None or x[\"lls\"][0] < bestLL:\n",
    "        bestParams = x[\"params\"][0]\n",
    "        bestLL = x[\"lls\"][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9a25e99d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(t[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9925c6090>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(t[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9d1115450>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(t[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe981056510>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(t[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pisTraj = tensor(testFit3[\"trajectoryPi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9812d5850>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTraj[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9a273ebd0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTraj[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe9a2739750>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTraj[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88750.1171875"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestParams = tensor(bestParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.6565e-02, 4.8880e-02, 3.8951e-02, 2.1546e+03, 5.1478e+03, 5.0106e+03,\n",
       "        5.8097e+03], dtype=torch.float64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCounts = testData[\"altCounts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8929, 0.0446, 0.0446, 0.0179])\n"
     ]
    }
   ],
   "source": [
    "testUnaffectedGenes = testData[\"unaffectedGenes\"]\n",
    "testAffectedGenes = testData[\"affectedGenes\"]\n",
    "testAllPDs = tensor([1-params[\"pDs\"].sum(), *params[\"pDs\"]])\n",
    "print(testAllPDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesFactor(n, altCount,pDs,rrMeans,rrsShape,afMeans,afShape,alpha0, alpha1, alpha2, alphaBoth):\n",
    "bfsUnaffected = []\n",
    "for unaffectedGene in testUnaffectedGenes:\n",
    "    testCount = testCounts[unaffectedGene]\n",
    "    bfsUnaffected.append(bayes.bayesFactor(testCount.sum(), testCount, testAllPDs, bestParams[0:3], bestParams[3:]))\n",
    "bfsUnaffected = tensor(bfsUnaffected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0125e-01, 8.5311e-06, 1.6218e-04,  ..., 3.2103e-04, 1.1671e-04,\n",
       "        5.6422e-03], dtype=torch.float64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfsUnaffected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bfsUnaffected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-64ff8b083210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbfsUnaffected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bfsUnaffected' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesFactor(n, altCount,pDs,rrMeans,rrsShape,afMeans,afShape,alpha0, alpha1, alpha2, alphaBoth):\n",
    "bfsAffected1 = []\n",
    "for affectedGene in testAffectedGenes[0]:\n",
    "    print(affectedGene, \"count:\", testCounts[affectedGene])\n",
    "    testCount = testCounts[affectedGene]\n",
    "    bfsAffected.append(bayes.bayesFactor(testCount.sum(), testCount, testAllPDs, bestParams[0:3], bestParams[3:]))\n",
    "bfsAffected1 = tensor(bfsAffected1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesFactor(n, altCount,pDs,rrMeans,rrsShape,afMeans,afShape,alpha0, alpha1, alpha2, alphaBoth):\n",
    "bfsAffected2 = []\n",
    "for affectedGene in testAffectedGenes[1]:\n",
    "    print(affectedGene, \"count:\", testCounts[affectedGene])\n",
    "    testCount = testCounts[affectedGene]\n",
    "    bfsAffected2.append(bayes.bayesFactor(testCount.sum(), testCount, testAllPDs, bestParams[0:3], bestParams[3:]))\n",
    "bfsAffected2 = tensor(bfsAffected2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfsAffected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = tensor([[1.6166e+04, 2.5759e+01, 3.6084e+01, 4.1214e+00],\n",
    "        [1.6166e+04, 8.0828e+02, 4.9681e+02, 1.9872e+02],\n",
    "        [1.6166e+04, 7.1153e+01, 6.7573e+01, 1.4933e+01]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['altCounts', 'afs', 'affectedGenes', 'unaffectedGenes', 'rrs'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testCounts.shape torch.Size([20000, 4])\n",
      "expanded torch.Size([20000, 3, 4])\n",
      "shapes: n torch.Size([20000, 3]), alphas: torch.Size([20000, 3, 4]) counts: torch.Size([20000, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "n = testCounts.sum(1).expand(3, len(testCounts)).T\n",
    "alphas = tensor([1.77041095e+02,\n",
    "       4.05096749e+02, 3.78310762e+02, 4.93211627e+02])\n",
    "a0 = alphas[0]\n",
    "a1 = alphas[1]\n",
    "a2 = alphas[2]\n",
    "a3 = alphas[3]\n",
    "alphas2 = testAllPDs * tensor([[a0,a1,a0,a1], [a0,a0,a1,a1], [a0, a1+a3, a2+a3, a1+a2+a3]])\n",
    "alphas2 = alphas2.expand(20_000, 3, 4)\n",
    "print(\"testCounts.shape\",testCounts.shape)\n",
    "testCounts2 = testCounts.expand(3, 20_000, 4).transpose(0,1)\n",
    "print(\"expanded\", testCounts.expand(3, 20_000, 4).transpose(0,1).shape)\n",
    "print(f\"shapes: n {n.shape}, alphas: {alphas2.shape} counts: {testCounts2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([20000, 3, 1]) torch.Size([20000, 3, 4])\n",
      "past\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.6811,  -7.6378,  -7.5507],\n",
       "        [ -9.4881, -13.3662,  -7.5881],\n",
       "        [ -8.8253,  -7.5478,  -5.7675],\n",
       "        ...,\n",
       "        [ -3.8760,  -5.3455,  -9.6926],\n",
       "        [ -5.9153,  -4.3251, -12.1820],\n",
       "        [ -3.7168,  -5.1863,  -8.7299]], dtype=torch.float64)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyro.distributions import DirichletMultinomial\n",
    "#. this output is: nGenes by nHypotheses; 1 hypothesis per column\n",
    "t = DirichletMultinomial(total_count = n, concentration=alphas2).log_prob(testCounts2)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.5507, dtype=torch.float64)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([34., 34., 34.], dtype=torch.float64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 genes, 3 hypothesis\n",
    "nt = tensor([1,1,1,1]).expand(3,4).T\n",
    "nt\n",
    "n.expand(3, len(n)).T[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([3, 1]) torch.Size([3, 4])\n",
      "past\n",
      "torch.Size([20000, 3, 4])\n",
      "shapes torch.Size([3, 1]) torch.Size([3, 4])\n",
      "past\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-4.2950, -2.3979, -3.3142],\n",
       "        [-3.1964, -3.0910, -3.0910],\n",
       "        [-2.9087, -1.9924, -2.3979],\n",
       "        ...,\n",
       "        [-1.9924, -3.0910, -4.7005],\n",
       "        [-3.1964, -2.2156, -1.9924],\n",
       "        [-2.3979, -2.2156, -3.0910]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = DirichletMultinomial(total_count=tensor([3., 3, 3.]),concentration=tensor([[1.,2.,3,4],[1.,2,3,4],[1.,2,3,4]])).sample([20_000])\n",
    "\n",
    "# total_count is hypotheses by 1 , concentration is hypotheses by sampleCategories, output is nGenes by hypotheses by sampleCategories\n",
    "r.shape\n",
    "\n",
    "print(r.shape)\n",
    "\n",
    "# the sample shape is compatible with log_prob\n",
    "DirichletMultinomial(total_count=tensor([3., 3, 3.]),concentration=tensor([[1.,2.,3,4],[1.,2,3,4],[1.,2,3,4]])).log_prob(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mis_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Compound distribution comprising of a dirichlet-multinomial pair. The probability of\n",
       "classes (``probs`` for the :class:`~pyro.distributions.Multinomial` distribution)\n",
       "is unknown and randomly drawn from a :class:`~pyro.distributions.Dirichlet`\n",
       "distribution prior to a certain number of Categorical trials given by\n",
       "``total_count``.\n",
       "\n",
       ":param float or torch.Tensor concentration: concentration parameter (alpha) for the\n",
       "    Dirichlet distribution.\n",
       ":param int or torch.Tensor total_count: number of Categorical trials.\n",
       ":param bool is_sparse: Whether to assume value is mostly zero when computing\n",
       "    :meth:`log_prob`, which can speed up computation when data is sparse.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
