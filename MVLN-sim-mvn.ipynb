{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyro\n",
    "# import torch\n",
    "# import torch.tensor as tensor\n",
    "# import pyro.distributions as dist\n",
    "# # from torch.distributions import Binomial, Gamma, Uniform\n",
    "# from pyro.distributions import Binomial, Bernoulli, Categorical, Dirichlet, DirichletMultinomial, Beta, BetaBinomial, Uniform, Gamma, Multinomial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from skopt import gp_minimize \n",
    "from scipy.stats import binom as ScipyBinom\n",
    "from matplotlib import pyplot\n",
    "from torch import tensor\n",
    "\n",
    "from collections import namedtuple\n",
    "import time\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvl import genData, likelihoods, bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([2.0000, 2.0000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[4.3519, 2.7890, 5.5548],\n",
      "        [2.8917, 4.4436, 5.2706],\n",
      "        [3.8678, 4.4712, 5.3107],\n",
      "        ...,\n",
      "        [4.7168, 4.2715, 6.7835],\n",
      "        [4.6791, 3.9330, 4.3859],\n",
      "        [2.6210, 1.9142, 4.4797]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.120481967926025\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[39., 10.,  0.,  3.],\n",
      "        [42.,  3.,  2.,  1.],\n",
      "        [50.,  3.,  2.,  0.],\n",
      "        ...,\n",
      "        [45.,  3.,  5.,  0.],\n",
      "        [60.,  0.,  1.,  2.],\n",
      "        [40.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "n tensor([52., 48., 55.,  ..., 53., 63., 42.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([10.,  3.,  3.,  ...,  3.,  0.,  1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 2.,  ..., 5., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 0.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[39., 10.,  0.,  3.],\n",
      "        [42.,  3.,  2.,  1.],\n",
      "        [50.,  3.,  2.,  0.],\n",
      "        ...,\n",
      "        [45.,  3.,  5.,  0.],\n",
      "        [60.,  0.,  1.,  2.],\n",
      "        [40.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([4.9863e-09, 7.6293e-03, 1.8464e-02,  ..., 8.1738e-04, 6.4453e-03,\n",
      "        3.3431e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8ac3320>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91056.366085773, bestParams: [0.021506596, 0.032269087, 0.032386456, 7456.216, 13592.753, 24910.842, 18917.502]\n",
      "epoch 0\n",
      "     fun: 90678.94727806201\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18988\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.49893948e-02, 4.43790738e-02, 4.08915328e-02, 8.60818913e+03,\n",
      "       2.44622045e+04, 2.48735515e+04, 2.14801207e+04])\n",
      "best ll: 91026.39509861523, bestParams: [0.11172657, 0.090561226, 0.053274393, 6340.836, 12428.718, 19741.955, 19129.791]\n",
      "epoch 1\n",
      "     fun: 90680.17847220492\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18535\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.87069860e-02, 4.87180474e-02, 4.18491463e-02, 9.10768397e+03,\n",
      "       2.46671325e+04, 2.48377120e+04, 2.38725486e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90935.85000957745, bestParams: [0.049423933, 0.009214227, 0.066587955, 8144.4087, 14092.45, 19146.107, 19184.744]\n",
      "epoch 2\n",
      "     fun: 90679.69408391253\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24517\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.51746074e-02, 4.28823114e-02, 4.09115182e-02, 8.49052334e+03,\n",
      "       2.41057989e+04, 2.49310807e+04, 2.09977006e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90968.04260795636, bestParams: [0.04376411, 0.00947107, 0.026495688, 2897.8872, 12433.758, 12579.159, 2175.1257]\n",
      "epoch 3\n",
      "     fun: 90682.20345662584\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21464\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.62273012e-02, 4.13341282e-02, 4.08307518e-02, 7.30724926e+03,\n",
      "       2.05368423e+04, 2.18005268e+04, 1.80006693e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 91230.94646826506, bestParams: [0.027580375, 0.03263207, 0.086327404, 9526.828, 13395.509, 20715.258, 16864.232]\n",
      "epoch 4\n",
      "     fun: 90680.42392596879\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21184\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93687837e-02, 4.50462777e-02, 4.14165165e-02, 8.13320033e+03,\n",
      "       2.20223509e+04, 2.30949390e+04, 2.09459093e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90891.22837955202, bestParams: [0.022499898, 0.05500002, 0.05387609, 7606.9336, 16116.186, 22950.53, 17725.414]\n",
      "epoch 5\n",
      "     fun: 91005.564852588\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19023\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.05560857e-01, 2.51295019e-02, 6.86739003e-02, 1.10150214e+04,\n",
      "       1.19546860e+04, 2.49755966e+04, 2.49999999e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90793.50734448066, bestParams: [0.04312596, 0.061409917, 0.055109084, 7393.3057, 17826.643, 19793.965, 14590.254]\n",
      "epoch 6\n",
      "     fun: 90682.98088077307\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29244\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.58835926e-02, 4.48804886e-02, 4.12324058e-02, 7.13580347e+03,\n",
      "       1.99591999e+04, 2.03665212e+04, 1.80069887e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90774.11209833511, bestParams: [0.029333118, 0.048051648, 0.034722798, 7021.4785, 19031.883, 23899.84, 18605.693]\n",
      "epoch 7\n",
      "     fun: 90677.6685678917\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18468\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.81858369e-02, 4.78172584e-02, 4.15692111e-02, 8.98392723e+03,\n",
      "       2.45434465e+04, 2.48292644e+04, 2.33467772e+04])\n",
      "minPrevious 90678.94727806201\n",
      "better by at >= 1; new ll:      fun: 90677.6685678917\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18468\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.81858369e-02, 4.78172584e-02, 4.15692111e-02, 8.98392723e+03,\n",
      "       2.45434465e+04, 2.48292644e+04, 2.33467772e+04])\n",
      "best ll: 90875.25550642482, bestParams: [0.052991223, 0.082086444, 0.03636626, 6475.547, 23251.305, 18497.258, 20307.602]\n",
      "epoch 8\n",
      "     fun: 90682.68245423601\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23101\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.50358851e-02, 4.28777768e-02, 4.09910386e-02, 4.24521045e+03,\n",
      "       1.20207836e+04, 1.24023136e+04, 1.05078487e+04])\n",
      "minPrevious 90677.6685678917\n",
      "best ll: 91548.96528524201, bestParams: [0.10768495, 0.22162051, 0.123172745, 3700.1165, 5095.398, 5719.5654, 14934.215]\n",
      "epoch 9\n",
      "     fun: 90684.1404879048\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18986\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.07374035e-02, 5.12185329e-02, 4.29776595e-02, 9.51878104e+03,\n",
      "       2.49567942e+04, 2.49907370e+04, 2.49999993e+04])\n",
      "minPrevious 90677.6685678917\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0482, 0.0478, 0.0416], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8889, 0.0632, 0.0281, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8732, 0.0716, 0.0262, 0.0290], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8816, 0.0280, 0.0648, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8726, 0.0261, 0.0723, 0.0289], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7458, 0.0981, 0.0993, 0.0618], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7052, 0.1128, 0.1135, 0.0685], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4189, 2.2110, 5.3853],\n",
      "        [2.8835, 1.5863, 4.1315],\n",
      "        [3.3437, 2.7164, 3.9165],\n",
      "        ...,\n",
      "        [3.8215, 3.8713, 6.7122],\n",
      "        [2.9858, 2.3850, 5.4729],\n",
      "        [3.9595, 3.6556, 5.0114]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.392677068710327\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[51.,  1.,  1.,  0.],\n",
      "        [49.,  6.,  3.,  0.],\n",
      "        [51.,  3.,  4.,  2.],\n",
      "        ...,\n",
      "        [52.,  1.,  2.,  0.],\n",
      "        [40.,  2.,  1.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 58., 60.,  ..., 55., 43., 45.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 3.,  ..., 1., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 4.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 2.,  ..., 0., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[51.,  1.,  1.,  0.],\n",
      "        [49.,  6.,  3.,  0.],\n",
      "        [51.,  3.,  4.,  2.],\n",
      "        ...,\n",
      "        [52.,  1.,  2.,  0.],\n",
      "        [40.,  2.,  1.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0623, 0.0003, 0.0009,  ..., 0.0464, 0.0503, 0.0438],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc680>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91239.19500249799, bestParams: [0.07369001, 0.04880978, 0.06687576, 4858.3516, 16533.74, 12923.512, 14745.741]\n",
      "epoch 0\n",
      "     fun: 90861.78577540864\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 28688\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.39126641e-02, 4.43361706e-02, 4.16877774e-02, 6.30811938e+03,\n",
      "       1.80875402e+04, 1.85093776e+04, 1.54715766e+04])\n",
      "best ll: 91471.4697084639, bestParams: [0.015408821, 0.025966937, 0.018776404, 6470.502, 16699.875, 22305.629, 7609.0425]\n",
      "epoch 1\n",
      "     fun: 90860.74902260769\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21083\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.31587597e-02, 4.55204559e-02, 4.21324394e-02, 8.65442240e+03,\n",
      "       2.47671562e+04, 2.49529431e+04, 2.13176385e+04])\n",
      "minPrevious 90861.78577540864\n",
      "better by at >= 1; new ll:      fun: 90860.74902260769\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21083\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.31587597e-02, 4.55204559e-02, 4.21324394e-02, 8.65442240e+03,\n",
      "       2.47671562e+04, 2.49529431e+04, 2.13176385e+04])\n",
      "best ll: 91429.35879988143, bestParams: [0.036266495, 0.03656501, 0.00981962, 4553.329, 23323.432, 16778.275, 3984.7922]\n",
      "epoch 2\n",
      "     fun: 90860.63394312932\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18826\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97057539e-02, 4.15170068e-02, 4.13327845e-02, 6.41557828e+03,\n",
      "       1.93464752e+04, 1.95896200e+04, 1.48570035e+04])\n",
      "minPrevious 90860.74902260769\n",
      "best ll: 91222.69810706898, bestParams: [0.03356081, 0.050940458, 0.040049728, 7300.6055, 11934.092, 23776.432, 21303.281]\n",
      "epoch 3\n",
      "     fun: 90859.43670833748\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22341\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56721447e-02, 4.79972960e-02, 4.25334885e-02, 8.95537658e+03,\n",
      "       2.48353903e+04, 2.49872164e+04, 2.28056060e+04])\n",
      "minPrevious 90860.74902260769\n",
      "better by at >= 1; new ll:      fun: 90859.43670833748\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22341\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56721447e-02, 4.79972960e-02, 4.25334885e-02, 8.95537658e+03,\n",
      "       2.48353903e+04, 2.49872164e+04, 2.28056060e+04])\n",
      "best ll: 91364.8767937252, bestParams: [0.22571534, 0.056864273, 0.07466884, 3741.4695, 6438.2812, 5871.1465, 15020.482]\n",
      "epoch 4\n",
      "     fun: 90860.23925054408\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22079\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.20028461e-02, 4.19424135e-02, 4.15822628e-02, 5.57662948e+03,\n",
      "       1.63079514e+04, 1.68432533e+04, 1.32242383e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91071.14442199793, bestParams: [0.09720786, 0.055112377, 0.06380207, 4636.733, 11534.753, 14002.477, 10913.797]\n",
      "epoch 5\n",
      "     fun: 90860.33036181553\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24815\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.16976590e-02, 4.24385731e-02, 4.17443828e-02, 4.79041325e+03,\n",
      "       1.40148252e+04, 1.43427167e+04, 1.13953899e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91144.26979706812, bestParams: [0.08022128, 0.08162482, 0.048925202, 8952.077, 16154.056, 24275.29, 19940.611]\n",
      "epoch 6\n",
      "     fun: 90858.7804887991\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16708\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.20979808e-02, 4.37486171e-02, 4.17546498e-02, 8.45101922e+03,\n",
      "       2.46176087e+04, 2.49695229e+04, 2.03637448e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91115.36426809937, bestParams: [0.05724043, 0.021042777, 0.07642279, 6261.3833, 16376.353, 23784.773, 8266.063]\n",
      "epoch 7\n",
      "     fun: 90859.69647791091\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19043\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.34963888e-02, 4.37891214e-02, 4.20289844e-02, 8.15363124e+03,\n",
      "       2.33686949e+04, 2.39683522e+04, 1.98420756e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91651.64624185565, bestParams: [0.046107255, 0.09424183, 0.00989835, 2757.5513, 14618.052, 10251.086, 9000.875]\n",
      "epoch 8\n",
      "     fun: 90859.06008520466\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20575\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44481442e-02, 4.75969522e-02, 4.21778176e-02, 8.81335975e+03,\n",
      "       2.48539057e+04, 2.48395582e+04, 2.23569747e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91065.11635174009, bestParams: [0.0242683, 0.053031314, 0.058199123, 5144.2104, 20661.969, 15971.761, 13266.957]\n",
      "epoch 9\n",
      "     fun: 90861.08577821162\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20001\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.19851050e-02, 4.17801837e-02, 4.15084630e-02, 7.28268698e+03,\n",
      "       2.13122623e+04, 2.20660360e+04, 1.72448063e+04])\n",
      "minPrevious 90859.43670833748\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0457, 0.0480, 0.0425], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8782, 0.0624, 0.0278, 0.0249], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8721, 0.0725, 0.0262, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8817, 0.0280, 0.0644, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8718, 0.0261, 0.0729, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7358, 0.0987, 0.0983, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7057, 0.1127, 0.1130, 0.0687], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.9071, 4.0096, 5.7722],\n",
      "        [3.1442, 3.7642, 4.7613],\n",
      "        [1.9910, 3.6197, 4.2653],\n",
      "        ...,\n",
      "        [2.0181, 4.2217, 4.7949],\n",
      "        [2.6019, 2.7535, 6.2110],\n",
      "        [2.9164, 2.6361, 4.6614]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.5227882862091064\n",
      "Run: 0, 2\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[27.,  4.,  2.,  2.],\n",
      "        [48.,  1.,  1.,  0.],\n",
      "        [41.,  2.,  1.,  3.],\n",
      "        ...,\n",
      "        [48.,  3.,  0.,  1.],\n",
      "        [49.,  2.,  3.,  1.],\n",
      "        [37.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([35., 50., 47.,  ..., 52., 55., 39.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 1., 2.,  ..., 3., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 0., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 3.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[27.,  4.,  2.,  2.],\n",
      "        [48.,  1.,  1.,  0.],\n",
      "        [41.,  2.,  1.,  3.],\n",
      "        ...,\n",
      "        [48.,  3.,  0.,  1.],\n",
      "        [49.,  2.,  3.,  1.],\n",
      "        [37.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([9.1044e-05, 6.8182e-02, 1.1450e-03,  ..., 9.4407e-03, 1.1078e-02,\n",
      "        8.8612e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc290>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91007.93332294546, bestParams: [0.0857708, 0.027353209, 0.056023873, 8389.133, 21786.912, 16894.488, 17575.045]\n",
      "epoch 0\n",
      "     fun: 90741.29185131165\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16482\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.23376169e-02, 4.93065527e-02, 4.38559895e-02, 9.47084934e+03,\n",
      "       2.48940172e+04, 2.48822170e+04, 2.49999981e+04])\n",
      "best ll: 91224.73436774276, bestParams: [0.043282628, 0.04283247, 0.015615053, 3965.399, 15119.752, 11289.01, 20118.45]\n",
      "epoch 1\n",
      "     fun: 90968.17657566987\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 39572\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.99538244e-02, 2.93838522e-01, 5.58080675e-02, 5.08857742e+03,\n",
      "       9.48498524e+03, 6.15838872e+03, 1.74503829e+04])\n",
      "minPrevious 90741.29185131165\n",
      "best ll: 90881.52796996137, bestParams: [0.057814863, 0.036603197, 0.048284452, 6125.3677, 14977.148, 11782.217, 16754.512]\n",
      "epoch 2\n",
      "     fun: 90729.455342717\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19418\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.65090442e-02, 4.45915397e-02, 4.23747175e-02, 8.80405812e+03,\n",
      "       2.49621024e+04, 2.48324605e+04, 2.18698763e+04])\n",
      "minPrevious 90741.29185131165\n",
      "better by at >= 1; new ll:      fun: 90729.455342717\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19418\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.65090442e-02, 4.45915397e-02, 4.23747175e-02, 8.80405812e+03,\n",
      "       2.49621024e+04, 2.48324605e+04, 2.18698763e+04])\n",
      "best ll: 91326.07627551297, bestParams: [0.095849864, 0.09590016, 0.092939384, 7666.34, 6450.7437, 15030.143, 23817.498]\n",
      "epoch 3\n",
      "     fun: 90729.30744291696\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22517\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.37379352e-02, 4.05152351e-02, 4.17252985e-02, 8.39802978e+03,\n",
      "       2.47668799e+04, 2.49916565e+04, 1.98267634e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91016.03464464155, bestParams: [0.06892339, 0.08220619, 0.041249212, 10588.921, 24391.959, 19792.424, 22084.648]\n",
      "epoch 4\n",
      "     fun: 90959.0438262211\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19051\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.16422571e-02, 8.50540140e-01, 5.78171661e-02, 5.56689535e+03,\n",
      "       9.72820890e+03, 5.85802465e+03, 1.96208622e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91027.85668282304, bestParams: [0.03505238, 0.044490505, 0.027420068, 6133.5425, 23373.82, 13148.674, 14960.702]\n",
      "epoch 5\n",
      "     fun: 90735.7505212659\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18858\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.04506841e-02, 4.75836595e-02, 4.31450513e-02, 9.25332768e+03,\n",
      "       2.49542178e+04, 2.49510328e+04, 2.40224887e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91344.33768614761, bestParams: [0.053518336, 0.08740302, 0.067629404, 6031.661, 18487.89, 9499.573, 9493.0]\n",
      "epoch 6\n",
      "     fun: 90742.86427037211\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 15856\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.25172955e-02, 4.97425219e-02, 4.43748053e-02, 9.57142437e+03,\n",
      "       2.49836514e+04, 2.48985330e+04, 2.49999996e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91210.99558153439, bestParams: [0.015522353, 0.020422507, 0.02180805, 5947.9175, 24499.941, 23246.885, 23200.797]\n",
      "epoch 7\n",
      "     fun: 90731.14997350496\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23205\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.28252218e-02, 3.99237022e-02, 4.15478607e-02, 6.40159151e+03,\n",
      "       1.90431847e+04, 1.92309877e+04, 1.49437001e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91095.22483766638, bestParams: [0.07067214, 0.03771307, 0.054919243, 6992.266, 20875.805, 19603.213, 6386.5703]\n",
      "epoch 8\n",
      "     fun: 90730.85085085777\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20929\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.53289295e-02, 4.27071902e-02, 4.20085505e-02, 8.40268795e+03,\n",
      "       2.42169186e+04, 2.42700284e+04, 2.04402196e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91393.03288045904, bestParams: [0.017872097, 0.053617258, 0.039089, 1954.1438, 5562.4053, 1457.8615, 7767.6426]\n",
      "epoch 9\n",
      "     fun: 90733.01401258064\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 31233\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.60272951e-02, 4.06109139e-02, 4.20647643e-02, 6.14139763e+03,\n",
      "       1.75751538e+04, 1.81183570e+04, 1.47902926e+04])\n",
      "minPrevious 90729.455342717\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0465, 0.0446, 0.0424], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8839, 0.0639, 0.0280, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8704, 0.0741, 0.0261, 0.0295], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8829, 0.0280, 0.0636, 0.0254], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8708, 0.0261, 0.0737, 0.0295], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7400, 0.0995, 0.0966, 0.0611], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7060, 0.1126, 0.1124, 0.0690], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.8960, 3.3836, 5.0518],\n",
      "        [3.8514, 4.7767, 6.8971],\n",
      "        [4.0691, 2.5010, 4.6004],\n",
      "        ...,\n",
      "        [4.4449, 3.2959, 3.9365],\n",
      "        [4.3674, 3.9315, 8.1608],\n",
      "        [3.6398, 2.5625, 7.4278]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.356298923492432\n",
      "Run: 0, 3\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[48.,  2.,  1.,  0.],\n",
      "        [41.,  3.,  2.,  2.],\n",
      "        [55.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [58.,  2.,  2.,  1.],\n",
      "        [48.,  2.,  0.,  0.],\n",
      "        [35.,  2.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([51., 48., 59.,  ..., 63., 50., 39.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 3.,  ..., 2., 2., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 0.,  ..., 2., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 1.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[48.,  2.,  1.,  0.],\n",
      "        [41.,  3.,  2.,  2.],\n",
      "        [55.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [58.,  2.,  2.,  1.],\n",
      "        [48.,  2.,  0.,  0.],\n",
      "        [35.,  2.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0487, 0.0019, 0.0098,  ..., 0.0257, 0.0341, 0.0266],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad03b00>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91021.23597877396, bestParams: [0.02387655, 0.09362935, 0.0531731, 8440.324, 13937.0, 11477.793, 16246.775]\n",
      "epoch 0\n",
      "     fun: 90367.46646443212\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18738\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.85798503e-02, 3.12189972e-02, 4.14406663e-02, 7.79360605e+03,\n",
      "       2.38725780e+04, 2.46992225e+04, 1.68480061e+04])\n",
      "best ll: 90814.01155907288, bestParams: [0.092853814, 0.079595976, 0.09696471, 9648.206, 12964.165, 13710.112, 22609.943]\n",
      "epoch 1\n",
      "     fun: 90370.16992066184\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20256\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.06782851e-02, 3.05888247e-02, 4.18256058e-02, 3.30614673e+03,\n",
      "       9.80870940e+03, 1.04315332e+04, 7.28013746e+03])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90693.35079318719, bestParams: [0.05039767, 0.07389942, 0.05925788, 5015.5117, 11736.682, 7729.9805, 10372.028]\n",
      "epoch 2\n",
      "     fun: 90544.51615211637\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26660\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([1.15173636e-01, 8.27076011e-01, 5.75481400e-02, 4.88184316e+03,\n",
      "       7.22753220e+03, 5.23483166e+03, 1.76610229e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90928.8394107176, bestParams: [0.08049662, 0.08387433, 0.06717268, 7118.226, 9401.673, 19610.592, 16397.375]\n",
      "epoch 3\n",
      "     fun: 90369.26401926341\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27176\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.55837197e-02, 3.36905447e-02, 4.29108512e-02, 6.71586563e+03,\n",
      "       1.85568972e+04, 1.98110040e+04, 1.60601036e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90849.15617868747, bestParams: [0.041133363, 0.06851273, 0.07244423, 6477.3115, 20420.096, 20529.924, 4543.0527]\n",
      "epoch 4\n",
      "     fun: 90369.74538215327\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 25662\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.46136940e-02, 3.52382008e-02, 4.29644138e-02, 7.05933251e+03,\n",
      "       1.96641948e+04, 2.05584337e+04, 1.69372313e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 91003.55947153617, bestParams: [0.020014536, 0.16380043, 0.05750044, 6207.0884, 6395.382, 14223.492, 21751.719]\n",
      "epoch 5\n",
      "     fun: 90366.05074559979\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19246\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44379285e-02, 3.86546502e-02, 4.30928573e-02, 8.90523070e+03,\n",
      "       2.47945943e+04, 2.48658296e+04, 2.19264077e+04])\n",
      "minPrevious 90367.46646443212\n",
      "better by at >= 1; new ll:      fun: 90366.05074559979\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19246\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44379285e-02, 3.86546502e-02, 4.30928573e-02, 8.90523070e+03,\n",
      "       2.47945943e+04, 2.48658296e+04, 2.19264077e+04])\n",
      "best ll: 90749.3357777144, bestParams: [0.054987807, 0.042462654, 0.019732246, 3481.5046, 8180.3594, 12040.532, 16030.645]\n",
      "epoch 6\n",
      "     fun: 90370.04277355093\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19775\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13956855e-02, 2.99751012e-02, 4.19297763e-02, 3.18547370e+03,\n",
      "       9.37089224e+03, 1.01267621e+04, 6.99713684e+03])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90595.93835730849, bestParams: [0.049502358, 0.05059789, 0.035600856, 5736.8604, 11006.914, 12817.075, 13380.541]\n",
      "epoch 7\n",
      "     fun: 90369.03492576667\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29654\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.43124944e-02, 3.33712831e-02, 4.27940979e-02, 6.64796216e+03,\n",
      "       1.85760876e+04, 1.98131480e+04, 1.58021285e+04])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90746.22974235666, bestParams: [0.111383274, 0.080073506, 0.042195205, 10159.44, 15388.807, 19346.172, 23211.58]\n",
      "epoch 8\n",
      "     fun: 90366.30277732995\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19017\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.62580895e-02, 3.77157167e-02, 4.32366444e-02, 8.81877383e+03,\n",
      "       2.40797226e+04, 2.47941350e+04, 2.18330276e+04])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90855.43160734844, bestParams: [0.07542367, 0.05570492, 0.015105497, 9331.249, 23335.158, 21321.234, 19561.578]\n",
      "epoch 9\n",
      "     fun: 90554.8816047398\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19215\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.37802480e-01, 6.55243135e-02, 5.54580874e-02, 5.84354058e+03,\n",
      "       6.36484808e+03, 1.06079831e+04, 2.04911301e+04])\n",
      "minPrevious 90366.05074559979\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0444, 0.0387, 0.0431], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8801, 0.0644, 0.0279, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8718, 0.0728, 0.0261, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8782, 0.0278, 0.0636, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8716, 0.0262, 0.0730, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7428, 0.0992, 0.0988, 0.0623], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7085, 0.1115, 0.1117, 0.0683], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7070, 3.3558, 5.7385],\n",
      "        [6.1712, 4.8968, 6.0728],\n",
      "        [5.5908, 6.0105, 9.0300],\n",
      "        ...,\n",
      "        [3.5412, 2.9084, 6.2405],\n",
      "        [4.0371, 3.8411, 6.2719],\n",
      "        [4.3172, 3.5554, 6.5065]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.310091972351074\n",
      "Run: 0, 4\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[46.,  3.,  2.,  2.],\n",
      "        [45.,  3.,  0.,  3.],\n",
      "        [54.,  5.,  1.,  4.],\n",
      "        ...,\n",
      "        [48.,  1.,  0.,  0.],\n",
      "        [40.,  2.,  1.,  1.],\n",
      "        [40.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 51., 64.,  ..., 49., 44., 42.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 5.,  ..., 1., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 1.,  ..., 0., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 4.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[46.,  3.,  2.,  2.],\n",
      "        [45.,  3.,  0.,  3.],\n",
      "        [54.,  5.,  1.,  4.],\n",
      "        ...,\n",
      "        [48.,  1.,  0.,  0.],\n",
      "        [40.,  2.,  1.,  1.],\n",
      "        [40.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.8431e-03, 4.8473e-04, 3.3705e-05,  ..., 4.8727e-02, 2.4768e-02,\n",
      "        8.3579e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc950>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91345.08023811383, bestParams: [0.06884586, 0.015770206, 0.08335171, 3087.4746, 10631.862, 13740.989, 2484.048]\n",
      "epoch 0\n",
      "     fun: 90879.9946159658\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23081\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.24280571e-02, 4.00968936e-02, 3.89581658e-02, 6.72886260e+03,\n",
      "       2.08850194e+04, 2.07802951e+04, 1.66012855e+04])\n",
      "best ll: 90987.4655751705, bestParams: [0.028817432, 0.02610038, 0.034790974, 7775.3364, 23897.207, 21864.736, 15247.122]\n",
      "epoch 1\n",
      "     fun: 90879.06292379234\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19756\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.14930094e-02, 3.82729929e-02, 3.86535609e-02, 7.50684449e+03,\n",
      "       2.37203578e+04, 2.38252110e+04, 1.80371150e+04])\n",
      "minPrevious 90879.9946159658\n",
      "best ll: 91464.60088640705, bestParams: [0.07165316, 0.0929115, 0.01606413, 4874.1367, 14892.382, 17925.348, 7632.4253]\n",
      "epoch 2\n",
      "     fun: 90879.14375478897\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27109\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.03898485e-02, 3.80772820e-02, 3.84634180e-02, 6.62194224e+03,\n",
      "       2.12415051e+04, 2.11538949e+04, 1.57061265e+04])\n",
      "minPrevious 90879.9946159658\n",
      "best ll: 91336.19074409138, bestParams: [0.029090187, 0.039958116, 0.025319178, 4308.908, 9381.063, 14304.205, 7759.76]\n",
      "epoch 3\n",
      "     fun: 90878.55891398477\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20515\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.09047276e-02, 3.79882333e-02, 3.86226516e-02, 5.33505945e+03,\n",
      "       1.69919902e+04, 1.70332626e+04, 1.26987930e+04])\n",
      "minPrevious 90879.9946159658\n",
      "better by at >= 1; new ll:      fun: 90878.55891398477\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20515\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.09047276e-02, 3.79882333e-02, 3.86226516e-02, 5.33505945e+03,\n",
      "       1.69919902e+04, 1.70332626e+04, 1.26987930e+04])\n",
      "best ll: 91335.93185690074, bestParams: [0.035876945, 0.06610922, 0.025485078, 4390.421, 22124.35, 10895.839, 7541.019]\n",
      "epoch 4\n",
      "     fun: 90880.92135410193\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 17484\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.59090218e-02, 4.33322652e-02, 3.96535940e-02, 8.43861685e+03,\n",
      "       2.49337275e+04, 2.48150587e+04, 2.19508901e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91250.95231934264, bestParams: [0.115218244, 0.048142098, 0.051294174, 6320.828, 14317.023, 12362.9, 13260.78]\n",
      "epoch 5\n",
      "     fun: 90878.97808052332\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19609\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.07574831e-02, 3.74625089e-02, 3.83613486e-02, 6.68112794e+03,\n",
      "       2.13446230e+04, 2.15390941e+04, 1.58039078e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91213.35925044058, bestParams: [0.15606245, 0.072391056, 0.046264574, 6354.5464, 13673.771, 19265.758, 22482.443]\n",
      "epoch 6\n",
      "     fun: 90883.28559989628\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19491\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93288901e-02, 4.60300073e-02, 4.03575042e-02, 8.80576916e+03,\n",
      "       2.49172318e+04, 2.48990628e+04, 2.38112812e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91046.46063479605, bestParams: [0.03268646, 0.011289387, 0.026305977, 6561.8726, 20767.113, 23554.947, 11815.014]\n",
      "epoch 7\n",
      "     fun: 90881.05394528931\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18450\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26334934e-02, 3.93476535e-02, 3.90612840e-02, 2.50669000e+03,\n",
      "       7.75529940e+03, 7.77798697e+03, 6.15010134e+03])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91213.77202473817, bestParams: [0.12363709, 0.07303361, 0.03884344, 5911.851, 10551.361, 9712.845, 17378.764]\n",
      "epoch 8\n",
      "     fun: 90879.20283692765\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19674\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.23063429e-02, 3.91398095e-02, 3.88485271e-02, 6.98045708e+03,\n",
      "       2.17313652e+04, 2.18296056e+04, 1.70652713e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91373.61481849875, bestParams: [0.119453534, 0.015104396, 0.048940077, 3980.3694, 9912.681, 20019.787, 4480.772]\n",
      "epoch 9\n",
      "     fun: 90964.70890373456\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16833\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.88640777e-02, 5.48396144e-02, 4.41396663e-02, 7.52303449e+03,\n",
      "       1.61309726e+04, 1.82623724e+04, 2.37081847e+04])\n",
      "minPrevious 90878.55891398477\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0409, 0.0380, 0.0386], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8845, 0.0643, 0.0281, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8593, 0.0821, 0.0257, 0.0329], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8793, 0.0279, 0.0645, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8591, 0.0257, 0.0823, 0.0329], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7472, 0.0997, 0.1000, 0.0626], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6948, 0.1160, 0.1162, 0.0730], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.2669, 1.9767, 5.1363],\n",
      "        [3.5628, 2.9073, 6.2435],\n",
      "        [3.7832, 3.7930, 6.8343],\n",
      "        ...,\n",
      "        [1.9421, 1.4840, 5.1770],\n",
      "        [4.2826, 3.2783, 5.4505],\n",
      "        [3.5943, 2.8795, 6.1372]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.476979970932007\n",
      "Run: 0, 5\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[42.,  5.,  3.,  3.],\n",
      "        [39.,  4.,  0.,  3.],\n",
      "        [43.,  1.,  3.,  0.],\n",
      "        ...,\n",
      "        [54.,  2.,  1.,  1.],\n",
      "        [47.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 46., 47.,  ..., 58., 49., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 4., 1.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 3.,  ..., 1., 1., 3.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 0.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[42.,  5.,  3.,  3.],\n",
      "        [39.,  4.,  0.,  3.],\n",
      "        [43.,  1.,  3.,  0.],\n",
      "        ...,\n",
      "        [54.,  2.,  1.,  1.],\n",
      "        [47.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.0043e-05, 1.0708e-04, 2.2014e-02,  ..., 2.9246e-02, 7.0167e-02,\n",
      "        1.6781e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdcdd0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90857.78330615468, bestParams: [0.065798305, 0.01862657, 0.08375965, 6535.119, 18724.98, 18402.521, 23863.832]\n",
      "epoch 0\n",
      "     fun: 90574.54329233595\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16861\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([8.85348671e-01, 5.79907422e-02, 5.65029340e-02, 4.43107258e+03,\n",
      "       4.70193766e+03, 8.01621143e+03, 1.52672211e+04])\n",
      "best ll: 90647.02931454076, bestParams: [0.006345086, 0.025668247, 0.041042943, 3689.1306, 14496.478, 9464.404, 3974.9004]\n",
      "epoch 1\n",
      "     fun: 90346.79818100025\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22437\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.38988240e-02, 3.73832477e-02, 4.08481269e-02, 5.29178931e+03,\n",
      "       1.53774819e+04, 1.54631092e+04, 1.26597146e+04])\n",
      "minPrevious 90574.54329233595\n",
      "better by at >= 1; new ll:      fun: 90346.79818100025\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22437\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.38988240e-02, 3.73832477e-02, 4.08481269e-02, 5.29178931e+03,\n",
      "       1.53774819e+04, 1.54631092e+04, 1.26597146e+04])\n",
      "best ll: 90701.66978014109, bestParams: [0.051171403, 0.004164878, 0.037289176, 9557.071, 24102.58, 17367.414, 20774.168]\n",
      "epoch 2\n",
      "     fun: 90346.5671615596\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19326\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93206864e-02, 4.19921320e-02, 4.19359552e-02, 9.13554443e+03,\n",
      "       2.47502305e+04, 2.48801472e+04, 2.34591945e+04])\n",
      "minPrevious 90346.79818100025\n",
      "best ll: 91283.78536810011, bestParams: [0.10908244, 0.048394613, 0.10494098, 7852.6562, 4134.3623, 18254.262, 22675.844]\n",
      "epoch 3\n",
      "     fun: 90350.25783864367\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.12992497e-02, 4.44887911e-02, 4.23193013e-02, 9.43948030e+03,\n",
      "       2.49271977e+04, 2.48737002e+04, 2.48733863e+04])\n",
      "minPrevious 90346.79818100025\n",
      "best ll: 90471.10462045555, bestParams: [0.0154586835, 0.069063015, 0.03530776, 5670.462, 21156.191, 15531.642, 14583.196]\n",
      "epoch 4\n",
      "     fun: 90343.67707197007\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21977\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.74123918e-02, 4.08289397e-02, 4.13656120e-02, 8.98044189e+03,\n",
      "       2.49493444e+04, 2.49868195e+04, 2.25900515e+04])\n",
      "minPrevious 90346.79818100025\n",
      "better by at >= 1; new ll:      fun: 90343.67707197007\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21977\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.74123918e-02, 4.08289397e-02, 4.13656120e-02, 8.98044189e+03,\n",
      "       2.49493444e+04, 2.49868195e+04, 2.25900515e+04])\n",
      "best ll: 90477.84335776992, bestParams: [0.04298072, 0.021439154, 0.036853362, 3680.7407, 9893.799, 10063.484, 6246.7983]\n",
      "epoch 5\n",
      "     fun: 90343.78822780929\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19929\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.27018839e-02, 3.55948896e-02, 4.04254643e-02, 8.00020766e+03,\n",
      "       2.37514479e+04, 2.40988899e+04, 1.86050897e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90690.74806032187, bestParams: [0.05707956, 0.04165197, 0.05212749, 5306.5737, 9165.7705, 7847.644, 21851.729]\n",
      "epoch 6\n",
      "     fun: 90347.22406009762\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27937\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.34300152e-02, 3.88849780e-02, 4.11301663e-02, 5.86526976e+03,\n",
      "       1.70700458e+04, 1.67733265e+04, 1.41632998e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90533.48503693526, bestParams: [0.05087774, 0.042099502, 0.04017582, 8607.724, 23974.309, 19314.508, 15243.791]\n",
      "epoch 7\n",
      "     fun: 90344.29825837338\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18976\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.23100412e-02, 3.51282897e-02, 4.02434122e-02, 8.19614332e+03,\n",
      "       2.44955698e+04, 2.49282104e+04, 1.89051281e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 91039.73336329563, bestParams: [0.010360104, 0.0056551113, 0.017288163, 4754.299, 16049.336, 10335.417, 10871.316]\n",
      "epoch 8\n",
      "     fun: 90605.03752168667\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 15852\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.06037770e-01, 3.14303850e-02, 6.25201762e-02, 9.78926227e+03,\n",
      "       1.04937148e+04, 2.09762757e+04, 2.49999997e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90869.42943766556, bestParams: [0.058097538, 0.054223366, 0.0151370205, 7250.6963, 17291.744, 14349.171, 17670.531]\n",
      "epoch 9\n",
      "     fun: 90346.44614650698\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21311\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.12671383e-02, 3.59230494e-02, 4.02898373e-02, 5.12029022e+03,\n",
      "       1.54464584e+04, 1.53887553e+04, 1.18023848e+04])\n",
      "minPrevious 90343.67707197007\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0474, 0.0408, 0.0414], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8833, 0.0641, 0.0280, 0.0256], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8721, 0.0726, 0.0261, 0.0291], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8836, 0.0280, 0.0633, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8720, 0.0262, 0.0728, 0.0291], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7439, 0.0981, 0.0983, 0.0618], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7069, 0.1122, 0.1124, 0.0685], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.5321, 2.1588, 5.2563],\n",
      "        [3.0922, 2.8446, 5.8659],\n",
      "        [2.4312, 3.2523, 5.2012],\n",
      "        ...,\n",
      "        [5.0824, 4.3565, 4.4788],\n",
      "        [1.8716, 3.1835, 5.8296],\n",
      "        [4.0581, 4.7861, 4.6592]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.654811859130859\n",
      "Run: 0, 6\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[38.,  1.,  2.,  0.],\n",
      "        [53.,  2.,  1.,  1.],\n",
      "        [45.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [52.,  1.,  1.,  0.],\n",
      "        [49.,  1.,  2.,  1.],\n",
      "        [55.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([41., 57., 49.,  ..., 54., 53., 58.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 3.,  ..., 1., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 0.,  ..., 1., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 0., 1., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[38.,  1.,  2.,  0.],\n",
      "        [53.,  2.,  1.,  1.],\n",
      "        [45.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [52.,  1.,  1.,  0.],\n",
      "        [49.,  1.,  2.,  1.],\n",
      "        [55.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0499, 0.0292, 0.0091,  ..., 0.0603, 0.0286, 0.0355],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdcef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91089.27396093101, bestParams: [0.0075157364, 0.016659165, 0.0528355, 6167.8413, 16675.133, 23120.914, 2626.2808]\n",
      "epoch 0\n",
      "     fun: 90528.09146807808\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21301\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.22089041e-02, 4.04911316e-02, 4.09398703e-02, 7.87634233e+03,\n",
      "       2.31800900e+04, 2.34644446e+04, 1.90780530e+04])\n",
      "best ll: 90732.33126287756, bestParams: [0.025354784, 0.034044795, 0.03233444, 3831.9717, 18235.803, 15221.045, 8825.367]\n",
      "epoch 1\n",
      "     fun: 90527.19937601546\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19413\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.15413749e-02, 3.99949216e-02, 4.07060772e-02, 7.98855681e+03,\n",
      "       2.37755273e+04, 2.40322552e+04, 1.91271434e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 91108.88783821915, bestParams: [0.086679004, 0.067132905, 0.09949029, 7799.4536, 21237.266, 20044.95, 20242.219]\n",
      "epoch 2\n",
      "     fun: 90528.26860756558\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19659\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26203286e-02, 3.91555797e-02, 4.07703934e-02, 7.61654461e+03,\n",
      "       2.23785640e+04, 2.30843006e+04, 1.83011955e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 90664.09878557731, bestParams: [0.07736944, 0.06300846, 0.045417767, 1886.3728, 4232.271, 3625.2512, 6741.4614]\n",
      "epoch 3\n",
      "     fun: 90748.34990709391\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16844\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.70603984e-02, 8.70443592e-01, 5.24885454e-02, 5.72624408e+03,\n",
      "       1.07173118e+04, 6.06026139e+03, 2.05226559e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 91160.88386263404, bestParams: [0.033290174, 0.055628516, 0.014551205, 3497.17, 22058.719, 12795.54, 5477.151]\n",
      "epoch 4\n",
      "     fun: 90526.43683545549\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18563\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.91724795e-02, 3.97801077e-02, 4.02951177e-02, 8.10570623e+03,\n",
      "       2.49413083e+04, 2.46312383e+04, 1.89534248e+04])\n",
      "minPrevious 90528.09146807808\n",
      "better by at >= 1; new ll:      fun: 90526.43683545549\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18563\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.91724795e-02, 3.97801077e-02, 4.02951177e-02, 8.10570623e+03,\n",
      "       2.49413083e+04, 2.46312383e+04, 1.89534248e+04])\n",
      "best ll: 91032.47008508065, bestParams: [0.12150022, 0.06901591, 0.044288684, 6986.347, 7713.5996, 20299.445, 23289.34]\n",
      "epoch 5\n",
      "     fun: 90527.10680973373\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19381\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.03379565e-02, 3.91045966e-02, 4.04755411e-02, 7.92413194e+03,\n",
      "       2.40087260e+04, 2.41783579e+04, 1.86340368e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 91151.68239117, bestParams: [0.02094275, 0.085978635, 0.05017864, 8948.37, 7969.455, 22098.55, 24430.57]\n",
      "epoch 6\n",
      "     fun: 90532.97349945629\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21698\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.71214153e-02, 4.57389432e-02, 4.20915576e-02, 9.02832071e+03,\n",
      "       2.47487861e+04, 2.49622212e+04, 2.35201731e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90674.02727068722, bestParams: [0.03838533, 0.010670561, 0.028407924, 4872.6216, 17658.736, 17240.87, 10353.156]\n",
      "epoch 7\n",
      "     fun: 90530.28907951455\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20557\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13376010e-02, 4.08275025e-02, 4.08953581e-02, 6.64909977e+03,\n",
      "       1.97295238e+04, 1.97269175e+04, 1.60526526e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90743.39248618434, bestParams: [0.04231918, 0.031651355, 0.027624661, 2601.6572, 11065.2, 12116.015, 5007.5166]\n",
      "epoch 8\n",
      "     fun: 90527.06941824801\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20300\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.10153887e-02, 4.13760606e-02, 4.07297194e-02, 8.06086496e+03,\n",
      "       2.41232330e+04, 2.38660672e+04, 1.94393666e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90981.63954946902, bestParams: [0.05607572, 0.03384001, 0.036304813, 11815.16, 23425.008, 23078.727, 23863.035]\n",
      "epoch 9\n",
      "     fun: 90528.45840234167\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20521\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.11606709e-02, 4.21507169e-02, 4.10246844e-02, 8.36091333e+03,\n",
      "       2.48268749e+04, 2.44381077e+04, 2.03805812e+04])\n",
      "minPrevious 90526.43683545549\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0392, 0.0398, 0.0403], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8763, 0.0643, 0.0278, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8630, 0.0796, 0.0259, 0.0315], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8857, 0.0281, 0.0657, 0.0263], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8639, 0.0259, 0.0787, 0.0315], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7398, 0.0976, 0.0982, 0.0613], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7016, 0.1140, 0.1132, 0.0712], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9121, 3.6197, 4.2672],\n",
      "        [2.9923, 3.6857, 6.1465],\n",
      "        [3.8417, 2.6237, 5.0056],\n",
      "        ...,\n",
      "        [3.7917, 3.6148, 4.5259],\n",
      "        [3.2769, 4.1533, 5.7003],\n",
      "        [4.0090, 3.2273, 4.1458]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.512847900390625\n",
      "Run: 0, 7\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[50.,  5.,  1.,  4.],\n",
      "        [45.,  2.,  2.,  1.],\n",
      "        [38.,  4.,  1.,  5.],\n",
      "        ...,\n",
      "        [56.,  2.,  2.,  0.],\n",
      "        [42.,  3.,  0.,  0.],\n",
      "        [51.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "n tensor([60., 50., 48.,  ..., 60., 45., 55.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 2., 4.,  ..., 2., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 1.,  ..., 2., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 1., 5.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[50.,  5.,  1.,  4.],\n",
      "        [45.,  2.,  2.,  1.],\n",
      "        [38.,  4.,  1.,  5.],\n",
      "        ...,\n",
      "        [56.,  2.,  2.,  0.],\n",
      "        [42.,  3.,  0.,  0.],\n",
      "        [51.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.2155e-05, 1.9104e-02, 1.7708e-06,  ..., 3.6563e-02, 1.6772e-02,\n",
      "        2.8963e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bccef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91243.91071417881, bestParams: [0.040498573, 0.039992083, 0.033642173, 6753.6836, 15692.065, 21096.775, 11753.506]\n",
      "epoch 0\n",
      "     fun: 91035.2144862661\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21164\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56112050e-02, 5.15920592e-02, 4.19819102e-02, 8.88284249e+03,\n",
      "       2.49907590e+04, 2.48726630e+04, 2.23069026e+04])\n",
      "best ll: 91357.54566372334, bestParams: [0.040997185, 0.04618633, 0.0838608, 10846.453, 19839.768, 20632.074, 23618.115]\n",
      "epoch 1\n",
      "     fun: 91032.30772549672\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26802\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.40870682e-02, 4.61593746e-02, 4.11538469e-02, 8.28519028e+03,\n",
      "       2.40384533e+04, 2.47662828e+04, 1.98040363e+04])\n",
      "minPrevious 91035.2144862661\n",
      "better by at >= 1; new ll:      fun: 91032.30772549672\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26802\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.40870682e-02, 4.61593746e-02, 4.11538469e-02, 8.28519028e+03,\n",
      "       2.40384533e+04, 2.47662828e+04, 1.98040363e+04])\n",
      "best ll: 91302.02347668094, bestParams: [0.072848134, 0.03889845, 0.056128502, 6435.528, 21272.988, 18763.773, 8352.756]\n",
      "epoch 2\n",
      "     fun: 91031.9209379922\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24570\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.36019089e-02, 4.66654380e-02, 4.10921218e-02, 7.96267313e+03,\n",
      "       2.31950003e+04, 2.36841385e+04, 1.90482360e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91338.92905650586, bestParams: [0.07102878, 0.008142718, 0.04293678, 6779.5894, 16760.775, 23199.021, 24335.203]\n",
      "epoch 3\n",
      "     fun: 91033.0256424332\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19511\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.05025247e-02, 4.48221899e-02, 4.04081393e-02, 5.73947926e+03,\n",
      "       1.73768584e+04, 1.75574538e+04, 1.31654564e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91237.5362622957, bestParams: [0.04897804, 0.02517828, 0.053476565, 6121.2505, 24571.582, 21428.121, 6433.1235]\n",
      "epoch 4\n",
      "     fun: 91033.0525860195\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20408\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13719928e-02, 4.36648545e-02, 4.02826805e-02, 6.16702916e+03,\n",
      "       1.86390630e+04, 1.91395485e+04, 1.41040120e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91642.97852024857, bestParams: [0.002547079, 0.031438496, 0.04191702, 10740.871, 20333.883, 15887.142, 24783.443]\n",
      "epoch 5\n",
      "     fun: 91034.54627224465\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23137\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26251794e-02, 4.60197835e-02, 4.10425927e-02, 6.91119423e+03,\n",
      "       2.02861702e+04, 2.07257963e+04, 1.63576711e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91317.27160636887, bestParams: [0.08740924, 0.015501036, 0.038114674, 9618.194, 22194.303, 20528.768, 23597.967]\n",
      "epoch 6\n",
      "     fun: 91034.88282504663\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20439\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.59857350e-02, 5.16670146e-02, 4.19960060e-02, 8.87733643e+03,\n",
      "       2.48689759e+04, 2.48395651e+04, 2.23461119e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91663.3816547386, bestParams: [0.11510229, 0.022979988, 0.07719361, 4350.521, 11100.692, 16230.497, 16443.652]\n",
      "epoch 7\n",
      "     fun: 91033.37773956737\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19850\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.01523012e-02, 4.31942038e-02, 4.02496093e-02, 4.25476136e+03,\n",
      "       1.30677735e+04, 1.33156742e+04, 9.56380154e+03])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91600.56161983634, bestParams: [0.021486541, 0.04493397, 0.05444471, 8626.893, 24781.225, 17456.62, 8928.072]\n",
      "epoch 8\n",
      "     fun: 91033.31471153395\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 31986\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.08887799e-02, 4.39664510e-02, 4.02960859e-02, 4.10381194e+03,\n",
      "       1.24499251e+04, 1.26908510e+04, 9.37283927e+03])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91558.65006552348, bestParams: [0.13935027, 0.023656605, 0.10880936, 7721.089, 14432.105, 18207.133, 15296.897]\n",
      "epoch 9\n",
      "     fun: 91034.43093651239\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19058\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.61504895e-02, 5.08239462e-02, 4.18637993e-02, 8.83570464e+03,\n",
      "       2.47664960e+04, 2.49518926e+04, 2.21539923e+04])\n",
      "minPrevious 91032.30772549672\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0441, 0.0462, 0.0412], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8834, 0.0644, 0.0280, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8673, 0.0756, 0.0260, 0.0311], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8760, 0.0278, 0.0650, 0.0260], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8654, 0.0259, 0.0776, 0.0311], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7375, 0.0976, 0.0992, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7045, 0.1118, 0.1137, 0.0700], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[5.3702, 4.2106, 6.4728],\n",
      "        [2.3497, 1.9903, 3.4842],\n",
      "        [3.2499, 2.2078, 5.5362],\n",
      "        ...,\n",
      "        [2.0072, 3.2786, 5.4871],\n",
      "        [4.0390, 2.2470, 6.6010],\n",
      "        [3.4164, 3.2387, 5.0540]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.588237047195435\n",
      "Run: 0, 8\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  2.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [58.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [51.,  1.,  0.,  0.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([47., 54., 61.,  ..., 52., 54., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 5., 0.,  ..., 1., 5., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 2.,  ..., 0., 2., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  2.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [58.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [51.,  1.,  0.,  0.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0106, 0.0011, 0.0168,  ..., 0.0420, 0.0011, 0.0503],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bcce60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91167.15270193382, bestParams: [0.014420534, 0.012763254, 0.08490746, 10409.463, 14869.195, 12726.8955, 24758.049]\n",
      "epoch 0\n",
      "     fun: 90664.13815521165\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18871\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.50519321e-02, 4.80974897e-02, 4.37722990e-02, 9.33124432e+03,\n",
      "       2.49952647e+04, 2.48946095e+04, 2.44922474e+04])\n",
      "best ll: 91064.46507395245, bestParams: [0.13599314, 0.0092406655, 0.06631607, 5395.3354, 13053.832, 21606.041, 11194.925]\n",
      "epoch 1\n",
      "     fun: 90658.51054391943\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21778\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97539028e-02, 3.85180081e-02, 4.21989798e-02, 5.29648514e+03,\n",
      "       1.53948253e+04, 1.60815565e+04, 1.24519796e+04])\n",
      "minPrevious 90664.13815521165\n",
      "better by at >= 1; new ll:      fun: 90658.51054391943\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21778\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97539028e-02, 3.85180081e-02, 4.21989798e-02, 5.29648514e+03,\n",
      "       1.53948253e+04, 1.60815565e+04, 1.24519796e+04])\n",
      "best ll: 91161.8533601003, bestParams: [0.034372266, 0.032068986, 0.05270397, 8083.9736, 19698.992, 9210.703, 19556.129]\n",
      "epoch 2\n",
      "     fun: 90657.06766549514\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.92766030e-02, 4.08158908e-02, 4.23739920e-02, 7.79916973e+03,\n",
      "       2.27167344e+04, 2.30158405e+04, 1.86388333e+04])\n",
      "minPrevious 90658.51054391943\n",
      "better by at >= 1; new ll:      fun: 90657.06766549514\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.92766030e-02, 4.08158908e-02, 4.23739920e-02, 7.79916973e+03,\n",
      "       2.27167344e+04, 2.30158405e+04, 1.86388333e+04])\n",
      "best ll: 91063.24965752647, bestParams: [0.021735504, 0.06495616, 0.022336451, 6890.512, 21746.352, 12447.272, 18961.99]\n",
      "epoch 3\n",
      "     fun: 90659.63845924352\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29426\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.96169439e-02, 4.09057274e-02, 4.24696771e-02, 5.79042445e+03,\n",
      "       1.67475000e+04, 1.69853353e+04, 1.39198936e+04])\n",
      "minPrevious 90657.06766549514\n",
      "best ll: 90977.47848692283, bestParams: [0.059151612, 0.05514521, 0.0882875, 7970.9907, 15740.975, 12443.312, 21263.242]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8d3d1ca8ed6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[0;31m#         fnArgs = [probs[0], probs[1], probs[2], *alphas]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m         \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mdual_annealing\u001b[0;34m(func, bounds, args, maxiter, local_search_options, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;31m# Possible local search at the end of the strategy chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_local_search\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mlocal_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;31m# Global energy has improved, let's see if LS improves further\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             e, x = self.minimizer_wrapper.local_search(self.energy_state.xbest,\n\u001b[0;32m--> 318\u001b[0;31m                                                        self.energy_state.ebest)\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mebest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_improved_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mlocal_search\u001b[0;34m(self, x, e)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Run local search from the given x location where energy value is e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mx_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mmres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'njev'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnjev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 600\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0ma1Both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1Both\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0ma21\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "resSim = {\n",
    "        \"allRes\": None,\n",
    "        \"nEpochs\": None,\n",
    "        \"bestRes\": {\n",
    "            \"pis\": None,\n",
    "            \"alphas\": None,\n",
    "            \"PDV_c1true\": None,\n",
    "            \"PDV_c2true\": None,\n",
    "            \"PDV_cBothTrue\": None,\n",
    "            \"PDV_c1inferred\": None,\n",
    "            \"PDV_c2inferred\": None,\n",
    "            \"PDV_cBothInferred\": None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cached6NormalSimRes = []\n",
    "\n",
    "rrsSim = tensor([[2, 2, 1.5]])\n",
    "pisSim = tensor([[.05, .05, .05]])\n",
    "\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(5e5)\n",
    "i = 0\n",
    "for rrsSimRun in rrsSim:\n",
    "    for pisSimRun in pisSim:\n",
    "        afMeanRun = 1e-4\n",
    "        generatingFn = genData.v6normal\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        # needs tensor for shapes, otherwise \"gamma_cpu not implemente for long\", e.g rrShape=50.0 doesn't work...\n",
    "        paramsRun = genData.genParams(rrMeans=rrsSimRun, pis=pisSimRun, afMean=afMeanRun, rrShape=tensor(50.), afShape=tensor(50.), nCases=nCases, nCtrls=nCtrls)[0]\n",
    "        \n",
    "        pDsRun = paramsRun[\"pDs\"]\n",
    "        pisRun = paramsRun[\"diseaseFractions\"]\n",
    "        print(\"params are:\", paramsRun)\n",
    "        \n",
    "        cached6NormalSimRes.append({\"params\": paramsRun, \"runs\": []})\n",
    "        for y in range(0, 10):\n",
    "            start = time.time()\n",
    "            r = generatingFn(**paramsRun)\n",
    "            print(\"took\", time.time() - start)\n",
    "            \n",
    "            resPointer = {\n",
    "                **r,\n",
    "                \"generatingFn\": generatingFn,\n",
    "                \"results\": None,\n",
    "            }\n",
    "\n",
    "            cached6NormalSimRes[i][\"runs\"].append(resPointer)\n",
    "            \n",
    "            print(f\"Run: {i}, {y}\")\n",
    "            \n",
    "            xsRun = resPointer[\"altCounts\"]\n",
    "            afsRun = resPointer[\"afs\"]\n",
    "            affectedGenesRun = resPointer[\"affectedGenes\"]\n",
    "            unaffectedGenesRun = resPointer[\"unaffectedGenes\"]\n",
    "\n",
    "            runCostFnIdx = 16\n",
    "\n",
    "            nEpochsRun = 10\n",
    "            print(\"nEpochsRun\", nEpochsRun)\n",
    "            \n",
    "            res = likelihoods.fitFnBivariateAnnealing(xsRun, pDsRun, nEpochs=nEpochsRun, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "            bestRes = res[\"params\"][-1]\n",
    "\n",
    "            inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "            inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "            #### Calculate actual ###\n",
    "            component1Afs = afsRun[affectedGenesRun[0]]\n",
    "            c1true = (component1Afs / afMeanRun).mean(0)\n",
    "\n",
    "            component2Afs = afsRun[affectedGenesRun[1]]\n",
    "            c2true = (component2Afs / afMeanRun).mean(0)\n",
    "\n",
    "            componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "            cBothTrue = (componentBothAfs / afMeanRun).mean(0)\n",
    "\n",
    "            ### calculate inferred values\n",
    "            pds = tensor([1-pDsRun.sum(), *pDsRun])\n",
    "            alphas = inferredAlphas.numpy()\n",
    "            c1inferred = Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            c2inferred = Dirichlet(tensor([alphas[0], alphas[0], alphas[2], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            cBothInferred = Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0)\n",
    "\n",
    "            print(f\"\\n\\nrun {i} results for rrs: {rrsSimRun}, pis: {pisSimRun}\")\n",
    "            print(\"Inferred pis:\", inferredPis)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c1true)\n",
    "            print(\"P(D|V) inferred in component 1:\", c1inferred)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c2true)\n",
    "            print(\"P(D|V) inferred in component both:\", c2inferred)\n",
    "            print(\"\\nP(D|V) true ans in component both:\", cBothTrue)\n",
    "            print(\"P(D|V) inferred in component both:\", cBothInferred,\"\\n\\n\")\n",
    "\n",
    "            resToStore = copy.deepcopy(resSim)\n",
    "            resToStore[\"allRes\"] = res\n",
    "            resToStore[\"nEpochs\"] = nEpochsRun\n",
    "            br = resToStore[\"bestRes\"]\n",
    "            br[\"pis\"] = inferredPis\n",
    "            br[\"alphas\"] = inferredAlphas\n",
    "            br[\"PDV_c1true\"] = c1true\n",
    "            br[\"PDV_c2true\"] = c2true\n",
    "            br[\"PDV_cBothTrue\"] = cBothTrue\n",
    "            br[\"PDV_c1inferred\"] = c1inferred\n",
    "            br[\"PDV_c2inferred\"] = c2inferred\n",
    "            br[\"PDV_cBothInferred\"] = cBothInferred\n",
    "\n",
    "            resPointer[\"results\"] = resToStore\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([2.0000, 2.0000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.0478, 2.3230, 4.9419],\n",
      "        [1.1123, 3.1260, 6.4751],\n",
      "        [3.7432, 4.8883, 4.0865],\n",
      "        ...,\n",
      "        [2.3440, 2.6389, 4.7504],\n",
      "        [3.1413, 3.7973, 5.2277],\n",
      "        [2.2387, 4.0079, 4.0649]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.850098848342896\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[45.,  5.,  3.,  2.],\n",
      "        [41.,  4.,  3.,  1.],\n",
      "        [37.,  7.,  1.,  0.],\n",
      "        ...,\n",
      "        [74.,  1.,  4.,  0.],\n",
      "        [34.,  0.,  0.,  1.],\n",
      "        [47.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([55., 49., 45.,  ..., 79., 35., 47.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 4., 7.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 1.,  ..., 4., 0., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 0.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[45.,  5.,  3.,  2.],\n",
      "        [41.,  4.,  3.,  1.],\n",
      "        [37.,  7.,  1.,  0.],\n",
      "        ...,\n",
      "        [74.,  1.,  4.,  0.],\n",
      "        [34.,  0.,  0.,  1.],\n",
      "        [47.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([1.5210e-04, 1.0985e-03, 4.9528e-05,  ..., 1.1274e-02, 3.6850e-02,\n",
      "        3.8093e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3eef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91172.32504614866, bestParams: [0.013028687, 0.04237689, 0.055741724, 11929.878, 23005.342, 24812.355, 19184.58]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.44827568e-02, 4.20886696e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886697e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204496e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886697e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204496e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886694e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04]]), array([90708.23269808, 90708.23269813, 90708.23269813, 90708.23269813,\n",
      "       90708.23269818, 90708.2326982 , 90708.23269824, 90708.23269824]))\n",
      "           fun: 90708.2326980827\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1318\n",
      "           nit: 493\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.44827568e-02, 4.20886696e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "       2.80864800e+04, 2.54391201e+04, 1.98356475e+04])\n",
      "best ll: 90890.87945008784, bestParams: [0.02896374, 0.014520663, 0.032099355, 7064.519, 15548.0, 21440.451, 23799.553]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528250e+04],\n",
      "       [3.38261325e-02, 1.79584957e-02, 3.97524944e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528248e+04],\n",
      "       [3.38261324e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519285e+04, 2.19081534e+04, 1.22528248e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524946e-02, 6.01717407e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04]]), array([90656.19387572, 90656.19387581, 90656.19387586, 90656.19387586,\n",
      "       90656.19387591, 90656.19387599, 90656.19387611, 90656.19387612]))\n",
      "           fun: 90656.19387571645\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1376\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "       1.88519284e+04, 2.19081534e+04, 1.22528249e+04])\n",
      "minPrevious 90708.2326980827\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528250e+04],\n",
      "       [3.38261325e-02, 1.79584957e-02, 3.97524944e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528248e+04],\n",
      "       [3.38261324e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519285e+04, 2.19081534e+04, 1.22528248e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524946e-02, 6.01717407e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04]]), array([90656.19387572, 90656.19387581, 90656.19387586, 90656.19387586,\n",
      "       90656.19387591, 90656.19387599, 90656.19387611, 90656.19387612]))\n",
      "           fun: 90656.19387571645\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1376\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "       1.88519284e+04, 2.19081534e+04, 1.22528249e+04])\n",
      "best ll: 91084.1192014738, bestParams: [0.09653744, 0.018029423, 0.09406014, 7974.054, 10447.645, 17449.232, 18952.387]\n",
      "epoch 2\n",
      " final_simplex: (array([[9.36961198e-02, 2.15226793e-02, 4.20764994e-02, 6.46469647e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961197e-02, 2.15226793e-02, 4.20764980e-02, 6.46469647e+03,\n",
      "        1.42865571e+04, 1.95487746e+04, 1.90451599e+04],\n",
      "       [9.36961201e-02, 2.15226793e-02, 4.20765002e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451600e+04],\n",
      "       [9.36961203e-02, 2.15226793e-02, 4.20764994e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487746e+04, 1.90451598e+04],\n",
      "       [9.36961203e-02, 2.15226792e-02, 4.20764988e-02, 6.46469647e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961206e-02, 2.15226793e-02, 4.20765004e-02, 6.46469645e+03,\n",
      "        1.42865569e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961209e-02, 2.15226792e-02, 4.20765011e-02, 6.46469645e+03,\n",
      "        1.42865569e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961205e-02, 2.15226792e-02, 4.20764990e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04]]), array([90681.43851664, 90681.43851693, 90681.43851704, 90681.43851723,\n",
      "       90681.43851748, 90681.43851752, 90681.43851769, 90681.43851779]))\n",
      "           fun: 90681.43851663727\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.36961198e-02, 2.15226793e-02, 4.20764994e-02, 6.46469647e+03,\n",
      "       1.42865570e+04, 1.95487745e+04, 1.90451599e+04])\n",
      "minPrevious 90656.19387571645\n",
      "best ll: 91034.65410804498, bestParams: [0.027997645, 0.11145982, 0.04767258, 7647.5757, 20896.21, 12109.757, 15794.455]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.29898119e-02, 8.95420892e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420892e-02, 4.67567476e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898118e-02, 8.95420892e-02, 4.67567477e-02, 6.32456128e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420894e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816320e+04, 1.92698622e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567478e-02, 6.32456126e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698622e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567478e-02, 6.32456125e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420898e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698622e+04]]), array([90716.56485695, 90716.56485706, 90716.56485719, 90716.56485742,\n",
      "       90716.56485758, 90716.56485805, 90716.56485833, 90716.56487249]))\n",
      "           fun: 90716.56485695229\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1182\n",
      "           nit: 442\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.29898119e-02, 8.95420892e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "       1.68206514e+04, 1.47816319e+04, 1.92698623e+04])\n",
      "minPrevious 90656.19387571645\n",
      "best ll: 90939.13863356014, bestParams: [0.07707118, 0.018570729, 0.07501205, 5894.602, 8311.181, 11558.4, 19163.01]\n",
      "epoch 4\n",
      " final_simplex: (array([[6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350208e-02, 2.24385760e-02, 3.93378972e-02, 4.60124344e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539976e+04],\n",
      "       [6.84350208e-02, 2.24385761e-02, 3.93378969e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350213e-02, 2.24385761e-02, 3.93378970e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539976e+04],\n",
      "       [6.84350210e-02, 2.24385763e-02, 3.93378962e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350214e-02, 2.24385761e-02, 3.93378967e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350228e-02, 2.24385758e-02, 3.93378974e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350233e-02, 2.24385756e-02, 3.93378983e-02, 4.60124348e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04]]), array([90648.44593427, 90648.44593435, 90648.44593449, 90648.44593476,\n",
      "       90648.44593506, 90648.4459351 , 90648.44593574, 90648.4459358 ]))\n",
      "           fun: 90648.44593427246\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1147\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "       1.17104156e+04, 1.52903364e+04, 1.15539975e+04])\n",
      "minPrevious 90656.19387571645\n",
      "better by at >= 1; new ll:  final_simplex: (array([[6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350208e-02, 2.24385760e-02, 3.93378972e-02, 4.60124344e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539976e+04],\n",
      "       [6.84350208e-02, 2.24385761e-02, 3.93378969e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350213e-02, 2.24385761e-02, 3.93378970e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539976e+04],\n",
      "       [6.84350210e-02, 2.24385763e-02, 3.93378962e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350214e-02, 2.24385761e-02, 3.93378967e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350228e-02, 2.24385758e-02, 3.93378974e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350233e-02, 2.24385756e-02, 3.93378983e-02, 4.60124348e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04]]), array([90648.44593427, 90648.44593435, 90648.44593449, 90648.44593476,\n",
      "       90648.44593506, 90648.4459351 , 90648.44593574, 90648.4459358 ]))\n",
      "           fun: 90648.44593427246\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1147\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "       1.17104156e+04, 1.52903364e+04, 1.15539975e+04])\n",
      "best ll: 91166.87153988995, bestParams: [0.068626955, 0.11146803, 0.06459778, 7812.6924, 19519.297, 9904.601, 17612.63]\n",
      "epoch 5\n",
      " final_simplex: (array([[7.59170859e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170857e-02, 1.01934340e-01, 4.47969147e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170858e-02, 1.01934340e-01, 4.47969150e-02, 6.65456055e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170859e-02, 1.01934340e-01, 4.47969144e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628879e+04, 2.17700551e+04],\n",
      "       [7.59170856e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934341e-01, 4.47969147e-02, 6.65456053e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934341e-01, 4.47969147e-02, 6.65456053e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04]]), array([90735.31638244, 90735.31638259, 90735.31638261, 90735.31638276,\n",
      "       90735.31638288, 90735.31638291, 90735.31638307, 90735.31638314]))\n",
      "           fun: 90735.31638244262\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1236\n",
      "           nit: 471\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.59170859e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "       1.49096890e+04, 1.34628878e+04, 2.17700551e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90917.66287739587, bestParams: [0.13892789, 0.10014813, 0.035001487, 4701.4688, 7708.276, 10219.709, 22012.11]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.36648091e-01, 9.30464598e-02, 3.80847363e-02, 4.89947091e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648091e-01, 9.30464598e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464601e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151964e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464605e-02, 3.80847362e-02, 4.89947092e+03,\n",
      "        8.76151962e+03, 1.02069802e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464605e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151957e+03, 1.02069801e+04, 1.80163115e+04],\n",
      "       [1.36648090e-01, 9.30464604e-02, 3.80847362e-02, 4.89947091e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464608e-02, 3.80847361e-02, 4.89947093e+03,\n",
      "        8.76151964e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464607e-02, 3.80847360e-02, 4.89947093e+03,\n",
      "        8.76151961e+03, 1.02069801e+04, 1.80163114e+04]]), array([90782.8870678 , 90782.88706813, 90782.88706825, 90782.88706835,\n",
      "       90782.88706844, 90782.8870687 , 90782.88706913, 90782.88706914]))\n",
      "           fun: 90782.88706779895\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1239\n",
      "           nit: 485\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.36648091e-01, 9.30464598e-02, 3.80847363e-02, 4.89947091e+03,\n",
      "       8.76151963e+03, 1.02069801e+04, 1.80163114e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90921.60896941471, bestParams: [0.039651427, 0.066044815, 0.0449088, 8883.905, 17105.955, 21929.596, 18417.646]\n",
      "epoch 7\n",
      " final_simplex: (array([[4.04578591e-02, 6.31349507e-02, 4.17312360e-02, 7.30683351e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349508e-02, 4.17312359e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349506e-02, 4.17312361e-02, 7.30683352e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130547e+04],\n",
      "       [4.04578590e-02, 6.31349505e-02, 4.17312361e-02, 7.30683351e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578592e-02, 6.31349508e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130547e+04],\n",
      "       [4.04578590e-02, 6.31349507e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349509e-02, 4.17312359e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349508e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04]]), array([90653.65813487, 90653.65813493, 90653.65813495, 90653.65813495,\n",
      "       90653.65813502, 90653.65813511, 90653.65813513, 90653.65813515]))\n",
      "           fun: 90653.65813486525\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1328\n",
      "           nit: 534\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.04578591e-02, 6.31349507e-02, 4.17312360e-02, 7.30683351e+03,\n",
      "       2.06655049e+04, 1.98816064e+04, 2.07130546e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90906.03571837083, bestParams: [0.046865396, 0.021055793, 0.022448916, 5707.723, 14474.583, 22354.312, 23248.088]\n",
      "epoch 8\n",
      " final_simplex: (array([[4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083142e-02, 2.66136979e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04]]), array([90636.62833643, 90636.62833654, 90636.6283387 , 90636.62833873,\n",
      "       90636.62833876, 90636.62833878, 90636.628347  , 90636.62834702]))\n",
      "           fun: 90636.62833642976\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1308\n",
      "           nit: 446\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "       1.71687415e+04, 1.90909270e+04, 1.19123748e+04])\n",
      "minPrevious 90648.44593427246\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083142e-02, 2.66136979e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04]]), array([90636.62833643, 90636.62833654, 90636.6283387 , 90636.62833873,\n",
      "       90636.62833876, 90636.62833878, 90636.628347  , 90636.62834702]))\n",
      "           fun: 90636.62833642976\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1308\n",
      "           nit: 446\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "       1.71687415e+04, 1.90909270e+04, 1.19123748e+04])\n",
      "best ll: 91011.59666077793, bestParams: [0.1238161, 0.015511246, 0.058201686, 9525.396, 21616.701, 17512.54, 22892.9]\n",
      "epoch 9\n",
      " final_simplex: (array([[1.03603268e-01, 1.67256257e-02, 5.42323187e-02, 8.78604866e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256257e-02, 5.42323187e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603268e-01, 1.67256256e-02, 5.42323188e-02, 8.78604868e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603268e-01, 1.67256256e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256256e-02, 5.42323188e-02, 8.78604866e+03,\n",
      "        1.78020607e+04, 2.35306881e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256256e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020608e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603269e-01, 1.67256255e-02, 5.42323190e-02, 8.78604870e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256255e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306881e+04, 2.62310912e+04]]), array([90724.66721506, 90724.66721543, 90724.66721548, 90724.66721562,\n",
      "       90724.66721583, 90724.6672159 , 90724.667216  , 90724.66721622]))\n",
      "           fun: 90724.66721505724\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1140\n",
      "           nit: 379\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.03603268e-01, 1.67256257e-02, 5.42323187e-02, 8.78604866e+03,\n",
      "       1.78020607e+04, 2.35306880e+04, 2.62310912e+04])\n",
      "minPrevious 90636.62833642976\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0405, 0.0266, 0.0348], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8832, 0.0633, 0.0280, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8564, 0.0816, 0.0256, 0.0363], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8810, 0.0279, 0.0632, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8486, 0.0255, 0.0899, 0.0360], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7405, 0.0996, 0.0999, 0.0624], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6942, 0.1121, 0.1194, 0.0742], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[1.7906, 2.9352, 4.7581],\n",
      "        [3.0976, 2.9503, 4.8961],\n",
      "        [3.5549, 4.4150, 6.2209],\n",
      "        ...,\n",
      "        [3.0932, 3.6773, 5.4842],\n",
      "        [4.8924, 3.0446, 5.1291],\n",
      "        [3.6147, 3.7954, 6.7355]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.719698190689087\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[39.,  1.,  0.,  3.],\n",
      "        [52.,  5.,  1.,  1.],\n",
      "        [48.,  1.,  0.,  3.],\n",
      "        ...,\n",
      "        [56.,  1.,  2.,  2.],\n",
      "        [43.,  4.,  0.,  1.],\n",
      "        [47.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([43., 59., 52.,  ..., 61., 48., 49.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 5., 1.,  ..., 1., 4., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 0.,  ..., 2., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 3.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[39.,  1.,  0.,  3.],\n",
      "        [52.,  5.,  1.,  1.],\n",
      "        [48.,  1.,  0.,  3.],\n",
      "        ...,\n",
      "        [56.,  1.,  2.,  2.],\n",
      "        [43.,  4.,  0.,  1.],\n",
      "        [47.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0013, 0.0021, 0.0015,  ..., 0.0100, 0.0030, 0.0702],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3ea70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90741.90852394194, bestParams: [0.07122339, 0.0030399286, 0.054159407, 10150.92, 21346.87, 23431.73, 21332.012]\n",
      "epoch 0\n",
      " final_simplex: (array([[6.75587190e-02, 3.35212914e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212913e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587193e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587193e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212914e-03, 5.38820011e-02, 8.95523095e+03,\n",
      "        2.17844697e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587194e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587194e-02, 3.35212913e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139825e+04]]), array([90648.67312646, 90648.6731265 , 90648.67312653, 90648.67312653,\n",
      "       90648.6731266 , 90648.67312662, 90648.67312669, 90648.67312672]))\n",
      "           fun: 90648.67312645877\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1299\n",
      "           nit: 485\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.75587190e-02, 3.35212914e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "       2.17844698e+04, 2.55800586e+04, 2.21139824e+04])\n",
      "best ll: 90681.83730196144, bestParams: [0.009099581, 0.0579189, 0.04930118, 3433.2517, 15866.488, 10614.559, 6043.5835]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482751e+03],\n",
      "       [3.97041955e-02, 3.83571503e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482756e+03],\n",
      "       [3.97041953e-02, 3.83571506e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482753e+03],\n",
      "       [3.97041955e-02, 3.83571505e-02, 4.01668990e-02, 1.65787189e+03,\n",
      "        5.10452657e+03, 4.99800959e+03, 3.89482751e+03],\n",
      "       [3.97041957e-02, 3.83571504e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452653e+03, 4.99800953e+03, 3.89482757e+03],\n",
      "       [3.97041957e-02, 3.83571501e-02, 4.01668989e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482757e+03],\n",
      "       [3.97041956e-02, 3.83571500e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452651e+03, 4.99800959e+03, 3.89482750e+03],\n",
      "       [3.97041950e-02, 3.83571509e-02, 4.01668988e-02, 1.65787188e+03,\n",
      "        5.10452655e+03, 4.99800972e+03, 3.89482750e+03]]), array([90476.89262346, 90476.89262354, 90476.89262355, 90476.89262356,\n",
      "       90476.89262359, 90476.89262365, 90476.89262374, 90476.89262375]))\n",
      "           fun: 90476.89262346049\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1303\n",
      "           nit: 537\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "       5.10452656e+03, 4.99800963e+03, 3.89482751e+03])\n",
      "minPrevious 90648.67312645877\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482751e+03],\n",
      "       [3.97041955e-02, 3.83571503e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482756e+03],\n",
      "       [3.97041953e-02, 3.83571506e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482753e+03],\n",
      "       [3.97041955e-02, 3.83571505e-02, 4.01668990e-02, 1.65787189e+03,\n",
      "        5.10452657e+03, 4.99800959e+03, 3.89482751e+03],\n",
      "       [3.97041957e-02, 3.83571504e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452653e+03, 4.99800953e+03, 3.89482757e+03],\n",
      "       [3.97041957e-02, 3.83571501e-02, 4.01668989e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482757e+03],\n",
      "       [3.97041956e-02, 3.83571500e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452651e+03, 4.99800959e+03, 3.89482750e+03],\n",
      "       [3.97041950e-02, 3.83571509e-02, 4.01668988e-02, 1.65787188e+03,\n",
      "        5.10452655e+03, 4.99800972e+03, 3.89482750e+03]]), array([90476.89262346, 90476.89262354, 90476.89262355, 90476.89262356,\n",
      "       90476.89262359, 90476.89262365, 90476.89262374, 90476.89262375]))\n",
      "           fun: 90476.89262346049\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1303\n",
      "           nit: 537\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "       5.10452656e+03, 4.99800963e+03, 3.89482751e+03])\n",
      "best ll: 90717.3162355351, bestParams: [0.06359781, 0.10405803, 0.046771917, 7625.652, 24112.361, 18915.994, 16105.375]\n",
      "epoch 2\n",
      " final_simplex: (array([[5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102427e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102420e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102419e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102418e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102419e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04]]), array([90500.47796516, 90500.47796518, 90500.47796518, 90500.47796519,\n",
      "       90500.47796527, 90500.47796527, 90500.47796527, 90500.47796528]))\n",
      "           fun: 90500.47796516292\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 4652\n",
      "           nit: 2308\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "       2.04976104e+04, 2.06011943e+04, 2.24340928e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90929.14797453234, bestParams: [0.021989336, 0.024018025, 0.07503793, 7889.689, 16223.559, 6951.5303, 24633.479]\n",
      "epoch 3\n",
      " final_simplex: (array([[2.99085125e-02, 2.41263715e-02, 4.27982693e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577086e+03],\n",
      "       [2.99085127e-02, 2.41263716e-02, 4.27982671e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577085e+03],\n",
      "       [2.99085125e-02, 2.41263714e-02, 4.27982700e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577081e+03],\n",
      "       [2.99085123e-02, 2.41263714e-02, 4.27982701e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577087e+03],\n",
      "       [2.99085125e-02, 2.41263713e-02, 4.27982700e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577081e+03],\n",
      "       [2.99085124e-02, 2.41263712e-02, 4.27982710e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577083e+03],\n",
      "       [2.99085124e-02, 2.41263713e-02, 4.27982702e-02, 4.40451852e+03,\n",
      "        1.47346393e+04, 1.45226304e+04, 8.34577086e+03],\n",
      "       [2.99085123e-02, 2.41263713e-02, 4.27982702e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577086e+03]]), array([90495.8006795 , 90495.80067955, 90495.80067955, 90495.8006796 ,\n",
      "       90495.80067963, 90495.80067969, 90495.80067975, 90495.80067979]))\n",
      "           fun: 90495.80067950126\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1186\n",
      "           nit: 463\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.99085125e-02, 2.41263715e-02, 4.27982693e-02, 4.40451852e+03,\n",
      "       1.47346392e+04, 1.45226304e+04, 8.34577086e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90864.35112277341, bestParams: [0.018510455, 0.058447286, 0.035942793, 6684.6064, 20323.559, 21613.281, 5399.623]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.43113091e-02, 2.92079757e-02, 4.39142700e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673893e+03],\n",
      "       [2.43113090e-02, 2.92079759e-02, 4.39142701e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03],\n",
      "       [2.43113090e-02, 2.92079760e-02, 4.39142702e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673896e+03],\n",
      "       [2.43113090e-02, 2.92079757e-02, 4.39142702e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905713e+04, 9.04673895e+03],\n",
      "       [2.43113090e-02, 2.92079757e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673892e+03],\n",
      "       [2.43113090e-02, 2.92079756e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03],\n",
      "       [2.43113090e-02, 2.92079758e-02, 4.39142706e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905711e+04, 9.04673894e+03],\n",
      "       [2.43113091e-02, 2.92079753e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03]]), array([90498.99775909, 90498.99775912, 90498.99775917, 90498.99775926,\n",
      "       90498.99775931, 90498.99775936, 90498.9977594 , 90498.99775941]))\n",
      "           fun: 90498.99775908835\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1218\n",
      "           nit: 417\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.43113091e-02, 2.92079757e-02, 4.39142700e-02, 4.97417025e+03,\n",
      "       1.72363324e+04, 1.66905712e+04, 9.04673893e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90989.41744427223, bestParams: [0.030847164, 0.029215563, 0.034289706, 2947.6792, 13085.451, 7149.294, 2870.779]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.08771419e-02, 3.15990099e-02, 4.33952910e-02, 2.10684217e+03,\n",
      "        6.80498898e+03, 6.67304328e+03, 4.34566725e+03],\n",
      "       [3.08771419e-02, 3.15990095e-02, 4.33952911e-02, 2.10684218e+03,\n",
      "        6.80498898e+03, 6.67304328e+03, 4.34566732e+03],\n",
      "       [3.08771415e-02, 3.15990100e-02, 4.33952912e-02, 2.10684217e+03,\n",
      "        6.80498897e+03, 6.67304334e+03, 4.34566724e+03],\n",
      "       [3.08771414e-02, 3.15990099e-02, 4.33952914e-02, 2.10684218e+03,\n",
      "        6.80498901e+03, 6.67304327e+03, 4.34566729e+03],\n",
      "       [3.08771412e-02, 3.15990097e-02, 4.33952913e-02, 2.10684219e+03,\n",
      "        6.80498900e+03, 6.67304332e+03, 4.34566733e+03],\n",
      "       [3.08771411e-02, 3.15990098e-02, 4.33952915e-02, 2.10684219e+03,\n",
      "        6.80498896e+03, 6.67304328e+03, 4.34566735e+03],\n",
      "       [3.08771410e-02, 3.15990097e-02, 4.33952914e-02, 2.10684220e+03,\n",
      "        6.80498899e+03, 6.67304331e+03, 4.34566735e+03],\n",
      "       [3.08771408e-02, 3.15990100e-02, 4.33952916e-02, 2.10684219e+03,\n",
      "        6.80498897e+03, 6.67304330e+03, 4.34566733e+03]]), array([90484.77045382, 90484.77045403, 90484.77045422, 90484.77045436,\n",
      "       90484.77045459, 90484.77045473, 90484.77045477, 90484.77045493]))\n",
      "           fun: 90484.7704538244\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1185\n",
      "           nit: 456\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.08771419e-02, 3.15990099e-02, 4.33952910e-02, 2.10684217e+03,\n",
      "       6.80498898e+03, 6.67304328e+03, 4.34566725e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90880.97895039347, bestParams: [0.024393914, 0.062279228, 0.049727906, 4949.1357, 22385.908, 15643.343, 17572.701]\n",
      "epoch 6\n",
      " final_simplex: (array([[3.06168610e-02, 4.95983339e-02, 4.25957054e-02, 6.09077079e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168609e-02, 4.95983338e-02, 4.25957054e-02, 6.09077077e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168610e-02, 4.95983339e-02, 4.25957053e-02, 6.09077077e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168608e-02, 4.95983342e-02, 4.25957057e-02, 6.09077079e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168608e-02, 4.95983345e-02, 4.25957059e-02, 6.09077080e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168606e-02, 4.95983349e-02, 4.25957058e-02, 6.09077083e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168607e-02, 4.95983349e-02, 4.25957063e-02, 6.09077083e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168606e-02, 4.95983351e-02, 4.25957061e-02, 6.09077086e+03,\n",
      "        1.90729034e+04, 1.73021239e+04, 1.45279573e+04]]), array([90486.75336569, 90486.75336575, 90486.75336577, 90486.75336609,\n",
      "       90486.75336629, 90486.75336661, 90486.75336662, 90486.75336664]))\n",
      "           fun: 90486.75336568736\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1230\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.06168610e-02, 4.95983339e-02, 4.25957054e-02, 6.09077079e+03,\n",
      "       1.90729035e+04, 1.73021239e+04, 1.45279573e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 91497.65906267175, bestParams: [0.054666173, 0.09095881, 0.06649772, 5459.7817, 5106.5513, 5879.891, 11712.161]\n",
      "epoch 7\n",
      " final_simplex: (array([[4.30860784e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "        9.78249630e+03, 9.13774297e+03, 7.77570167e+03],\n",
      "       [4.30860784e-02, 4.05039918e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249625e+03, 9.13774294e+03, 7.77570159e+03],\n",
      "       [4.30860785e-02, 4.05039917e-02, 4.19283439e-02, 3.17918518e+03,\n",
      "        9.78249632e+03, 9.13774297e+03, 7.77570168e+03],\n",
      "       [4.30860788e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "        9.78249631e+03, 9.13774300e+03, 7.77570166e+03],\n",
      "       [4.30860793e-02, 4.05039921e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249629e+03, 9.13774301e+03, 7.77570167e+03],\n",
      "       [4.30860797e-02, 4.05039928e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249627e+03, 9.13774295e+03, 7.77570175e+03],\n",
      "       [4.30860799e-02, 4.05039931e-02, 4.19283442e-02, 3.17918518e+03,\n",
      "        9.78249625e+03, 9.13774295e+03, 7.77570174e+03],\n",
      "       [4.30860800e-02, 4.05039930e-02, 4.19283442e-02, 3.17918518e+03,\n",
      "        9.78249624e+03, 9.13774295e+03, 7.77570174e+03]]), array([90480.57137342, 90480.57137345, 90480.57137348, 90480.57137366,\n",
      "       90480.57137391, 90480.571374  , 90480.57137409, 90480.57137411]))\n",
      "           fun: 90480.57137341992\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1357\n",
      "           nit: 569\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.30860784e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "       9.78249630e+03, 9.13774297e+03, 7.77570167e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90748.30062683142, bestParams: [0.07419606, 0.039394133, 0.028832112, 6168.2896, 21175.932, 24372.55, 6964.5005]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.83425215e-02, 3.05141356e-02, 4.41328425e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425210e-02, 3.05141358e-02, 4.41328427e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425213e-02, 3.05141355e-02, 4.41328426e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425204e-02, 3.05141360e-02, 4.41328427e-02, 6.29920487e+03,\n",
      "        2.23644696e+04, 2.12074130e+04, 1.02575861e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644696e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425206e-02, 3.05141358e-02, 4.41328426e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575861e+04]]), array([90499.4328383 , 90499.43283833, 90499.43283834, 90499.4328384 ,\n",
      "       90499.43283843, 90499.43283848, 90499.43283849, 90499.43283851]))\n",
      "           fun: 90499.43283829854\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1204\n",
      "           nit: 459\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.83425215e-02, 3.05141356e-02, 4.41328425e-02, 6.29920489e+03,\n",
      "       2.23644697e+04, 2.12074130e+04, 1.02575860e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 91296.27290015653, bestParams: [0.11290184, 0.13054714, 0.1386694, 5181.501, 8365.07, 8362.464, 14073.521]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.02097583e-02, 1.10225090e-01, 5.28885652e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097588e-02, 1.10225090e-01, 5.28885651e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097587e-02, 1.10225090e-01, 5.28885651e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097504e-02, 1.10225090e-01, 5.28885671e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099462e+04],\n",
      "       [9.02097550e-02, 1.10225090e-01, 5.28885660e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097555e-02, 1.10225090e-01, 5.28885659e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097559e-02, 1.10225090e-01, 5.28885658e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097561e-02, 1.10225090e-01, 5.28885658e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04]]), array([90626.40935142, 90626.40935145, 90626.40935145, 90626.40935773,\n",
      "       90626.40935794, 90626.40935797, 90626.40935799, 90626.40935799]))\n",
      "           fun: 90626.40935142341\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2984\n",
      "           nit: 1336\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.02097583e-02, 1.10225090e-01, 5.28885652e-02, 5.25880194e+03,\n",
      "       1.01009865e+04, 1.00144483e+04, 1.76099461e+04])\n",
      "minPrevious 90476.89262346049\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0397, 0.0384, 0.0402], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8799, 0.0645, 0.0279, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8632, 0.0797, 0.0259, 0.0312], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8797, 0.0279, 0.0630, 0.0252], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8646, 0.0259, 0.0782, 0.0313], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7380, 0.0977, 0.0978, 0.0611], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7017, 0.1143, 0.1130, 0.0710], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7900, 4.1484, 4.0321],\n",
      "        [3.0761, 4.3315, 6.6560],\n",
      "        [2.8822, 3.3881, 5.3680],\n",
      "        ...,\n",
      "        [2.3470, 2.6197, 4.9254],\n",
      "        [1.9785, 2.4099, 3.6386],\n",
      "        [2.8596, 1.1003, 4.5087]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.632166147232056\n",
      "Run: 0, 2\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[38.,  5.,  3.,  2.],\n",
      "        [46.,  6.,  0.,  4.],\n",
      "        [42.,  5.,  3.,  4.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [53.,  2.,  3.,  2.],\n",
      "        [47.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([48., 56., 54.,  ..., 70., 60., 50.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 6., 5.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 3.,  ..., 2., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 4., 4.,  ..., 2., 2., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[38.,  5.,  3.,  2.],\n",
      "        [46.,  6.,  0.,  4.],\n",
      "        [42.,  5.,  3.,  4.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [53.,  2.,  3.,  2.],\n",
      "        [47.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([5.5336e-05, 2.3030e-06, 3.0288e-06,  ..., 5.4883e-03, 4.3785e-03,\n",
      "        3.9273e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3eb90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90729.31401045548, bestParams: [0.04714876, 0.012392071, 0.053447075, 7013.6914, 12085.93, 22692.54, 17837.424]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.33117250e-02, 2.04074664e-02, 4.59170420e-02, 5.82361142e+03,\n",
      "        1.80858056e+04, 2.06137097e+04, 9.83484979e+03],\n",
      "       [3.33117247e-02, 2.04074666e-02, 4.59170423e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484977e+03],\n",
      "       [3.33117250e-02, 2.04074665e-02, 4.59170422e-02, 5.82361140e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484981e+03],\n",
      "       [3.33117246e-02, 2.04074667e-02, 4.59170427e-02, 5.82361135e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484984e+03],\n",
      "       [3.33117235e-02, 2.04074668e-02, 4.59170428e-02, 5.82361134e+03,\n",
      "        1.80858056e+04, 2.06137097e+04, 9.83484973e+03],\n",
      "       [3.33117244e-02, 2.04074666e-02, 4.59170425e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484982e+03],\n",
      "       [3.33117253e-02, 2.04074665e-02, 4.59170425e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484977e+03],\n",
      "       [3.33117247e-02, 2.04074666e-02, 4.59170427e-02, 5.82361137e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484979e+03]]), array([90493.42080322, 90493.42080323, 90493.42080334, 90493.42080338,\n",
      "       90493.4208034 , 90493.42080347, 90493.42080347, 90493.42080351]))\n",
      "           fun: 90493.42080322158\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1276\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.33117250e-02, 2.04074664e-02, 4.59170420e-02, 5.82361142e+03,\n",
      "       1.80858056e+04, 2.06137097e+04, 9.83484979e+03])\n",
      "best ll: 90732.75782383714, bestParams: [0.026286537, 0.090551235, 0.06254556, 6272.722, 16600.713, 17853.037, 18413.832]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379185e-02, 3.65881725e-02, 4.13337161e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379184e-02, 3.65881725e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379192e-02, 3.65881712e-02, 4.13337149e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379215e-02, 3.65881670e-02, 4.13337104e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379220e-02, 3.65881662e-02, 4.13337095e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04]]), array([90476.45793291, 90476.45793291, 90476.45793292, 90476.45793292,\n",
      "       90476.45793305, 90476.45793305, 90476.45793305, 90476.45793306]))\n",
      "           fun: 90476.45793290669\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2009\n",
      "           nit: 867\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "       2.20264360e+04, 2.27778555e+04, 1.56540855e+04])\n",
      "minPrevious 90493.42080322158\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379185e-02, 3.65881725e-02, 4.13337161e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379184e-02, 3.65881725e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379192e-02, 3.65881712e-02, 4.13337149e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379215e-02, 3.65881670e-02, 4.13337104e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379220e-02, 3.65881662e-02, 4.13337095e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04]]), array([90476.45793291, 90476.45793291, 90476.45793292, 90476.45793292,\n",
      "       90476.45793305, 90476.45793305, 90476.45793305, 90476.45793306]))\n",
      "           fun: 90476.45793290669\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2009\n",
      "           nit: 867\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "       2.20264360e+04, 2.27778555e+04, 1.56540855e+04])\n",
      "best ll: 90768.5476276376, bestParams: [0.035219885, 0.09352289, 0.08136546, 7144.487, 12225.303, 11796.263, 16765.65]\n",
      "epoch 2\n",
      " final_simplex: (array([[4.65238400e-02, 6.44146076e-02, 4.12197981e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146078e-02, 4.12197982e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146078e-02, 4.12197982e-02, 5.96552759e+03,\n",
      "        1.68314529e+04, 1.52391460e+04, 1.52451012e+04],\n",
      "       [4.65238401e-02, 6.44146081e-02, 4.12197979e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238401e-02, 6.44146082e-02, 4.12197980e-02, 5.96552759e+03,\n",
      "        1.68314529e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146084e-02, 4.12197976e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451012e+04],\n",
      "       [4.65238401e-02, 6.44146083e-02, 4.12197978e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146084e-02, 4.12197976e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451012e+04]]), array([90515.26528606, 90515.26528614, 90515.26528617, 90515.26528672,\n",
      "       90515.26528676, 90515.26528692, 90515.26528698, 90515.26528702]))\n",
      "           fun: 90515.26528606444\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1692\n",
      "           nit: 718\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.65238400e-02, 6.44146076e-02, 4.12197981e-02, 5.96552759e+03,\n",
      "       1.68314530e+04, 1.52391460e+04, 1.52451011e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 91066.53966861677, bestParams: [0.074466266, 0.08731467, 0.05386589, 5332.576, 21387.4, 14033.31, 14331.92]\n",
      "epoch 3\n",
      " final_simplex: (array([[6.01747648e-02, 4.74827058e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747647e-02, 4.74827060e-02, 4.25113519e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747646e-02, 4.74827057e-02, 4.25113525e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267154e+04],\n",
      "       [6.01747648e-02, 4.74827057e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747647e-02, 4.74827060e-02, 4.25113524e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267154e+04],\n",
      "       [6.01747649e-02, 4.74827058e-02, 4.25113522e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747649e-02, 4.74827055e-02, 4.25113523e-02, 6.63523070e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267156e+04],\n",
      "       [6.01747651e-02, 4.74827060e-02, 4.25113520e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04]]), array([90504.39416636, 90504.39416637, 90504.39416639, 90504.3941664 ,\n",
      "       90504.39416647, 90504.39416659, 90504.39416662, 90504.39416662]))\n",
      "           fun: 90504.39416636349\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1256\n",
      "           nit: 502\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.01747648e-02, 4.74827058e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "       1.67311435e+04, 1.85195322e+04, 1.85267155e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90970.57307666962, bestParams: [0.0472617, 0.06842829, 0.05356198, 8647.348, 17162.938, 13426.564, 15939.611]\n",
      "epoch 4\n",
      " final_simplex: (array([[4.82379986e-02, 6.64176122e-02, 5.29707453e-02, 6.53249533e+03,\n",
      "        1.67371434e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379985e-02, 6.64176126e-02, 5.29707455e-02, 6.53249532e+03,\n",
      "        1.67371435e+04, 1.62008374e+04, 1.69415655e+04],\n",
      "       [4.82379985e-02, 6.64176125e-02, 5.29707455e-02, 6.53249531e+03,\n",
      "        1.67371435e+04, 1.62008374e+04, 1.69415655e+04],\n",
      "       [4.82379987e-02, 6.64176129e-02, 5.29707456e-02, 6.53249531e+03,\n",
      "        1.67371434e+04, 1.62008374e+04, 1.69415654e+04],\n",
      "       [4.82379989e-02, 6.64176128e-02, 5.29707456e-02, 6.53249531e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379995e-02, 6.64176129e-02, 5.29707460e-02, 6.53249531e+03,\n",
      "        1.67371434e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379992e-02, 6.64176132e-02, 5.29707460e-02, 6.53249530e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415654e+04],\n",
      "       [4.82379995e-02, 6.64176132e-02, 5.29707461e-02, 6.53249529e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415655e+04]]), array([90529.94631074, 90529.94631171, 90529.94631177, 90529.94631258,\n",
      "       90529.9463127 , 90529.94631417, 90529.94631475, 90529.94631492]))\n",
      "           fun: 90529.94631074075\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1416\n",
      "           nit: 580\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.82379986e-02, 6.64176122e-02, 5.29707453e-02, 6.53249533e+03,\n",
      "       1.67371434e+04, 1.62008373e+04, 1.69415655e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90676.96857508212, bestParams: [0.019758662, 0.040811747, 0.07994546, 5986.399, 18685.148, 19524.918, 7057.7544]\n",
      "epoch 5\n",
      " final_simplex: (array([[2.16419345e-02, 3.82889994e-02, 4.21537846e-02, 5.67924004e+03,\n",
      "        1.92461813e+04, 1.89292301e+04, 9.56055409e+03],\n",
      "       [2.16419346e-02, 3.82889993e-02, 4.21537843e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292300e+04, 9.56055415e+03],\n",
      "       [2.16419345e-02, 3.82889994e-02, 4.21537847e-02, 5.67924006e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055411e+03],\n",
      "       [2.16419346e-02, 3.82889994e-02, 4.21537843e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055413e+03],\n",
      "       [2.16419346e-02, 3.82889995e-02, 4.21537839e-02, 5.67924004e+03,\n",
      "        1.92461813e+04, 1.89292300e+04, 9.56055416e+03],\n",
      "       [2.16419345e-02, 3.82889994e-02, 4.21537847e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055411e+03],\n",
      "       [2.16419346e-02, 3.82889994e-02, 4.21537842e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055413e+03],\n",
      "       [2.16419345e-02, 3.82889995e-02, 4.21537854e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292302e+04, 9.56055403e+03]]), array([90489.89028648, 90489.89028649, 90489.8902865 , 90489.89028651,\n",
      "       90489.89028664, 90489.89029371, 90489.89029371, 90489.89029372]))\n",
      "           fun: 90489.89028647794\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1144\n",
      "           nit: 370\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.16419345e-02, 3.82889994e-02, 4.21537846e-02, 5.67924004e+03,\n",
      "       1.92461813e+04, 1.89292301e+04, 9.56055409e+03])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90614.04184293446, bestParams: [0.045280494, 0.037793145, 0.059227735, 7774.5674, 18537.154, 16869.389, 16223.571]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.63254603e-02, 4.03578762e-02, 4.26819493e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254605e-02, 4.03578763e-02, 4.26819491e-02, 6.80712184e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04],\n",
      "       [4.63254611e-02, 4.03578752e-02, 4.26819506e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254615e-02, 4.03578750e-02, 4.26819507e-02, 6.80712185e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254623e-02, 4.03578738e-02, 4.26819521e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254625e-02, 4.03578735e-02, 4.26819527e-02, 6.80712185e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04],\n",
      "       [4.63254627e-02, 4.03578731e-02, 4.26819533e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254631e-02, 4.03578727e-02, 4.26819538e-02, 6.80712185e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04]]), array([90481.01067873, 90481.01067887, 90481.01067918, 90481.01067943,\n",
      "       90481.01067984, 90481.01068004, 90481.01068014, 90481.01068039]))\n",
      "           fun: 90481.0106787277\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1407\n",
      "           nit: 591\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.63254603e-02, 4.03578762e-02, 4.26819493e-02, 6.80712183e+03,\n",
      "       1.93045360e+04, 2.10435576e+04, 1.53310997e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 91118.26744689574, bestParams: [0.16203003, 0.019491551, 0.10167087, 9075.078, 17631.64, 23901.205, 12888.103]\n",
      "epoch 7\n",
      " final_simplex: (array([[5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136007e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136009e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136009e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136010e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136010e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04]]), array([90512.80037146, 90512.80037147, 90512.80037148, 90512.80037158,\n",
      "       90512.80037168, 90512.80037168, 90512.8003717 , 90512.80037172]))\n",
      "           fun: 90512.80037145794\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2992\n",
      "           nit: 1354\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "       2.06886979e+04, 2.46288633e+04, 2.07469199e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90838.88955760052, bestParams: [0.01900933, 0.062275536, 0.047462903, 11755.048, 22521.502, 21961.916, 23298.01]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299854e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299854e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219301e-02, 5.02727421e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727421e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04],\n",
      "       [2.01924312e-02, 6.12219301e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04]]), array([90532.29920238, 90532.29920238, 90532.2992024 , 90532.29920254,\n",
      "       90532.29920259, 90532.2992027 , 90532.2992027 , 90532.29920271]))\n",
      "           fun: 90532.2992023793\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2184\n",
      "           nit: 1013\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "       2.50541339e+04, 2.34886631e+04, 2.30431254e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90645.41395072266, bestParams: [0.03879742, 0.05967664, 0.0748788, 9502.963, 20872.686, 20331.674, 22603.602]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04],\n",
      "       [4.06434334e-02, 5.88736021e-02, 5.93604534e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04],\n",
      "       [4.06434335e-02, 5.88736021e-02, 5.93604534e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434334e-02, 5.88736020e-02, 5.93604535e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434335e-02, 5.88736020e-02, 5.93604536e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434334e-02, 5.88736019e-02, 5.93604537e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434333e-02, 5.88736020e-02, 5.93604536e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04]]), array([90534.19459469, 90534.19459469, 90534.19459501, 90534.19459519,\n",
      "       90534.1945955 , 90534.19459563, 90534.19459592, 90534.19459592]))\n",
      "           fun: 90534.1945946857\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1561\n",
      "           nit: 650\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "       2.27999522e+04, 2.37345303e+04, 2.21734048e+04])\n",
      "minPrevious 90476.45793290669\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0330, 0.0366, 0.0413], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8823, 0.0643, 0.0280, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8625, 0.0789, 0.0259, 0.0327], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8854, 0.0280, 0.0632, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8602, 0.0258, 0.0814, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7355, 0.0985, 0.0995, 0.0613], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7058, 0.1106, 0.1127, 0.0709], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4515, 3.4402, 6.3490],\n",
      "        [3.4732, 3.5567, 6.1192],\n",
      "        [2.5983, 1.4514, 4.2065],\n",
      "        ...,\n",
      "        [2.9968, 3.2012, 6.9698],\n",
      "        [3.0024, 3.0444, 5.9488],\n",
      "        [3.8132, 4.7613, 6.0924]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.432267189025879\n",
      "Run: 0, 3\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  0.],\n",
      "        [45.,  6.,  2.,  3.],\n",
      "        [35.,  6.,  2.,  3.],\n",
      "        ...,\n",
      "        [52.,  0.,  0.,  0.],\n",
      "        [49.,  2.,  0.,  0.],\n",
      "        [45.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "n tensor([45., 56., 46.,  ..., 52., 51., 49.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 6.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 2.,  ..., 0., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 3., 3.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  0.],\n",
      "        [45.,  6.,  2.,  3.],\n",
      "        [35.,  6.,  2.,  3.],\n",
      "        ...,\n",
      "        [52.,  0.,  0.,  0.],\n",
      "        [49.,  2.,  0.,  0.],\n",
      "        [45.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([7.8009e-02, 1.5891e-05, 2.8535e-06,  ..., 2.6907e-02, 3.3099e-02,\n",
      "        2.7306e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3e8c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90687.73814175435, bestParams: [0.020037124, 0.0016247494, 0.040445533, 5294.021, 10814.926, 12456.389, 21372.918]\n",
      "epoch 0\n",
      " final_simplex: (array([[6.23123949e-02, 6.27163447e-03, 4.18681284e-02, 1.50217719e+03,\n",
      "        4.00664783e+03, 5.09986993e+03, 3.23227687e+03],\n",
      "       [6.23123948e-02, 6.27163447e-03, 4.18681283e-02, 1.50217718e+03,\n",
      "        4.00664785e+03, 5.09986989e+03, 3.23227688e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681282e-02, 1.50217718e+03,\n",
      "        4.00664787e+03, 5.09986996e+03, 3.23227683e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681282e-02, 1.50217718e+03,\n",
      "        4.00664788e+03, 5.09986997e+03, 3.23227683e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681281e-02, 1.50217718e+03,\n",
      "        4.00664789e+03, 5.09986998e+03, 3.23227682e+03],\n",
      "       [6.23123947e-02, 6.27163449e-03, 4.18681278e-02, 1.50217718e+03,\n",
      "        4.00664791e+03, 5.09986998e+03, 3.23227682e+03],\n",
      "       [6.23123950e-02, 6.27163449e-03, 4.18681283e-02, 1.50217718e+03,\n",
      "        4.00664785e+03, 5.09986993e+03, 3.23227683e+03],\n",
      "       [6.23123948e-02, 6.27163449e-03, 4.18681280e-02, 1.50217718e+03,\n",
      "        4.00664789e+03, 5.09986997e+03, 3.23227682e+03]]), array([90272.52946674, 90272.52946678, 90272.52946686, 90272.52946687,\n",
      "       90272.52946696, 90272.52946701, 90272.52946703, 90272.52946704]))\n",
      "           fun: 90272.52946674361\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1461\n",
      "           nit: 666\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.23123949e-02, 6.27163447e-03, 4.18681284e-02, 1.50217719e+03,\n",
      "       4.00664783e+03, 5.09986993e+03, 3.23227687e+03])\n",
      "best ll: 90497.28227752695, bestParams: [0.06955907, 0.049383625, 0.019450903, 993.1664, 3395.9521, 4111.0713, 3434.7034]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "        3.48913750e+03, 3.62500697e+03, 2.81886087e+03],\n",
      "       [4.14664508e-02, 3.51992356e-02, 3.96515439e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500699e+03, 2.81886085e+03],\n",
      "       [4.14664512e-02, 3.51992344e-02, 3.96515438e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500696e+03, 2.81886087e+03],\n",
      "       [4.14664522e-02, 3.51992339e-02, 3.96515431e-02, 1.18685429e+03,\n",
      "        3.48913748e+03, 3.62500698e+03, 2.81886091e+03],\n",
      "       [4.14664516e-02, 3.51992308e-02, 3.96515449e-02, 1.18685428e+03,\n",
      "        3.48913748e+03, 3.62500705e+03, 2.81886082e+03],\n",
      "       [4.14664515e-02, 3.51992312e-02, 3.96515447e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500707e+03, 2.81886080e+03],\n",
      "       [4.14664519e-02, 3.51992301e-02, 3.96515453e-02, 1.18685429e+03,\n",
      "        3.48913751e+03, 3.62500700e+03, 2.81886079e+03],\n",
      "       [4.14664531e-02, 3.51992354e-02, 3.96515419e-02, 1.18685429e+03,\n",
      "        3.48913745e+03, 3.62500700e+03, 2.81886093e+03]]), array([90173.52423769, 90173.52423776, 90173.52423781, 90173.52423785,\n",
      "       90173.52423792, 90173.52423796, 90173.52423814, 90173.52423952]))\n",
      "           fun: 90173.52423769064\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1084\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "       3.48913750e+03, 3.62500697e+03, 2.81886087e+03])\n",
      "minPrevious 90272.52946674361\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "        3.48913750e+03, 3.62500697e+03, 2.81886087e+03],\n",
      "       [4.14664508e-02, 3.51992356e-02, 3.96515439e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500699e+03, 2.81886085e+03],\n",
      "       [4.14664512e-02, 3.51992344e-02, 3.96515438e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500696e+03, 2.81886087e+03],\n",
      "       [4.14664522e-02, 3.51992339e-02, 3.96515431e-02, 1.18685429e+03,\n",
      "        3.48913748e+03, 3.62500698e+03, 2.81886091e+03],\n",
      "       [4.14664516e-02, 3.51992308e-02, 3.96515449e-02, 1.18685428e+03,\n",
      "        3.48913748e+03, 3.62500705e+03, 2.81886082e+03],\n",
      "       [4.14664515e-02, 3.51992312e-02, 3.96515447e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500707e+03, 2.81886080e+03],\n",
      "       [4.14664519e-02, 3.51992301e-02, 3.96515453e-02, 1.18685429e+03,\n",
      "        3.48913751e+03, 3.62500700e+03, 2.81886079e+03],\n",
      "       [4.14664531e-02, 3.51992354e-02, 3.96515419e-02, 1.18685429e+03,\n",
      "        3.48913745e+03, 3.62500700e+03, 2.81886093e+03]]), array([90173.52423769, 90173.52423776, 90173.52423781, 90173.52423785,\n",
      "       90173.52423792, 90173.52423796, 90173.52423814, 90173.52423952]))\n",
      "           fun: 90173.52423769064\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1084\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "       3.48913750e+03, 3.62500697e+03, 2.81886087e+03])\n",
      "best ll: 90579.49768806256, bestParams: [0.03288942, 0.02397951, 0.07897693, 8103.033, 16135.493, 20025.127, 11541.397]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.42412644e-02, 2.66188892e-02, 4.06631400e-02, 6.36961886e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707348e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631401e-02, 6.36961884e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631400e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412646e-02, 2.66188891e-02, 4.06631403e-02, 6.36961884e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631402e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631403e-02, 6.36961883e+03,\n",
      "        1.97342763e+04, 2.11661146e+04, 1.37707349e+04],\n",
      "       [3.42412646e-02, 2.66188891e-02, 4.06631406e-02, 6.36961883e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412644e-02, 2.66188891e-02, 4.06631404e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707348e+04]]), array([90179.97233838, 90179.9723385 , 90179.97233857, 90179.97233863,\n",
      "       90179.97233866, 90179.97233875, 90179.97233881, 90179.97233886]))\n",
      "           fun: 90179.97233838026\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1185\n",
      "           nit: 451\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.42412644e-02, 2.66188892e-02, 4.06631400e-02, 6.36961886e+03,\n",
      "       1.97342764e+04, 2.11661147e+04, 1.37707348e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90290.6061973017, bestParams: [0.03196858, 0.025042191, 0.034106273, 8508.276, 24321.596, 20359.771, 22960.518]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.41951284e-02, 2.69611168e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757822e+04],\n",
      "       [3.41951285e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951284e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951286e-02, 2.69611168e-02, 3.76004125e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04]]), array([90177.91638654, 90177.91638655, 90177.91638656, 90177.91638657,\n",
      "       90177.91638659, 90177.9163866 , 90177.9163866 , 90177.91638661]))\n",
      "           fun: 90177.91638654124\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1191\n",
      "           nit: 457\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.41951284e-02, 2.69611168e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "       2.34625869e+04, 2.45893096e+04, 1.64757822e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90575.35435100387, bestParams: [0.0060032983, 0.026933348, 0.054366462, 7137.234, 10640.545, 9179.854, 21404.568]\n",
      "epoch 4\n",
      " final_simplex: (array([[8.03986655e-03, 2.82214893e-02, 4.14128756e-02, 4.25668422e+03,\n",
      "        1.54685785e+04, 1.41980696e+04, 6.95569755e+03],\n",
      "       [8.03986660e-03, 2.82214881e-02, 4.14128762e-02, 4.25668422e+03,\n",
      "        1.54685784e+04, 1.41980697e+04, 6.95569753e+03],\n",
      "       [8.03986647e-03, 2.82214902e-02, 4.14128754e-02, 4.25668422e+03,\n",
      "        1.54685786e+04, 1.41980695e+04, 6.95569755e+03],\n",
      "       [8.03986655e-03, 2.82214896e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569747e+03],\n",
      "       [8.03986653e-03, 2.82214897e-02, 4.14128750e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569756e+03],\n",
      "       [8.03986652e-03, 2.82214897e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685786e+04, 1.41980696e+04, 6.95569756e+03],\n",
      "       [8.03986652e-03, 2.82214894e-02, 4.14128750e-02, 4.25668422e+03,\n",
      "        1.54685785e+04, 1.41980696e+04, 6.95569755e+03],\n",
      "       [8.03986650e-03, 2.82214895e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569751e+03]]), array([90268.35024825, 90268.35024842, 90268.35024844, 90268.35024859,\n",
      "       90268.3502486 , 90268.3502487 , 90268.35024901, 90268.35024905]))\n",
      "           fun: 90268.35024824677\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1183\n",
      "           nit: 456\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.03986655e-03, 2.82214893e-02, 4.14128756e-02, 4.25668422e+03,\n",
      "       1.54685785e+04, 1.41980696e+04, 6.95569755e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90520.96658633223, bestParams: [0.006762284, 0.055848576, 0.053748373, 5909.411, 13514.936, 18434.523, 10014.059]\n",
      "epoch 5\n",
      " final_simplex: (array([[8.16848907e-03, 4.04653276e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848907e-03, 4.04653277e-02, 4.27240406e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848906e-03, 4.04653277e-02, 4.27240406e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751150e+04],\n",
      "       [8.16848904e-03, 4.04653280e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848902e-03, 4.04653284e-02, 4.27240407e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848900e-03, 4.04653289e-02, 4.27240411e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453744e+04, 1.08751149e+04],\n",
      "       [8.16848899e-03, 4.04653285e-02, 4.27240409e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751150e+04],\n",
      "       [8.16848898e-03, 4.04653292e-02, 4.27240411e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453744e+04, 1.08751149e+04]]), array([90267.56486031, 90267.56486033, 90267.5648605 , 90267.56486061,\n",
      "       90267.56486088, 90267.56486105, 90267.56486109, 90267.56486112]))\n",
      "           fun: 90267.56486031177\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1342\n",
      "           nit: 543\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.16848907e-03, 4.04653276e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "       1.78493877e+04, 1.54453745e+04, 1.08751149e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90581.20782424859, bestParams: [0.10886746, 0.06707341, 0.07024887, 10999.218, 23754.08, 24885.004, 19561.732]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.83275297e-02, 5.67416707e-02, 3.65272603e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573896e+04, 3.13480199e+04],\n",
      "       [4.83275299e-02, 5.67416707e-02, 3.65272602e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573896e+04, 3.13480199e+04],\n",
      "       [4.83275332e-02, 5.67416700e-02, 3.65272598e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480198e+04],\n",
      "       [4.83275290e-02, 5.67416709e-02, 3.65272605e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275295e-02, 5.67416707e-02, 3.65272600e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275297e-02, 5.67416707e-02, 3.65272600e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275298e-02, 5.67416707e-02, 3.65272599e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480200e+04],\n",
      "       [4.83275303e-02, 5.67416706e-02, 3.65272598e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04]]), array([90189.04135044, 90189.04135049, 90189.0413505 , 90189.04135052,\n",
      "       90189.04135053, 90189.04135054, 90189.04135061, 90189.04135062]))\n",
      "           fun: 90189.04135044114\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1331\n",
      "           nit: 546\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83275297e-02, 5.67416707e-02, 3.65272603e-02, 1.05765347e+04,\n",
      "       2.91787862e+04, 2.91573896e+04, 3.13480199e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90555.35314912771, bestParams: [0.075666025, 0.008240507, 0.07280902, 4451.4316, 14403.895, 18652.873, 7124.4673]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.75345528e-02, 1.18217802e-02, 4.36060567e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302072e+03],\n",
      "       [3.75345531e-02, 1.18217801e-02, 4.36060564e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302069e+03],\n",
      "       [3.75345538e-02, 1.18217800e-02, 4.36060561e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249052e+04, 8.93302064e+03],\n",
      "       [3.75345535e-02, 1.18217800e-02, 4.36060565e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249052e+04, 8.93302072e+03],\n",
      "       [3.75345529e-02, 1.18217799e-02, 4.36060556e-02, 4.78113062e+03,\n",
      "        1.46175004e+04, 1.68249053e+04, 8.93302074e+03],\n",
      "       [3.75345543e-02, 1.18217799e-02, 4.36060568e-02, 4.78113064e+03,\n",
      "        1.46175002e+04, 1.68249052e+04, 8.93302079e+03],\n",
      "       [3.75345536e-02, 1.18217798e-02, 4.36060554e-02, 4.78113063e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302072e+03],\n",
      "       [3.75345542e-02, 1.18217797e-02, 4.36060553e-02, 4.78113064e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302075e+03]]), array([90221.61895767, 90221.61895817, 90221.61895843, 90221.61895862,\n",
      "       90221.61895898, 90221.61895898, 90221.61895918, 90221.61895972]))\n",
      "           fun: 90221.61895766677\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1194\n",
      "           nit: 489\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.75345528e-02, 1.18217802e-02, 4.36060567e-02, 4.78113062e+03,\n",
      "       1.46175003e+04, 1.68249053e+04, 8.93302072e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90395.4796038286, bestParams: [0.06134892, 0.003452808, 0.03632547, 3497.0854, 10186.098, 13472.928, 3790.0637]\n",
      "epoch 8\n",
      " final_simplex: (array([[3.49284716e-02, 4.18222349e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580012e+03],\n",
      "       [3.49284732e-02, 4.18222342e-03, 4.69575910e-02, 3.10646349e+03,\n",
      "        9.64244548e+03, 1.13777085e+04, 4.91580008e+03],\n",
      "       [3.49284699e-02, 4.18222349e-03, 4.69575907e-02, 3.10646349e+03,\n",
      "        9.64244538e+03, 1.13777085e+04, 4.91580018e+03],\n",
      "       [3.49284715e-02, 4.18222344e-03, 4.69575909e-02, 3.10646349e+03,\n",
      "        9.64244541e+03, 1.13777085e+04, 4.91580014e+03],\n",
      "       [3.49284719e-02, 4.18222343e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "        9.64244541e+03, 1.13777085e+04, 4.91580014e+03],\n",
      "       [3.49284714e-02, 4.18222340e-03, 4.69575908e-02, 3.10646349e+03,\n",
      "        9.64244538e+03, 1.13777086e+04, 4.91580016e+03],\n",
      "       [3.49284753e-02, 4.18222328e-03, 4.69575913e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580006e+03],\n",
      "       [3.49284752e-02, 4.18222327e-03, 4.69575913e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580007e+03]]), array([90285.22832312, 90285.22832343, 90285.22832362, 90285.22832367,\n",
      "       90285.22832372, 90285.22832417, 90285.22832441, 90285.22832463]))\n",
      "           fun: 90285.22832312356\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 492\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.49284716e-02, 4.18222349e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "       9.64244544e+03, 1.13777085e+04, 4.91580012e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90804.47701967844, bestParams: [0.02829881, 0.04583288, 0.060337245, 3230.8723, 12052.119, 7720.8174, 1496.0844]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809893e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809893e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809891e+03, 5.06995532e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809891e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167376e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995534e+03, 3.69568086e+03]]), array([90177.73267181, 90177.73267182, 90177.73267233, 90177.73267234,\n",
      "       90177.73267234, 90177.73267235, 90177.73267237, 90177.73267239]))\n",
      "           fun: 90177.73267181247\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1430\n",
      "           nit: 545\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "       5.11809893e+03, 5.06995534e+03, 3.69568086e+03])\n",
      "minPrevious 90173.52423769064\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0415, 0.0352, 0.0397], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8723, 0.0624, 0.0276, 0.0250], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8661, 0.0763, 0.0259, 0.0318], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8843, 0.0280, 0.0639, 0.0256], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8633, 0.0259, 0.0792, 0.0316], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7430, 0.0978, 0.0982, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7028, 0.1122, 0.1146, 0.0705], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4822, 2.8212, 6.3377],\n",
      "        [4.2235, 4.4837, 6.1296],\n",
      "        [1.2765, 2.0591, 4.8962],\n",
      "        ...,\n",
      "        [4.5062, 4.2377, 5.8085],\n",
      "        [1.4207, 1.4554, 5.4347],\n",
      "        [4.4840, 3.6525, 6.3723]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.543172121047974\n",
      "Run: 0, 4\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[49., 11.,  0.,  0.],\n",
      "        [39.,  2.,  1.,  1.],\n",
      "        [35.,  3.,  1.,  4.],\n",
      "        ...,\n",
      "        [42.,  4.,  2.,  0.],\n",
      "        [43.,  0.,  1.,  4.],\n",
      "        [55.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([60., 43., 43.,  ..., 48., 48., 57.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([11.,  2.,  3.,  ...,  4.,  0.,  1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 4.,  ..., 0., 4., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[49., 11.,  0.,  0.],\n",
      "        [39.,  2.,  1.,  1.],\n",
      "        [35.,  3.,  1.,  4.],\n",
      "        ...,\n",
      "        [42.,  4.,  2.,  0.],\n",
      "        [43.,  0.,  1.,  4.],\n",
      "        [55.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([9.3661e-08, 2.4138e-02, 3.4307e-05,  ..., 4.7683e-03, 1.8925e-04,\n",
      "        5.4601e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3ed40>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91158.47332401684, bestParams: [0.014721362, 0.040411327, 0.04527418, 4070.2559, 20366.186, 16429.271, 14589.068]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.72872707e-02, 4.17161449e-02, 4.35534533e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534529e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514173e+04, 1.15286872e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534536e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514175e+04, 1.15286870e+04],\n",
      "       [1.72872708e-02, 4.17161450e-02, 4.35534534e-02, 5.36272838e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161450e-02, 4.35534530e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534535e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514175e+04, 1.15286871e+04],\n",
      "       [1.72872706e-02, 4.17161451e-02, 4.35534529e-02, 5.36272841e+03,\n",
      "        1.76994581e+04, 1.59514173e+04, 1.15286872e+04],\n",
      "       [1.72872706e-02, 4.17161446e-02, 4.35534535e-02, 5.36272842e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04]]), array([90634.76874514, 90634.76874517, 90634.7687452 , 90634.76874525,\n",
      "       90634.76874526, 90634.76874527, 90634.76874536, 90634.76874539]))\n",
      "           fun: 90634.76874513857\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1217\n",
      "           nit: 489\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.72872707e-02, 4.17161449e-02, 4.35534533e-02, 5.36272840e+03,\n",
      "       1.76994581e+04, 1.59514174e+04, 1.15286871e+04])\n",
      "best ll: 91029.49863072427, bestParams: [0.000116868476, 0.083636425, 0.05230697, 6775.021, 20220.621, 12728.145, 23588.809]\n",
      "epoch 1\n",
      " final_simplex: (array([[1.18818834e-04, 8.64093273e-02, 5.59627736e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818831e-04, 8.64093286e-02, 5.59627736e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818831e-04, 8.64093282e-02, 5.59627739e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008582e+04],\n",
      "       [1.18818830e-04, 8.64093284e-02, 5.59627741e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818829e-04, 8.64093286e-02, 5.59627741e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008582e+04],\n",
      "       [1.18818827e-04, 8.64093296e-02, 5.59627742e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818824e-04, 8.64093300e-02, 5.59627745e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008580e+04],\n",
      "       [1.18818824e-04, 8.64093304e-02, 5.59627745e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04]]), array([90829.02245938, 90829.02246006, 90829.02246008, 90829.02246026,\n",
      "       90829.02246044, 90829.02246087, 90829.02246132, 90829.02246156]))\n",
      "           fun: 90829.02245937861\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1663\n",
      "           nit: 713\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.18818834e-04, 8.64093273e-02, 5.59627736e-02, 7.16703301e+03,\n",
      "       1.82555166e+04, 1.55257759e+04, 1.81008581e+04])\n",
      "minPrevious 90634.76874513857\n",
      "best ll: 90847.93749848523, bestParams: [0.07447942, 0.020183373, 0.01751763, 5548.3296, 16806.486, 18398.387, 15708.237]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368230e+03],\n",
      "       [3.32608952e-02, 2.91607544e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786958e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598481e+04, 9.34368237e+03],\n",
      "       [3.32608968e-02, 2.91607543e-02, 3.74786956e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368236e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786957e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368233e+03],\n",
      "       [3.32608950e-02, 2.91607544e-02, 3.74786960e-02, 4.76599757e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608951e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117015e+04, 1.59598482e+04, 9.34368238e+03],\n",
      "       [3.32608951e-02, 2.91607543e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03]]), array([90610.2728004 , 90610.27280042, 90610.27280048, 90610.27280051,\n",
      "       90610.27280056, 90610.27280063, 90610.27280069, 90610.27280072]))\n",
      "           fun: 90610.27280040468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "       1.59117016e+04, 1.59598482e+04, 9.34368230e+03])\n",
      "minPrevious 90634.76874513857\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368230e+03],\n",
      "       [3.32608952e-02, 2.91607544e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786958e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598481e+04, 9.34368237e+03],\n",
      "       [3.32608968e-02, 2.91607543e-02, 3.74786956e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368236e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786957e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368233e+03],\n",
      "       [3.32608950e-02, 2.91607544e-02, 3.74786960e-02, 4.76599757e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608951e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117015e+04, 1.59598482e+04, 9.34368238e+03],\n",
      "       [3.32608951e-02, 2.91607543e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03]]), array([90610.2728004 , 90610.27280042, 90610.27280048, 90610.27280051,\n",
      "       90610.27280056, 90610.27280063, 90610.27280069, 90610.27280072]))\n",
      "           fun: 90610.27280040468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "       1.59117016e+04, 1.59598482e+04, 9.34368230e+03])\n",
      "best ll: 90890.4621477907, bestParams: [0.028222447, 0.017594956, 0.0381772, 3712.175, 18208.807, 12144.222, 4784.1777]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.32745082e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086204e+03],\n",
      "       [3.32745080e-02, 2.12040114e-02, 4.29595582e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595581e-02, 3.36413636e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086202e+03],\n",
      "       [3.32745081e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086205e+03],\n",
      "       [3.32745080e-02, 2.12040113e-02, 4.29595581e-02, 3.36413636e+03,\n",
      "        1.12159341e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595582e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086205e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595583e-02, 3.36413636e+03,\n",
      "        1.12159339e+04, 1.19742536e+04, 5.79086203e+03]]), array([90628.72181675, 90628.72181677, 90628.72181677, 90628.72181681,\n",
      "       90628.72181681, 90628.72181685, 90628.7218169 , 90628.7218169 ]))\n",
      "           fun: 90628.72181674631\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1181\n",
      "           nit: 436\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32745082e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "       1.12159340e+04, 1.19742536e+04, 5.79086204e+03])\n",
      "minPrevious 90610.27280040468\n",
      "best ll: 90804.34225338264, bestParams: [0.023374725, 0.09260894, 0.04005881, 8117.6123, 16497.006, 16204.368, 24964.37]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274795e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190240e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819772e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190242e-02, 3.86819771e-02, 6.92017778e+03,\n",
      "        2.38232316e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190238e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274795e+04],\n",
      "       [2.53037902e-02, 4.64190240e-02, 3.86819774e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472489e+04, 1.47274796e+04]]), array([90610.97812776, 90610.97812779, 90610.9781278 , 90610.9781278 ,\n",
      "       90610.97812784, 90610.97812801, 90610.97814434, 90610.97814438]))\n",
      "           fun: 90610.97812776301\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1231\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "       2.38232317e+04, 2.13472490e+04, 1.47274795e+04])\n",
      "minPrevious 90610.27280040468\n",
      "best ll: 91012.84705452244, bestParams: [0.06232762, 0.034690365, 0.038248792, 3659.6003, 12318.186, 6756.515, 8484.942]\n",
      "epoch 5\n",
      " final_simplex: (array([[4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861992e+03],\n",
      "       [4.83273467e-02, 4.23176213e-02, 4.03140866e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861993e+03],\n",
      "       [4.83273481e-02, 4.23176224e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273481e-02, 4.23176225e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273487e-02, 4.23176230e-02, 4.03140823e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862000e+03],\n",
      "       [4.83273490e-02, 4.23176232e-02, 4.03140817e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273491e-02, 4.23176233e-02, 4.03140815e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273494e-02, 4.23176235e-02, 4.03140810e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862002e+03]]), array([90604.5572683 , 90604.55726843, 90604.55726955, 90604.55726956,\n",
      "       90604.55727007, 90604.55727031, 90604.55727036, 90604.55727057]))\n",
      "           fun: 90604.5572682951\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 3106\n",
      "           nit: 1429\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "       9.51034532e+03, 9.65504541e+03, 7.93861992e+03])\n",
      "minPrevious 90610.27280040468\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861992e+03],\n",
      "       [4.83273467e-02, 4.23176213e-02, 4.03140866e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861993e+03],\n",
      "       [4.83273481e-02, 4.23176224e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273481e-02, 4.23176225e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273487e-02, 4.23176230e-02, 4.03140823e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862000e+03],\n",
      "       [4.83273490e-02, 4.23176232e-02, 4.03140817e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273491e-02, 4.23176233e-02, 4.03140815e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273494e-02, 4.23176235e-02, 4.03140810e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862002e+03]]), array([90604.5572683 , 90604.55726843, 90604.55726955, 90604.55726956,\n",
      "       90604.55727007, 90604.55727031, 90604.55727036, 90604.55727057]))\n",
      "           fun: 90604.5572682951\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 3106\n",
      "           nit: 1429\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "       9.51034532e+03, 9.65504541e+03, 7.93861992e+03])\n",
      "best ll: 90973.150105765, bestParams: [0.0043483237, 0.1723103, 0.063694075, 5563.539, 10523.814, 9726.051, 20610.318]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.48004476e-03, 1.69499920e-01, 6.10019645e-02, 5.98757017e+03,\n",
      "        1.11423656e+04, 9.44868017e+03, 1.84977817e+04],\n",
      "       [4.48004475e-03, 1.69499920e-01, 6.10019649e-02, 5.98757013e+03,\n",
      "        1.11423657e+04, 9.44868016e+03, 1.84977817e+04],\n",
      "       [4.48004478e-03, 1.69499921e-01, 6.10019649e-02, 5.98757011e+03,\n",
      "        1.11423657e+04, 9.44868014e+03, 1.84977817e+04],\n",
      "       [4.48004476e-03, 1.69499921e-01, 6.10019650e-02, 5.98757014e+03,\n",
      "        1.11423657e+04, 9.44868013e+03, 1.84977817e+04],\n",
      "       [4.48004475e-03, 1.69499922e-01, 6.10019654e-02, 5.98757014e+03,\n",
      "        1.11423656e+04, 9.44868012e+03, 1.84977818e+04],\n",
      "       [4.48004474e-03, 1.69499924e-01, 6.10019654e-02, 5.98757012e+03,\n",
      "        1.11423656e+04, 9.44868008e+03, 1.84977818e+04],\n",
      "       [4.48004471e-03, 1.69499924e-01, 6.10019651e-02, 5.98757016e+03,\n",
      "        1.11423657e+04, 9.44868010e+03, 1.84977816e+04],\n",
      "       [4.48004469e-03, 1.69499924e-01, 6.10019655e-02, 5.98757013e+03,\n",
      "        1.11423657e+04, 9.44868009e+03, 1.84977817e+04]]), array([90875.20110852, 90875.2011087 , 90875.20110879, 90875.20110889,\n",
      "       90875.20110966, 90875.20111022, 90875.2011103 , 90875.20111065]))\n",
      "           fun: 90875.20110852493\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1082\n",
      "           nit: 377\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.48004476e-03, 1.69499920e-01, 6.10019645e-02, 5.98757017e+03,\n",
      "       1.11423656e+04, 9.44868017e+03, 1.84977817e+04])\n",
      "minPrevious 90604.5572682951\n",
      "best ll: 91007.53714748367, bestParams: [0.03484704, 0.027896117, 0.062791444, 4148.296, 18361.578, 16205.281, 10942.79]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529420e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334977e+04],\n",
      "       [3.58243337e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111420e+04, 1.57094699e+04, 1.04334975e+04]]), array([90602.51359827, 90602.51359829, 90602.51359829, 90602.51359829,\n",
      "       90602.51359833, 90602.51359836, 90602.51359864, 90602.51360201]))\n",
      "           fun: 90602.51359826833\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1241\n",
      "           nit: 441\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "       1.57111421e+04, 1.57094699e+04, 1.04334976e+04])\n",
      "minPrevious 90604.5572682951\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529420e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334977e+04],\n",
      "       [3.58243337e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111420e+04, 1.57094699e+04, 1.04334975e+04]]), array([90602.51359827, 90602.51359829, 90602.51359829, 90602.51359829,\n",
      "       90602.51359833, 90602.51359836, 90602.51359864, 90602.51360201]))\n",
      "           fun: 90602.51359826833\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1241\n",
      "           nit: 441\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "       1.57111421e+04, 1.57094699e+04, 1.04334976e+04])\n",
      "best ll: 91015.41612460106, bestParams: [0.12024945, 0.09470742, 0.06604782, 6515.7124, 9441.274, 11384.588, 14921.515]\n",
      "epoch 8\n",
      " final_simplex: (array([[1.15905749e-01, 8.86839476e-02, 6.41709445e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839473e-02, 6.41709447e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839465e-02, 6.41709450e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181450e+04, 1.75717270e+04],\n",
      "       [1.15905750e-01, 8.86839466e-02, 6.41709449e-02, 5.67383150e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839466e-02, 6.41709453e-02, 5.67383149e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839466e-02, 6.41709455e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181452e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839461e-02, 6.41709455e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717270e+04],\n",
      "       [1.15905749e-01, 8.86839464e-02, 6.41709457e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04]]), array([90791.50925081, 90791.50925131, 90791.509252  , 90791.50925231,\n",
      "       90791.50925269, 90791.50925337, 90791.50925357, 90791.50925369]))\n",
      "           fun: 90791.50925081424\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1149\n",
      "           nit: 380\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.15905749e-01, 8.86839476e-02, 6.41709445e-02, 5.67383148e+03,\n",
      "       1.04222081e+04, 1.12181451e+04, 1.75717269e+04])\n",
      "minPrevious 90602.51359826833\n",
      "best ll: 91011.46463348175, bestParams: [0.06312266, 0.029164523, 0.039597854, 8029.851, 24910.959, 18420.938, 11092.687]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093559e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093560e-02, 3.06041703e-02, 4.03519653e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04]]), array([90610.3734693 , 90610.37346932, 90610.37346938, 90610.37346949,\n",
      "       90610.3734696 , 90610.37346963, 90610.37346964, 90610.37346966]))\n",
      "           fun: 90610.37346929763\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2680\n",
      "           nit: 1248\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "       2.11833428e+04, 2.21593122e+04, 1.38361985e+04])\n",
      "minPrevious 90602.51359826833\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0358, 0.0335, 0.0445], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8858, 0.0647, 0.0281, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8600, 0.0815, 0.0258, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8860, 0.0281, 0.0646, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8600, 0.0258, 0.0816, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7406, 0.0995, 0.0989, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7059, 0.1114, 0.1115, 0.0713], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.0054, 3.8620, 6.9140],\n",
      "        [2.8371, 3.1236, 4.0172],\n",
      "        [3.2060, 4.0941, 6.7157],\n",
      "        ...,\n",
      "        [2.7681, 3.9681, 4.6108],\n",
      "        [2.3565, 2.2976, 6.9109],\n",
      "        [2.9001, 2.6971, 4.8654]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.674013376235962\n",
      "Run: 0, 5\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  1.],\n",
      "        [51.,  2.,  1.,  1.],\n",
      "        [47.,  3.,  1.,  1.],\n",
      "        ...,\n",
      "        [48.,  2.,  3.,  1.],\n",
      "        [59.,  2.,  0.,  1.],\n",
      "        [63.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "n tensor([44., 55., 52.,  ..., 54., 62., 66.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 3.,  ..., 2., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 3., 0., 3.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 1., 1.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  1.],\n",
      "        [51.,  2.,  1.,  1.],\n",
      "        [47.,  3.,  1.,  1.],\n",
      "        ...,\n",
      "        [48.,  2.,  3.,  1.],\n",
      "        [59.,  2.,  0.,  1.],\n",
      "        [63.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0248, 0.0290, 0.0136,  ..., 0.0106, 0.0165, 0.0126],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad035f0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91090.3604514042, bestParams: [0.043571133, 0.095463604, 0.0505203, 5832.7603, 16079.994, 12313.426, 8391.266]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.59893537e-02, 5.64996138e-02, 4.31957835e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996138e-02, 4.31957836e-02, 5.33859644e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893539e-02, 5.64996138e-02, 4.31957834e-02, 5.33859642e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996138e-02, 4.31957836e-02, 5.33859643e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996140e-02, 4.31957838e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996140e-02, 4.31957838e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893535e-02, 5.64996143e-02, 4.31957837e-02, 5.33859643e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028398e+04],\n",
      "       [3.59893536e-02, 5.64996143e-02, 4.31957839e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028398e+04]]), array([90799.07161255, 90799.07161264, 90799.07161274, 90799.07161275,\n",
      "       90799.07161278, 90799.0716128 , 90799.07161297, 90799.07161297]))\n",
      "           fun: 90799.07161254974\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.59893537e-02, 5.64996138e-02, 4.31957835e-02, 5.33859643e+03,\n",
      "       1.57706471e+04, 1.39949641e+04, 1.36028399e+04])\n",
      "best ll: 91093.57377619602, bestParams: [0.04420233, 0.06357479, 0.03340114, 4500.3525, 14206.233, 8924.385, 19454.049]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.49744082e-02, 6.21665645e-02, 4.15310181e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744086e-02, 6.21665646e-02, 4.15310186e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128040e+04],\n",
      "       [4.49744083e-02, 6.21665648e-02, 4.15310179e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128040e+04],\n",
      "       [4.49744083e-02, 6.21665651e-02, 4.15310180e-02, 4.61027368e+03,\n",
      "        1.30328999e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744086e-02, 6.21665651e-02, 4.15310186e-02, 4.61027367e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744088e-02, 6.21665655e-02, 4.15310183e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128039e+04],\n",
      "       [4.49744091e-02, 6.21665658e-02, 4.15310189e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744092e-02, 6.21665660e-02, 4.15310189e-02, 4.61027367e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128039e+04]]), array([90804.01018453, 90804.01018466, 90804.01018486, 90804.01018504,\n",
      "       90804.01018508, 90804.01018544, 90804.01018563, 90804.0101859 ]))\n",
      "           fun: 90804.01018452992\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1264\n",
      "           nit: 490\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.49744082e-02, 6.21665645e-02, 4.15310181e-02, 4.61027368e+03,\n",
      "       1.30329000e+04, 1.18758442e+04, 1.20128039e+04])\n",
      "minPrevious 90799.07161254974\n",
      "best ll: 91258.20962960232, bestParams: [0.0017469097, 0.01823081, 0.084255494, 10602.629, 13127.086, 18705.941, 23800.89]\n",
      "epoch 2\n",
      " final_simplex: (array([[2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294313e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864185e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864181e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864183e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864184e+03],\n",
      "       [2.11020782e-03, 2.95814602e-02, 5.19149978e-02, 6.74294313e+03,\n",
      "        2.45263191e+04, 2.07048135e+04, 9.00864183e+03]]), array([90955.06447395, 90955.06447396, 90955.06447396, 90955.06447397,\n",
      "       90955.06447398, 90955.06447399, 90955.06447401, 90955.06447402]))\n",
      "           fun: 90955.06447394771\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1358\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294313e+03,\n",
      "       2.45263190e+04, 2.07048135e+04, 9.00864185e+03])\n",
      "minPrevious 90799.07161254974\n",
      "best ll: 91230.90592004443, bestParams: [0.1362636, 0.18482453, 0.031719703, 2449.1853, 4716.1143, 3088.015, 11587.606]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "        7.21950271e+03, 6.88453503e+03, 5.45878630e+03],\n",
      "       [3.67651936e-02, 4.28943901e-02, 4.23365698e-02, 2.39682393e+03,\n",
      "        7.21950274e+03, 6.88453506e+03, 5.45878628e+03],\n",
      "       [3.67651929e-02, 4.28943907e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950270e+03, 6.88453500e+03, 5.45878628e+03],\n",
      "       [3.67651926e-02, 4.28943908e-02, 4.23365705e-02, 2.39682392e+03,\n",
      "        7.21950270e+03, 6.88453498e+03, 5.45878633e+03],\n",
      "       [3.67651912e-02, 4.28943931e-02, 4.23365699e-02, 2.39682394e+03,\n",
      "        7.21950278e+03, 6.88453496e+03, 5.45878628e+03],\n",
      "       [3.67651901e-02, 4.28943919e-02, 4.23365704e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453499e+03, 5.45878620e+03],\n",
      "       [3.67651903e-02, 4.28943912e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453498e+03, 5.45878626e+03],\n",
      "       [3.67651909e-02, 4.28943884e-02, 4.23365714e-02, 2.39682393e+03,\n",
      "        7.21950273e+03, 6.88453499e+03, 5.45878636e+03]]), array([90793.71585391, 90793.71585413, 90793.71585419, 90793.71585449,\n",
      "       90793.71585464, 90793.71585486, 90793.7158549 , 90793.7158549 ]))\n",
      "           fun: 90793.71585391468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1238\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "       7.21950271e+03, 6.88453503e+03, 5.45878630e+03])\n",
      "minPrevious 90799.07161254974\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "        7.21950271e+03, 6.88453503e+03, 5.45878630e+03],\n",
      "       [3.67651936e-02, 4.28943901e-02, 4.23365698e-02, 2.39682393e+03,\n",
      "        7.21950274e+03, 6.88453506e+03, 5.45878628e+03],\n",
      "       [3.67651929e-02, 4.28943907e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950270e+03, 6.88453500e+03, 5.45878628e+03],\n",
      "       [3.67651926e-02, 4.28943908e-02, 4.23365705e-02, 2.39682392e+03,\n",
      "        7.21950270e+03, 6.88453498e+03, 5.45878633e+03],\n",
      "       [3.67651912e-02, 4.28943931e-02, 4.23365699e-02, 2.39682394e+03,\n",
      "        7.21950278e+03, 6.88453496e+03, 5.45878628e+03],\n",
      "       [3.67651901e-02, 4.28943919e-02, 4.23365704e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453499e+03, 5.45878620e+03],\n",
      "       [3.67651903e-02, 4.28943912e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453498e+03, 5.45878626e+03],\n",
      "       [3.67651909e-02, 4.28943884e-02, 4.23365714e-02, 2.39682393e+03,\n",
      "        7.21950273e+03, 6.88453499e+03, 5.45878636e+03]]), array([90793.71585391, 90793.71585413, 90793.71585419, 90793.71585449,\n",
      "       90793.71585464, 90793.71585486, 90793.7158549 , 90793.7158549 ]))\n",
      "           fun: 90793.71585391468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1238\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "       7.21950271e+03, 6.88453503e+03, 5.45878630e+03])\n",
      "best ll: 91326.84358438406, bestParams: [0.02248766, 0.032484304, 0.052385617, 8575.685, 11063.958, 10108.009, 22795.377]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.84420417e-02, 3.46959567e-02, 4.26539702e-02, 4.46333716e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539702e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930251e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539704e-02, 4.46333716e+03,\n",
      "        1.44521197e+04, 1.37119075e+04, 9.14930251e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539703e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930248e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539703e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930251e+03],\n",
      "       [2.84420416e-02, 3.46959568e-02, 4.26539705e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420416e-02, 3.46959568e-02, 4.26539705e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420418e-02, 3.46959566e-02, 4.26539705e-02, 4.46333716e+03,\n",
      "        1.44521198e+04, 1.37119075e+04, 9.14930237e+03]]), array([90801.40632214, 90801.40632216, 90801.40632217, 90801.40632218,\n",
      "       90801.40632219, 90801.40632224, 90801.40632224, 90801.40632478]))\n",
      "           fun: 90801.40632214482\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1364\n",
      "           nit: 549\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.84420417e-02, 3.46959567e-02, 4.26539702e-02, 4.46333716e+03,\n",
      "       1.44521197e+04, 1.37119076e+04, 9.14930242e+03])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91152.77248384545, bestParams: [0.029007705, 0.047266837, 0.042739347, 3103.6965, 9688.097, 14387.982, 6064.706]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.05385898e-02, 4.40237968e-02, 4.16521419e-02, 3.36519154e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03],\n",
      "       [3.05385899e-02, 4.40237969e-02, 4.16521414e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845911e+03],\n",
      "       [3.05385899e-02, 4.40237970e-02, 4.16521414e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845912e+03],\n",
      "       [3.05385898e-02, 4.40237970e-02, 4.16521415e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845910e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521424e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845895e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521419e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845903e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521421e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03],\n",
      "       [3.05385892e-02, 4.40237968e-02, 4.16521421e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03]]), array([90798.38403306, 90798.3840331 , 90798.38403313, 90798.38403316,\n",
      "       90798.38403323, 90798.38403329, 90798.3840333 , 90798.38403332]))\n",
      "           fun: 90798.38403306226\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1259\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.05385898e-02, 4.40237968e-02, 4.16521419e-02, 3.36519154e+03,\n",
      "       1.10735933e+04, 1.00880013e+04, 6.82845902e+03])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91270.70408583432, bestParams: [0.015127707, 0.041919302, 0.03150278, 4334.455, 22769.922, 24498.379, 190.21886]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.75785932e-02, 1.95895246e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895245e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233751e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895247e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895246e-02, 4.58603911e-02, 5.09205005e+03,\n",
      "        2.27880383e+04, 2.20233750e+04, 2.36272117e+02],\n",
      "       [1.75785931e-02, 1.95895251e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895251e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895247e-02, 4.58603912e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895250e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02]]), array([90949.33571342, 90949.33571344, 90949.33571346, 90949.33571348,\n",
      "       90949.33571358, 90949.3357136 , 90949.3357136 , 90949.33571367]))\n",
      "           fun: 90949.33571342296\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1312\n",
      "           nit: 515\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.75785932e-02, 1.95895246e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "       2.27880384e+04, 2.20233750e+04, 2.36272116e+02])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91344.40237445639, bestParams: [0.03907052, 0.037808415, 0.034087338, 9922.918, 22659.93, 13472.755, 21920.426]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.74444807e-02, 4.19909125e-02, 4.05683430e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04],\n",
      "       [3.74444808e-02, 4.19909125e-02, 4.05683430e-02, 6.81299451e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909126e-02, 4.05683430e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444807e-02, 4.19909125e-02, 4.05683429e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04],\n",
      "       [3.74444808e-02, 4.19909127e-02, 4.05683430e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909127e-02, 4.05683429e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909126e-02, 4.05683429e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444807e-02, 4.19909125e-02, 4.05683428e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04]]), array([90794.23716006, 90794.23716007, 90794.23716007, 90794.23716008,\n",
      "       90794.23716009, 90794.23716009, 90794.2371601 , 90794.23716011]))\n",
      "           fun: 90794.2371600552\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1301\n",
      "           nit: 543\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.74444807e-02, 4.19909125e-02, 4.05683430e-02, 6.81299449e+03,\n",
      "       2.13149873e+04, 2.03928135e+04, 1.47412558e+04])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91361.03540276109, bestParams: [0.045425393, 0.07026239, 0.050605606, 5734.493, 18005.092, 5601.4487, 22472.11]\n",
      "epoch 8\n",
      " final_simplex: (array([[5.31215249e-02, 7.05228155e-02, 4.47838949e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215248e-02, 7.05228156e-02, 4.47838951e-02, 4.51425556e+03,\n",
      "        1.17898264e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228154e-02, 4.47838952e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215251e-02, 7.05228153e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228152e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215250e-02, 7.05228154e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898264e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215251e-02, 7.05228155e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228155e-02, 4.47838958e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939907e+04]]), array([90817.22476695, 90817.22476704, 90817.22476722, 90817.22476724,\n",
      "       90817.22476725, 90817.22476726, 90817.22476734, 90817.22476763]))\n",
      "           fun: 90817.22476694567\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1196\n",
      "           nit: 465\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.31215249e-02, 7.05228155e-02, 4.47838949e-02, 4.51425556e+03,\n",
      "       1.17898265e+04, 1.08016156e+04, 1.24939908e+04])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91309.75771624263, bestParams: [0.02029038, 0.014870982, 0.010115627, 4392.174, 19204.947, 19952.209, 9782.406]\n",
      "epoch 9\n",
      " final_simplex: (array([[2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587151e+02,\n",
      "        8.13689375e+02, 7.66991520e+02, 4.17404243e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689369e+02, 7.66991516e+02, 4.17404245e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689365e+02, 7.66991513e+02, 4.17404247e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689378e+02, 7.66991522e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587148e+02,\n",
      "        8.13689380e+02, 7.66991520e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587147e+02,\n",
      "        8.13689364e+02, 7.66991510e+02, 4.17404239e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587146e+02,\n",
      "        8.13689362e+02, 7.66991506e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587146e+02,\n",
      "        8.13689362e+02, 7.66991507e+02, 4.17404237e+02]]), array([90811.60778462, 90811.60778465, 90811.60778467, 90811.60778474,\n",
      "       90811.60778501, 90811.60778518, 90811.60778533, 90811.60778536]))\n",
      "           fun: 90811.60778462133\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1301\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587151e+02,\n",
      "       8.13689375e+02, 7.66991520e+02, 4.17404243e+02])\n",
      "minPrevious 90793.71585391468\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0368, 0.0429, 0.0423], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8815, 0.0637, 0.0279, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8660, 0.0782, 0.0259, 0.0299], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8880, 0.0282, 0.0649, 0.0260], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8691, 0.0260, 0.0749, 0.0299], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7411, 0.0987, 0.0971, 0.0616], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7086, 0.1125, 0.1095, 0.0694], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9130, 3.9638, 4.5806],\n",
      "        [4.8477, 3.1204, 4.6859],\n",
      "        [2.5043, 3.4648, 5.4998],\n",
      "        ...,\n",
      "        [2.2138, 3.9310, 6.0372],\n",
      "        [3.0004, 1.5042, 4.5456],\n",
      "        [3.2652, 3.3443, 5.2215]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.484266996383667\n",
      "Run: 0, 6\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[51.,  4.,  1.,  2.],\n",
      "        [40.,  2.,  0.,  0.],\n",
      "        [55.,  3.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  1.,  2.,  1.],\n",
      "        [59.,  0.,  4.,  0.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([58., 42., 61.,  ..., 52., 63., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 2., 3.,  ..., 1., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 0., 2.,  ..., 2., 4., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 1.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[51.,  4.,  1.,  2.],\n",
      "        [40.,  2.,  0.,  0.],\n",
      "        [55.,  3.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  1.,  2.,  1.],\n",
      "        [59.,  0.,  4.,  0.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0020, 0.0418, 0.0140,  ..., 0.0283, 0.0060, 0.0503],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad03950>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90705.78630343798, bestParams: [0.042797178, 0.03189743, 0.0427665, 7865.0444, 19529.307, 18785.924, 20957.984]\n",
      "epoch 0\n",
      " final_simplex: (array([[4.53094590e-02, 3.29430425e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289733e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675401e-02, 7.16461646e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718439e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718441e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04]]), array([90617.68016446, 90617.68016449, 90617.68016451, 90617.68016452,\n",
      "       90617.68016454, 90617.68016455, 90617.68016455, 90617.68016455]))\n",
      "           fun: 90617.68016446201\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1139\n",
      "           nit: 416\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.53094590e-02, 3.29430425e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "       2.07289734e+04, 2.24192353e+04, 1.77718440e+04])\n",
      "best ll: 91238.05435765057, bestParams: [0.05948744, 0.04102097, 0.013038766, 4660.9634, 18500.773, 21041.572, 23418.262]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.42696088e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799659e+03],\n",
      "       [3.42696092e-02, 3.41024516e-02, 3.87974592e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799652e+03],\n",
      "       [3.42696087e-02, 3.41024514e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799661e+03],\n",
      "       [3.42696086e-02, 3.41024513e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799663e+03],\n",
      "       [3.42696086e-02, 3.41024513e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799663e+03],\n",
      "       [3.42696085e-02, 3.41024512e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799664e+03],\n",
      "       [3.42696089e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799657e+03],\n",
      "       [3.42696082e-02, 3.41024511e-02, 3.87974589e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799669e+03]]), array([90618.91761162, 90618.91761169, 90618.91761169, 90618.91761183,\n",
      "       90618.91761185, 90618.91761194, 90618.91761205, 90618.91761219]))\n",
      "           fun: 90618.91761162136\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1909\n",
      "           nit: 848\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.42696088e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "       1.46360708e+04, 1.49596490e+04, 9.92799659e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90799.13652237343, bestParams: [0.08314967, 0.07155339, 0.06358579, 7604.4014, 13512.055, 14740.179, 23051.545]\n",
      "epoch 2\n",
      " final_simplex: (array([[8.04633027e-02, 7.18090937e-02, 5.02449341e-02, 7.23852176e+03,\n",
      "        1.58024603e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633030e-02, 7.18090935e-02, 5.02449344e-02, 7.23852175e+03,\n",
      "        1.58024603e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633039e-02, 7.18090933e-02, 5.02449343e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286440e+04],\n",
      "       [8.04633037e-02, 7.18090932e-02, 5.02449345e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286440e+04],\n",
      "       [8.04633047e-02, 7.18090929e-02, 5.02449349e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633055e-02, 7.18090926e-02, 5.02449354e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633062e-02, 7.18090923e-02, 5.02449354e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840773e+04, 2.23286441e+04],\n",
      "       [8.04633062e-02, 7.18090921e-02, 5.02449357e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04]]), array([90698.9332218 , 90698.93322237, 90698.93322263, 90698.93322275,\n",
      "       90698.933224  , 90698.93322516, 90698.93322544, 90698.93322595]))\n",
      "           fun: 90698.93322179955\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1389\n",
      "           nit: 554\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.04633027e-02, 7.18090937e-02, 5.02449341e-02, 7.23852176e+03,\n",
      "       1.58024603e+04, 1.67840772e+04, 2.23286441e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91004.02822016623, bestParams: [0.16847368, 0.006867244, 0.057000216, 9718.201, 20643.424, 24615.924, 21438.463]\n",
      "epoch 3\n",
      " final_simplex: (array([[1.02033897e-01, 7.74125429e-03, 5.54624499e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125427e-03, 5.54624498e-02, 9.58666804e+03,\n",
      "        1.95816961e+04, 2.80791649e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033898e-01, 7.74125426e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624499e-02, 9.58666804e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624498e-02, 9.58666805e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624498e-02, 9.58666804e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04]]), array([90777.40346946, 90777.40346956, 90777.40346965, 90777.40347029,\n",
      "       90777.40348193, 90777.40348194, 90777.40348196, 90777.40348204]))\n",
      "           fun: 90777.40346946282\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1171\n",
      "           nit: 404\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.02033897e-01, 7.74125429e-03, 5.54624499e-02, 9.58666803e+03,\n",
      "       1.95816962e+04, 2.80791648e+04, 2.53911261e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91187.95797366982, bestParams: [0.025342675, 0.00792712, 0.07620231, 7194.6675, 7506.416, 14323.318, 16886.123]\n",
      "epoch 4\n",
      " final_simplex: (array([[4.70038040e-02, 1.84890042e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "        7.18730002e+03, 8.35538060e+03, 5.06572632e+03],\n",
      "       [4.70038039e-02, 1.84890042e-02, 4.10251852e-02, 2.37962911e+03,\n",
      "        7.18730004e+03, 8.35538056e+03, 5.06572636e+03],\n",
      "       [4.70038041e-02, 1.84890043e-02, 4.10251854e-02, 2.37962910e+03,\n",
      "        7.18729996e+03, 8.35538056e+03, 5.06572631e+03],\n",
      "       [4.70038043e-02, 1.84890043e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "        7.18729999e+03, 8.35538061e+03, 5.06572625e+03],\n",
      "       [4.70038041e-02, 1.84890041e-02, 4.10251853e-02, 2.37962912e+03,\n",
      "        7.18730005e+03, 8.35538060e+03, 5.06572628e+03],\n",
      "       [4.70038039e-02, 1.84890042e-02, 4.10251854e-02, 2.37962909e+03,\n",
      "        7.18730002e+03, 8.35538059e+03, 5.06572628e+03],\n",
      "       [4.70038044e-02, 1.84890041e-02, 4.10251855e-02, 2.37962911e+03,\n",
      "        7.18729996e+03, 8.35538050e+03, 5.06572636e+03],\n",
      "       [4.70038042e-02, 1.84890042e-02, 4.10251853e-02, 2.37962910e+03,\n",
      "        7.18729999e+03, 8.35538054e+03, 5.06572629e+03]]), array([90641.67199394, 90641.67199403, 90641.6719941 , 90641.67199412,\n",
      "       90641.67199429, 90641.67199461, 90641.67199472, 90641.67199474]))\n",
      "           fun: 90641.67199393519\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1292\n",
      "           nit: 503\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.70038040e-02, 1.84890042e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "       7.18730002e+03, 8.35538060e+03, 5.06572632e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90934.9975112686, bestParams: [0.059806045, 0.055613108, 0.043168016, 2348.8328, 6146.4946, 8322.338, 10317.607]\n",
      "epoch 5\n",
      " final_simplex: (array([[5.42056891e-02, 4.70911906e-02, 4.19282268e-02, 2.83251915e+03,\n",
      "        7.79437423e+03, 8.19122192e+03, 7.15410411e+03],\n",
      "       [5.42056896e-02, 4.70911906e-02, 4.19282266e-02, 2.83251915e+03,\n",
      "        7.79437421e+03, 8.19122190e+03, 7.15410413e+03],\n",
      "       [5.42056846e-02, 4.70911897e-02, 4.19282289e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122191e+03, 7.15410401e+03],\n",
      "       [5.42056853e-02, 4.70911896e-02, 4.19282286e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122192e+03, 7.15410403e+03],\n",
      "       [5.42056859e-02, 4.70911898e-02, 4.19282282e-02, 2.83251916e+03,\n",
      "        7.79437423e+03, 8.19122191e+03, 7.15410403e+03],\n",
      "       [5.42056850e-02, 4.70911905e-02, 4.19282288e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122186e+03, 7.15410404e+03],\n",
      "       [5.42056864e-02, 4.70911897e-02, 4.19282281e-02, 2.83251916e+03,\n",
      "        7.79437420e+03, 8.19122190e+03, 7.15410405e+03],\n",
      "       [5.42056863e-02, 4.70911901e-02, 4.19282281e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122190e+03, 7.15410405e+03]]), array([90626.22011514, 90626.22011537, 90626.22012032, 90626.22012065,\n",
      "       90626.22012113, 90626.22012132, 90626.22012138, 90626.22012175]))\n",
      "           fun: 90626.22011513563\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1256\n",
      "           nit: 501\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.42056891e-02, 4.70911906e-02, 4.19282268e-02, 2.83251915e+03,\n",
      "       7.79437423e+03, 8.19122192e+03, 7.15410411e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90970.36604372214, bestParams: [0.054490186, 0.02661631, 0.0485164, 5726.952, 16087.912, 22577.627, 24207.025]\n",
      "epoch 6\n",
      " final_simplex: (array([[5.10958411e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958412e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636176e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958411e-02, 3.04632786e-02, 4.19672827e-02, 7.06673511e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958418e-02, 3.04632787e-02, 4.19672826e-02, 7.06673511e+03,\n",
      "        1.98636178e+04, 2.25615731e+04, 1.60116670e+04],\n",
      "       [5.10958411e-02, 3.04632785e-02, 4.19672830e-02, 7.06673513e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116672e+04],\n",
      "       [5.10958419e-02, 3.04632787e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636176e+04, 2.25615731e+04, 1.60116671e+04],\n",
      "       [5.10958414e-02, 3.04632786e-02, 4.19672828e-02, 7.06673512e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958415e-02, 3.04632785e-02, 4.19672829e-02, 7.06673512e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04]]), array([90621.57495985, 90621.57495994, 90621.57496008, 90621.57496039,\n",
      "       90621.5749604 , 90621.57496041, 90621.57496041, 90621.57496047]))\n",
      "           fun: 90621.57495984525\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1245\n",
      "           nit: 492\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.10958411e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "       1.98636177e+04, 2.25615730e+04, 1.60116671e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90804.903153182, bestParams: [0.014491759, 0.01909757, 0.026884345, 5839.411, 24984.732, 21505.56, 5679.6772]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.54264133e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "        8.02301535e+03, 8.15135230e+03, 5.64047497e+03],\n",
      "       [3.54264126e-02, 3.62265995e-02, 4.01003738e-02, 2.57159949e+03,\n",
      "        8.02301536e+03, 8.15135231e+03, 5.64047505e+03],\n",
      "       [3.54264131e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "        8.02301538e+03, 8.15135232e+03, 5.64047498e+03],\n",
      "       [3.54264143e-02, 3.62266000e-02, 4.01003715e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047488e+03],\n",
      "       [3.54264139e-02, 3.62266001e-02, 4.01003719e-02, 2.57159949e+03,\n",
      "        8.02301538e+03, 8.15135232e+03, 5.64047489e+03],\n",
      "       [3.54264141e-02, 3.62266000e-02, 4.01003716e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047490e+03],\n",
      "       [3.54264137e-02, 3.62265999e-02, 4.01003720e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047495e+03],\n",
      "       [3.54264137e-02, 3.62266000e-02, 4.01003719e-02, 2.57159949e+03,\n",
      "        8.02301537e+03, 8.15135233e+03, 5.64047494e+03]]), array([90617.76238034, 90617.76238038, 90617.76238043, 90617.76238056,\n",
      "       90617.76238057, 90617.7623806 , 90617.76238062, 90617.7623807 ]))\n",
      "           fun: 90617.76238033785\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1396\n",
      "           nit: 595\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.54264133e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "       8.02301535e+03, 8.15135230e+03, 5.64047497e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91071.9845670912, bestParams: [0.031488296, 0.07208441, 0.074685715, 6185.3647, 13709.426, 18131.521, 23476.797]\n",
      "epoch 8\n",
      " final_simplex: (array([[4.05461957e-02, 6.34717350e-02, 4.05830887e-02, 6.92152710e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461958e-02, 6.34717351e-02, 4.05830884e-02, 6.92152710e+03,\n",
      "        1.97748038e+04, 1.88326454e+04, 1.90989072e+04],\n",
      "       [4.05461960e-02, 6.34717351e-02, 4.05830884e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989071e+04],\n",
      "       [4.05461959e-02, 6.34717351e-02, 4.05830885e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461962e-02, 6.34717354e-02, 4.05830879e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989071e+04],\n",
      "       [4.05461953e-02, 6.34717350e-02, 4.05830889e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461959e-02, 6.34717353e-02, 4.05830882e-02, 6.92152708e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461954e-02, 6.34717352e-02, 4.05830887e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326454e+04, 1.90989073e+04]]), array([90642.89946052, 90642.89946059, 90642.8994606 , 90642.89946067,\n",
      "       90642.89946078, 90642.89946086, 90642.89946098, 90642.899461  ]))\n",
      "           fun: 90642.89946051945\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1339\n",
      "           nit: 563\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05461957e-02, 6.34717350e-02, 4.05830887e-02, 6.92152710e+03,\n",
      "       1.97748038e+04, 1.88326455e+04, 1.90989072e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90978.47709523376, bestParams: [0.052268486, 0.059164874, 0.029479917, 3384.196, 9466.865, 13828.556, 13715.061]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228951e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202685e+03],\n",
      "       [4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202684e+03],\n",
      "       [4.94145725e-02, 3.66047327e-02, 4.05901828e-02, 4.08228951e+03,\n",
      "        1.18931871e+04, 1.29963842e+04, 9.45202687e+03],\n",
      "       [4.94145723e-02, 3.66047329e-02, 4.05901829e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202687e+03],\n",
      "       [4.94145725e-02, 3.66047330e-02, 4.05901828e-02, 4.08228951e+03,\n",
      "        1.18931871e+04, 1.29963842e+04, 9.45202685e+03],\n",
      "       [4.94145724e-02, 3.66047332e-02, 4.05901828e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202689e+03],\n",
      "       [4.94145725e-02, 3.66047332e-02, 4.05901829e-02, 4.08228951e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202689e+03],\n",
      "       [4.94145724e-02, 3.66047334e-02, 4.05901830e-02, 4.08228952e+03,\n",
      "        1.18931871e+04, 1.29963843e+04, 9.45202682e+03]]), array([90618.74920601, 90618.74920613, 90618.74920624, 90618.74920633,\n",
      "       90618.74920639, 90618.74920644, 90618.74920651, 90618.7492066 ]))\n",
      "           fun: 90618.74920601156\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1229\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228951e+03,\n",
      "       1.18931870e+04, 1.29963842e+04, 9.45202685e+03])\n",
      "minPrevious 90617.68016446201\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0453, 0.0329, 0.0414], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8794, 0.0631, 0.0279, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8663, 0.0752, 0.0260, 0.0325], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8795, 0.0279, 0.0647, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8611, 0.0258, 0.0808, 0.0323], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7352, 0.0984, 0.0988, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6986, 0.1126, 0.1175, 0.0713], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.1919, 3.2663, 5.4709],\n",
      "        [4.1986, 3.8897, 7.2400],\n",
      "        [3.3917, 2.4035, 5.7041],\n",
      "        ...,\n",
      "        [4.9667, 4.5339, 5.2203],\n",
      "        [3.8287, 3.7274, 4.9386],\n",
      "        [3.6731, 2.6413, 5.4393]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 17.216406106948853\n",
      "Run: 0, 7\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[57.,  3.,  2.,  0.],\n",
      "        [54.,  1.,  1.,  0.],\n",
      "        [40.,  2.,  2.,  3.],\n",
      "        ...,\n",
      "        [59.,  0.,  1.,  0.],\n",
      "        [57.,  2.,  0.,  2.],\n",
      "        [46.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([62., 56., 47.,  ..., 60., 61., 48.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 2.,  ..., 0., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 2.,  ..., 1., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 3.,  ..., 0., 2., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[57.,  3.,  2.,  0.],\n",
      "        [54.,  1.,  1.,  0.],\n",
      "        [40.,  2.,  2.,  3.],\n",
      "        ...,\n",
      "        [59.,  0.,  1.,  0.],\n",
      "        [57.,  2.,  0.,  2.],\n",
      "        [46.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0211, 0.0565, 0.0007,  ..., 0.0278, 0.0058, 0.0361],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7d8437830>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90698.00966445002, bestParams: [0.03601381, 0.05376842, 0.037697803, 4858.81, 17559.475, 15117.588, 10296.187]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695246e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397107e-02, 5.12695245e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708269e-02, 4.24062757e-02, 4.20397107e-02, 5.12695246e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498577e+04],\n",
      "       [3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695247e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498577e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397106e-02, 5.12695245e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062758e-02, 4.20397103e-02, 5.12695247e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397105e-02, 5.12695248e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062755e-02, 4.20397105e-02, 5.12695246e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04]]), array([90642.85781501, 90642.85781503, 90642.85781505, 90642.85781506,\n",
      "       90642.85781507, 90642.8578153 , 90642.85781912, 90642.85781919]))\n",
      "           fun: 90642.85781500832\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 451\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695246e+03,\n",
      "       1.55116198e+04, 1.47037155e+04, 1.20498578e+04])\n",
      "best ll: 90989.10931874896, bestParams: [0.055018455, 0.058657233, 0.013274319, 6479.689, 24181.266, 18899.627, 20080.443]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.85959234e-02, 2.70830341e-02, 3.75888685e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959248e-02, 2.70830345e-02, 3.75888666e-02, 5.60836646e+03,\n",
      "        1.79338975e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959256e-02, 2.70830349e-02, 3.75888652e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959263e-02, 2.70830352e-02, 3.75888641e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154940e+04],\n",
      "       [3.85959273e-02, 2.70830354e-02, 3.75888626e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959274e-02, 2.70830356e-02, 3.75888624e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959275e-02, 2.70830356e-02, 3.75888623e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959273e-02, 2.70830360e-02, 3.75888620e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154940e+04]]), array([90650.21241961, 90650.21242353, 90650.21242637, 90650.21242847,\n",
      "       90650.21243156, 90650.21243183, 90650.21243221, 90650.2124325 ]))\n",
      "           fun: 90650.21241961051\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1903\n",
      "           nit: 830\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.85959234e-02, 2.70830341e-02, 3.75888685e-02, 5.60836646e+03,\n",
      "       1.79338974e+04, 1.86206826e+04, 1.15154939e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91231.4553234166, bestParams: [0.0892526, 0.12577815, 0.064923555, 8575.71, 16426.484, 17164.031, 13682.164]\n",
      "epoch 2\n",
      " final_simplex: (array([[6.24537414e-02, 6.15992439e-02, 4.87048961e-02, 8.10050348e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666122e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537410e-02, 6.15992442e-02, 4.87048963e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537408e-02, 6.15992444e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385009e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537410e-02, 6.15992443e-02, 4.87048963e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537413e-02, 6.15992439e-02, 4.87048963e-02, 8.10050348e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666121e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048965e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666122e+04]]), array([90678.49280484, 90678.49280488, 90678.49280488, 90678.4928049 ,\n",
      "       90678.49280491, 90678.49280492, 90678.49280495, 90678.49280495]))\n",
      "           fun: 90678.49280484293\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1336\n",
      "           nit: 527\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.24537414e-02, 6.15992439e-02, 4.87048961e-02, 8.10050348e+03,\n",
      "       1.87385010e+04, 1.77667491e+04, 2.46666122e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91162.11827079224, bestParams: [0.028731208, 0.08052614, 0.038748782, 6678.704, 9787.624, 20217.812, 20754.006]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.70904892e-02, 3.81834950e-02, 4.32858909e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550785e+04, 1.31698874e+04],\n",
      "       [3.70904891e-02, 3.81834947e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550785e+04, 1.31698875e+04],\n",
      "       [3.70904891e-02, 3.81834950e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550784e+04, 1.31698875e+04],\n",
      "       [3.70904892e-02, 3.81834948e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698873e+04],\n",
      "       [3.70904892e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698874e+04],\n",
      "       [3.70904891e-02, 3.81834949e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698875e+04],\n",
      "       [3.70904891e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550784e+04, 1.31698874e+04],\n",
      "       [3.70904890e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550784e+04, 1.31698875e+04]]), array([90642.60568465, 90642.60568466, 90642.60568467, 90642.60568468,\n",
      "       90642.60568469, 90642.60568473, 90642.60568474, 90642.60568475]))\n",
      "           fun: 90642.60568464609\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1275\n",
      "           nit: 507\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.70904892e-02, 3.81834950e-02, 4.32858909e-02, 5.98454029e+03,\n",
      "       1.81339736e+04, 1.72550785e+04, 1.31698874e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91382.86227142713, bestParams: [0.061809793, 0.19442773, 0.026268564, 4953.1294, 21892.15, 9520.106, 16782.123]\n",
      "epoch 4\n",
      " final_simplex: (array([[6.27800301e-02, 1.23767454e-01, 3.50697812e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800298e-02, 1.23767455e-01, 3.50697812e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800299e-02, 1.23767454e-01, 3.50697811e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604067e+04],\n",
      "       [6.27800297e-02, 1.23767455e-01, 3.50697811e-02, 5.48175073e+03,\n",
      "        1.28766665e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767454e-01, 3.50697811e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767455e-01, 3.50697810e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604065e+04],\n",
      "       [6.27800302e-02, 1.23767454e-01, 3.50697809e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767455e-01, 3.50697810e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04]]), array([90777.06158995, 90777.06159034, 90777.06159078, 90777.0615909 ,\n",
      "       90777.06159123, 90777.06159134, 90777.06159178, 90777.06159179]))\n",
      "           fun: 90777.06158994799\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 491\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.27800301e-02, 1.23767454e-01, 3.50697812e-02, 5.48175072e+03,\n",
      "       1.28766666e+04, 1.04008147e+04, 1.94604066e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91244.41189886695, bestParams: [0.10861425, 0.073448956, 0.058375053, 7751.9844, 24126.418, 15650.825, 13502.183]\n",
      "epoch 5\n",
      " final_simplex: (array([[4.98106413e-02, 4.31442532e-02, 4.55770178e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106415e-02, 4.31442537e-02, 4.55770179e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106417e-02, 4.31442545e-02, 4.55770180e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106419e-02, 4.31442552e-02, 4.55770181e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106422e-02, 4.31442562e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106423e-02, 4.31442564e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106423e-02, 4.31442564e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106424e-02, 4.31442567e-02, 4.55770184e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04]]), array([90645.14444341, 90645.14444347, 90645.14444356, 90645.14444367,\n",
      "       90645.14444379, 90645.14444382, 90645.14444382, 90645.14444386]))\n",
      "           fun: 90645.14444341193\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 4867\n",
      "           nit: 2501\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.98106413e-02, 4.31442532e-02, 4.55770178e-02, 8.17344313e+03,\n",
      "       2.22304248e+04, 2.16693584e+04, 2.17261576e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 90929.83437789878, bestParams: [0.042998888, 0.0036338635, 0.08923576, 6261.846, 20105.752, 21534.959, 8484.541]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.07350802e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004541e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790768e-03, 4.90472196e-02, 6.49933175e+03,\n",
      "        1.96476728e+04, 2.31004541e+04, 1.06442170e+04],\n",
      "       [4.07350803e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350800e-02, 4.32790766e-03, 4.90472198e-02, 6.49933176e+03,\n",
      "        1.96476727e+04, 2.31004541e+04, 1.06442172e+04],\n",
      "       [4.07350800e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476727e+04, 2.31004541e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790766e-03, 4.90472196e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790766e-03, 4.90472196e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350801e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04]]), array([90729.51111848, 90729.51111852, 90729.51111854, 90729.51111854,\n",
      "       90729.51111856, 90729.51111859, 90729.51111859, 90729.51111861]))\n",
      "           fun: 90729.51111847878\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1384\n",
      "           nit: 534\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.07350802e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "       1.96476728e+04, 2.31004541e+04, 1.06442171e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91338.66029620953, bestParams: [0.029967176, 0.105418496, 0.045315336, 5352.596, 2545.1953, 7796.2197, 16043.894]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.44726379e-02, 3.49043068e-02, 4.37101311e-02, 2.02821194e+03,\n",
      "        6.23612173e+03, 6.14653739e+03, 4.45542382e+03],\n",
      "       [3.44726355e-02, 3.49043034e-02, 4.37101328e-02, 2.02821196e+03,\n",
      "        6.23612174e+03, 6.14653748e+03, 4.45542375e+03],\n",
      "       [3.44726365e-02, 3.49043101e-02, 4.37101292e-02, 2.02821195e+03,\n",
      "        6.23612173e+03, 6.14653742e+03, 4.45542384e+03],\n",
      "       [3.44726357e-02, 3.49043114e-02, 4.37101301e-02, 2.02821195e+03,\n",
      "        6.23612168e+03, 6.14653744e+03, 4.45542382e+03],\n",
      "       [3.44726353e-02, 3.49043095e-02, 4.37101309e-02, 2.02821194e+03,\n",
      "        6.23612172e+03, 6.14653741e+03, 4.45542374e+03],\n",
      "       [3.44726354e-02, 3.49043147e-02, 4.37101280e-02, 2.02821196e+03,\n",
      "        6.23612170e+03, 6.14653740e+03, 4.45542391e+03],\n",
      "       [3.44726344e-02, 3.49043115e-02, 4.37101279e-02, 2.02821195e+03,\n",
      "        6.23612180e+03, 6.14653744e+03, 4.45542372e+03],\n",
      "       [3.44726337e-02, 3.49043122e-02, 4.37101303e-02, 2.02821194e+03,\n",
      "        6.23612172e+03, 6.14653737e+03, 4.45542377e+03]]), array([90642.45046539, 90642.45046608, 90642.45046658, 90642.45046711,\n",
      "       90642.45046727, 90642.45046771, 90642.45046814, 90642.45046855]))\n",
      "           fun: 90642.45046539283\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1428\n",
      "           nit: 638\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.44726379e-02, 3.49043068e-02, 4.37101311e-02, 2.02821194e+03,\n",
      "       6.23612173e+03, 6.14653739e+03, 4.45542382e+03])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 90822.19754322112, bestParams: [0.010888182, 0.014153072, 0.046646245, 3893.9783, 13470.374, 10266.924, 8581.38]\n",
      "epoch 8\n",
      " final_simplex: (array([[3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "        1.12126544e+03, 1.14623685e+03, 8.33927990e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580955e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623686e+03, 8.33927984e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903620e+02,\n",
      "        1.12126543e+03, 1.14623683e+03, 8.33927991e+02],\n",
      "       [3.82086249e-02, 3.13148454e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623682e+03, 8.33927983e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623684e+03, 8.33927993e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903611e+02,\n",
      "        1.12126540e+03, 1.14623683e+03, 8.33927973e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903626e+02,\n",
      "        1.12126544e+03, 1.14623684e+03, 8.33928033e+02],\n",
      "       [3.82086251e-02, 3.13148453e-02, 4.25580949e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623685e+03, 8.33928012e+02]]), array([90635.50396325, 90635.5039651 , 90635.5039652 , 90635.50396555,\n",
      "       90635.50396556, 90635.50396586, 90635.50397008, 90635.50397061]))\n",
      "           fun: 90635.50396325192\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 561\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "       1.12126544e+03, 1.14623685e+03, 8.33927990e+02])\n",
      "minPrevious 90642.85781500832\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "        1.12126544e+03, 1.14623685e+03, 8.33927990e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580955e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623686e+03, 8.33927984e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903620e+02,\n",
      "        1.12126543e+03, 1.14623683e+03, 8.33927991e+02],\n",
      "       [3.82086249e-02, 3.13148454e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623682e+03, 8.33927983e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623684e+03, 8.33927993e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903611e+02,\n",
      "        1.12126540e+03, 1.14623683e+03, 8.33927973e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903626e+02,\n",
      "        1.12126544e+03, 1.14623684e+03, 8.33928033e+02],\n",
      "       [3.82086251e-02, 3.13148453e-02, 4.25580949e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623685e+03, 8.33928012e+02]]), array([90635.50396325, 90635.5039651 , 90635.5039652 , 90635.50396555,\n",
      "       90635.50396556, 90635.50396586, 90635.50397008, 90635.50397061]))\n",
      "           fun: 90635.50396325192\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 561\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "       1.12126544e+03, 1.14623685e+03, 8.33927990e+02])\n",
      "best ll: 90795.9848434706, bestParams: [0.023895113, 0.04085701, 0.05497067, 7981.157, 15722.58, 17191.658, 21199.53]\n",
      "epoch 9\n",
      " final_simplex: (array([[2.82889394e-02, 4.02806717e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889394e-02, 4.02806719e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889396e-02, 4.02806716e-02, 4.32251584e-02, 6.71342930e+03,\n",
      "        2.14952765e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889396e-02, 4.02806717e-02, 4.32251585e-02, 6.71342930e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889395e-02, 4.02806717e-02, 4.32251589e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889396e-02, 4.02806717e-02, 4.32251583e-02, 6.71342930e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889395e-02, 4.02806718e-02, 4.32251588e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889395e-02, 4.02806717e-02, 4.32251587e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04]]), array([90649.70138782, 90649.70138796, 90649.70139572, 90649.70139578,\n",
      "       90649.70139578, 90649.70139579, 90649.7013958 , 90649.7013958 ]))\n",
      "           fun: 90649.70138781719\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1123\n",
      "           nit: 377\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.82889394e-02, 4.02806717e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "       2.14952764e+04, 1.98861867e+04, 1.47146669e+04])\n",
      "minPrevious 90635.50396325192\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0382, 0.0313, 0.0426], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8729, 0.0646, 0.0277, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8656, 0.0769, 0.0261, 0.0314], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8894, 0.0282, 0.0649, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8639, 0.0260, 0.0787, 0.0314], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7354, 0.0989, 0.0981, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7093, 0.1098, 0.1113, 0.0696], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.0017, 4.0782, 5.5325],\n",
      "        [2.8935, 2.9939, 5.7539],\n",
      "        [3.9443, 2.9939, 5.9781],\n",
      "        ...,\n",
      "        [4.9808, 4.8651, 7.1442],\n",
      "        [3.4877, 2.3421, 6.7752],\n",
      "        [2.0068, 2.9318, 5.2629]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.899680852890015\n",
      "Run: 0, 8\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[32.,  4.,  0.,  2.],\n",
      "        [48.,  2.,  2.,  0.],\n",
      "        [50.,  7.,  1.,  3.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [49.,  0.,  1.,  1.],\n",
      "        [50.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([38., 52., 61.,  ..., 70., 51., 53.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 2., 7.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 1.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 3.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[32.,  4.,  0.,  2.],\n",
      "        [48.,  2.,  2.,  0.],\n",
      "        [50.,  7.,  1.,  3.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [49.,  0.,  1.,  1.],\n",
      "        [50.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([3.4400e-04, 3.5403e-02, 9.0049e-06,  ..., 5.4883e-03, 2.6479e-02,\n",
      "        3.8102e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7d8437680>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90866.38670202054, bestParams: [0.04227104, 0.043204933, 0.035604723, 4999.505, 6446.358, 10356.963, 18687.867]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.78586233e-02, 4.97323902e-02, 4.39350770e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147190e+04, 8.49245920e+03],\n",
      "       [3.78586235e-02, 4.97323902e-02, 4.39350773e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147190e+04, 8.49245919e+03],\n",
      "       [3.78586232e-02, 4.97323905e-02, 4.39350767e-02, 3.58313190e+03,\n",
      "        1.04477020e+04, 1.02147190e+04, 8.49245911e+03],\n",
      "       [3.78586227e-02, 4.97323902e-02, 4.39350774e-02, 3.58313190e+03,\n",
      "        1.04477020e+04, 1.02147191e+04, 8.49245916e+03],\n",
      "       [3.78586228e-02, 4.97323899e-02, 4.39350782e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245925e+03],\n",
      "       [3.78586223e-02, 4.97323901e-02, 4.39350782e-02, 3.58313191e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245913e+03],\n",
      "       [3.78586225e-02, 4.97323904e-02, 4.39350773e-02, 3.58313189e+03,\n",
      "        1.04477020e+04, 1.02147191e+04, 8.49245911e+03],\n",
      "       [3.78586225e-02, 4.97323902e-02, 4.39350780e-02, 3.58313191e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245913e+03]]), array([90487.06109292, 90487.06109304, 90487.06109312, 90487.06109314,\n",
      "       90487.06109322, 90487.06109331, 90487.06109333, 90487.06109339]))\n",
      "           fun: 90487.06109292197\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1122\n",
      "           nit: 395\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.78586233e-02, 4.97323902e-02, 4.39350770e-02, 3.58313192e+03,\n",
      "       1.04477019e+04, 1.02147190e+04, 8.49245920e+03])\n",
      "best ll: 90778.79449381144, bestParams: [0.08165928, 0.087960355, 0.063273296, 6014.191, 7127.5513, 11117.987, 22590.318]\n",
      "epoch 1\n",
      " final_simplex: (array([[8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994274e-02, 7.17538081e-02, 4.81073032e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994274e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994276e-02, 7.17538080e-02, 4.81073031e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04],\n",
      "       [8.64994276e-02, 7.17538083e-02, 4.81073030e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04],\n",
      "       [8.64994279e-02, 7.17538081e-02, 4.81073029e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04]]), array([90562.47709194, 90562.47709201, 90562.47709202, 90562.47709211,\n",
      "       90562.47709213, 90562.47709218, 90562.47709236, 90562.47709241]))\n",
      "           fun: 90562.47709193993\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1227\n",
      "           nit: 471\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "       1.14898833e+04, 1.26010591e+04, 1.55118784e+04])\n",
      "minPrevious 90487.06109292197\n",
      "best ll: 90970.5610899757, bestParams: [0.09997445, 0.12198489, 0.051259637, 7826.5796, 23443.818, 14464.848, 18766.902]\n",
      "epoch 2\n",
      " final_simplex: (array([[8.71740907e-02, 9.11163488e-02, 5.16494257e-02, 8.27206657e+03,\n",
      "        1.61201928e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740909e-02, 9.11163489e-02, 5.16494256e-02, 8.27206655e+03,\n",
      "        1.61201928e+04, 1.78121709e+04, 2.57831929e+04],\n",
      "       [8.71740908e-02, 9.11163492e-02, 5.16494255e-02, 8.27206658e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740912e-02, 9.11163500e-02, 5.16494251e-02, 8.27206657e+03,\n",
      "        1.61201928e+04, 1.78121709e+04, 2.57831930e+04],\n",
      "       [8.71740911e-02, 9.11163504e-02, 5.16494251e-02, 8.27206659e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740911e-02, 9.11163502e-02, 5.16494252e-02, 8.27206659e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740914e-02, 9.11163510e-02, 5.16494248e-02, 8.27206657e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740915e-02, 9.11163513e-02, 5.16494247e-02, 8.27206658e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831931e+04]]), array([90589.73553078, 90589.73553096, 90589.73553098, 90589.73553157,\n",
      "       90589.73553194, 90589.73553196, 90589.73553245, 90589.73553278]))\n",
      "           fun: 90589.73553077558\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1493\n",
      "           nit: 613\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.71740907e-02, 9.11163488e-02, 5.16494257e-02, 8.27206657e+03,\n",
      "       1.61201928e+04, 1.78121708e+04, 2.57831930e+04])\n",
      "minPrevious 90487.06109292197\n",
      "best ll: 90702.98167128472, bestParams: [0.03473026, 0.046426747, 0.061863348, 9696.083, 24623.559, 19582.648, 17360.992]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639317e-02, 4.45271009e-02, 4.57781923e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639318e-02, 4.45271006e-02, 4.57781931e-02, 8.53728467e+03,\n",
      "        2.49527256e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639319e-02, 4.45271002e-02, 4.57781944e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639321e-02, 4.45270995e-02, 4.57781964e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639323e-02, 4.45270990e-02, 4.57781979e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639324e-02, 4.45270989e-02, 4.57781981e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966649e+04, 1.98905847e+04],\n",
      "       [3.66639324e-02, 4.45270987e-02, 4.57781989e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04]]), array([90482.69509499, 90482.69509598, 90482.69509679, 90482.69509802,\n",
      "       90482.69510007, 90482.69510157, 90482.69510186, 90482.69510255]))\n",
      "           fun: 90482.69509499139\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1646\n",
      "           nit: 743\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "       2.49527257e+04, 2.45966650e+04, 1.98905847e+04])\n",
      "minPrevious 90487.06109292197\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639317e-02, 4.45271009e-02, 4.57781923e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639318e-02, 4.45271006e-02, 4.57781931e-02, 8.53728467e+03,\n",
      "        2.49527256e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639319e-02, 4.45271002e-02, 4.57781944e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639321e-02, 4.45270995e-02, 4.57781964e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639323e-02, 4.45270990e-02, 4.57781979e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639324e-02, 4.45270989e-02, 4.57781981e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966649e+04, 1.98905847e+04],\n",
      "       [3.66639324e-02, 4.45270987e-02, 4.57781989e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04]]), array([90482.69509499, 90482.69509598, 90482.69509679, 90482.69509802,\n",
      "       90482.69510007, 90482.69510157, 90482.69510186, 90482.69510255]))\n",
      "           fun: 90482.69509499139\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1646\n",
      "           nit: 743\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "       2.49527257e+04, 2.45966650e+04, 1.98905847e+04])\n",
      "best ll: 90867.56193183556, bestParams: [0.0098387115, 0.062886804, 0.053461675, 6239.042, 23488.914, 22569.387, 434.96948]\n",
      "epoch 4\n",
      " final_simplex: (array([[1.15378583e-02, 2.04791823e-02, 4.61124020e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670302e+04, 6.11843483e+02],\n",
      "       [1.15378583e-02, 2.04791820e-02, 4.61124014e-02, 5.84323512e+03,\n",
      "        2.64481986e+04, 2.49670302e+04, 6.11843490e+02],\n",
      "       [1.15378582e-02, 2.04791827e-02, 4.61124012e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843491e+02],\n",
      "       [1.15378581e-02, 2.04791822e-02, 4.61124010e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843498e+02],\n",
      "       [1.15378580e-02, 2.04791818e-02, 4.61124008e-02, 5.84323512e+03,\n",
      "        2.64481986e+04, 2.49670302e+04, 6.11843501e+02],\n",
      "       [1.15378578e-02, 2.04791817e-02, 4.61124003e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843513e+02],\n",
      "       [1.15378578e-02, 2.04791814e-02, 4.61124005e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843513e+02],\n",
      "       [1.15378578e-02, 2.04791806e-02, 4.61124008e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670302e+04, 6.11843515e+02]]), array([90612.29504722, 90612.29504755, 90612.29504758, 90612.29504799,\n",
      "       90612.29504825, 90612.29504873, 90612.29504883, 90612.29504907]))\n",
      "           fun: 90612.29504722435\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1277\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.15378583e-02, 2.04791823e-02, 4.61124020e-02, 5.84323512e+03,\n",
      "       2.64481985e+04, 2.49670302e+04, 6.11843483e+02])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90725.9879271773, bestParams: [0.043563887, 0.012296107, 0.08686379, 4552.979, 12478.696, 12336.921, 8655.909]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.38270526e-02, 2.14812023e-02, 4.24158900e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403708e+03],\n",
      "       [3.38270531e-02, 2.14812022e-02, 4.24158901e-02, 4.15356910e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403705e+03],\n",
      "       [3.38270544e-02, 2.14812014e-02, 4.24158909e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212583e+04, 6.94403701e+03],\n",
      "       [3.38270549e-02, 2.14812012e-02, 4.24158914e-02, 4.15356913e+03,\n",
      "        1.34924801e+04, 1.44212583e+04, 6.94403698e+03],\n",
      "       [3.38270561e-02, 2.14812008e-02, 4.24158918e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403707e+03],\n",
      "       [3.38270559e-02, 2.14812006e-02, 4.24158918e-02, 4.15356913e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403715e+03],\n",
      "       [3.38270568e-02, 2.14812003e-02, 4.24158922e-02, 4.15356911e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403715e+03],\n",
      "       [3.38270567e-02, 2.14812002e-02, 4.24158924e-02, 4.15356912e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403709e+03]]), array([90506.88456244, 90506.8845628 , 90506.88456515, 90506.88456571,\n",
      "       90506.88456661, 90506.8845673 , 90506.8845681 , 90506.88456827]))\n",
      "           fun: 90506.88456243879\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1294\n",
      "           nit: 525\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38270526e-02, 2.14812023e-02, 4.24158900e-02, 4.15356911e+03,\n",
      "       1.34924801e+04, 1.44212582e+04, 6.94403708e+03])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90707.96802735567, bestParams: [0.01074106, 0.056317706, 0.062326808, 6906.7803, 14660.881, 12282.025, 20889.7]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948854e-02, 4.49989146e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948855e-02, 4.49989148e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948855e-02, 4.49989147e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778318e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948857e-02, 4.49989150e-02, 5.80778323e+03,\n",
      "        1.99696317e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948856e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948856e-02, 4.49989148e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04]]), array([90513.85897781, 90513.85897782, 90513.85897782, 90513.8589779 ,\n",
      "       90513.85897801, 90513.85897812, 90513.85897819, 90513.85897819]))\n",
      "           fun: 90513.85897780894\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1223\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "       1.99696318e+04, 1.68266749e+04, 1.13317168e+04])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 91208.12679174251, bestParams: [0.018939186, 0.13372447, 0.09658249, 7547.9326, 16754.46, 12379.46, 9450.32]\n",
      "epoch 7\n",
      " final_simplex: (array([[2.38771336e-02, 4.86939481e-02, 4.37289625e-02, 6.16011838e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658889e+04],\n",
      "       [2.38771335e-02, 4.86939479e-02, 4.37289625e-02, 6.16011839e+03,\n",
      "        1.88306626e+04, 1.72063936e+04, 1.41658889e+04],\n",
      "       [2.38771332e-02, 4.86939487e-02, 4.37289632e-02, 6.16011841e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771331e-02, 4.86939495e-02, 4.37289634e-02, 6.16011841e+03,\n",
      "        1.88306626e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771334e-02, 4.86939500e-02, 4.37289621e-02, 6.16011839e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771332e-02, 4.86939498e-02, 4.37289632e-02, 6.16011840e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771332e-02, 4.86939496e-02, 4.37289630e-02, 6.16011839e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771331e-02, 4.86939479e-02, 4.37289631e-02, 6.16011840e+03,\n",
      "        1.88306626e+04, 1.72063937e+04, 1.41658888e+04]]), array([90493.66767072, 90493.66767083, 90493.667671  , 90493.66767111,\n",
      "       90493.66767112, 90493.66767118, 90493.66767124, 90493.66767134]))\n",
      "           fun: 90493.6676707186\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1261\n",
      "           nit: 515\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.38771336e-02, 4.86939481e-02, 4.37289625e-02, 6.16011838e+03,\n",
      "       1.88306625e+04, 1.72063936e+04, 1.41658889e+04])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90946.33073211275, bestParams: [0.06552671, 0.03858188, 0.027416045, 5274.589, 17153.447, 15913.322, 3718.8213]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.66046495e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111184e+03],\n",
      "       [2.66046496e-02, 3.30193378e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046496e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046495e-02, 3.30193379e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111182e+03],\n",
      "       [2.66046494e-02, 3.30193379e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046494e-02, 3.30193379e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314351e+04, 1.28060088e+04, 6.71111184e+03],\n",
      "       [2.66046493e-02, 3.30193377e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060087e+04, 6.71111188e+03],\n",
      "       [2.66046494e-02, 3.30193377e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060087e+04, 6.71111185e+03]]), array([90491.11260967, 90491.11260969, 90491.1126097 , 90491.11260972,\n",
      "       90491.11260973, 90491.11260974, 90491.11260981, 90491.11260981]))\n",
      "           fun: 90491.11260967342\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1209\n",
      "           nit: 424\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.66046495e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "       1.31314350e+04, 1.28060088e+04, 6.71111184e+03])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90979.13690442877, bestParams: [0.03663157, 0.05130152, 0.088229544, 6370.648, 15553.35, 12778.411, 7697.9907]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.97788087e-02, 4.67508439e-02, 4.20900894e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412336e+04],\n",
      "       [3.97788089e-02, 4.67508438e-02, 4.20900895e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412336e+04],\n",
      "       [3.97788088e-02, 4.67508436e-02, 4.20900896e-02, 5.37312917e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412336e+04],\n",
      "       [3.97788087e-02, 4.67508442e-02, 4.20900896e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412335e+04],\n",
      "       [3.97788087e-02, 4.67508442e-02, 4.20900894e-02, 5.37312917e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412335e+04],\n",
      "       [3.97788085e-02, 4.67508446e-02, 4.20900899e-02, 5.37312915e+03,\n",
      "        1.61818613e+04, 1.60830102e+04, 1.16412335e+04],\n",
      "       [3.97788087e-02, 4.67508439e-02, 4.20900892e-02, 5.37312918e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412336e+04],\n",
      "       [3.97788084e-02, 4.67508448e-02, 4.20900899e-02, 5.37312916e+03,\n",
      "        1.61818613e+04, 1.60830102e+04, 1.16412335e+04]]), array([90485.31169553, 90485.31169555, 90485.31169556, 90485.31169564,\n",
      "       90485.31169573, 90485.31169573, 90485.31169582, 90485.31169587]))\n",
      "           fun: 90485.31169552742\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1246\n",
      "           nit: 478\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97788087e-02, 4.67508439e-02, 4.20900894e-02, 5.37312916e+03,\n",
      "       1.61818614e+04, 1.60830103e+04, 1.16412336e+04])\n",
      "minPrevious 90482.69509499139\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0367, 0.0445, 0.0458], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8773, 0.0628, 0.0278, 0.0251], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8679, 0.0761, 0.0260, 0.0300], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8874, 0.0282, 0.0652, 0.0261], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8687, 0.0261, 0.0751, 0.0301], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7379, 0.0985, 0.0987, 0.0616], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7085, 0.1116, 0.1107, 0.0692], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7394, 3.1648, 4.3888],\n",
      "        [3.2083, 2.9599, 5.7800],\n",
      "        [2.2675, 2.0366, 4.9875],\n",
      "        ...,\n",
      "        [3.8538, 3.8462, 5.9722],\n",
      "        [3.6667, 5.0235, 5.9005],\n",
      "        [5.0420, 4.6122, 7.5952]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.200846195220947\n",
      "Run: 0, 9\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[50.,  1.,  1.,  2.],\n",
      "        [61.,  3.,  1.,  1.],\n",
      "        [52.,  2.,  1.,  1.],\n",
      "        ...,\n",
      "        [53.,  0.,  1.,  1.],\n",
      "        [56.,  1.,  1.,  0.],\n",
      "        [47.,  2.,  1.,  2.]], dtype=torch.float64)\n",
      "n tensor([54., 66., 56.,  ..., 55., 58., 52.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 2.,  ..., 0., 1., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 1., 0., 2.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[50.,  1.,  1.,  2.],\n",
      "        [61.,  3.,  1.,  1.],\n",
      "        [52.,  2.,  1.,  1.],\n",
      "        ...,\n",
      "        [53.,  0.,  1.,  1.],\n",
      "        [56.,  1.,  1.,  0.],\n",
      "        [47.,  2.,  1.,  2.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0115, 0.0177, 0.0291,  ..., 0.0234, 0.0528, 0.0082],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3f200>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90761.7781549094, bestParams: [0.04600825, 0.034627862, 0.03320431, 3705.6182, 7804.2446, 11532.189, 11376.845]\n",
      "epoch 0\n",
      " final_simplex: (array([[4.79401002e-02, 3.59860707e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126223e+03],\n",
      "       [4.79401001e-02, 3.59860709e-02, 4.02713562e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126223e+03],\n",
      "       [4.79401002e-02, 3.59860711e-02, 4.02713562e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126226e+03],\n",
      "       [4.79401004e-02, 3.59860708e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043620e+04, 7.70126228e+03],\n",
      "       [4.79401003e-02, 3.59860708e-02, 4.02713564e-02, 3.34189612e+03,\n",
      "        9.83545166e+03, 1.05043621e+04, 7.70126227e+03],\n",
      "       [4.79401006e-02, 3.59860705e-02, 4.02713567e-02, 3.34189612e+03,\n",
      "        9.83545165e+03, 1.05043620e+04, 7.70126230e+03],\n",
      "       [4.79401005e-02, 3.59860707e-02, 4.02713564e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126229e+03],\n",
      "       [4.79401005e-02, 3.59860705e-02, 4.02713563e-02, 3.34189612e+03,\n",
      "        9.83545165e+03, 1.05043621e+04, 7.70126227e+03]]), array([90616.66706736, 90616.66706748, 90616.66706754, 90616.66706756,\n",
      "       90616.66706758, 90616.66706764, 90616.66706774, 90616.66706778]))\n",
      "           fun: 90616.66706735565\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1129\n",
      "           nit: 411\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.79401002e-02, 3.59860707e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "       9.83545164e+03, 1.05043621e+04, 7.70126223e+03])\n",
      "best ll: 91516.6859835903, bestParams: [0.026306985, 0.08133267, 0.024871472, 6414.625, 13429.396, 3964.474, 20765.12]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.28815934e-02, 8.33975562e-02, 4.81044641e-02, 2.66958385e+03,\n",
      "        7.24460965e+03, 6.30083680e+03, 7.38755573e+03],\n",
      "       [3.28815935e-02, 8.33975565e-02, 4.81044639e-02, 2.66958386e+03,\n",
      "        7.24460964e+03, 6.30083682e+03, 7.38755570e+03],\n",
      "       [3.28815934e-02, 8.33975568e-02, 4.81044637e-02, 2.66958386e+03,\n",
      "        7.24460973e+03, 6.30083679e+03, 7.38755579e+03],\n",
      "       [3.28815934e-02, 8.33975564e-02, 4.81044642e-02, 2.66958386e+03,\n",
      "        7.24460969e+03, 6.30083679e+03, 7.38755583e+03],\n",
      "       [3.28815934e-02, 8.33975567e-02, 4.81044638e-02, 2.66958386e+03,\n",
      "        7.24460967e+03, 6.30083680e+03, 7.38755576e+03],\n",
      "       [3.28815935e-02, 8.33975571e-02, 4.81044636e-02, 2.66958386e+03,\n",
      "        7.24460967e+03, 6.30083682e+03, 7.38755564e+03],\n",
      "       [3.28815934e-02, 8.33975570e-02, 4.81044637e-02, 2.66958386e+03,\n",
      "        7.24460966e+03, 6.30083681e+03, 7.38755572e+03],\n",
      "       [3.28815934e-02, 8.33975569e-02, 4.81044638e-02, 2.66958385e+03,\n",
      "        7.24460973e+03, 6.30083679e+03, 7.38755575e+03]]), array([90672.74759503, 90672.74759516, 90672.74759536, 90672.74759546,\n",
      "       90672.7475955 , 90672.74759568, 90672.74759569, 90672.74759581]))\n",
      "           fun: 90672.74759502892\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1175\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.28815934e-02, 8.33975562e-02, 4.81044641e-02, 2.66958385e+03,\n",
      "       7.24460965e+03, 6.30083680e+03, 7.38755573e+03])\n",
      "minPrevious 90616.66706735565\n",
      "best ll: 91198.52576890608, bestParams: [0.06617981, 0.0026062375, 0.052282184, 5632.2466, 15811.634, 23665.295, 21685.236]\n",
      "epoch 2\n",
      " final_simplex: (array([[5.97788174e-02, 2.86239567e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788175e-02, 2.86239567e-03, 5.14519103e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788175e-02, 2.86239566e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766147e+04, 1.54040265e+04],\n",
      "       [5.97788177e-02, 2.86239567e-03, 5.14519102e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766145e+04, 1.54040266e+04],\n",
      "       [5.97788177e-02, 2.86239565e-03, 5.14519106e-02, 7.10048604e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04],\n",
      "       [5.97788175e-02, 2.86239568e-03, 5.14519099e-02, 7.10048600e+03,\n",
      "        1.78954599e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788178e-02, 2.86239566e-03, 5.14519104e-02, 7.10048604e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04],\n",
      "       [5.97788177e-02, 2.86239566e-03, 5.14519103e-02, 7.10048602e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04]]), array([90761.99558966, 90761.99558975, 90761.99558987, 90761.99558988,\n",
      "       90761.99558996, 90761.99559001, 90761.99559002, 90761.99559008]))\n",
      "           fun: 90761.99558965943\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1259\n",
      "           nit: 478\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.97788174e-02, 2.86239567e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "       1.78954598e+04, 2.16766146e+04, 1.54040265e+04])\n",
      "minPrevious 90616.66706735565\n",
      "best ll: 90782.52717622745, bestParams: [0.028903035, 0.05556211, 0.03673761, 6341.9014, 12760.6875, 16858.322, 19627.572]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5c67a24bbe10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    586\u001b[0m                       callback=callback, **options)\n\u001b[1;32m    587\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mxbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxbar\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mfxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mdoshrink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0ma1Both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1Both\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0ma21\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "resSim = {\n",
    "        \"allRes\": None,\n",
    "        \"nEpochs\": None,\n",
    "        \"bestRes\": {\n",
    "            \"pis\": None,\n",
    "            \"alphas\": None,\n",
    "            \"PDV_c1true\": None,\n",
    "            \"PDV_c2true\": None,\n",
    "            \"PDV_cBothTrue\": None,\n",
    "            \"PDV_c1inferred\": None,\n",
    "            \"PDV_c2inferred\": None,\n",
    "            \"PDV_cBothInferred\": None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cached6NormalSimResNonAnnealing = []\n",
    "\n",
    "rrsSim = tensor([[2, 2, 1.5]])\n",
    "pisSim = tensor([[.05, .05, .05]])\n",
    "\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(5e5)\n",
    "i = 0\n",
    "for rrsSimRun in rrsSim:\n",
    "    for pisSimRun in pisSim:\n",
    "        afMeanRun = 1e-4\n",
    "        generatingFn = genData.v6normal\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        # needs tensor for shapes, otherwise \"gamma_cpu not implemente for long\", e.g rrShape=50.0 doesn't work...\n",
    "        paramsRun = genData.genParams(rrMeans=rrsSimRun, pis=pisSimRun, afMean=afMeanRun, rrShape=tensor(50.), afShape=tensor(50.), nCases=nCases, nCtrls=nCtrls)[0]\n",
    "        \n",
    "        pDsRun = paramsRun[\"pDs\"]\n",
    "        pisRun = paramsRun[\"diseaseFractions\"]\n",
    "        print(\"params are:\", paramsRun)\n",
    "        \n",
    "        cached6NormalSimResNonAnnealing.append({\"params\": paramsRun, \"runs\": []})\n",
    "        for y in range(0, 10):\n",
    "            start = time.time()\n",
    "            r = generatingFn(**paramsRun)\n",
    "            print(\"took\", time.time() - start)\n",
    "            \n",
    "            resPointer = {\n",
    "                **r,\n",
    "                \"generatingFn\": generatingFn,\n",
    "                \"results\": None,\n",
    "            }\n",
    "\n",
    "            cached6NormalSimResNonAnnealing[i][\"runs\"].append(resPointer)\n",
    "            \n",
    "            print(f\"Run: {i}, {y}\")\n",
    "            \n",
    "            xsRun = resPointer[\"altCounts\"]\n",
    "            afsRun = resPointer[\"afs\"]\n",
    "            affectedGenesRun = resPointer[\"affectedGenes\"]\n",
    "            unaffectedGenesRun = resPointer[\"unaffectedGenes\"]\n",
    "\n",
    "            runCostFnIdx = 16\n",
    "\n",
    "            nEpochsRun = 10\n",
    "            print(\"nEpochsRun\", nEpochsRun)\n",
    "            \n",
    "            res = likelihoods.fitFnBivariate(xsRun, pDsRun, nEpochs=nEpochsRun, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "            bestRes = res[\"params\"][-1]\n",
    "\n",
    "            inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "            inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "            #### Calculate actual ###\n",
    "            component1Afs = afsRun[affectedGenesRun[0]]\n",
    "            c1true = (component1Afs / afMeanRun).mean(0)\n",
    "\n",
    "            component2Afs = afsRun[affectedGenesRun[1]]\n",
    "            c2true = (component2Afs / afMeanRun).mean(0)\n",
    "\n",
    "            componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "            cBothTrue = (componentBothAfs / afMeanRun).mean(0)\n",
    "\n",
    "            ### calculate inferred values\n",
    "            pds = tensor([1-pDsRun.sum(), *pDsRun])\n",
    "            alphas = inferredAlphas.numpy()\n",
    "            c1inferred = Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            c2inferred = Dirichlet(tensor([alphas[0], alphas[0], alphas[2], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            cBothInferred = Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0)\n",
    "\n",
    "            print(f\"\\n\\nrun {i} results for rrs: {rrsSimRun}, pis: {pisSimRun}\")\n",
    "            print(\"Inferred pis:\", inferredPis)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c1true)\n",
    "            print(\"P(D|V) inferred in component 1:\", c1inferred)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c2true)\n",
    "            print(\"P(D|V) inferred in component both:\", c2inferred)\n",
    "            print(\"\\nP(D|V) true ans in component both:\", cBothTrue)\n",
    "            print(\"P(D|V) inferred in component both:\", cBothInferred,\"\\n\\n\")\n",
    "\n",
    "            resToStore = copy.deepcopy(resSim)\n",
    "            resToStore[\"allRes\"] = res\n",
    "            resToStore[\"nEpochs\"] = nEpochsRun\n",
    "            br = resToStore[\"bestRes\"]\n",
    "            br[\"pis\"] = inferredPis\n",
    "            br[\"alphas\"] = inferredAlphas\n",
    "            br[\"PDV_c1true\"] = c1true\n",
    "            br[\"PDV_c2true\"] = c2true\n",
    "            br[\"PDV_cBothTrue\"] = cBothTrue\n",
    "            br[\"PDV_c1inferred\"] = c1inferred\n",
    "            br[\"PDV_c2inferred\"] = c2inferred\n",
    "            br[\"PDV_cBothInferred\"] = cBothInferred\n",
    "\n",
    "            resPointer[\"results\"] = resToStore\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([1.5000, 1.5000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.8293, 2.6289, 3.8956],\n",
      "        [2.4995, 2.3651, 2.9228],\n",
      "        [2.9986, 3.1782, 5.7793],\n",
      "        ...,\n",
      "        [1.6170, 2.4270, 3.9871],\n",
      "        [2.6860, 2.5748, 3.5131],\n",
      "        [3.5057, 4.4161, 3.9715]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.05718994140625\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  0.],\n",
      "        [44.,  6.,  1.,  1.],\n",
      "        [50.,  2.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  3.,  2.,  0.],\n",
      "        [53.,  1.,  1.,  3.],\n",
      "        [53.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "n tensor([50., 52., 55.,  ..., 53., 58., 55.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 6., 2.,  ..., 3., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 2.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 0., 3., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  0.],\n",
      "        [44.,  6.,  1.,  1.],\n",
      "        [50.,  2.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  3.,  2.,  0.],\n",
      "        [53.,  1.,  1.,  3.],\n",
      "        [53.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0164, 0.0003, 0.0222,  ..., 0.0175, 0.0025, 0.0234],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa6304e8440>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89254.57939981687, bestParams: [0.09598137, 0.18161891, 0.066081025, 8628.348, 19064.254, 11141.051, 24336.697]\n",
      "epoch 0\n",
      "     fun: 89087.15867372246\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 17512\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.06655157e-01, 8.05196165e-03, 8.52313234e-02, 1.51882047e+04,\n",
      "       1.59563997e+04, 2.49997166e+04, 2.49999993e+04])\n",
      "took 263.1990089416504\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([1.5000, 1.5000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.9067, 0.0081, 0.0852], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8974, 0.0550, 0.0281, 0.0220], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.9248, 0.0291, 0.0277, 0.0183], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8934, 0.0280, 0.0558, 0.0223], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.9098, 0.0273, 0.0449, 0.0180], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7746, 0.0863, 0.0874, 0.0510], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8119, 0.0657, 0.0802, 0.0423], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.0191, 2.4042, 5.8232],\n",
      "        [1.0840, 2.3261, 4.9498],\n",
      "        [3.7891, 1.8827, 4.6055],\n",
      "        ...,\n",
      "        [4.0709, 3.3965, 6.2600],\n",
      "        [1.4524, 3.2465, 4.9516],\n",
      "        [2.2135, 1.7095, 4.1531]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.519060134887695\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  2.],\n",
      "        [45.,  6.,  4.,  3.],\n",
      "        [54.,  5.,  1.,  0.],\n",
      "        ...,\n",
      "        [59.,  3.,  2.,  3.],\n",
      "        [44.,  1.,  3.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([45., 58., 60.,  ..., 67., 48., 45.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 5.,  ..., 3., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 4., 1.,  ..., 2., 3., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 0.,  ..., 3., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  2.],\n",
      "        [45.,  6.,  4.,  3.],\n",
      "        [54.,  5.,  1.,  0.],\n",
      "        ...,\n",
      "        [59.,  3.,  2.,  3.],\n",
      "        [44.,  1.,  3.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([6.2383e-03, 3.4287e-06, 3.3784e-03,  ..., 1.4544e-03, 2.2402e-02,\n",
      "        4.3776e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa6411153b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89545.34098332483, bestParams: [0.019650858, 0.005765289, 0.015805295, 8096.601, 15435.601, 23816.336, 12740.194]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-087714822751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunSim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1387c87bde79>\u001b[0m in \u001b[0;36mrunSim\u001b[0;34m(rrs, pis, nCases, nCtrls, afMean, rrShape, afShape, generatingFn, fitMethod)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitMethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx, method)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Nelder-Mead'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adaptive\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"annealing\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"basinhopping\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasinhopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mdual_annealing\u001b[0;34m(func, bounds, args, maxiter, local_search_options, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0)\u001b[0m\n\u001b[1;32m    663\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;31m# starting strategy chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, step, temperature)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 self.energy_state.current_location, j, temperature)\n\u001b[1;32m    290\u001b[0m             \u001b[0;31m# Calling the objective function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_visit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_energy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;31m# We have got a better energy value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0maBothBoth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malphaBoth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mh3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBoth1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBoth2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBothBoth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mh0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runSim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN\n",
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([1.5000, 1.5000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9334, 2.5262, 4.5972],\n",
      "        [2.9295, 2.6827, 4.2659],\n",
      "        [3.4033, 4.0980, 4.6098],\n",
      "        ...,\n",
      "        [3.2606, 1.8734, 3.4271],\n",
      "        [2.4874, 2.7894, 4.5732],\n",
      "        [3.8228, 2.9923, 4.2592]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.798516273498535\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  1.],\n",
      "        [51.,  0.,  2.,  3.],\n",
      "        [41.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [55.,  1.,  4.,  0.],\n",
      "        [40.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([51., 56., 44.,  ..., 60., 42., 43.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 0.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 2.,  ..., 4., 1., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 1.,  ..., 0., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  1.],\n",
      "        [51.,  0.,  2.,  3.],\n",
      "        [41.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [55.,  1.,  4.,  0.],\n",
      "        [40.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0093, 0.0012, 0.0201,  ..., 0.0102, 0.0836, 0.0409],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa60809c050>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89504.27484045511, bestParams: [0.01460946, 0.02944035, 0.03863643, 3142.4583, 3569.245, 5062.629, 6662.2]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112738e+03,\n",
      "        5.21052634e+03, 4.99263541e+03, 2.62354673e+03],\n",
      "       [1.98604401e-02, 3.41540280e-02, 3.55878742e-02, 1.65112738e+03,\n",
      "        5.21052633e+03, 4.99263546e+03, 2.62354667e+03],\n",
      "       [1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112737e+03,\n",
      "        5.21052636e+03, 4.99263542e+03, 2.62354672e+03],\n",
      "       [1.98604400e-02, 3.41540281e-02, 3.55878741e-02, 1.65112738e+03,\n",
      "        5.21052634e+03, 4.99263542e+03, 2.62354670e+03],\n",
      "       [1.98604401e-02, 3.41540283e-02, 3.55878742e-02, 1.65112737e+03,\n",
      "        5.21052638e+03, 4.99263537e+03, 2.62354673e+03],\n",
      "       [1.98604401e-02, 3.41540280e-02, 3.55878744e-02, 1.65112737e+03,\n",
      "        5.21052634e+03, 4.99263546e+03, 2.62354667e+03],\n",
      "       [1.98604400e-02, 3.41540281e-02, 3.55878747e-02, 1.65112738e+03,\n",
      "        5.21052627e+03, 4.99263541e+03, 2.62354677e+03],\n",
      "       [1.98604400e-02, 3.41540282e-02, 3.55878745e-02, 1.65112738e+03,\n",
      "        5.21052630e+03, 4.99263539e+03, 2.62354675e+03]]), array([89097.20969999, 89097.20970001, 89097.20970011, 89097.20970015,\n",
      "       89097.20970023, 89097.20970029, 89097.2097003 , 89097.20970032]))\n",
      "           fun: 89097.20969998793\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1187\n",
      "           nit: 474\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112738e+03,\n",
      "       5.21052634e+03, 4.99263541e+03, 2.62354673e+03])\n",
      "best ll: 89661.97322291948, bestParams: [0.03616922, 0.032769334, 0.045829535, 10727.266, 24210.703, 12838.759, 15205.117]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514215e-02, 7.07864376e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259062e+04],\n",
      "       [4.19236529e-02, 3.25639602e-02, 3.48514220e-02, 7.07864378e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236527e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514220e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041261e+04, 2.08219659e+04, 1.43259061e+04]]), array([89076.07821087, 89076.07821088, 89076.07821092, 89076.07821098,\n",
      "       89076.07821101, 89076.07821117, 89076.07821118, 89076.07821121]))\n",
      "           fun: 89076.07821086713\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1248\n",
      "           nit: 473\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "       1.96041260e+04, 2.08219659e+04, 1.43259061e+04])\n",
      "minPrevious 89097.20969998793\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514215e-02, 7.07864376e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259062e+04],\n",
      "       [4.19236529e-02, 3.25639602e-02, 3.48514220e-02, 7.07864378e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236527e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514220e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041261e+04, 2.08219659e+04, 1.43259061e+04]]), array([89076.07821087, 89076.07821088, 89076.07821092, 89076.07821098,\n",
      "       89076.07821101, 89076.07821117, 89076.07821118, 89076.07821121]))\n",
      "           fun: 89076.07821086713\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1248\n",
      "           nit: 473\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "       1.96041260e+04, 2.08219659e+04, 1.43259061e+04])\n",
      "best ll: 89396.0603735198, bestParams: [0.02752898, 0.02535716, 0.018690322, 5718.255, 12018.066, 19256.404, 19616.584]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.03046914e-02, 2.79128625e-02, 2.73070996e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259645e+03],\n",
      "       [3.03046915e-02, 2.79128625e-02, 2.73070995e-02, 4.82605052e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259643e+03],\n",
      "       [3.03046916e-02, 2.79128625e-02, 2.73070995e-02, 4.82605052e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259641e+03],\n",
      "       [3.03046916e-02, 2.79128625e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259646e+03],\n",
      "       [3.03046915e-02, 2.79128626e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259648e+03],\n",
      "       [3.03046916e-02, 2.79128626e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259646e+03],\n",
      "       [3.03046918e-02, 2.79128627e-02, 2.73070993e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259651e+03],\n",
      "       [3.03046916e-02, 2.79128624e-02, 2.73070996e-02, 4.82605052e+03,\n",
      "        1.52177117e+04, 1.57090374e+04, 7.96259636e+03]]), array([89090.52106561, 89090.52106562, 89090.52106564, 89090.52106565,\n",
      "       89090.52106566, 89090.52106567, 89090.52106586, 89090.52107062]))\n",
      "           fun: 89090.52106561436\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1246\n",
      "           nit: 440\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.03046914e-02, 2.79128625e-02, 2.73070996e-02, 4.82605053e+03,\n",
      "       1.52177116e+04, 1.57090374e+04, 7.96259645e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89159.98797501124, bestParams: [0.07087075, 0.035208993, 0.046770897, 7998.9688, 20401.977, 21096.521, 20626.426]\n",
      "epoch 3\n",
      " final_simplex: (array([[6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623725e+04],\n",
      "       [6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730239e+04, 1.97623725e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623724e+04],\n",
      "       [6.71874810e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874810e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874811e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623724e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04]]), array([89100.40359353, 89100.40359355, 89100.40359361, 89100.40359362,\n",
      "       89100.40359366, 89100.40359367, 89100.40359371, 89100.40359375]))\n",
      "           fun: 89100.40359352919\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1309\n",
      "           nit: 496\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "       1.97499805e+04, 2.14730240e+04, 1.97623725e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89266.87360477714, bestParams: [0.02102224, 0.0073940502, 0.04933069, 9835.428, 20614.709, 23006.111, 24559.834]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.81792183e-02, 1.00385350e-02, 4.10791068e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436391e+03],\n",
      "       [2.81792178e-02, 1.00385350e-02, 4.10791081e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436387e+03],\n",
      "       [2.81792169e-02, 1.00385350e-02, 4.10791109e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436386e+03],\n",
      "       [2.81792169e-02, 1.00385350e-02, 4.10791111e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436397e+03],\n",
      "       [2.81792162e-02, 1.00385350e-02, 4.10791133e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436397e+03],\n",
      "       [2.81792161e-02, 1.00385351e-02, 4.10791135e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436386e+03],\n",
      "       [2.81792156e-02, 1.00385350e-02, 4.10791151e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436393e+03],\n",
      "       [2.81792146e-02, 1.00385351e-02, 4.10791183e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436391e+03]]), array([89131.49405002, 89131.49405098, 89131.49405308, 89131.49405339,\n",
      "       89131.49405506, 89131.49405509, 89131.4940564 , 89131.4940588 ]))\n",
      "           fun: 89131.49405001549\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2322\n",
      "           nit: 1097\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.81792183e-02, 1.00385350e-02, 4.10791068e-02, 7.92193726e+03,\n",
      "       2.46257826e+04, 2.70287627e+04, 8.82436391e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89362.65263565104, bestParams: [0.012687951, 0.011631452, 0.07809705, 6797.328, 13523.173, 17862.2, 14069.145]\n",
      "epoch 5\n",
      " final_simplex: (array([[1.84218776e-02, 1.37973849e-02, 3.77607203e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083500e+03],\n",
      "       [1.84218775e-02, 1.37973850e-02, 3.77607202e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083503e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607205e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083504e+03],\n",
      "       [1.84218776e-02, 1.37973850e-02, 3.77607202e-02, 5.59975530e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083499e+03],\n",
      "       [1.84218777e-02, 1.37973848e-02, 3.77607207e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083490e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607205e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083495e+03],\n",
      "       [1.84218776e-02, 1.37973850e-02, 3.77607202e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083502e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607204e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083499e+03]]), array([89133.97795553, 89133.97795554, 89133.97795572, 89133.9779627 ,\n",
      "       89133.97796275, 89133.97796276, 89133.97796276, 89133.97796277]))\n",
      "           fun: 89133.97795552979\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1228\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.84218776e-02, 1.37973849e-02, 3.77607203e-02, 5.59975531e+03,\n",
      "       1.89100468e+04, 1.95686277e+04, 5.99083500e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89212.69924155968, bestParams: [0.025522236, 0.07102064, 0.04095869, 6469.978, 23772.977, 16247.678, 7731.7466]\n",
      "epoch 6\n",
      " final_simplex: (array([[2.70476141e-02, 4.01468282e-02, 3.26248241e-02, 6.48001244e+03,\n",
      "        1.99119150e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476140e-02, 4.01468277e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394004e+04],\n",
      "       [2.70476141e-02, 4.01468286e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476141e-02, 4.01468292e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394002e+04],\n",
      "       [2.70476141e-02, 4.01468287e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394003e+04],\n",
      "       [2.70476141e-02, 4.01468291e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394002e+04],\n",
      "       [2.70476141e-02, 4.01468290e-02, 3.26248239e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476142e-02, 4.01468298e-02, 3.26248239e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394002e+04]]), array([89083.15977387, 89083.15977388, 89083.15977389, 89083.15977391,\n",
      "       89083.15977393, 89083.15977395, 89083.15977396, 89083.15977396]))\n",
      "           fun: 89083.15977387255\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 540\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.70476141e-02, 4.01468282e-02, 3.26248241e-02, 6.48001244e+03,\n",
      "       1.99119150e+04, 1.85927180e+04, 1.18394003e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89330.68493643744, bestParams: [0.082257316, 0.027428642, 0.07051255, 7407.681, 12604.67, 11728.0625, 22984.412]\n",
      "epoch 7\n",
      " final_simplex: (array([[7.22722643e-02, 4.08138975e-02, 3.35494221e-02, 6.23642624e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722643e-02, 4.08138976e-02, 3.35494214e-02, 6.23642621e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722637e-02, 4.08138975e-02, 3.35494209e-02, 6.23642626e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722640e-02, 4.08138976e-02, 3.35494211e-02, 6.23642624e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722644e-02, 4.08138975e-02, 3.35494216e-02, 6.23642623e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722642e-02, 4.08138974e-02, 3.35494214e-02, 6.23642625e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722651e-02, 4.08138974e-02, 3.35494229e-02, 6.23642620e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722644e-02, 4.08138975e-02, 3.35494217e-02, 6.23642623e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04]]), array([89092.78697749, 89092.78697752, 89092.78697752, 89092.78697755,\n",
      "       89092.78697766, 89092.78697766, 89092.78697766, 89092.78697769]))\n",
      "           fun: 89092.78697748706\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1211\n",
      "           nit: 458\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.22722643e-02, 4.08138975e-02, 3.35494221e-02, 6.23642624e+03,\n",
      "       1.45974907e+04, 1.66629287e+04, 1.42103738e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89389.45489296163, bestParams: [0.060271375, 0.042252373, 0.050650936, 6876.2065, 11556.726, 21871.658, 21758.736]\n",
      "epoch 8\n",
      " final_simplex: (array([[6.51869746e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869748e-02, 5.30897589e-02, 3.51516079e-02, 7.05962329e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869746e-02, 5.30897590e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869746e-02, 5.30897590e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869748e-02, 5.30897588e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123699e+04, 1.75684742e+04],\n",
      "       [6.51869746e-02, 5.30897591e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869747e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869747e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04]]), array([89093.22690281, 89093.22690282, 89093.22690284, 89093.22690284,\n",
      "       89093.22690285, 89093.22690287, 89093.22690287, 89093.2269029 ]))\n",
      "           fun: 89093.22690280867\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1255\n",
      "           nit: 513\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.51869746e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "       1.66074072e+04, 1.75123700e+04, 1.75684742e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89479.24696850716, bestParams: [0.0029611788, 0.048730392, 0.018831836, 9358.529, 19040.064, 23882.67, 18005.031]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.08114659e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147293e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532136e-02, 3.99157607e-02, 6.77894951e+03,\n",
      "        2.23243264e+04, 1.88557299e+04, 9.53147285e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147293e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157607e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147291e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147294e+03]]), array([89195.54214277, 89195.54214282, 89195.54214284, 89195.54214284,\n",
      "       89195.54214303, 89195.54216626, 89195.54216627, 89195.54216628]))\n",
      "           fun: 89195.5421427736\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1323\n",
      "           nit: 487\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.08114659e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "       2.23243264e+04, 1.88557300e+04, 9.53147293e+03])\n",
      "minPrevious 89076.07821086713\n",
      "took 407.44111680984497\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([1.5000, 1.5000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0419, 0.0326, 0.0349], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8933, 0.0569, 0.0280, 0.0227], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8708, 0.0723, 0.0261, 0.0307], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8975, 0.0281, 0.0563, 0.0225], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8670, 0.0260, 0.0765, 0.0305], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7772, 0.0856, 0.0853, 0.0511], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7218, 0.1037, 0.1075, 0.0670], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[4.4937, 4.8385, 5.2157],\n",
      "        [3.3180, 2.5832, 3.6836],\n",
      "        [4.3122, 2.5246, 4.8452],\n",
      "        ...,\n",
      "        [2.7396, 4.5652, 3.7115],\n",
      "        [1.9112, 3.0687, 5.9062],\n",
      "        [1.3352, 2.5593, 3.5319]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-879fdf1954c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunSim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitMethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1387c87bde79>\u001b[0m in \u001b[0;36mrunSim\u001b[0;34m(rrs, pis, nCases, nCtrls, afMean, rrShape, afShape, generatingFn, fitMethod)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneratingFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparamsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/genData.py\u001b[0m in \u001b[0;36mv6normal\u001b[0;34m(nCases, nCtrls, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mmarginalAlleleCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalProbability\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotalSamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0maltCountsGene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarginalAlleleCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0maltCounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsGene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/distributions/multinomial.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# samples.shape is (total_count, sample_shape, batch_shape), need to change it to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# (sample_shape, batch_shape, total_count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mshifted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mshifted_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshifted_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshifted_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runSim(fitMethod='nelder-mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f646b1ec66d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./mvln-sim-mvln.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf_should_read_directly\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = np.load(\"./mvln-sim-mvln.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resByParams = []\n",
    "for runSet in res:\n",
    "    params = (runSet[\"params\"][\"diseaseFractions\"], runSet[\"params\"][\"rrMeans\"], runSet[\"params\"][\"rrShape\"])\n",
    "#     print(\"param\", params)\n",
    "    res = []\n",
    "#     if params not in resByParam:\n",
    "#         resByParams[params] = []\n",
    "    \n",
    "    for run in runSet[\"runs\"]:\n",
    "        if run is None or \"results\" not in run or run[\"results\"] is None:\n",
    "            print(f\"no results found for {params}\")\n",
    "            continue\n",
    "        res.append(run[\"results\"])\n",
    "    resByParams.append([params, res])\n",
    "\n",
    "np.save(\"mvln-sim-mvln-results2\", resByParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resByParams = np.load(\"mvln-sim-mvln-results.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[(tensor([0.0500, 0.0500, 0.0500]), tensor([2.0000, 2.0000, 1.5000]), tensor(50.)),\n",
       "        list([{'allRes': {'lls': [90916.4783589971, 90708.31368424412, 90689.04874179952, 90677.23983613223], 'params': [array([3.87333861e-02, 1.40812486e-01, 7.59025824e-02, 9.31141067e+03,\n",
       "       2.18500134e+04, 1.68652588e+04, 2.63598593e+04]), array([1.67543257e-02, 3.13060638e-02, 4.29277051e-02, 2.50496081e+03,\n",
       "       8.64518025e+03, 8.37694873e+03, 4.74332877e+03]), array([4.07980539e-02, 5.92690249e-02, 4.06981218e-02, 4.76417261e+03,\n",
       "       1.30584069e+04, 1.28133394e+04, 1.26034808e+04]), array([3.56317955e-02, 3.20989858e-02, 4.08777915e-02, 5.02625412e+03,\n",
       "       1.52388589e+04, 1.62573997e+04, 1.10763793e+04])], 'llTrajectory': [90916.4783589971, 90708.31368424412, 90727.26669070916, 90689.04874179952, 90677.23983613223, 90676.96371994552, 90738.01226968745, 90784.31279984681, 90787.42281897092, 90677.4934384852]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0356, 0.0321, 0.0409], dtype=torch.float64), 'alphas': tensor([ 5026.2541, 15238.8589, 16257.3997, 11076.3793], dtype=torch.float64), 'PDV_c1true': tensor([0.8812, 0.0628, 0.0279, 0.0251], dtype=torch.float64), 'PDV_c2true': tensor([0.8833, 0.0281, 0.0651, 0.0261], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7405, 0.0993, 0.0996, 0.0623], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8622, 0.0785, 0.0259, 0.0335], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8577, 0.0257, 0.0832, 0.0333], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7032, 0.1105, 0.1148, 0.0715], dtype=torch.float64)}}, {'allRes': {'lls': [90645.57342181327, 90644.31351623876, 90641.27069583946], 'params': [array([3.63755073e-02, 4.57749896e-02, 4.18899664e-02, 1.42087064e+03,\n",
       "       4.35121665e+03, 4.00355358e+03, 3.50070375e+03]), array([4.66029047e-02, 4.53761282e-02, 4.29744549e-02, 6.07873461e+03,\n",
       "       1.78237112e+04, 1.71242042e+04, 1.58362642e+04]), array([4.33810405e-02, 4.52988838e-02, 4.13633647e-02, 6.96476709e+02,\n",
       "       2.04656915e+03, 1.91605097e+03, 1.77271015e+03])], 'llTrajectory': [90645.57342181327, 90651.2118646526, 90719.94317753878, 90644.31351623876, 90666.92657482934, 90653.34651654988, 90641.27069583946, 90651.3464135098, 90680.92933323765, 90792.21030335355]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0434, 0.0453, 0.0414], dtype=torch.float64), 'alphas': tensor([ 696.4767, 2046.5691, 1916.0510, 1772.7101], dtype=torch.float64), 'PDV_c1true': tensor([0.8797, 0.0642, 0.0279, 0.0257], dtype=torch.float64), 'PDV_c2true': tensor([0.8793, 0.0278, 0.0627, 0.0251], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7303, 0.0996, 0.0971, 0.0614], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8686, 0.0767, 0.0261, 0.0286], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8730, 0.0261, 0.0721, 0.0288], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7034, 0.1153, 0.1118, 0.0695], dtype=torch.float64)}}, {'allRes': {'lls': [90748.6465155581, 90711.14503326186], 'params': [array([6.27341823e-02, 4.63341146e-02, 3.75087980e-02, 6.10706763e+03,\n",
       "       1.62508186e+04, 1.74873704e+04, 1.57440691e+04]), array([3.54220726e-02, 4.85500888e-02, 4.49141211e-02, 2.28821775e+02,\n",
       "       6.42604102e+02, 6.38308739e+02, 5.08927552e+02])], 'llTrajectory': [90748.6465155581, 90711.14503326186, 90744.77986211523, 90876.14512541448, 90742.77190618007, 90800.03142956684, 90875.49917612775, 90747.52190318814, 90775.94721973015, 90878.82993506195]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0354, 0.0486, 0.0449], dtype=torch.float64), 'alphas': tensor([228.8218, 642.6041, 638.3087, 508.9276], dtype=torch.float64), 'PDV_c1true': tensor([0.8907, 0.0641, 0.0282, 0.0257], dtype=torch.float64), 'PDV_c2true': tensor([0.8856, 0.0281, 0.0643, 0.0257], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7492, 0.0969, 0.0963, 0.0615], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8712, 0.0735, 0.0262, 0.0291], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8716, 0.0263, 0.0729, 0.0293], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7170, 0.1081, 0.1075, 0.0673], dtype=torch.float64)}}, {'allRes': {'lls': [90933.72918146176, 90838.29602316262], 'params': [array([9.06864522e-02, 6.50148984e-02, 5.37885695e-02, 7.24642505e+03,\n",
       "       1.56345132e+04, 1.71235809e+04, 2.05677764e+04]), array([3.85649052e-02, 4.20795687e-02, 4.01053337e-02, 1.89342510e+03,\n",
       "       5.93866294e+03, 5.77638420e+03, 4.21878917e+03])], 'llTrajectory': [90933.72918146176, 90838.29602316262, 90868.60640369028, 90882.07712309291, 90847.74550284173, 90896.76813160375, 91157.13067761659, 90877.09566313706, 90838.3988977742, 90894.50289291705]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0386, 0.0421, 0.0401], dtype=torch.float64), 'alphas': tensor([1893.4251, 5938.6629, 5776.3842, 4218.7892], dtype=torch.float64), 'PDV_c1true': tensor([0.8888, 0.0641, 0.0282, 0.0256], dtype=torch.float64), 'PDV_c2true': tensor([0.8769, 0.0278, 0.0635, 0.0254], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7435, 0.0972, 0.0976, 0.0616], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8615, 0.0811, 0.0258, 0.0315], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8636, 0.0258, 0.0790, 0.0316], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7040, 0.1134, 0.1116, 0.0710], dtype=torch.float64)}}, {'allRes': {'lls': [90747.7696123132, 90585.67194419992, 90566.73709957347], 'params': [array([5.91826890e-02, 1.44589234e-01, 6.69387920e-02, 7.98395162e+03,\n",
       "       1.52393288e+04, 1.31918445e+04, 2.25971498e+04]), array([3.23620186e-02, 2.38361870e-02, 3.69261663e-02, 6.10035669e+03,\n",
       "       2.08475809e+04, 2.21919581e+04, 9.74581440e+03]), array([3.78255556e-02, 3.46743998e-02, 4.08244155e-02, 3.95583458e+03,\n",
       "       1.26977546e+04, 1.28829457e+04, 7.45632495e+03])], 'llTrajectory': [90747.7696123132, 90749.95843612179, 90585.67194419992, 90878.04322170046, 90566.73709957347, 90566.96453252305, 90861.6203819377, 90571.64204209404, 90615.46630737893, 90606.66331600855]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0378, 0.0347, 0.0408], dtype=torch.float64), 'alphas': tensor([ 3955.8346, 12697.7546, 12882.9457,  7456.3249], dtype=torch.float64), 'PDV_c1true': tensor([0.8825, 0.0635, 0.0280, 0.0254], dtype=torch.float64), 'PDV_c2true': tensor([0.8835, 0.0280, 0.0631, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7426, 0.0973, 0.0990, 0.0610], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8581, 0.0826, 0.0257, 0.0336], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8570, 0.0257, 0.0838, 0.0335], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7106, 0.1086, 0.1096, 0.0712], dtype=torch.float64)}}, {'allRes': {'lls': [90830.07972194639, 90562.237920496], 'params': [array([1.69463338e-01, 1.98575139e-01, 6.22025970e-02, 4.41316805e+03,\n",
       "       6.28159370e+03, 5.39738695e+03, 1.63099014e+04]), array([4.85819986e-02, 4.43267999e-02, 4.25625903e-02, 2.84641270e+02,\n",
       "       7.71902383e+02, 7.79988251e+02, 7.35633621e+02])], 'llTrajectory': [90830.07972194639, 90562.237920496, 90774.41540520656, 90774.76133135978, 90857.23196144999, 90587.14554848513, 90638.69745056726, 90581.18297009883, 90642.92672963747, 90596.53639301992]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0486, 0.0443, 0.0426], dtype=torch.float64), 'alphas': tensor([284.6413, 771.9024, 779.9883, 735.6336], dtype=torch.float64), 'PDV_c1true': tensor([0.8809, 0.0633, 0.0279, 0.0253], dtype=torch.float64), 'PDV_c2true': tensor([0.8849, 0.0280, 0.0629, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7376, 0.1000, 0.0991, 0.0615], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8736, 0.0712, 0.0264, 0.0288], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8738, 0.0261, 0.0714, 0.0286], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7067, 0.1122, 0.1130, 0.0681], dtype=torch.float64)}}, {'allRes': {'lls': [90541.19690546543, 90485.83852292394, 90450.04864336646], 'params': [array([1.05198885e-01, 5.61385155e-02, 4.30683468e-02, 7.16649842e+03,\n",
       "       1.50831749e+04, 1.90234287e+04, 2.11213115e+04]), array([1.45415926e-02, 3.60020275e-02, 4.32792564e-02, 5.79867892e+03,\n",
       "       2.10841845e+04, 1.86303955e+04, 1.00095742e+04]), array([4.04756141e-02, 2.69877192e-02, 4.02918327e-02, 5.89913599e+03,\n",
       "       1.83048623e+04, 1.99880264e+04, 1.21531034e+04])], 'llTrajectory': [90541.19690546543, 90485.83852292394, 90640.86004954319, 90450.04864336646, 90702.5564634097, 90557.9040388632, 90460.6229193173, 90467.91167992419, 90520.90760929213, 90557.50718726793]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0405, 0.0270, 0.0403], dtype=torch.float64), 'alphas': tensor([ 5899.1360, 18304.8623, 19988.0264, 12153.1034], dtype=torch.float64), 'PDV_c1true': tensor([0.8760, 0.0640, 0.0278, 0.0256], dtype=torch.float64), 'PDV_c2true': tensor([0.8838, 0.0280, 0.0630, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7420, 0.0999, 0.0992, 0.0621], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8593, 0.0800, 0.0258, 0.0349], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8530, 0.0256, 0.0868, 0.0346], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7038, 0.1090, 0.1150, 0.0722], dtype=torch.float64)}}, {'allRes': {'lls': [90757.56968553299, 90527.69242737578, 90521.27001448293], 'params': [array([1.61995075e-03, 1.05690047e-01, 5.31147218e-02, 7.83678126e+03,\n",
       "       2.34720398e+04, 1.67885869e+04, 1.81920206e+04]), array([3.75891039e-02, 3.93849894e-02, 4.27479940e-02, 3.83229961e+03,\n",
       "       1.20099977e+04, 1.13342312e+04, 9.03855526e+03]), array([3.71189801e-02, 3.75458264e-02, 4.12923202e-02, 9.18698687e+02,\n",
       "       2.84332494e+03, 2.78552088e+03, 2.18573783e+03])], 'llTrajectory': [90757.56968553299, 90527.69242737578, 90711.2276505137, 90521.27001448293, 90578.02820961754, 90562.84654239606, 90559.02988606176, 90559.19154174202, 90661.38357505882, 90574.89262462722]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0371, 0.0375, 0.0413], dtype=torch.float64), 'alphas': tensor([ 918.6987, 2843.3249, 2785.5209, 2185.7378], dtype=torch.float64), 'PDV_c1true': tensor([0.8806, 0.0645, 0.0280, 0.0258], dtype=torch.float64), 'PDV_c2true': tensor([0.8815, 0.0279, 0.0636, 0.0254], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7461, 0.1002, 0.0990, 0.0622], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8627, 0.0800, 0.0259, 0.0314], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8642, 0.0259, 0.0785, 0.0314], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.6999, 0.1150, 0.1135, 0.0715], dtype=torch.float64)}}, {'allRes': {'lls': [90897.96160983646, 90822.30100460075, 90813.7933164202], 'params': [array([4.94523337e-02, 8.98534427e-02, 5.08059703e-02, 9.33431412e+03,\n",
       "       2.31980772e+04, 2.01782677e+04, 2.67851825e+04]), array([5.22288505e-02, 3.94783721e-02, 3.29460235e-02, 6.27854966e+03,\n",
       "       1.81322217e+04, 2.01847985e+04, 1.56110186e+04]), array([4.59210324e-02, 3.17754408e-02, 3.75392591e-02, 2.79599712e+03,\n",
       "       8.37452682e+03, 9.36512056e+03, 6.22258891e+03])], 'llTrajectory': [90897.96160983646, 90822.30100460075, 90813.7933164202, 91195.13795952266, 90824.4409889472, 90948.83020724998, 90833.29153831744, 90914.45047672343, 90828.49674330515, 90894.21608835603]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0459, 0.0318, 0.0375], dtype=torch.float64), 'alphas': tensor([2795.9971, 8374.5268, 9365.1206, 6222.5889], dtype=torch.float64), 'PDV_c1true': tensor([0.8817, 0.0646, 0.0280, 0.0258], dtype=torch.float64), 'PDV_c2true': tensor([0.8855, 0.0281, 0.0642, 0.0257], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7387, 0.0989, 0.0991, 0.0620], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8621, 0.0774, 0.0258, 0.0346], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8541, 0.0256, 0.0859, 0.0344], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7009, 0.1097, 0.1173, 0.0721], dtype=torch.float64)}}, {'allRes': {'lls': [90674.24682333917, 90639.08503812845, 90635.38566081121], 'params': [array([8.25512430e-02, 4.47077237e-02, 3.81560217e-02, 4.85958175e+03,\n",
       "       1.15702661e+04, 1.34392115e+04, 1.46426684e+04]), array([3.22876832e-02, 3.94240441e-02, 4.00764617e-02, 7.08816185e+03,\n",
       "       2.15671201e+04, 2.13042256e+04, 1.77545086e+04]), array([4.38503233e-02, 4.14981181e-02, 4.02783387e-02, 4.39219918e+03,\n",
       "       1.27983245e+04, 1.36739819e+04, 1.11025385e+04])], 'llTrajectory': [90674.24682333917, 90639.08503812845, 90824.46248323756, 90645.51300320614, 90877.98499150135, 90635.38566081121, 90641.18017866093, 90640.17212894236, 90647.75311221162, 90634.58400619372]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0439, 0.0415, 0.0403], dtype=torch.float64), 'alphas': tensor([ 4392.1992, 12798.3245, 13673.9819, 11102.5385], dtype=torch.float64), 'PDV_c1true': tensor([0.8838, 0.0650, 0.0281, 0.0260], dtype=torch.float64), 'PDV_c2true': tensor([0.8842, 0.0280, 0.0629, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7435, 0.0991, 0.0996, 0.0620], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8659, 0.0758, 0.0260, 0.0323], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8616, 0.0258, 0.0804, 0.0322], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.6969, 0.1137, 0.1179, 0.0715], dtype=torch.float64)}}])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resByParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.subplot([1,len(resByParams)])\n",
    "i = 0\n",
    "with open(\"mvln-sim-mvln-res.tsv\", \"w\") as file:\n",
    "    file.write(f\"Notes: 15000 samples1, 15000 samples2, 6000 samplesBoth; rrs generated from normal distribution with. 1 variance, .4 covariance, and individual effect rr summed with shared-effect rr in genes affecting both conditions\\n\")\n",
    "    file.write(f\"\\tmean\\tstd\\n\")\n",
    "    for res in resByParams:\n",
    "        i += 1\n",
    "\n",
    "        paramsRun = res[0]\n",
    "        resRun = res[1]\n",
    "\n",
    "        pis = tensor([x[\"bestRes\"][\"pis\"].numpy() for x in resRun])\n",
    "        PDV_c1true = tensor([x[\"bestRes\"][\"PDV_c1true\"].numpy() for x in resRun])\n",
    "        PDV_c2true = tensor([x[\"bestRes\"][\"PDV_c2true\"].numpy() for x in resRun])\n",
    "        PDV_c3true = tensor([x[\"bestRes\"][\"PDV_cBothTrue\"].numpy() for x in resRun])\n",
    "        PDV_c1inferred = tensor([x[\"bestRes\"][\"PDV_c1inferred\"].numpy() for x in resRun])\n",
    "        PDV_c2inferred = tensor([x[\"bestRes\"][\"PDV_c2inferred\"].numpy() for x in resRun])\n",
    "        PDV_c3inferred = tensor([x[\"bestRes\"][\"PDV_cBothInferred\"].numpy() for x in resRun])\n",
    "\n",
    "        file.write(f\"\\n\\ntrue params: \\t{paramsRun} \\n\\n\")\n",
    "\n",
    "        file.write(f\"pi\\t {pis.mean(0).numpy()} \\t  {pis.std(0).numpy()} \\n\")\n",
    "\n",
    "        file.write(f\"PDV_c1inferred \\t {PDV_c1inferred.mean(0).numpy()}\\t {PDV_c1inferred.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c1true \\t {PDV_c1true.mean(0).numpy()} \\t {PDV_c1true.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c2inferred \\t {PDV_c2inferred.mean(0).numpy()} \\t {PDV_c2inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c2true \\t {PDV_c2true.mean(0).numpy()} \\t {PDV_c2true.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3inferred \\t {PDV_c3inferred.mean(0).numpy()} \\t {PDV_c3inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3true \\t {PDV_c3true.mean(0).numpy()} \\t {PDV_c3true.std(0).numpy()}\\n\")\n",
    "\n",
    "    #     plt.figure(i)\n",
    "    #     plt.plot(t, s1)\n",
    "    #     plt.plot(t, 2*s1)\n",
    "        # plt.subplot(222)\n",
    "        # plt.plot(t, 2*s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Tensor is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5cb54c57e780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mvln-sim-mvn.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached6NormalSimRes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Tensor is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open('./mvln-sim-mvn.json', 'w') as outfile:\n",
    "    json.dump(cached6NormalSimRes, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 5\n"
     ]
    }
   ],
   "source": [
    "def one(a, b, c, d = 5):\n",
    "    print(a, b, c, d)\n",
    "    \n",
    "def two(*args, **kwargs):\n",
    "    one(*args, **kwargs)\n",
    "    \n",
    "two(1, 2, c = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size = multiprocessing.cpu_count()\n",
    "os.system('taskset -cp 0-%d %s' % (pool_size, os.getpid()))\n",
    "\n",
    "genData.runSim(fitMethod=\"nelder-mead\", mt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('taskset -p %s' %os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "def compute_something(t):\n",
    "    a = 0.\n",
    "    for i in range(10000000):\n",
    "        a = math.sqrt(t)\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Pool size:\", pool_size)\n",
    "pool = multiprocessing.Pool(processes=pool_size)\n",
    "\n",
    "inputs = range(10)\n",
    "\n",
    "tic = time.time()\n",
    "builtin_outputs = map(compute_something, inputs)\n",
    "print('Built-in:', time.time() - tic)\n",
    "\n",
    "tic = time.time()\n",
    "pool_outputs = pool.map(compute_something, inputs)\n",
    "print('Pool    :', time.time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    "# import pyro\n",
    "# from torch.multiprocessing import Process\n",
    "# from torch.distributions import Uniform\n",
    "# import time\n",
    "# import numpy as np\n",
    "# def writer():\n",
    "#     message = f\"I am Process {i}\"\n",
    "#     print(torch.utils.data.get_worker_info())\n",
    "#     x = np.random.seed()\n",
    "#     x = np.random.randint(1000)\n",
    "#     print('seed', x)\n",
    "#     torch.manual_seed(x)\n",
    "#     pis = Uniform(1/100, .5).rsample([3])\n",
    "#     print(\"r is\", pis)\n",
    "#     time.sleep(1)\n",
    "\n",
    "# def reader(i,q):\n",
    "#     message = q.get()\n",
    "#     print(\"got message\", message)\n",
    "\n",
    "# for i in range(10):\n",
    "   \n",
    "#     Process(target=writer, args=()).start()\n",
    "#     time.sleep(.5)\n",
    "#    # Create multiprocessing pool\n",
    "#     p = Pool(10)\n",
    "#    # Create a group of parallel readers and start them\n",
    "#    # Number of readers is matching the number of writers\n",
    "#    # However, the number of simultaneously running\n",
    "#    # readers is constrained to the pool size\n",
    "#     readers = []\n",
    "#     for i in range(10):\n",
    "#         readers.append(p.apply_async(reader, (i,q,)))\n",
    "#     # Wait for the asynchrounous reader threads to finish\n",
    "#     [r.get() for r in readers]\n",
    "    \n",
    "    \n",
    "#     # Establish communication queues\n",
    "#     tasks = torch.multiprocessing.JoinableQueue()\n",
    "#     results = torch.multiprocessing.Queue()\n",
    "    \n",
    "#     # Start consumers\n",
    "#     num_consumers = torch.multiprocessing.cpu_count()\n",
    "#     print('Creating %d consumers' % num_consumers)\n",
    "#     consumers = [ Consumer(tasks, results)\n",
    "#                   for i in range(num_consumers) ]\n",
    "#     for w in consumers:\n",
    "#         w.start()\n",
    "    \n",
    "#     # Enqueue jobs\n",
    "#     for i in range(nEpochs):\n",
    "#         tasks.put(Task(altCountsByGene, pDs, 1, minLLThresholdCount, K, debug, costFnIdx, method))\n",
    "    \n",
    "#     # Add a poison pill for each consumer\n",
    "#     for i in range(nEpochs):\n",
    "#         tasks.put(None)\n",
    "\n",
    "#     # Wait for all of the tasks to finish\n",
    "#     tasks.join()\n",
    "    \n",
    "#     # Start printing results\n",
    "#     while nEpochs:\n",
    "#         result = results.get()\n",
    "#         print('Result:', result)\n",
    "#         num_jobs -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e0d0c7993644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msmoke_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'CI'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.3.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genData.runSim(fitMethod=\"nelder-mead\", mt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.distributions import DirichletMultinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c19e38a749ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, concentration, total_count, is_sparse, validate_args)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtotal_count_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "DirichletMultinomial(total_count=1000, concentration=[1, 1, 1, 1]).log_prob([10, 10, 10, 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0309, 0.0309, 0.0123])\n",
      "TESTING WITH: nCases tensor([10000., 10000.,  4000.]) nCtrls tensor(300000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0309, 0.0309, 0.0123]) covShared tensor([[1.0000, 0.4000, 0.4000],\n",
      "        [0.4000, 1.0000, 0.4000],\n",
      "        [0.4000, 0.4000, 1.0000]]) covSingle tensor([[1, 0],\n",
      "        [0, 1]])\n",
      "\n",
      "\n",
      "test tensor 1.0,0.4,0.4,0.4,1.0,0.4,0.4,0.4,1.0\n",
      "tensor([[2.2820, 2.3491, 5.4208],\n",
      "        [4.0392, 3.5623, 5.4373],\n",
      "        [3.7367, 2.6922, 3.8519],\n",
      "        ...,\n",
      "        [2.9129, 3.4894, 3.1099],\n",
      "        [4.3435, 2.6478, 4.8442],\n",
      "        [2.0386, 2.2731, 4.5712]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 324000\n"
     ]
    }
   ],
   "source": [
    "rrs = tensor([1.5, 1.5, 1.5])\n",
    "pis = tensor([.05, .05, .05])\n",
    "nCases = tensor([10e3, 10e3, 4e3])\n",
    "nCtrls = tensor(3e5)\n",
    "afMean = 1e-4\n",
    "rrShape=tensor(50.)\n",
    "afShape=tensor(50.)\n",
    "generatingFn =  genData.v6normal\n",
    "fitMethod = 'nelder-mead'\n",
    "nEpochs=20\n",
    "mt = True\n",
    "covShared=tensor([[1,.4,.4], [.4, 1, .4], [.4, .4, 1]])\n",
    "covSingle=tensor([[1, 0], [0, 1]])\n",
    "\n",
    "try:\n",
    "    params = genData.genParams(rrMeans=rrs, pis=pis, afMean=afMean, rrShape=rrShape, afShape=afShape, nCases=nCases, nCtrls=nCtrls)[0]\n",
    "    testData = generatingFn(**params, covShared=covShared, covSingle=covSingle)\n",
    "except Exception as e:\n",
    "    print(f\"Run failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nGenes': 20000,\n",
       " 'nCases': tensor([10000., 10000.,  4000.]),\n",
       " 'nCtrls': tensor(300000.),\n",
       " 'pDs': tensor([0.0309, 0.0309, 0.0123]),\n",
       " 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]),\n",
       " 'rrShape': tensor(50.),\n",
       " 'rrMeans': tensor([1.5000, 1.5000, 1.5000]),\n",
       " 'afShape': tensor(50.),\n",
       " 'afMean': 0.0001}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdCtrl, pd1, pd2, pdBoth:  tensor([0.9259, 0.0309, 0.0309, 0.0123], dtype=torch.float64)\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7f95ca40b8c0>\n",
      "best ll: 74790.942529128, bestParams: [0.0053168144, 0.1608949, 0.07438568, 10316.419, 16415.621, 12798.016, 22587.65]\n",
      "Epoch took 74.48648691177368\n"
     ]
    }
   ],
   "source": [
    "testFit = likelihoods.fitFnBivariate(testData[\"altCounts\"], params[\"pDs\"], nEpochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lls', 'llsAll', 'params', 'trajectoryLLs', 'trajectoryPi', 'trajectoryAlphas'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFit.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = tensor(testFit[\"trajectoryAlphas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-869cdce3ce85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestFit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbestLL\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbestLL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mbestParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mbestLL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "bestLL = None\n",
    "bestParams = None\n",
    "for x in testFit:\n",
    "    if bestLL is None or x[\"lls\"][0] < bestLL:\n",
    "        bestParams = x[\"params\"][0]\n",
    "        bestLL = x[\"lls\"][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95a90b8b10>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(testFit[\"trajectoryLLs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95aa4e1cd0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(ta[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9598410990>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(ta[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95985f71d0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(ta[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f959862b890>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(ta[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pisTraj = tensor(testFit[\"trajectoryPi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9598613750>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTraj[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9598663390>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTraj[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f959869f810>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTraj[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCounts = testData[\"altCounts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9259, 0.0309, 0.0309, 0.0123])\n"
     ]
    }
   ],
   "source": [
    "testUnaffectedGenes = testData[\"unaffectedGenes\"]\n",
    "testAffectedGenes = testData[\"affectedGenes\"]\n",
    "testAllPDs = tensor([1-params[\"pDs\"].sum(), *params[\"pDs\"]])\n",
    "print(testAllPDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0309, 0.0309, 0.0123])\n",
      "TESTING WITH: nCases tensor([10000., 10000.,  4000.]) nCtrls tensor(300000.) rrMeans tensor([5, 5, 5]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0309, 0.0309, 0.0123]) covShared tensor([[1.0000, 0.4000, 0.4000],\n",
      "        [0.4000, 1.0000, 0.4000],\n",
      "        [0.4000, 0.4000, 1.0000]]) covSingle tensor([[1, 0],\n",
      "        [0, 1]])\n",
      "\n",
      "\n",
      "test tensor 1.0,0.4,0.4,0.4,1.0,0.4,0.4,0.4,1.0\n",
      "tensor([[11.0434, 10.4541, 16.1183],\n",
      "        [ 9.1425, 10.7578, 15.2818],\n",
      "        [ 8.6147,  8.8815, 14.4847],\n",
      "        ...,\n",
      "        [10.7323,  8.9242, 14.3081],\n",
      "        [10.8891, 10.5284, 17.0868],\n",
      "        [11.6047,  9.6869, 15.2436]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 324000\n"
     ]
    }
   ],
   "source": [
    "rrsMisspecified = tensor([5, 5, 5])\n",
    "\n",
    "try:\n",
    "    params = genData.genParams(rrMeans=rrsMisspecified, pis=pis, afMean=afMean, rrShape=rrShape, afShape=afShape, nCases=nCases, nCtrls=nCtrls)[0]\n",
    "    testDataMisspecified = generatingFn(**params, covShared=covShared, covSingle=covSingle)\n",
    "except Exception as e:\n",
    "    print(f\"Run failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesFactor(n, altCount,pDs,rrMeans,rrsShape,afMeans,afShape,alpha0, alpha1, alpha2, alphaBoth):\n",
    "bfsUnaffected = []\n",
    "for unaffectedGene in testUnaffectedGenes:\n",
    "    testCount = testCounts[unaffectedGene]\n",
    "    bfsUnaffected.append(bayes.bayesFactor(testCount.sum(), testCount, testAllPDs, bestParams[0:3], bestParams[3:]))\n",
    "bfsUnaffected = tensor(bfsUnaffected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0125e-01, 8.5311e-06, 1.6218e-04,  ..., 3.2103e-04, 1.1671e-04,\n",
       "        5.6422e-03], dtype=torch.float64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfsUnaffected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 count: tensor([34.,  0.,  3.,  0.], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5028239d672c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffectedGene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"count:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maffectedGene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtestCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestCountMisspecified\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maffectedGene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbfsAffected1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbayesFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestCountMisspecified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestCountMisspecified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestAllPDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mbfsAffected1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbfsAffected1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "testCountMisspecified = testDataMisspecified[\"altCounts\"]\n",
    "\n",
    "# bayesFactor(n, altCount,pDs,rrMeans,rrsShape,afMeans,afShape,alpha0, alpha1, alpha2, alphaBoth):\n",
    "bfsAffected1 = []\n",
    "for affectedGene in testAffectedGenes[0]:\n",
    "    print(affectedGene, \"count:\", testCounts[affectedGene])\n",
    "    testCount = testCountMisspecified[affectedGene]\n",
    "    bfsAffected1.append(bayes.bayesFactor(testCountMisspecified.sum(), testCountMisspecified, testAllPDs, bestParams[0:3], bestParams[3:]))\n",
    "bfsAffected1 = tensor(bfsAffected1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfsAffected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = tensor([[1.6166e+04, 2.5759e+01, 3.6084e+01, 4.1214e+00],\n",
    "        [1.6166e+04, 8.0828e+02, 4.9681e+02, 1.9872e+02],\n",
    "        [1.6166e+04, 7.1153e+01, 6.7573e+01, 1.4933e+01]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['altCounts', 'afs', 'affectedGenes', 'unaffectedGenes', 'rrs'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testCounts.shape torch.Size([20000, 4])\n",
      "expanded torch.Size([20000, 3, 4])\n",
      "shapes: n torch.Size([20000, 3]), alphas: torch.Size([20000, 3, 4]) counts: torch.Size([20000, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "n = testCounts.sum(1).expand(3, len(testCounts)).T\n",
    "alphas = tensor([1.77041095e+02,\n",
    "       4.05096749e+02, 3.78310762e+02, 4.93211627e+02])\n",
    "a0 = alphas[0]\n",
    "a1 = alphas[1]\n",
    "a2 = alphas[2]\n",
    "a3 = alphas[3]\n",
    "alphas2 = testAllPDs * tensor([[a0,a1,a0,a1], [a0,a0,a1,a1], [a0, a1+a3, a2+a3, a1+a2+a3]])\n",
    "alphas2 = alphas2.expand(20_000, 3, 4)\n",
    "print(\"testCounts.shape\",testCounts.shape)\n",
    "testCounts2 = testCounts.expand(3, 20_000, 4).transpose(0,1)\n",
    "print(\"expanded\", testCounts.expand(3, 20_000, 4).transpose(0,1).shape)\n",
    "print(f\"shapes: n {n.shape}, alphas: {alphas2.shape} counts: {testCounts2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([20000, 3, 1]) torch.Size([20000, 3, 4])\n",
      "past\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.6811,  -7.6378,  -7.5507],\n",
       "        [ -9.4881, -13.3662,  -7.5881],\n",
       "        [ -8.8253,  -7.5478,  -5.7675],\n",
       "        ...,\n",
       "        [ -3.8760,  -5.3455,  -9.6926],\n",
       "        [ -5.9153,  -4.3251, -12.1820],\n",
       "        [ -3.7168,  -5.1863,  -8.7299]], dtype=torch.float64)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyro.distributions import DirichletMultinomial\n",
    "#. this output is: nGenes by nHypotheses; 1 hypothesis per column\n",
    "t = DirichletMultinomial(total_count = n, concentration=alphas2).log_prob(testCounts2)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.5507, dtype=torch.float64)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([34., 34., 34.], dtype=torch.float64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 genes, 3 hypothesis\n",
    "nt = tensor([1,1,1,1]).expand(3,4).T\n",
    "nt\n",
    "n.expand(3, len(n)).T[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([3, 1]) torch.Size([3, 4])\n",
      "past\n",
      "torch.Size([20000, 3, 4])\n",
      "shapes torch.Size([3, 1]) torch.Size([3, 4])\n",
      "past\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-4.2950, -2.3979, -3.3142],\n",
       "        [-3.1964, -3.0910, -3.0910],\n",
       "        [-2.9087, -1.9924, -2.3979],\n",
       "        ...,\n",
       "        [-1.9924, -3.0910, -4.7005],\n",
       "        [-3.1964, -2.2156, -1.9924],\n",
       "        [-2.3979, -2.2156, -3.0910]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = DirichletMultinomial(total_count=tensor([3., 3, 3.]),concentration=tensor([[1.,2.,3,4],[1.,2,3,4],[1.,2,3,4]])).sample([20_000])\n",
    "\n",
    "# total_count is hypotheses by 1 , concentration is hypotheses by sampleCategories, output is nGenes by hypotheses by sampleCategories\n",
    "r.shape\n",
    "\n",
    "print(r.shape)\n",
    "\n",
    "# the sample shape is compatible with log_prob\n",
    "DirichletMultinomial(total_count=tensor([3., 3, 3.]),concentration=tensor([[1.,2.,3,4],[1.,2,3,4],[1.,2,3,4]])).log_prob(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mis_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Compound distribution comprising of a dirichlet-multinomial pair. The probability of\n",
       "classes (``probs`` for the :class:`~pyro.distributions.Multinomial` distribution)\n",
       "is unknown and randomly drawn from a :class:`~pyro.distributions.Dirichlet`\n",
       "distribution prior to a certain number of Categorical trials given by\n",
       "``total_count``.\n",
       "\n",
       ":param float or torch.Tensor concentration: concentration parameter (alpha) for the\n",
       "    Dirichlet distribution.\n",
       ":param int or torch.Tensor total_count: number of Categorical trials.\n",
       ":param bool is_sparse: Whether to assume value is mostly zero when computing\n",
       "    :meth:`log_prob`, which can speed up computation when data is sparse.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihoodBivariateFast(altCountsFlat, pDs, trajectoryPis, trajectoryAlphas, trajectoryLLs):\n",
    "    nGenes = altCountsByGene.shape[0]\n",
    "\n",
    "    # nGenes x 4\n",
    "    xCtrl = altCountsFlat[:, 0]\n",
    "    xCase1 = altCountsFlat[:, 1]\n",
    "    xCase2 = altCountsFlat[:, 2]\n",
    "    xCase12 = altCountsFlat[:, 3]\n",
    "    # nGenes x 1\n",
    "    n = xCtrl + xCase1 + xCase2 + xCase12\n",
    "\n",
    "    pd1 = pDs[0]\n",
    "    pd2 = pDs[1]\n",
    "    pdBoth = pDs[2]\n",
    "    pdCtrl = 1 - pDs.sum()\n",
    "\n",
    "    pDsAll = tensor([pdCtrl, pd1, pd2, pdBoth], dtype=torch.float64)\n",
    "    \n",
    "    print(\"pdCtrl, pd1, pd2, pdBoth: \", pDsAll)\n",
    "\n",
    "    allNull2 = nullLikelihood(pDsAll, altCountsFlat)\n",
    "    allNull2Log = torch.log(allNull2)\n",
    "\n",
    "    # TODO: make this flexible for multivariate\n",
    "    nConditions = 4\n",
    "    nHypothesesNonNull = 3\n",
    "\n",
    "    altCountsShaped = altCountsFlat.expand(nHypothesesNonNull, nGenes, nConditions).transpose(0, 1)\n",
    "    nShaped = n.expand(nHypothesesNonNull, nGenes).T\n",
    "    pdsAllShaped = pDsAll.expand(nHypothesesNonNull, nConditions)\n",
    "    def jointLikelihood(params):\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "\n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "\n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "\n",
    "        h0 = pi0 * allNull2\n",
    "\n",
    "        trajectoryPis.append([pi1, pi2, piBoth])\n",
    "        trajectoryAlphas.append([alpha0, alpha1, alpha2, alphaBoth])\n",
    "\n",
    "        concentrations = pdsAllShaped * tensor([\n",
    "            [alpha0, alpha1, alpha0, alpha1],\n",
    "            [alpha0, alpha0, alpha2, alpha2],\n",
    "            [alpha0, alpha1 + alphaBoth, alpha2 + alphaBoth, alpha1 + alpha2 + alphaBoth]\n",
    "        ]).expand(nGenes, nHypothesesNonNull, nConditions)\n",
    "        \n",
    "        hs = tensor([[pi1, pi2, piBoth]]) * torch.exp(DirichletMultinomial(total_count=nShaped, concentration=concentrations).log_prob(altCountsShaped))\n",
    "\n",
    "        ll = -torch.log(h0 + hs.sum(1)).sum()\n",
    "        trajectoryLLs.append(ll)\n",
    "        return ll\n",
    "    return jointLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
