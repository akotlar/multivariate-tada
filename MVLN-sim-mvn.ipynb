{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyro\n",
    "# import torch\n",
    "# import torch.tensor as tensor\n",
    "# import pyro.distributions as dist\n",
    "# # from torch.distributions import Binomial, Gamma, Uniform\n",
    "# from pyro.distributions import Binomial, Bernoulli, Categorical, Dirichlet, DirichletMultinomial, Beta, BetaBinomial, Uniform, Gamma, Multinomial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from skopt import gp_minimize \n",
    "from scipy.stats import binom as ScipyBinom\n",
    "from matplotlib import pyplot\n",
    "from torch import tensor\n",
    "\n",
    "from collections import namedtuple\n",
    "import time\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvl import genData, likelihoods, bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([2.0000, 2.0000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[4.3519, 2.7890, 5.5548],\n",
      "        [2.8917, 4.4436, 5.2706],\n",
      "        [3.8678, 4.4712, 5.3107],\n",
      "        ...,\n",
      "        [4.7168, 4.2715, 6.7835],\n",
      "        [4.6791, 3.9330, 4.3859],\n",
      "        [2.6210, 1.9142, 4.4797]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.120481967926025\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[39., 10.,  0.,  3.],\n",
      "        [42.,  3.,  2.,  1.],\n",
      "        [50.,  3.,  2.,  0.],\n",
      "        ...,\n",
      "        [45.,  3.,  5.,  0.],\n",
      "        [60.,  0.,  1.,  2.],\n",
      "        [40.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "n tensor([52., 48., 55.,  ..., 53., 63., 42.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([10.,  3.,  3.,  ...,  3.,  0.,  1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 2.,  ..., 5., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 0.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[39., 10.,  0.,  3.],\n",
      "        [42.,  3.,  2.,  1.],\n",
      "        [50.,  3.,  2.,  0.],\n",
      "        ...,\n",
      "        [45.,  3.,  5.,  0.],\n",
      "        [60.,  0.,  1.,  2.],\n",
      "        [40.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([4.9863e-09, 7.6293e-03, 1.8464e-02,  ..., 8.1738e-04, 6.4453e-03,\n",
      "        3.3431e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8ac3320>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91056.366085773, bestParams: [0.021506596, 0.032269087, 0.032386456, 7456.216, 13592.753, 24910.842, 18917.502]\n",
      "epoch 0\n",
      "     fun: 90678.94727806201\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18988\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.49893948e-02, 4.43790738e-02, 4.08915328e-02, 8.60818913e+03,\n",
      "       2.44622045e+04, 2.48735515e+04, 2.14801207e+04])\n",
      "best ll: 91026.39509861523, bestParams: [0.11172657, 0.090561226, 0.053274393, 6340.836, 12428.718, 19741.955, 19129.791]\n",
      "epoch 1\n",
      "     fun: 90680.17847220492\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18535\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.87069860e-02, 4.87180474e-02, 4.18491463e-02, 9.10768397e+03,\n",
      "       2.46671325e+04, 2.48377120e+04, 2.38725486e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90935.85000957745, bestParams: [0.049423933, 0.009214227, 0.066587955, 8144.4087, 14092.45, 19146.107, 19184.744]\n",
      "epoch 2\n",
      "     fun: 90679.69408391253\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24517\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.51746074e-02, 4.28823114e-02, 4.09115182e-02, 8.49052334e+03,\n",
      "       2.41057989e+04, 2.49310807e+04, 2.09977006e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90968.04260795636, bestParams: [0.04376411, 0.00947107, 0.026495688, 2897.8872, 12433.758, 12579.159, 2175.1257]\n",
      "epoch 3\n",
      "     fun: 90682.20345662584\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21464\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.62273012e-02, 4.13341282e-02, 4.08307518e-02, 7.30724926e+03,\n",
      "       2.05368423e+04, 2.18005268e+04, 1.80006693e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 91230.94646826506, bestParams: [0.027580375, 0.03263207, 0.086327404, 9526.828, 13395.509, 20715.258, 16864.232]\n",
      "epoch 4\n",
      "     fun: 90680.42392596879\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21184\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93687837e-02, 4.50462777e-02, 4.14165165e-02, 8.13320033e+03,\n",
      "       2.20223509e+04, 2.30949390e+04, 2.09459093e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90891.22837955202, bestParams: [0.022499898, 0.05500002, 0.05387609, 7606.9336, 16116.186, 22950.53, 17725.414]\n",
      "epoch 5\n",
      "     fun: 91005.564852588\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19023\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.05560857e-01, 2.51295019e-02, 6.86739003e-02, 1.10150214e+04,\n",
      "       1.19546860e+04, 2.49755966e+04, 2.49999999e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90793.50734448066, bestParams: [0.04312596, 0.061409917, 0.055109084, 7393.3057, 17826.643, 19793.965, 14590.254]\n",
      "epoch 6\n",
      "     fun: 90682.98088077307\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29244\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.58835926e-02, 4.48804886e-02, 4.12324058e-02, 7.13580347e+03,\n",
      "       1.99591999e+04, 2.03665212e+04, 1.80069887e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90774.11209833511, bestParams: [0.029333118, 0.048051648, 0.034722798, 7021.4785, 19031.883, 23899.84, 18605.693]\n",
      "epoch 7\n",
      "     fun: 90677.6685678917\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18468\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.81858369e-02, 4.78172584e-02, 4.15692111e-02, 8.98392723e+03,\n",
      "       2.45434465e+04, 2.48292644e+04, 2.33467772e+04])\n",
      "minPrevious 90678.94727806201\n",
      "better by at >= 1; new ll:      fun: 90677.6685678917\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18468\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.81858369e-02, 4.78172584e-02, 4.15692111e-02, 8.98392723e+03,\n",
      "       2.45434465e+04, 2.48292644e+04, 2.33467772e+04])\n",
      "best ll: 90875.25550642482, bestParams: [0.052991223, 0.082086444, 0.03636626, 6475.547, 23251.305, 18497.258, 20307.602]\n",
      "epoch 8\n",
      "     fun: 90682.68245423601\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23101\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.50358851e-02, 4.28777768e-02, 4.09910386e-02, 4.24521045e+03,\n",
      "       1.20207836e+04, 1.24023136e+04, 1.05078487e+04])\n",
      "minPrevious 90677.6685678917\n",
      "best ll: 91548.96528524201, bestParams: [0.10768495, 0.22162051, 0.123172745, 3700.1165, 5095.398, 5719.5654, 14934.215]\n",
      "epoch 9\n",
      "     fun: 90684.1404879048\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18986\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.07374035e-02, 5.12185329e-02, 4.29776595e-02, 9.51878104e+03,\n",
      "       2.49567942e+04, 2.49907370e+04, 2.49999993e+04])\n",
      "minPrevious 90677.6685678917\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0482, 0.0478, 0.0416], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8889, 0.0632, 0.0281, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8732, 0.0716, 0.0262, 0.0290], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8816, 0.0280, 0.0648, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8726, 0.0261, 0.0723, 0.0289], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7458, 0.0981, 0.0993, 0.0618], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7052, 0.1128, 0.1135, 0.0685], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4189, 2.2110, 5.3853],\n",
      "        [2.8835, 1.5863, 4.1315],\n",
      "        [3.3437, 2.7164, 3.9165],\n",
      "        ...,\n",
      "        [3.8215, 3.8713, 6.7122],\n",
      "        [2.9858, 2.3850, 5.4729],\n",
      "        [3.9595, 3.6556, 5.0114]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.392677068710327\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[51.,  1.,  1.,  0.],\n",
      "        [49.,  6.,  3.,  0.],\n",
      "        [51.,  3.,  4.,  2.],\n",
      "        ...,\n",
      "        [52.,  1.,  2.,  0.],\n",
      "        [40.,  2.,  1.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 58., 60.,  ..., 55., 43., 45.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 3.,  ..., 1., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 4.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 2.,  ..., 0., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[51.,  1.,  1.,  0.],\n",
      "        [49.,  6.,  3.,  0.],\n",
      "        [51.,  3.,  4.,  2.],\n",
      "        ...,\n",
      "        [52.,  1.,  2.,  0.],\n",
      "        [40.,  2.,  1.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0623, 0.0003, 0.0009,  ..., 0.0464, 0.0503, 0.0438],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc680>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91239.19500249799, bestParams: [0.07369001, 0.04880978, 0.06687576, 4858.3516, 16533.74, 12923.512, 14745.741]\n",
      "epoch 0\n",
      "     fun: 90861.78577540864\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 28688\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.39126641e-02, 4.43361706e-02, 4.16877774e-02, 6.30811938e+03,\n",
      "       1.80875402e+04, 1.85093776e+04, 1.54715766e+04])\n",
      "best ll: 91471.4697084639, bestParams: [0.015408821, 0.025966937, 0.018776404, 6470.502, 16699.875, 22305.629, 7609.0425]\n",
      "epoch 1\n",
      "     fun: 90860.74902260769\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21083\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.31587597e-02, 4.55204559e-02, 4.21324394e-02, 8.65442240e+03,\n",
      "       2.47671562e+04, 2.49529431e+04, 2.13176385e+04])\n",
      "minPrevious 90861.78577540864\n",
      "better by at >= 1; new ll:      fun: 90860.74902260769\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21083\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.31587597e-02, 4.55204559e-02, 4.21324394e-02, 8.65442240e+03,\n",
      "       2.47671562e+04, 2.49529431e+04, 2.13176385e+04])\n",
      "best ll: 91429.35879988143, bestParams: [0.036266495, 0.03656501, 0.00981962, 4553.329, 23323.432, 16778.275, 3984.7922]\n",
      "epoch 2\n",
      "     fun: 90860.63394312932\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18826\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97057539e-02, 4.15170068e-02, 4.13327845e-02, 6.41557828e+03,\n",
      "       1.93464752e+04, 1.95896200e+04, 1.48570035e+04])\n",
      "minPrevious 90860.74902260769\n",
      "best ll: 91222.69810706898, bestParams: [0.03356081, 0.050940458, 0.040049728, 7300.6055, 11934.092, 23776.432, 21303.281]\n",
      "epoch 3\n",
      "     fun: 90859.43670833748\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22341\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56721447e-02, 4.79972960e-02, 4.25334885e-02, 8.95537658e+03,\n",
      "       2.48353903e+04, 2.49872164e+04, 2.28056060e+04])\n",
      "minPrevious 90860.74902260769\n",
      "better by at >= 1; new ll:      fun: 90859.43670833748\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22341\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56721447e-02, 4.79972960e-02, 4.25334885e-02, 8.95537658e+03,\n",
      "       2.48353903e+04, 2.49872164e+04, 2.28056060e+04])\n",
      "best ll: 91364.8767937252, bestParams: [0.22571534, 0.056864273, 0.07466884, 3741.4695, 6438.2812, 5871.1465, 15020.482]\n",
      "epoch 4\n",
      "     fun: 90860.23925054408\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22079\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.20028461e-02, 4.19424135e-02, 4.15822628e-02, 5.57662948e+03,\n",
      "       1.63079514e+04, 1.68432533e+04, 1.32242383e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91071.14442199793, bestParams: [0.09720786, 0.055112377, 0.06380207, 4636.733, 11534.753, 14002.477, 10913.797]\n",
      "epoch 5\n",
      "     fun: 90860.33036181553\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24815\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.16976590e-02, 4.24385731e-02, 4.17443828e-02, 4.79041325e+03,\n",
      "       1.40148252e+04, 1.43427167e+04, 1.13953899e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91144.26979706812, bestParams: [0.08022128, 0.08162482, 0.048925202, 8952.077, 16154.056, 24275.29, 19940.611]\n",
      "epoch 6\n",
      "     fun: 90858.7804887991\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16708\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.20979808e-02, 4.37486171e-02, 4.17546498e-02, 8.45101922e+03,\n",
      "       2.46176087e+04, 2.49695229e+04, 2.03637448e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91115.36426809937, bestParams: [0.05724043, 0.021042777, 0.07642279, 6261.3833, 16376.353, 23784.773, 8266.063]\n",
      "epoch 7\n",
      "     fun: 90859.69647791091\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19043\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.34963888e-02, 4.37891214e-02, 4.20289844e-02, 8.15363124e+03,\n",
      "       2.33686949e+04, 2.39683522e+04, 1.98420756e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91651.64624185565, bestParams: [0.046107255, 0.09424183, 0.00989835, 2757.5513, 14618.052, 10251.086, 9000.875]\n",
      "epoch 8\n",
      "     fun: 90859.06008520466\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20575\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44481442e-02, 4.75969522e-02, 4.21778176e-02, 8.81335975e+03,\n",
      "       2.48539057e+04, 2.48395582e+04, 2.23569747e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91065.11635174009, bestParams: [0.0242683, 0.053031314, 0.058199123, 5144.2104, 20661.969, 15971.761, 13266.957]\n",
      "epoch 9\n",
      "     fun: 90861.08577821162\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20001\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.19851050e-02, 4.17801837e-02, 4.15084630e-02, 7.28268698e+03,\n",
      "       2.13122623e+04, 2.20660360e+04, 1.72448063e+04])\n",
      "minPrevious 90859.43670833748\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0457, 0.0480, 0.0425], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8782, 0.0624, 0.0278, 0.0249], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8721, 0.0725, 0.0262, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8817, 0.0280, 0.0644, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8718, 0.0261, 0.0729, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7358, 0.0987, 0.0983, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7057, 0.1127, 0.1130, 0.0687], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.9071, 4.0096, 5.7722],\n",
      "        [3.1442, 3.7642, 4.7613],\n",
      "        [1.9910, 3.6197, 4.2653],\n",
      "        ...,\n",
      "        [2.0181, 4.2217, 4.7949],\n",
      "        [2.6019, 2.7535, 6.2110],\n",
      "        [2.9164, 2.6361, 4.6614]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.5227882862091064\n",
      "Run: 0, 2\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[27.,  4.,  2.,  2.],\n",
      "        [48.,  1.,  1.,  0.],\n",
      "        [41.,  2.,  1.,  3.],\n",
      "        ...,\n",
      "        [48.,  3.,  0.,  1.],\n",
      "        [49.,  2.,  3.,  1.],\n",
      "        [37.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([35., 50., 47.,  ..., 52., 55., 39.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 1., 2.,  ..., 3., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 0., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 3.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[27.,  4.,  2.,  2.],\n",
      "        [48.,  1.,  1.,  0.],\n",
      "        [41.,  2.,  1.,  3.],\n",
      "        ...,\n",
      "        [48.,  3.,  0.,  1.],\n",
      "        [49.,  2.,  3.,  1.],\n",
      "        [37.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([9.1044e-05, 6.8182e-02, 1.1450e-03,  ..., 9.4407e-03, 1.1078e-02,\n",
      "        8.8612e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc290>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91007.93332294546, bestParams: [0.0857708, 0.027353209, 0.056023873, 8389.133, 21786.912, 16894.488, 17575.045]\n",
      "epoch 0\n",
      "     fun: 90741.29185131165\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16482\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.23376169e-02, 4.93065527e-02, 4.38559895e-02, 9.47084934e+03,\n",
      "       2.48940172e+04, 2.48822170e+04, 2.49999981e+04])\n",
      "best ll: 91224.73436774276, bestParams: [0.043282628, 0.04283247, 0.015615053, 3965.399, 15119.752, 11289.01, 20118.45]\n",
      "epoch 1\n",
      "     fun: 90968.17657566987\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 39572\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.99538244e-02, 2.93838522e-01, 5.58080675e-02, 5.08857742e+03,\n",
      "       9.48498524e+03, 6.15838872e+03, 1.74503829e+04])\n",
      "minPrevious 90741.29185131165\n",
      "best ll: 90881.52796996137, bestParams: [0.057814863, 0.036603197, 0.048284452, 6125.3677, 14977.148, 11782.217, 16754.512]\n",
      "epoch 2\n",
      "     fun: 90729.455342717\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19418\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.65090442e-02, 4.45915397e-02, 4.23747175e-02, 8.80405812e+03,\n",
      "       2.49621024e+04, 2.48324605e+04, 2.18698763e+04])\n",
      "minPrevious 90741.29185131165\n",
      "better by at >= 1; new ll:      fun: 90729.455342717\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19418\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.65090442e-02, 4.45915397e-02, 4.23747175e-02, 8.80405812e+03,\n",
      "       2.49621024e+04, 2.48324605e+04, 2.18698763e+04])\n",
      "best ll: 91326.07627551297, bestParams: [0.095849864, 0.09590016, 0.092939384, 7666.34, 6450.7437, 15030.143, 23817.498]\n",
      "epoch 3\n",
      "     fun: 90729.30744291696\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22517\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.37379352e-02, 4.05152351e-02, 4.17252985e-02, 8.39802978e+03,\n",
      "       2.47668799e+04, 2.49916565e+04, 1.98267634e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91016.03464464155, bestParams: [0.06892339, 0.08220619, 0.041249212, 10588.921, 24391.959, 19792.424, 22084.648]\n",
      "epoch 4\n",
      "     fun: 90959.0438262211\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19051\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.16422571e-02, 8.50540140e-01, 5.78171661e-02, 5.56689535e+03,\n",
      "       9.72820890e+03, 5.85802465e+03, 1.96208622e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91027.85668282304, bestParams: [0.03505238, 0.044490505, 0.027420068, 6133.5425, 23373.82, 13148.674, 14960.702]\n",
      "epoch 5\n",
      "     fun: 90735.7505212659\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18858\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.04506841e-02, 4.75836595e-02, 4.31450513e-02, 9.25332768e+03,\n",
      "       2.49542178e+04, 2.49510328e+04, 2.40224887e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91344.33768614761, bestParams: [0.053518336, 0.08740302, 0.067629404, 6031.661, 18487.89, 9499.573, 9493.0]\n",
      "epoch 6\n",
      "     fun: 90742.86427037211\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 15856\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.25172955e-02, 4.97425219e-02, 4.43748053e-02, 9.57142437e+03,\n",
      "       2.49836514e+04, 2.48985330e+04, 2.49999996e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91210.99558153439, bestParams: [0.015522353, 0.020422507, 0.02180805, 5947.9175, 24499.941, 23246.885, 23200.797]\n",
      "epoch 7\n",
      "     fun: 90731.14997350496\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23205\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.28252218e-02, 3.99237022e-02, 4.15478607e-02, 6.40159151e+03,\n",
      "       1.90431847e+04, 1.92309877e+04, 1.49437001e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91095.22483766638, bestParams: [0.07067214, 0.03771307, 0.054919243, 6992.266, 20875.805, 19603.213, 6386.5703]\n",
      "epoch 8\n",
      "     fun: 90730.85085085777\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20929\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.53289295e-02, 4.27071902e-02, 4.20085505e-02, 8.40268795e+03,\n",
      "       2.42169186e+04, 2.42700284e+04, 2.04402196e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91393.03288045904, bestParams: [0.017872097, 0.053617258, 0.039089, 1954.1438, 5562.4053, 1457.8615, 7767.6426]\n",
      "epoch 9\n",
      "     fun: 90733.01401258064\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 31233\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.60272951e-02, 4.06109139e-02, 4.20647643e-02, 6.14139763e+03,\n",
      "       1.75751538e+04, 1.81183570e+04, 1.47902926e+04])\n",
      "minPrevious 90729.455342717\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0465, 0.0446, 0.0424], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8839, 0.0639, 0.0280, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8704, 0.0741, 0.0261, 0.0295], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8829, 0.0280, 0.0636, 0.0254], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8708, 0.0261, 0.0737, 0.0295], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7400, 0.0995, 0.0966, 0.0611], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7060, 0.1126, 0.1124, 0.0690], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.8960, 3.3836, 5.0518],\n",
      "        [3.8514, 4.7767, 6.8971],\n",
      "        [4.0691, 2.5010, 4.6004],\n",
      "        ...,\n",
      "        [4.4449, 3.2959, 3.9365],\n",
      "        [4.3674, 3.9315, 8.1608],\n",
      "        [3.6398, 2.5625, 7.4278]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.356298923492432\n",
      "Run: 0, 3\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[48.,  2.,  1.,  0.],\n",
      "        [41.,  3.,  2.,  2.],\n",
      "        [55.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [58.,  2.,  2.,  1.],\n",
      "        [48.,  2.,  0.,  0.],\n",
      "        [35.,  2.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([51., 48., 59.,  ..., 63., 50., 39.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 3.,  ..., 2., 2., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 0.,  ..., 2., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 1.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[48.,  2.,  1.,  0.],\n",
      "        [41.,  3.,  2.,  2.],\n",
      "        [55.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [58.,  2.,  2.,  1.],\n",
      "        [48.,  2.,  0.,  0.],\n",
      "        [35.,  2.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0487, 0.0019, 0.0098,  ..., 0.0257, 0.0341, 0.0266],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad03b00>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91021.23597877396, bestParams: [0.02387655, 0.09362935, 0.0531731, 8440.324, 13937.0, 11477.793, 16246.775]\n",
      "epoch 0\n",
      "     fun: 90367.46646443212\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18738\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.85798503e-02, 3.12189972e-02, 4.14406663e-02, 7.79360605e+03,\n",
      "       2.38725780e+04, 2.46992225e+04, 1.68480061e+04])\n",
      "best ll: 90814.01155907288, bestParams: [0.092853814, 0.079595976, 0.09696471, 9648.206, 12964.165, 13710.112, 22609.943]\n",
      "epoch 1\n",
      "     fun: 90370.16992066184\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20256\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.06782851e-02, 3.05888247e-02, 4.18256058e-02, 3.30614673e+03,\n",
      "       9.80870940e+03, 1.04315332e+04, 7.28013746e+03])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90693.35079318719, bestParams: [0.05039767, 0.07389942, 0.05925788, 5015.5117, 11736.682, 7729.9805, 10372.028]\n",
      "epoch 2\n",
      "     fun: 90544.51615211637\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26660\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([1.15173636e-01, 8.27076011e-01, 5.75481400e-02, 4.88184316e+03,\n",
      "       7.22753220e+03, 5.23483166e+03, 1.76610229e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90928.8394107176, bestParams: [0.08049662, 0.08387433, 0.06717268, 7118.226, 9401.673, 19610.592, 16397.375]\n",
      "epoch 3\n",
      "     fun: 90369.26401926341\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27176\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.55837197e-02, 3.36905447e-02, 4.29108512e-02, 6.71586563e+03,\n",
      "       1.85568972e+04, 1.98110040e+04, 1.60601036e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90849.15617868747, bestParams: [0.041133363, 0.06851273, 0.07244423, 6477.3115, 20420.096, 20529.924, 4543.0527]\n",
      "epoch 4\n",
      "     fun: 90369.74538215327\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 25662\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.46136940e-02, 3.52382008e-02, 4.29644138e-02, 7.05933251e+03,\n",
      "       1.96641948e+04, 2.05584337e+04, 1.69372313e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 91003.55947153617, bestParams: [0.020014536, 0.16380043, 0.05750044, 6207.0884, 6395.382, 14223.492, 21751.719]\n",
      "epoch 5\n",
      "     fun: 90366.05074559979\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19246\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44379285e-02, 3.86546502e-02, 4.30928573e-02, 8.90523070e+03,\n",
      "       2.47945943e+04, 2.48658296e+04, 2.19264077e+04])\n",
      "minPrevious 90367.46646443212\n",
      "better by at >= 1; new ll:      fun: 90366.05074559979\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19246\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44379285e-02, 3.86546502e-02, 4.30928573e-02, 8.90523070e+03,\n",
      "       2.47945943e+04, 2.48658296e+04, 2.19264077e+04])\n",
      "best ll: 90749.3357777144, bestParams: [0.054987807, 0.042462654, 0.019732246, 3481.5046, 8180.3594, 12040.532, 16030.645]\n",
      "epoch 6\n",
      "     fun: 90370.04277355093\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19775\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13956855e-02, 2.99751012e-02, 4.19297763e-02, 3.18547370e+03,\n",
      "       9.37089224e+03, 1.01267621e+04, 6.99713684e+03])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90595.93835730849, bestParams: [0.049502358, 0.05059789, 0.035600856, 5736.8604, 11006.914, 12817.075, 13380.541]\n",
      "epoch 7\n",
      "     fun: 90369.03492576667\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29654\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.43124944e-02, 3.33712831e-02, 4.27940979e-02, 6.64796216e+03,\n",
      "       1.85760876e+04, 1.98131480e+04, 1.58021285e+04])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90746.22974235666, bestParams: [0.111383274, 0.080073506, 0.042195205, 10159.44, 15388.807, 19346.172, 23211.58]\n",
      "epoch 8\n",
      "     fun: 90366.30277732995\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19017\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.62580895e-02, 3.77157167e-02, 4.32366444e-02, 8.81877383e+03,\n",
      "       2.40797226e+04, 2.47941350e+04, 2.18330276e+04])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90855.43160734844, bestParams: [0.07542367, 0.05570492, 0.015105497, 9331.249, 23335.158, 21321.234, 19561.578]\n",
      "epoch 9\n",
      "     fun: 90554.8816047398\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19215\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.37802480e-01, 6.55243135e-02, 5.54580874e-02, 5.84354058e+03,\n",
      "       6.36484808e+03, 1.06079831e+04, 2.04911301e+04])\n",
      "minPrevious 90366.05074559979\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0444, 0.0387, 0.0431], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8801, 0.0644, 0.0279, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8718, 0.0728, 0.0261, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8782, 0.0278, 0.0636, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8716, 0.0262, 0.0730, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7428, 0.0992, 0.0988, 0.0623], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7085, 0.1115, 0.1117, 0.0683], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7070, 3.3558, 5.7385],\n",
      "        [6.1712, 4.8968, 6.0728],\n",
      "        [5.5908, 6.0105, 9.0300],\n",
      "        ...,\n",
      "        [3.5412, 2.9084, 6.2405],\n",
      "        [4.0371, 3.8411, 6.2719],\n",
      "        [4.3172, 3.5554, 6.5065]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.310091972351074\n",
      "Run: 0, 4\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[46.,  3.,  2.,  2.],\n",
      "        [45.,  3.,  0.,  3.],\n",
      "        [54.,  5.,  1.,  4.],\n",
      "        ...,\n",
      "        [48.,  1.,  0.,  0.],\n",
      "        [40.,  2.,  1.,  1.],\n",
      "        [40.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 51., 64.,  ..., 49., 44., 42.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 5.,  ..., 1., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 1.,  ..., 0., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 4.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[46.,  3.,  2.,  2.],\n",
      "        [45.,  3.,  0.,  3.],\n",
      "        [54.,  5.,  1.,  4.],\n",
      "        ...,\n",
      "        [48.,  1.,  0.,  0.],\n",
      "        [40.,  2.,  1.,  1.],\n",
      "        [40.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.8431e-03, 4.8473e-04, 3.3705e-05,  ..., 4.8727e-02, 2.4768e-02,\n",
      "        8.3579e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc950>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91345.08023811383, bestParams: [0.06884586, 0.015770206, 0.08335171, 3087.4746, 10631.862, 13740.989, 2484.048]\n",
      "epoch 0\n",
      "     fun: 90879.9946159658\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23081\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.24280571e-02, 4.00968936e-02, 3.89581658e-02, 6.72886260e+03,\n",
      "       2.08850194e+04, 2.07802951e+04, 1.66012855e+04])\n",
      "best ll: 90987.4655751705, bestParams: [0.028817432, 0.02610038, 0.034790974, 7775.3364, 23897.207, 21864.736, 15247.122]\n",
      "epoch 1\n",
      "     fun: 90879.06292379234\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19756\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.14930094e-02, 3.82729929e-02, 3.86535609e-02, 7.50684449e+03,\n",
      "       2.37203578e+04, 2.38252110e+04, 1.80371150e+04])\n",
      "minPrevious 90879.9946159658\n",
      "best ll: 91464.60088640705, bestParams: [0.07165316, 0.0929115, 0.01606413, 4874.1367, 14892.382, 17925.348, 7632.4253]\n",
      "epoch 2\n",
      "     fun: 90879.14375478897\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27109\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.03898485e-02, 3.80772820e-02, 3.84634180e-02, 6.62194224e+03,\n",
      "       2.12415051e+04, 2.11538949e+04, 1.57061265e+04])\n",
      "minPrevious 90879.9946159658\n",
      "best ll: 91336.19074409138, bestParams: [0.029090187, 0.039958116, 0.025319178, 4308.908, 9381.063, 14304.205, 7759.76]\n",
      "epoch 3\n",
      "     fun: 90878.55891398477\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20515\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.09047276e-02, 3.79882333e-02, 3.86226516e-02, 5.33505945e+03,\n",
      "       1.69919902e+04, 1.70332626e+04, 1.26987930e+04])\n",
      "minPrevious 90879.9946159658\n",
      "better by at >= 1; new ll:      fun: 90878.55891398477\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20515\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.09047276e-02, 3.79882333e-02, 3.86226516e-02, 5.33505945e+03,\n",
      "       1.69919902e+04, 1.70332626e+04, 1.26987930e+04])\n",
      "best ll: 91335.93185690074, bestParams: [0.035876945, 0.06610922, 0.025485078, 4390.421, 22124.35, 10895.839, 7541.019]\n",
      "epoch 4\n",
      "     fun: 90880.92135410193\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 17484\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.59090218e-02, 4.33322652e-02, 3.96535940e-02, 8.43861685e+03,\n",
      "       2.49337275e+04, 2.48150587e+04, 2.19508901e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91250.95231934264, bestParams: [0.115218244, 0.048142098, 0.051294174, 6320.828, 14317.023, 12362.9, 13260.78]\n",
      "epoch 5\n",
      "     fun: 90878.97808052332\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19609\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.07574831e-02, 3.74625089e-02, 3.83613486e-02, 6.68112794e+03,\n",
      "       2.13446230e+04, 2.15390941e+04, 1.58039078e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91213.35925044058, bestParams: [0.15606245, 0.072391056, 0.046264574, 6354.5464, 13673.771, 19265.758, 22482.443]\n",
      "epoch 6\n",
      "     fun: 90883.28559989628\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19491\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93288901e-02, 4.60300073e-02, 4.03575042e-02, 8.80576916e+03,\n",
      "       2.49172318e+04, 2.48990628e+04, 2.38112812e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91046.46063479605, bestParams: [0.03268646, 0.011289387, 0.026305977, 6561.8726, 20767.113, 23554.947, 11815.014]\n",
      "epoch 7\n",
      "     fun: 90881.05394528931\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18450\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26334934e-02, 3.93476535e-02, 3.90612840e-02, 2.50669000e+03,\n",
      "       7.75529940e+03, 7.77798697e+03, 6.15010134e+03])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91213.77202473817, bestParams: [0.12363709, 0.07303361, 0.03884344, 5911.851, 10551.361, 9712.845, 17378.764]\n",
      "epoch 8\n",
      "     fun: 90879.20283692765\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19674\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.23063429e-02, 3.91398095e-02, 3.88485271e-02, 6.98045708e+03,\n",
      "       2.17313652e+04, 2.18296056e+04, 1.70652713e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91373.61481849875, bestParams: [0.119453534, 0.015104396, 0.048940077, 3980.3694, 9912.681, 20019.787, 4480.772]\n",
      "epoch 9\n",
      "     fun: 90964.70890373456\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16833\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.88640777e-02, 5.48396144e-02, 4.41396663e-02, 7.52303449e+03,\n",
      "       1.61309726e+04, 1.82623724e+04, 2.37081847e+04])\n",
      "minPrevious 90878.55891398477\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0409, 0.0380, 0.0386], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8845, 0.0643, 0.0281, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8593, 0.0821, 0.0257, 0.0329], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8793, 0.0279, 0.0645, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8591, 0.0257, 0.0823, 0.0329], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7472, 0.0997, 0.1000, 0.0626], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6948, 0.1160, 0.1162, 0.0730], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.2669, 1.9767, 5.1363],\n",
      "        [3.5628, 2.9073, 6.2435],\n",
      "        [3.7832, 3.7930, 6.8343],\n",
      "        ...,\n",
      "        [1.9421, 1.4840, 5.1770],\n",
      "        [4.2826, 3.2783, 5.4505],\n",
      "        [3.5943, 2.8795, 6.1372]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.476979970932007\n",
      "Run: 0, 5\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[42.,  5.,  3.,  3.],\n",
      "        [39.,  4.,  0.,  3.],\n",
      "        [43.,  1.,  3.,  0.],\n",
      "        ...,\n",
      "        [54.,  2.,  1.,  1.],\n",
      "        [47.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 46., 47.,  ..., 58., 49., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 4., 1.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 3.,  ..., 1., 1., 3.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 0.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[42.,  5.,  3.,  3.],\n",
      "        [39.,  4.,  0.,  3.],\n",
      "        [43.,  1.,  3.,  0.],\n",
      "        ...,\n",
      "        [54.,  2.,  1.,  1.],\n",
      "        [47.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.0043e-05, 1.0708e-04, 2.2014e-02,  ..., 2.9246e-02, 7.0167e-02,\n",
      "        1.6781e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdcdd0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90857.78330615468, bestParams: [0.065798305, 0.01862657, 0.08375965, 6535.119, 18724.98, 18402.521, 23863.832]\n",
      "epoch 0\n",
      "     fun: 90574.54329233595\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16861\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([8.85348671e-01, 5.79907422e-02, 5.65029340e-02, 4.43107258e+03,\n",
      "       4.70193766e+03, 8.01621143e+03, 1.52672211e+04])\n",
      "best ll: 90647.02931454076, bestParams: [0.006345086, 0.025668247, 0.041042943, 3689.1306, 14496.478, 9464.404, 3974.9004]\n",
      "epoch 1\n",
      "     fun: 90346.79818100025\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22437\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.38988240e-02, 3.73832477e-02, 4.08481269e-02, 5.29178931e+03,\n",
      "       1.53774819e+04, 1.54631092e+04, 1.26597146e+04])\n",
      "minPrevious 90574.54329233595\n",
      "better by at >= 1; new ll:      fun: 90346.79818100025\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22437\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.38988240e-02, 3.73832477e-02, 4.08481269e-02, 5.29178931e+03,\n",
      "       1.53774819e+04, 1.54631092e+04, 1.26597146e+04])\n",
      "best ll: 90701.66978014109, bestParams: [0.051171403, 0.004164878, 0.037289176, 9557.071, 24102.58, 17367.414, 20774.168]\n",
      "epoch 2\n",
      "     fun: 90346.5671615596\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19326\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93206864e-02, 4.19921320e-02, 4.19359552e-02, 9.13554443e+03,\n",
      "       2.47502305e+04, 2.48801472e+04, 2.34591945e+04])\n",
      "minPrevious 90346.79818100025\n",
      "best ll: 91283.78536810011, bestParams: [0.10908244, 0.048394613, 0.10494098, 7852.6562, 4134.3623, 18254.262, 22675.844]\n",
      "epoch 3\n",
      "     fun: 90350.25783864367\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.12992497e-02, 4.44887911e-02, 4.23193013e-02, 9.43948030e+03,\n",
      "       2.49271977e+04, 2.48737002e+04, 2.48733863e+04])\n",
      "minPrevious 90346.79818100025\n",
      "best ll: 90471.10462045555, bestParams: [0.0154586835, 0.069063015, 0.03530776, 5670.462, 21156.191, 15531.642, 14583.196]\n",
      "epoch 4\n",
      "     fun: 90343.67707197007\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21977\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.74123918e-02, 4.08289397e-02, 4.13656120e-02, 8.98044189e+03,\n",
      "       2.49493444e+04, 2.49868195e+04, 2.25900515e+04])\n",
      "minPrevious 90346.79818100025\n",
      "better by at >= 1; new ll:      fun: 90343.67707197007\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21977\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.74123918e-02, 4.08289397e-02, 4.13656120e-02, 8.98044189e+03,\n",
      "       2.49493444e+04, 2.49868195e+04, 2.25900515e+04])\n",
      "best ll: 90477.84335776992, bestParams: [0.04298072, 0.021439154, 0.036853362, 3680.7407, 9893.799, 10063.484, 6246.7983]\n",
      "epoch 5\n",
      "     fun: 90343.78822780929\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19929\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.27018839e-02, 3.55948896e-02, 4.04254643e-02, 8.00020766e+03,\n",
      "       2.37514479e+04, 2.40988899e+04, 1.86050897e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90690.74806032187, bestParams: [0.05707956, 0.04165197, 0.05212749, 5306.5737, 9165.7705, 7847.644, 21851.729]\n",
      "epoch 6\n",
      "     fun: 90347.22406009762\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27937\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.34300152e-02, 3.88849780e-02, 4.11301663e-02, 5.86526976e+03,\n",
      "       1.70700458e+04, 1.67733265e+04, 1.41632998e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90533.48503693526, bestParams: [0.05087774, 0.042099502, 0.04017582, 8607.724, 23974.309, 19314.508, 15243.791]\n",
      "epoch 7\n",
      "     fun: 90344.29825837338\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18976\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.23100412e-02, 3.51282897e-02, 4.02434122e-02, 8.19614332e+03,\n",
      "       2.44955698e+04, 2.49282104e+04, 1.89051281e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 91039.73336329563, bestParams: [0.010360104, 0.0056551113, 0.017288163, 4754.299, 16049.336, 10335.417, 10871.316]\n",
      "epoch 8\n",
      "     fun: 90605.03752168667\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 15852\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.06037770e-01, 3.14303850e-02, 6.25201762e-02, 9.78926227e+03,\n",
      "       1.04937148e+04, 2.09762757e+04, 2.49999997e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90869.42943766556, bestParams: [0.058097538, 0.054223366, 0.0151370205, 7250.6963, 17291.744, 14349.171, 17670.531]\n",
      "epoch 9\n",
      "     fun: 90346.44614650698\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21311\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.12671383e-02, 3.59230494e-02, 4.02898373e-02, 5.12029022e+03,\n",
      "       1.54464584e+04, 1.53887553e+04, 1.18023848e+04])\n",
      "minPrevious 90343.67707197007\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0474, 0.0408, 0.0414], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8833, 0.0641, 0.0280, 0.0256], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8721, 0.0726, 0.0261, 0.0291], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8836, 0.0280, 0.0633, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8720, 0.0262, 0.0728, 0.0291], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7439, 0.0981, 0.0983, 0.0618], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7069, 0.1122, 0.1124, 0.0685], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.5321, 2.1588, 5.2563],\n",
      "        [3.0922, 2.8446, 5.8659],\n",
      "        [2.4312, 3.2523, 5.2012],\n",
      "        ...,\n",
      "        [5.0824, 4.3565, 4.4788],\n",
      "        [1.8716, 3.1835, 5.8296],\n",
      "        [4.0581, 4.7861, 4.6592]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.654811859130859\n",
      "Run: 0, 6\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[38.,  1.,  2.,  0.],\n",
      "        [53.,  2.,  1.,  1.],\n",
      "        [45.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [52.,  1.,  1.,  0.],\n",
      "        [49.,  1.,  2.,  1.],\n",
      "        [55.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([41., 57., 49.,  ..., 54., 53., 58.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 3.,  ..., 1., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 0.,  ..., 1., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 0., 1., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[38.,  1.,  2.,  0.],\n",
      "        [53.,  2.,  1.,  1.],\n",
      "        [45.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [52.,  1.,  1.,  0.],\n",
      "        [49.,  1.,  2.,  1.],\n",
      "        [55.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0499, 0.0292, 0.0091,  ..., 0.0603, 0.0286, 0.0355],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdcef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91089.27396093101, bestParams: [0.0075157364, 0.016659165, 0.0528355, 6167.8413, 16675.133, 23120.914, 2626.2808]\n",
      "epoch 0\n",
      "     fun: 90528.09146807808\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21301\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.22089041e-02, 4.04911316e-02, 4.09398703e-02, 7.87634233e+03,\n",
      "       2.31800900e+04, 2.34644446e+04, 1.90780530e+04])\n",
      "best ll: 90732.33126287756, bestParams: [0.025354784, 0.034044795, 0.03233444, 3831.9717, 18235.803, 15221.045, 8825.367]\n",
      "epoch 1\n",
      "     fun: 90527.19937601546\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19413\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.15413749e-02, 3.99949216e-02, 4.07060772e-02, 7.98855681e+03,\n",
      "       2.37755273e+04, 2.40322552e+04, 1.91271434e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 91108.88783821915, bestParams: [0.086679004, 0.067132905, 0.09949029, 7799.4536, 21237.266, 20044.95, 20242.219]\n",
      "epoch 2\n",
      "     fun: 90528.26860756558\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19659\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26203286e-02, 3.91555797e-02, 4.07703934e-02, 7.61654461e+03,\n",
      "       2.23785640e+04, 2.30843006e+04, 1.83011955e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 90664.09878557731, bestParams: [0.07736944, 0.06300846, 0.045417767, 1886.3728, 4232.271, 3625.2512, 6741.4614]\n",
      "epoch 3\n",
      "     fun: 90748.34990709391\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16844\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.70603984e-02, 8.70443592e-01, 5.24885454e-02, 5.72624408e+03,\n",
      "       1.07173118e+04, 6.06026139e+03, 2.05226559e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 91160.88386263404, bestParams: [0.033290174, 0.055628516, 0.014551205, 3497.17, 22058.719, 12795.54, 5477.151]\n",
      "epoch 4\n",
      "     fun: 90526.43683545549\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18563\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.91724795e-02, 3.97801077e-02, 4.02951177e-02, 8.10570623e+03,\n",
      "       2.49413083e+04, 2.46312383e+04, 1.89534248e+04])\n",
      "minPrevious 90528.09146807808\n",
      "better by at >= 1; new ll:      fun: 90526.43683545549\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18563\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.91724795e-02, 3.97801077e-02, 4.02951177e-02, 8.10570623e+03,\n",
      "       2.49413083e+04, 2.46312383e+04, 1.89534248e+04])\n",
      "best ll: 91032.47008508065, bestParams: [0.12150022, 0.06901591, 0.044288684, 6986.347, 7713.5996, 20299.445, 23289.34]\n",
      "epoch 5\n",
      "     fun: 90527.10680973373\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19381\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.03379565e-02, 3.91045966e-02, 4.04755411e-02, 7.92413194e+03,\n",
      "       2.40087260e+04, 2.41783579e+04, 1.86340368e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 91151.68239117, bestParams: [0.02094275, 0.085978635, 0.05017864, 8948.37, 7969.455, 22098.55, 24430.57]\n",
      "epoch 6\n",
      "     fun: 90532.97349945629\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21698\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.71214153e-02, 4.57389432e-02, 4.20915576e-02, 9.02832071e+03,\n",
      "       2.47487861e+04, 2.49622212e+04, 2.35201731e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90674.02727068722, bestParams: [0.03838533, 0.010670561, 0.028407924, 4872.6216, 17658.736, 17240.87, 10353.156]\n",
      "epoch 7\n",
      "     fun: 90530.28907951455\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20557\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13376010e-02, 4.08275025e-02, 4.08953581e-02, 6.64909977e+03,\n",
      "       1.97295238e+04, 1.97269175e+04, 1.60526526e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90743.39248618434, bestParams: [0.04231918, 0.031651355, 0.027624661, 2601.6572, 11065.2, 12116.015, 5007.5166]\n",
      "epoch 8\n",
      "     fun: 90527.06941824801\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20300\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.10153887e-02, 4.13760606e-02, 4.07297194e-02, 8.06086496e+03,\n",
      "       2.41232330e+04, 2.38660672e+04, 1.94393666e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90981.63954946902, bestParams: [0.05607572, 0.03384001, 0.036304813, 11815.16, 23425.008, 23078.727, 23863.035]\n",
      "epoch 9\n",
      "     fun: 90528.45840234167\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20521\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.11606709e-02, 4.21507169e-02, 4.10246844e-02, 8.36091333e+03,\n",
      "       2.48268749e+04, 2.44381077e+04, 2.03805812e+04])\n",
      "minPrevious 90526.43683545549\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0392, 0.0398, 0.0403], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8763, 0.0643, 0.0278, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8630, 0.0796, 0.0259, 0.0315], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8857, 0.0281, 0.0657, 0.0263], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8639, 0.0259, 0.0787, 0.0315], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7398, 0.0976, 0.0982, 0.0613], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7016, 0.1140, 0.1132, 0.0712], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9121, 3.6197, 4.2672],\n",
      "        [2.9923, 3.6857, 6.1465],\n",
      "        [3.8417, 2.6237, 5.0056],\n",
      "        ...,\n",
      "        [3.7917, 3.6148, 4.5259],\n",
      "        [3.2769, 4.1533, 5.7003],\n",
      "        [4.0090, 3.2273, 4.1458]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.512847900390625\n",
      "Run: 0, 7\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[50.,  5.,  1.,  4.],\n",
      "        [45.,  2.,  2.,  1.],\n",
      "        [38.,  4.,  1.,  5.],\n",
      "        ...,\n",
      "        [56.,  2.,  2.,  0.],\n",
      "        [42.,  3.,  0.,  0.],\n",
      "        [51.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "n tensor([60., 50., 48.,  ..., 60., 45., 55.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 2., 4.,  ..., 2., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 1.,  ..., 2., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 1., 5.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[50.,  5.,  1.,  4.],\n",
      "        [45.,  2.,  2.,  1.],\n",
      "        [38.,  4.,  1.,  5.],\n",
      "        ...,\n",
      "        [56.,  2.,  2.,  0.],\n",
      "        [42.,  3.,  0.,  0.],\n",
      "        [51.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.2155e-05, 1.9104e-02, 1.7708e-06,  ..., 3.6563e-02, 1.6772e-02,\n",
      "        2.8963e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bccef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91243.91071417881, bestParams: [0.040498573, 0.039992083, 0.033642173, 6753.6836, 15692.065, 21096.775, 11753.506]\n",
      "epoch 0\n",
      "     fun: 91035.2144862661\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21164\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56112050e-02, 5.15920592e-02, 4.19819102e-02, 8.88284249e+03,\n",
      "       2.49907590e+04, 2.48726630e+04, 2.23069026e+04])\n",
      "best ll: 91357.54566372334, bestParams: [0.040997185, 0.04618633, 0.0838608, 10846.453, 19839.768, 20632.074, 23618.115]\n",
      "epoch 1\n",
      "     fun: 91032.30772549672\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26802\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.40870682e-02, 4.61593746e-02, 4.11538469e-02, 8.28519028e+03,\n",
      "       2.40384533e+04, 2.47662828e+04, 1.98040363e+04])\n",
      "minPrevious 91035.2144862661\n",
      "better by at >= 1; new ll:      fun: 91032.30772549672\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26802\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.40870682e-02, 4.61593746e-02, 4.11538469e-02, 8.28519028e+03,\n",
      "       2.40384533e+04, 2.47662828e+04, 1.98040363e+04])\n",
      "best ll: 91302.02347668094, bestParams: [0.072848134, 0.03889845, 0.056128502, 6435.528, 21272.988, 18763.773, 8352.756]\n",
      "epoch 2\n",
      "     fun: 91031.9209379922\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24570\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.36019089e-02, 4.66654380e-02, 4.10921218e-02, 7.96267313e+03,\n",
      "       2.31950003e+04, 2.36841385e+04, 1.90482360e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91338.92905650586, bestParams: [0.07102878, 0.008142718, 0.04293678, 6779.5894, 16760.775, 23199.021, 24335.203]\n",
      "epoch 3\n",
      "     fun: 91033.0256424332\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19511\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.05025247e-02, 4.48221899e-02, 4.04081393e-02, 5.73947926e+03,\n",
      "       1.73768584e+04, 1.75574538e+04, 1.31654564e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91237.5362622957, bestParams: [0.04897804, 0.02517828, 0.053476565, 6121.2505, 24571.582, 21428.121, 6433.1235]\n",
      "epoch 4\n",
      "     fun: 91033.0525860195\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20408\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13719928e-02, 4.36648545e-02, 4.02826805e-02, 6.16702916e+03,\n",
      "       1.86390630e+04, 1.91395485e+04, 1.41040120e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91642.97852024857, bestParams: [0.002547079, 0.031438496, 0.04191702, 10740.871, 20333.883, 15887.142, 24783.443]\n",
      "epoch 5\n",
      "     fun: 91034.54627224465\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23137\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26251794e-02, 4.60197835e-02, 4.10425927e-02, 6.91119423e+03,\n",
      "       2.02861702e+04, 2.07257963e+04, 1.63576711e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91317.27160636887, bestParams: [0.08740924, 0.015501036, 0.038114674, 9618.194, 22194.303, 20528.768, 23597.967]\n",
      "epoch 6\n",
      "     fun: 91034.88282504663\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20439\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.59857350e-02, 5.16670146e-02, 4.19960060e-02, 8.87733643e+03,\n",
      "       2.48689759e+04, 2.48395651e+04, 2.23461119e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91663.3816547386, bestParams: [0.11510229, 0.022979988, 0.07719361, 4350.521, 11100.692, 16230.497, 16443.652]\n",
      "epoch 7\n",
      "     fun: 91033.37773956737\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19850\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.01523012e-02, 4.31942038e-02, 4.02496093e-02, 4.25476136e+03,\n",
      "       1.30677735e+04, 1.33156742e+04, 9.56380154e+03])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91600.56161983634, bestParams: [0.021486541, 0.04493397, 0.05444471, 8626.893, 24781.225, 17456.62, 8928.072]\n",
      "epoch 8\n",
      "     fun: 91033.31471153395\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 31986\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.08887799e-02, 4.39664510e-02, 4.02960859e-02, 4.10381194e+03,\n",
      "       1.24499251e+04, 1.26908510e+04, 9.37283927e+03])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91558.65006552348, bestParams: [0.13935027, 0.023656605, 0.10880936, 7721.089, 14432.105, 18207.133, 15296.897]\n",
      "epoch 9\n",
      "     fun: 91034.43093651239\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19058\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.61504895e-02, 5.08239462e-02, 4.18637993e-02, 8.83570464e+03,\n",
      "       2.47664960e+04, 2.49518926e+04, 2.21539923e+04])\n",
      "minPrevious 91032.30772549672\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0441, 0.0462, 0.0412], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8834, 0.0644, 0.0280, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8673, 0.0756, 0.0260, 0.0311], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8760, 0.0278, 0.0650, 0.0260], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8654, 0.0259, 0.0776, 0.0311], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7375, 0.0976, 0.0992, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7045, 0.1118, 0.1137, 0.0700], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[5.3702, 4.2106, 6.4728],\n",
      "        [2.3497, 1.9903, 3.4842],\n",
      "        [3.2499, 2.2078, 5.5362],\n",
      "        ...,\n",
      "        [2.0072, 3.2786, 5.4871],\n",
      "        [4.0390, 2.2470, 6.6010],\n",
      "        [3.4164, 3.2387, 5.0540]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.588237047195435\n",
      "Run: 0, 8\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  2.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [58.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [51.,  1.,  0.,  0.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([47., 54., 61.,  ..., 52., 54., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 5., 0.,  ..., 1., 5., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 2.,  ..., 0., 2., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  2.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [58.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [51.,  1.,  0.,  0.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0106, 0.0011, 0.0168,  ..., 0.0420, 0.0011, 0.0503],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bcce60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91167.15270193382, bestParams: [0.014420534, 0.012763254, 0.08490746, 10409.463, 14869.195, 12726.8955, 24758.049]\n",
      "epoch 0\n",
      "     fun: 90664.13815521165\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18871\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.50519321e-02, 4.80974897e-02, 4.37722990e-02, 9.33124432e+03,\n",
      "       2.49952647e+04, 2.48946095e+04, 2.44922474e+04])\n",
      "best ll: 91064.46507395245, bestParams: [0.13599314, 0.0092406655, 0.06631607, 5395.3354, 13053.832, 21606.041, 11194.925]\n",
      "epoch 1\n",
      "     fun: 90658.51054391943\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21778\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97539028e-02, 3.85180081e-02, 4.21989798e-02, 5.29648514e+03,\n",
      "       1.53948253e+04, 1.60815565e+04, 1.24519796e+04])\n",
      "minPrevious 90664.13815521165\n",
      "better by at >= 1; new ll:      fun: 90658.51054391943\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21778\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97539028e-02, 3.85180081e-02, 4.21989798e-02, 5.29648514e+03,\n",
      "       1.53948253e+04, 1.60815565e+04, 1.24519796e+04])\n",
      "best ll: 91161.8533601003, bestParams: [0.034372266, 0.032068986, 0.05270397, 8083.9736, 19698.992, 9210.703, 19556.129]\n",
      "epoch 2\n",
      "     fun: 90657.06766549514\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.92766030e-02, 4.08158908e-02, 4.23739920e-02, 7.79916973e+03,\n",
      "       2.27167344e+04, 2.30158405e+04, 1.86388333e+04])\n",
      "minPrevious 90658.51054391943\n",
      "better by at >= 1; new ll:      fun: 90657.06766549514\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.92766030e-02, 4.08158908e-02, 4.23739920e-02, 7.79916973e+03,\n",
      "       2.27167344e+04, 2.30158405e+04, 1.86388333e+04])\n",
      "best ll: 91063.24965752647, bestParams: [0.021735504, 0.06495616, 0.022336451, 6890.512, 21746.352, 12447.272, 18961.99]\n",
      "epoch 3\n",
      "     fun: 90659.63845924352\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29426\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.96169439e-02, 4.09057274e-02, 4.24696771e-02, 5.79042445e+03,\n",
      "       1.67475000e+04, 1.69853353e+04, 1.39198936e+04])\n",
      "minPrevious 90657.06766549514\n",
      "best ll: 90977.47848692283, bestParams: [0.059151612, 0.05514521, 0.0882875, 7970.9907, 15740.975, 12443.312, 21263.242]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8d3d1ca8ed6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[0;31m#         fnArgs = [probs[0], probs[1], probs[2], *alphas]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m         \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mdual_annealing\u001b[0;34m(func, bounds, args, maxiter, local_search_options, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;31m# Possible local search at the end of the strategy chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_local_search\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mlocal_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;31m# Global energy has improved, let's see if LS improves further\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             e, x = self.minimizer_wrapper.local_search(self.energy_state.xbest,\n\u001b[0;32m--> 318\u001b[0;31m                                                        self.energy_state.ebest)\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mebest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_improved_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mlocal_search\u001b[0;34m(self, x, e)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Run local search from the given x location where energy value is e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mx_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mmres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'njev'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnjev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 600\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0ma1Both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1Both\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0ma21\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "resSim = {\n",
    "        \"allRes\": None,\n",
    "        \"nEpochs\": None,\n",
    "        \"bestRes\": {\n",
    "            \"pis\": None,\n",
    "            \"alphas\": None,\n",
    "            \"PDV_c1true\": None,\n",
    "            \"PDV_c2true\": None,\n",
    "            \"PDV_cBothTrue\": None,\n",
    "            \"PDV_c1inferred\": None,\n",
    "            \"PDV_c2inferred\": None,\n",
    "            \"PDV_cBothInferred\": None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cached6NormalSimRes = []\n",
    "\n",
    "rrsSim = tensor([[2, 2, 1.5]])\n",
    "pisSim = tensor([[.05, .05, .05]])\n",
    "\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(5e5)\n",
    "i = 0\n",
    "for rrsSimRun in rrsSim:\n",
    "    for pisSimRun in pisSim:\n",
    "        afMeanRun = 1e-4\n",
    "        generatingFn = genData.v6normal\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        # needs tensor for shapes, otherwise \"gamma_cpu not implemente for long\", e.g rrShape=50.0 doesn't work...\n",
    "        paramsRun = genData.genParams(rrMeans=rrsSimRun, pis=pisSimRun, afMean=afMeanRun, rrShape=tensor(50.), afShape=tensor(50.), nCases=nCases, nCtrls=nCtrls)[0]\n",
    "        \n",
    "        pDsRun = paramsRun[\"pDs\"]\n",
    "        pisRun = paramsRun[\"diseaseFractions\"]\n",
    "        print(\"params are:\", paramsRun)\n",
    "        \n",
    "        cached6NormalSimRes.append({\"params\": paramsRun, \"runs\": []})\n",
    "        for y in range(0, 10):\n",
    "            start = time.time()\n",
    "            r = generatingFn(**paramsRun)\n",
    "            print(\"took\", time.time() - start)\n",
    "            \n",
    "            resPointer = {\n",
    "                **r,\n",
    "                \"generatingFn\": generatingFn,\n",
    "                \"results\": None,\n",
    "            }\n",
    "\n",
    "            cached6NormalSimRes[i][\"runs\"].append(resPointer)\n",
    "            \n",
    "            print(f\"Run: {i}, {y}\")\n",
    "            \n",
    "            xsRun = resPointer[\"altCounts\"]\n",
    "            afsRun = resPointer[\"afs\"]\n",
    "            affectedGenesRun = resPointer[\"affectedGenes\"]\n",
    "            unaffectedGenesRun = resPointer[\"unaffectedGenes\"]\n",
    "\n",
    "            runCostFnIdx = 16\n",
    "\n",
    "            nEpochsRun = 10\n",
    "            print(\"nEpochsRun\", nEpochsRun)\n",
    "            \n",
    "            res = likelihoods.fitFnBivariateAnnealing(xsRun, pDsRun, nEpochs=nEpochsRun, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "            bestRes = res[\"params\"][-1]\n",
    "\n",
    "            inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "            inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "            #### Calculate actual ###\n",
    "            component1Afs = afsRun[affectedGenesRun[0]]\n",
    "            c1true = (component1Afs / afMeanRun).mean(0)\n",
    "\n",
    "            component2Afs = afsRun[affectedGenesRun[1]]\n",
    "            c2true = (component2Afs / afMeanRun).mean(0)\n",
    "\n",
    "            componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "            cBothTrue = (componentBothAfs / afMeanRun).mean(0)\n",
    "\n",
    "            ### calculate inferred values\n",
    "            pds = tensor([1-pDsRun.sum(), *pDsRun])\n",
    "            alphas = inferredAlphas.numpy()\n",
    "            c1inferred = Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            c2inferred = Dirichlet(tensor([alphas[0], alphas[0], alphas[2], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            cBothInferred = Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0)\n",
    "\n",
    "            print(f\"\\n\\nrun {i} results for rrs: {rrsSimRun}, pis: {pisSimRun}\")\n",
    "            print(\"Inferred pis:\", inferredPis)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c1true)\n",
    "            print(\"P(D|V) inferred in component 1:\", c1inferred)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c2true)\n",
    "            print(\"P(D|V) inferred in component both:\", c2inferred)\n",
    "            print(\"\\nP(D|V) true ans in component both:\", cBothTrue)\n",
    "            print(\"P(D|V) inferred in component both:\", cBothInferred,\"\\n\\n\")\n",
    "\n",
    "            resToStore = copy.deepcopy(resSim)\n",
    "            resToStore[\"allRes\"] = res\n",
    "            resToStore[\"nEpochs\"] = nEpochsRun\n",
    "            br = resToStore[\"bestRes\"]\n",
    "            br[\"pis\"] = inferredPis\n",
    "            br[\"alphas\"] = inferredAlphas\n",
    "            br[\"PDV_c1true\"] = c1true\n",
    "            br[\"PDV_c2true\"] = c2true\n",
    "            br[\"PDV_cBothTrue\"] = cBothTrue\n",
    "            br[\"PDV_c1inferred\"] = c1inferred\n",
    "            br[\"PDV_c2inferred\"] = c2inferred\n",
    "            br[\"PDV_cBothInferred\"] = cBothInferred\n",
    "\n",
    "            resPointer[\"results\"] = resToStore\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([2.0000, 2.0000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.0478, 2.3230, 4.9419],\n",
      "        [1.1123, 3.1260, 6.4751],\n",
      "        [3.7432, 4.8883, 4.0865],\n",
      "        ...,\n",
      "        [2.3440, 2.6389, 4.7504],\n",
      "        [3.1413, 3.7973, 5.2277],\n",
      "        [2.2387, 4.0079, 4.0649]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.850098848342896\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[45.,  5.,  3.,  2.],\n",
      "        [41.,  4.,  3.,  1.],\n",
      "        [37.,  7.,  1.,  0.],\n",
      "        ...,\n",
      "        [74.,  1.,  4.,  0.],\n",
      "        [34.,  0.,  0.,  1.],\n",
      "        [47.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([55., 49., 45.,  ..., 79., 35., 47.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 4., 7.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 1.,  ..., 4., 0., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 0.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[45.,  5.,  3.,  2.],\n",
      "        [41.,  4.,  3.,  1.],\n",
      "        [37.,  7.,  1.,  0.],\n",
      "        ...,\n",
      "        [74.,  1.,  4.,  0.],\n",
      "        [34.,  0.,  0.,  1.],\n",
      "        [47.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([1.5210e-04, 1.0985e-03, 4.9528e-05,  ..., 1.1274e-02, 3.6850e-02,\n",
      "        3.8093e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3eef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91172.32504614866, bestParams: [0.013028687, 0.04237689, 0.055741724, 11929.878, 23005.342, 24812.355, 19184.58]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.44827568e-02, 4.20886696e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886697e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204496e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886697e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204496e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886694e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04]]), array([90708.23269808, 90708.23269813, 90708.23269813, 90708.23269813,\n",
      "       90708.23269818, 90708.2326982 , 90708.23269824, 90708.23269824]))\n",
      "           fun: 90708.2326980827\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1318\n",
      "           nit: 493\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.44827568e-02, 4.20886696e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "       2.80864800e+04, 2.54391201e+04, 1.98356475e+04])\n",
      "best ll: 90890.87945008784, bestParams: [0.02896374, 0.014520663, 0.032099355, 7064.519, 15548.0, 21440.451, 23799.553]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528250e+04],\n",
      "       [3.38261325e-02, 1.79584957e-02, 3.97524944e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528248e+04],\n",
      "       [3.38261324e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519285e+04, 2.19081534e+04, 1.22528248e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524946e-02, 6.01717407e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04]]), array([90656.19387572, 90656.19387581, 90656.19387586, 90656.19387586,\n",
      "       90656.19387591, 90656.19387599, 90656.19387611, 90656.19387612]))\n",
      "           fun: 90656.19387571645\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1376\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "       1.88519284e+04, 2.19081534e+04, 1.22528249e+04])\n",
      "minPrevious 90708.2326980827\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528250e+04],\n",
      "       [3.38261325e-02, 1.79584957e-02, 3.97524944e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528248e+04],\n",
      "       [3.38261324e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519285e+04, 2.19081534e+04, 1.22528248e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524946e-02, 6.01717407e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04]]), array([90656.19387572, 90656.19387581, 90656.19387586, 90656.19387586,\n",
      "       90656.19387591, 90656.19387599, 90656.19387611, 90656.19387612]))\n",
      "           fun: 90656.19387571645\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1376\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "       1.88519284e+04, 2.19081534e+04, 1.22528249e+04])\n",
      "best ll: 91084.1192014738, bestParams: [0.09653744, 0.018029423, 0.09406014, 7974.054, 10447.645, 17449.232, 18952.387]\n",
      "epoch 2\n",
      " final_simplex: (array([[9.36961198e-02, 2.15226793e-02, 4.20764994e-02, 6.46469647e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961197e-02, 2.15226793e-02, 4.20764980e-02, 6.46469647e+03,\n",
      "        1.42865571e+04, 1.95487746e+04, 1.90451599e+04],\n",
      "       [9.36961201e-02, 2.15226793e-02, 4.20765002e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451600e+04],\n",
      "       [9.36961203e-02, 2.15226793e-02, 4.20764994e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487746e+04, 1.90451598e+04],\n",
      "       [9.36961203e-02, 2.15226792e-02, 4.20764988e-02, 6.46469647e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961206e-02, 2.15226793e-02, 4.20765004e-02, 6.46469645e+03,\n",
      "        1.42865569e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961209e-02, 2.15226792e-02, 4.20765011e-02, 6.46469645e+03,\n",
      "        1.42865569e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961205e-02, 2.15226792e-02, 4.20764990e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04]]), array([90681.43851664, 90681.43851693, 90681.43851704, 90681.43851723,\n",
      "       90681.43851748, 90681.43851752, 90681.43851769, 90681.43851779]))\n",
      "           fun: 90681.43851663727\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.36961198e-02, 2.15226793e-02, 4.20764994e-02, 6.46469647e+03,\n",
      "       1.42865570e+04, 1.95487745e+04, 1.90451599e+04])\n",
      "minPrevious 90656.19387571645\n",
      "best ll: 91034.65410804498, bestParams: [0.027997645, 0.11145982, 0.04767258, 7647.5757, 20896.21, 12109.757, 15794.455]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.29898119e-02, 8.95420892e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420892e-02, 4.67567476e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898118e-02, 8.95420892e-02, 4.67567477e-02, 6.32456128e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420894e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816320e+04, 1.92698622e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567478e-02, 6.32456126e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698622e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567478e-02, 6.32456125e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420898e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698622e+04]]), array([90716.56485695, 90716.56485706, 90716.56485719, 90716.56485742,\n",
      "       90716.56485758, 90716.56485805, 90716.56485833, 90716.56487249]))\n",
      "           fun: 90716.56485695229\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1182\n",
      "           nit: 442\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.29898119e-02, 8.95420892e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "       1.68206514e+04, 1.47816319e+04, 1.92698623e+04])\n",
      "minPrevious 90656.19387571645\n",
      "best ll: 90939.13863356014, bestParams: [0.07707118, 0.018570729, 0.07501205, 5894.602, 8311.181, 11558.4, 19163.01]\n",
      "epoch 4\n",
      " final_simplex: (array([[6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350208e-02, 2.24385760e-02, 3.93378972e-02, 4.60124344e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539976e+04],\n",
      "       [6.84350208e-02, 2.24385761e-02, 3.93378969e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350213e-02, 2.24385761e-02, 3.93378970e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539976e+04],\n",
      "       [6.84350210e-02, 2.24385763e-02, 3.93378962e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350214e-02, 2.24385761e-02, 3.93378967e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350228e-02, 2.24385758e-02, 3.93378974e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350233e-02, 2.24385756e-02, 3.93378983e-02, 4.60124348e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04]]), array([90648.44593427, 90648.44593435, 90648.44593449, 90648.44593476,\n",
      "       90648.44593506, 90648.4459351 , 90648.44593574, 90648.4459358 ]))\n",
      "           fun: 90648.44593427246\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1147\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "       1.17104156e+04, 1.52903364e+04, 1.15539975e+04])\n",
      "minPrevious 90656.19387571645\n",
      "better by at >= 1; new ll:  final_simplex: (array([[6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350208e-02, 2.24385760e-02, 3.93378972e-02, 4.60124344e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539976e+04],\n",
      "       [6.84350208e-02, 2.24385761e-02, 3.93378969e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350213e-02, 2.24385761e-02, 3.93378970e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539976e+04],\n",
      "       [6.84350210e-02, 2.24385763e-02, 3.93378962e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350214e-02, 2.24385761e-02, 3.93378967e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350228e-02, 2.24385758e-02, 3.93378974e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350233e-02, 2.24385756e-02, 3.93378983e-02, 4.60124348e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04]]), array([90648.44593427, 90648.44593435, 90648.44593449, 90648.44593476,\n",
      "       90648.44593506, 90648.4459351 , 90648.44593574, 90648.4459358 ]))\n",
      "           fun: 90648.44593427246\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1147\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "       1.17104156e+04, 1.52903364e+04, 1.15539975e+04])\n",
      "best ll: 91166.87153988995, bestParams: [0.068626955, 0.11146803, 0.06459778, 7812.6924, 19519.297, 9904.601, 17612.63]\n",
      "epoch 5\n",
      " final_simplex: (array([[7.59170859e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170857e-02, 1.01934340e-01, 4.47969147e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170858e-02, 1.01934340e-01, 4.47969150e-02, 6.65456055e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170859e-02, 1.01934340e-01, 4.47969144e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628879e+04, 2.17700551e+04],\n",
      "       [7.59170856e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934341e-01, 4.47969147e-02, 6.65456053e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934341e-01, 4.47969147e-02, 6.65456053e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04]]), array([90735.31638244, 90735.31638259, 90735.31638261, 90735.31638276,\n",
      "       90735.31638288, 90735.31638291, 90735.31638307, 90735.31638314]))\n",
      "           fun: 90735.31638244262\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1236\n",
      "           nit: 471\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.59170859e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "       1.49096890e+04, 1.34628878e+04, 2.17700551e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90917.66287739587, bestParams: [0.13892789, 0.10014813, 0.035001487, 4701.4688, 7708.276, 10219.709, 22012.11]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.36648091e-01, 9.30464598e-02, 3.80847363e-02, 4.89947091e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648091e-01, 9.30464598e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464601e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151964e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464605e-02, 3.80847362e-02, 4.89947092e+03,\n",
      "        8.76151962e+03, 1.02069802e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464605e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151957e+03, 1.02069801e+04, 1.80163115e+04],\n",
      "       [1.36648090e-01, 9.30464604e-02, 3.80847362e-02, 4.89947091e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464608e-02, 3.80847361e-02, 4.89947093e+03,\n",
      "        8.76151964e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464607e-02, 3.80847360e-02, 4.89947093e+03,\n",
      "        8.76151961e+03, 1.02069801e+04, 1.80163114e+04]]), array([90782.8870678 , 90782.88706813, 90782.88706825, 90782.88706835,\n",
      "       90782.88706844, 90782.8870687 , 90782.88706913, 90782.88706914]))\n",
      "           fun: 90782.88706779895\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1239\n",
      "           nit: 485\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.36648091e-01, 9.30464598e-02, 3.80847363e-02, 4.89947091e+03,\n",
      "       8.76151963e+03, 1.02069801e+04, 1.80163114e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90921.60896941471, bestParams: [0.039651427, 0.066044815, 0.0449088, 8883.905, 17105.955, 21929.596, 18417.646]\n",
      "epoch 7\n",
      " final_simplex: (array([[4.04578591e-02, 6.31349507e-02, 4.17312360e-02, 7.30683351e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349508e-02, 4.17312359e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349506e-02, 4.17312361e-02, 7.30683352e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130547e+04],\n",
      "       [4.04578590e-02, 6.31349505e-02, 4.17312361e-02, 7.30683351e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578592e-02, 6.31349508e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130547e+04],\n",
      "       [4.04578590e-02, 6.31349507e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349509e-02, 4.17312359e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349508e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04]]), array([90653.65813487, 90653.65813493, 90653.65813495, 90653.65813495,\n",
      "       90653.65813502, 90653.65813511, 90653.65813513, 90653.65813515]))\n",
      "           fun: 90653.65813486525\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1328\n",
      "           nit: 534\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.04578591e-02, 6.31349507e-02, 4.17312360e-02, 7.30683351e+03,\n",
      "       2.06655049e+04, 1.98816064e+04, 2.07130546e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90906.03571837083, bestParams: [0.046865396, 0.021055793, 0.022448916, 5707.723, 14474.583, 22354.312, 23248.088]\n",
      "epoch 8\n",
      " final_simplex: (array([[4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083142e-02, 2.66136979e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04]]), array([90636.62833643, 90636.62833654, 90636.6283387 , 90636.62833873,\n",
      "       90636.62833876, 90636.62833878, 90636.628347  , 90636.62834702]))\n",
      "           fun: 90636.62833642976\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1308\n",
      "           nit: 446\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "       1.71687415e+04, 1.90909270e+04, 1.19123748e+04])\n",
      "minPrevious 90648.44593427246\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083142e-02, 2.66136979e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04]]), array([90636.62833643, 90636.62833654, 90636.6283387 , 90636.62833873,\n",
      "       90636.62833876, 90636.62833878, 90636.628347  , 90636.62834702]))\n",
      "           fun: 90636.62833642976\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1308\n",
      "           nit: 446\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "       1.71687415e+04, 1.90909270e+04, 1.19123748e+04])\n",
      "best ll: 91011.59666077793, bestParams: [0.1238161, 0.015511246, 0.058201686, 9525.396, 21616.701, 17512.54, 22892.9]\n",
      "epoch 9\n",
      " final_simplex: (array([[1.03603268e-01, 1.67256257e-02, 5.42323187e-02, 8.78604866e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256257e-02, 5.42323187e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603268e-01, 1.67256256e-02, 5.42323188e-02, 8.78604868e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603268e-01, 1.67256256e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256256e-02, 5.42323188e-02, 8.78604866e+03,\n",
      "        1.78020607e+04, 2.35306881e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256256e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020608e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603269e-01, 1.67256255e-02, 5.42323190e-02, 8.78604870e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256255e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306881e+04, 2.62310912e+04]]), array([90724.66721506, 90724.66721543, 90724.66721548, 90724.66721562,\n",
      "       90724.66721583, 90724.6672159 , 90724.667216  , 90724.66721622]))\n",
      "           fun: 90724.66721505724\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1140\n",
      "           nit: 379\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.03603268e-01, 1.67256257e-02, 5.42323187e-02, 8.78604866e+03,\n",
      "       1.78020607e+04, 2.35306880e+04, 2.62310912e+04])\n",
      "minPrevious 90636.62833642976\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0405, 0.0266, 0.0348], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8832, 0.0633, 0.0280, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8564, 0.0816, 0.0256, 0.0363], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8810, 0.0279, 0.0632, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8486, 0.0255, 0.0899, 0.0360], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7405, 0.0996, 0.0999, 0.0624], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6942, 0.1121, 0.1194, 0.0742], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[1.7906, 2.9352, 4.7581],\n",
      "        [3.0976, 2.9503, 4.8961],\n",
      "        [3.5549, 4.4150, 6.2209],\n",
      "        ...,\n",
      "        [3.0932, 3.6773, 5.4842],\n",
      "        [4.8924, 3.0446, 5.1291],\n",
      "        [3.6147, 3.7954, 6.7355]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.719698190689087\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[39.,  1.,  0.,  3.],\n",
      "        [52.,  5.,  1.,  1.],\n",
      "        [48.,  1.,  0.,  3.],\n",
      "        ...,\n",
      "        [56.,  1.,  2.,  2.],\n",
      "        [43.,  4.,  0.,  1.],\n",
      "        [47.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([43., 59., 52.,  ..., 61., 48., 49.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 5., 1.,  ..., 1., 4., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 0.,  ..., 2., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 3.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[39.,  1.,  0.,  3.],\n",
      "        [52.,  5.,  1.,  1.],\n",
      "        [48.,  1.,  0.,  3.],\n",
      "        ...,\n",
      "        [56.,  1.,  2.,  2.],\n",
      "        [43.,  4.,  0.,  1.],\n",
      "        [47.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0013, 0.0021, 0.0015,  ..., 0.0100, 0.0030, 0.0702],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3ea70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90741.90852394194, bestParams: [0.07122339, 0.0030399286, 0.054159407, 10150.92, 21346.87, 23431.73, 21332.012]\n",
      "epoch 0\n",
      " final_simplex: (array([[6.75587190e-02, 3.35212914e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212913e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587193e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587193e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212914e-03, 5.38820011e-02, 8.95523095e+03,\n",
      "        2.17844697e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587194e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587194e-02, 3.35212913e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139825e+04]]), array([90648.67312646, 90648.6731265 , 90648.67312653, 90648.67312653,\n",
      "       90648.6731266 , 90648.67312662, 90648.67312669, 90648.67312672]))\n",
      "           fun: 90648.67312645877\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1299\n",
      "           nit: 485\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.75587190e-02, 3.35212914e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "       2.17844698e+04, 2.55800586e+04, 2.21139824e+04])\n",
      "best ll: 90681.83730196144, bestParams: [0.009099581, 0.0579189, 0.04930118, 3433.2517, 15866.488, 10614.559, 6043.5835]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482751e+03],\n",
      "       [3.97041955e-02, 3.83571503e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482756e+03],\n",
      "       [3.97041953e-02, 3.83571506e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482753e+03],\n",
      "       [3.97041955e-02, 3.83571505e-02, 4.01668990e-02, 1.65787189e+03,\n",
      "        5.10452657e+03, 4.99800959e+03, 3.89482751e+03],\n",
      "       [3.97041957e-02, 3.83571504e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452653e+03, 4.99800953e+03, 3.89482757e+03],\n",
      "       [3.97041957e-02, 3.83571501e-02, 4.01668989e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482757e+03],\n",
      "       [3.97041956e-02, 3.83571500e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452651e+03, 4.99800959e+03, 3.89482750e+03],\n",
      "       [3.97041950e-02, 3.83571509e-02, 4.01668988e-02, 1.65787188e+03,\n",
      "        5.10452655e+03, 4.99800972e+03, 3.89482750e+03]]), array([90476.89262346, 90476.89262354, 90476.89262355, 90476.89262356,\n",
      "       90476.89262359, 90476.89262365, 90476.89262374, 90476.89262375]))\n",
      "           fun: 90476.89262346049\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1303\n",
      "           nit: 537\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "       5.10452656e+03, 4.99800963e+03, 3.89482751e+03])\n",
      "minPrevious 90648.67312645877\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482751e+03],\n",
      "       [3.97041955e-02, 3.83571503e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482756e+03],\n",
      "       [3.97041953e-02, 3.83571506e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482753e+03],\n",
      "       [3.97041955e-02, 3.83571505e-02, 4.01668990e-02, 1.65787189e+03,\n",
      "        5.10452657e+03, 4.99800959e+03, 3.89482751e+03],\n",
      "       [3.97041957e-02, 3.83571504e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452653e+03, 4.99800953e+03, 3.89482757e+03],\n",
      "       [3.97041957e-02, 3.83571501e-02, 4.01668989e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482757e+03],\n",
      "       [3.97041956e-02, 3.83571500e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452651e+03, 4.99800959e+03, 3.89482750e+03],\n",
      "       [3.97041950e-02, 3.83571509e-02, 4.01668988e-02, 1.65787188e+03,\n",
      "        5.10452655e+03, 4.99800972e+03, 3.89482750e+03]]), array([90476.89262346, 90476.89262354, 90476.89262355, 90476.89262356,\n",
      "       90476.89262359, 90476.89262365, 90476.89262374, 90476.89262375]))\n",
      "           fun: 90476.89262346049\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1303\n",
      "           nit: 537\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "       5.10452656e+03, 4.99800963e+03, 3.89482751e+03])\n",
      "best ll: 90717.3162355351, bestParams: [0.06359781, 0.10405803, 0.046771917, 7625.652, 24112.361, 18915.994, 16105.375]\n",
      "epoch 2\n",
      " final_simplex: (array([[5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102427e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102420e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102419e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102418e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102419e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04]]), array([90500.47796516, 90500.47796518, 90500.47796518, 90500.47796519,\n",
      "       90500.47796527, 90500.47796527, 90500.47796527, 90500.47796528]))\n",
      "           fun: 90500.47796516292\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 4652\n",
      "           nit: 2308\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "       2.04976104e+04, 2.06011943e+04, 2.24340928e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90929.14797453234, bestParams: [0.021989336, 0.024018025, 0.07503793, 7889.689, 16223.559, 6951.5303, 24633.479]\n",
      "epoch 3\n",
      " final_simplex: (array([[2.99085125e-02, 2.41263715e-02, 4.27982693e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577086e+03],\n",
      "       [2.99085127e-02, 2.41263716e-02, 4.27982671e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577085e+03],\n",
      "       [2.99085125e-02, 2.41263714e-02, 4.27982700e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577081e+03],\n",
      "       [2.99085123e-02, 2.41263714e-02, 4.27982701e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577087e+03],\n",
      "       [2.99085125e-02, 2.41263713e-02, 4.27982700e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577081e+03],\n",
      "       [2.99085124e-02, 2.41263712e-02, 4.27982710e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577083e+03],\n",
      "       [2.99085124e-02, 2.41263713e-02, 4.27982702e-02, 4.40451852e+03,\n",
      "        1.47346393e+04, 1.45226304e+04, 8.34577086e+03],\n",
      "       [2.99085123e-02, 2.41263713e-02, 4.27982702e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577086e+03]]), array([90495.8006795 , 90495.80067955, 90495.80067955, 90495.8006796 ,\n",
      "       90495.80067963, 90495.80067969, 90495.80067975, 90495.80067979]))\n",
      "           fun: 90495.80067950126\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1186\n",
      "           nit: 463\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.99085125e-02, 2.41263715e-02, 4.27982693e-02, 4.40451852e+03,\n",
      "       1.47346392e+04, 1.45226304e+04, 8.34577086e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90864.35112277341, bestParams: [0.018510455, 0.058447286, 0.035942793, 6684.6064, 20323.559, 21613.281, 5399.623]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.43113091e-02, 2.92079757e-02, 4.39142700e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673893e+03],\n",
      "       [2.43113090e-02, 2.92079759e-02, 4.39142701e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03],\n",
      "       [2.43113090e-02, 2.92079760e-02, 4.39142702e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673896e+03],\n",
      "       [2.43113090e-02, 2.92079757e-02, 4.39142702e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905713e+04, 9.04673895e+03],\n",
      "       [2.43113090e-02, 2.92079757e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673892e+03],\n",
      "       [2.43113090e-02, 2.92079756e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03],\n",
      "       [2.43113090e-02, 2.92079758e-02, 4.39142706e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905711e+04, 9.04673894e+03],\n",
      "       [2.43113091e-02, 2.92079753e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03]]), array([90498.99775909, 90498.99775912, 90498.99775917, 90498.99775926,\n",
      "       90498.99775931, 90498.99775936, 90498.9977594 , 90498.99775941]))\n",
      "           fun: 90498.99775908835\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1218\n",
      "           nit: 417\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.43113091e-02, 2.92079757e-02, 4.39142700e-02, 4.97417025e+03,\n",
      "       1.72363324e+04, 1.66905712e+04, 9.04673893e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90989.41744427223, bestParams: [0.030847164, 0.029215563, 0.034289706, 2947.6792, 13085.451, 7149.294, 2870.779]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.08771419e-02, 3.15990099e-02, 4.33952910e-02, 2.10684217e+03,\n",
      "        6.80498898e+03, 6.67304328e+03, 4.34566725e+03],\n",
      "       [3.08771419e-02, 3.15990095e-02, 4.33952911e-02, 2.10684218e+03,\n",
      "        6.80498898e+03, 6.67304328e+03, 4.34566732e+03],\n",
      "       [3.08771415e-02, 3.15990100e-02, 4.33952912e-02, 2.10684217e+03,\n",
      "        6.80498897e+03, 6.67304334e+03, 4.34566724e+03],\n",
      "       [3.08771414e-02, 3.15990099e-02, 4.33952914e-02, 2.10684218e+03,\n",
      "        6.80498901e+03, 6.67304327e+03, 4.34566729e+03],\n",
      "       [3.08771412e-02, 3.15990097e-02, 4.33952913e-02, 2.10684219e+03,\n",
      "        6.80498900e+03, 6.67304332e+03, 4.34566733e+03],\n",
      "       [3.08771411e-02, 3.15990098e-02, 4.33952915e-02, 2.10684219e+03,\n",
      "        6.80498896e+03, 6.67304328e+03, 4.34566735e+03],\n",
      "       [3.08771410e-02, 3.15990097e-02, 4.33952914e-02, 2.10684220e+03,\n",
      "        6.80498899e+03, 6.67304331e+03, 4.34566735e+03],\n",
      "       [3.08771408e-02, 3.15990100e-02, 4.33952916e-02, 2.10684219e+03,\n",
      "        6.80498897e+03, 6.67304330e+03, 4.34566733e+03]]), array([90484.77045382, 90484.77045403, 90484.77045422, 90484.77045436,\n",
      "       90484.77045459, 90484.77045473, 90484.77045477, 90484.77045493]))\n",
      "           fun: 90484.7704538244\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1185\n",
      "           nit: 456\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.08771419e-02, 3.15990099e-02, 4.33952910e-02, 2.10684217e+03,\n",
      "       6.80498898e+03, 6.67304328e+03, 4.34566725e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90880.97895039347, bestParams: [0.024393914, 0.062279228, 0.049727906, 4949.1357, 22385.908, 15643.343, 17572.701]\n",
      "epoch 6\n",
      " final_simplex: (array([[3.06168610e-02, 4.95983339e-02, 4.25957054e-02, 6.09077079e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168609e-02, 4.95983338e-02, 4.25957054e-02, 6.09077077e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168610e-02, 4.95983339e-02, 4.25957053e-02, 6.09077077e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168608e-02, 4.95983342e-02, 4.25957057e-02, 6.09077079e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168608e-02, 4.95983345e-02, 4.25957059e-02, 6.09077080e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168606e-02, 4.95983349e-02, 4.25957058e-02, 6.09077083e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168607e-02, 4.95983349e-02, 4.25957063e-02, 6.09077083e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168606e-02, 4.95983351e-02, 4.25957061e-02, 6.09077086e+03,\n",
      "        1.90729034e+04, 1.73021239e+04, 1.45279573e+04]]), array([90486.75336569, 90486.75336575, 90486.75336577, 90486.75336609,\n",
      "       90486.75336629, 90486.75336661, 90486.75336662, 90486.75336664]))\n",
      "           fun: 90486.75336568736\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1230\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.06168610e-02, 4.95983339e-02, 4.25957054e-02, 6.09077079e+03,\n",
      "       1.90729035e+04, 1.73021239e+04, 1.45279573e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 91497.65906267175, bestParams: [0.054666173, 0.09095881, 0.06649772, 5459.7817, 5106.5513, 5879.891, 11712.161]\n",
      "epoch 7\n",
      " final_simplex: (array([[4.30860784e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "        9.78249630e+03, 9.13774297e+03, 7.77570167e+03],\n",
      "       [4.30860784e-02, 4.05039918e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249625e+03, 9.13774294e+03, 7.77570159e+03],\n",
      "       [4.30860785e-02, 4.05039917e-02, 4.19283439e-02, 3.17918518e+03,\n",
      "        9.78249632e+03, 9.13774297e+03, 7.77570168e+03],\n",
      "       [4.30860788e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "        9.78249631e+03, 9.13774300e+03, 7.77570166e+03],\n",
      "       [4.30860793e-02, 4.05039921e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249629e+03, 9.13774301e+03, 7.77570167e+03],\n",
      "       [4.30860797e-02, 4.05039928e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249627e+03, 9.13774295e+03, 7.77570175e+03],\n",
      "       [4.30860799e-02, 4.05039931e-02, 4.19283442e-02, 3.17918518e+03,\n",
      "        9.78249625e+03, 9.13774295e+03, 7.77570174e+03],\n",
      "       [4.30860800e-02, 4.05039930e-02, 4.19283442e-02, 3.17918518e+03,\n",
      "        9.78249624e+03, 9.13774295e+03, 7.77570174e+03]]), array([90480.57137342, 90480.57137345, 90480.57137348, 90480.57137366,\n",
      "       90480.57137391, 90480.571374  , 90480.57137409, 90480.57137411]))\n",
      "           fun: 90480.57137341992\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1357\n",
      "           nit: 569\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.30860784e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "       9.78249630e+03, 9.13774297e+03, 7.77570167e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90748.30062683142, bestParams: [0.07419606, 0.039394133, 0.028832112, 6168.2896, 21175.932, 24372.55, 6964.5005]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.83425215e-02, 3.05141356e-02, 4.41328425e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425210e-02, 3.05141358e-02, 4.41328427e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425213e-02, 3.05141355e-02, 4.41328426e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425204e-02, 3.05141360e-02, 4.41328427e-02, 6.29920487e+03,\n",
      "        2.23644696e+04, 2.12074130e+04, 1.02575861e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644696e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425206e-02, 3.05141358e-02, 4.41328426e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575861e+04]]), array([90499.4328383 , 90499.43283833, 90499.43283834, 90499.4328384 ,\n",
      "       90499.43283843, 90499.43283848, 90499.43283849, 90499.43283851]))\n",
      "           fun: 90499.43283829854\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1204\n",
      "           nit: 459\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.83425215e-02, 3.05141356e-02, 4.41328425e-02, 6.29920489e+03,\n",
      "       2.23644697e+04, 2.12074130e+04, 1.02575860e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 91296.27290015653, bestParams: [0.11290184, 0.13054714, 0.1386694, 5181.501, 8365.07, 8362.464, 14073.521]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.02097583e-02, 1.10225090e-01, 5.28885652e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097588e-02, 1.10225090e-01, 5.28885651e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097587e-02, 1.10225090e-01, 5.28885651e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097504e-02, 1.10225090e-01, 5.28885671e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099462e+04],\n",
      "       [9.02097550e-02, 1.10225090e-01, 5.28885660e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097555e-02, 1.10225090e-01, 5.28885659e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097559e-02, 1.10225090e-01, 5.28885658e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097561e-02, 1.10225090e-01, 5.28885658e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04]]), array([90626.40935142, 90626.40935145, 90626.40935145, 90626.40935773,\n",
      "       90626.40935794, 90626.40935797, 90626.40935799, 90626.40935799]))\n",
      "           fun: 90626.40935142341\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2984\n",
      "           nit: 1336\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.02097583e-02, 1.10225090e-01, 5.28885652e-02, 5.25880194e+03,\n",
      "       1.01009865e+04, 1.00144483e+04, 1.76099461e+04])\n",
      "minPrevious 90476.89262346049\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0397, 0.0384, 0.0402], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8799, 0.0645, 0.0279, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8632, 0.0797, 0.0259, 0.0312], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8797, 0.0279, 0.0630, 0.0252], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8646, 0.0259, 0.0782, 0.0313], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7380, 0.0977, 0.0978, 0.0611], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7017, 0.1143, 0.1130, 0.0710], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7900, 4.1484, 4.0321],\n",
      "        [3.0761, 4.3315, 6.6560],\n",
      "        [2.8822, 3.3881, 5.3680],\n",
      "        ...,\n",
      "        [2.3470, 2.6197, 4.9254],\n",
      "        [1.9785, 2.4099, 3.6386],\n",
      "        [2.8596, 1.1003, 4.5087]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.632166147232056\n",
      "Run: 0, 2\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[38.,  5.,  3.,  2.],\n",
      "        [46.,  6.,  0.,  4.],\n",
      "        [42.,  5.,  3.,  4.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [53.,  2.,  3.,  2.],\n",
      "        [47.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([48., 56., 54.,  ..., 70., 60., 50.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 6., 5.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 3.,  ..., 2., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 4., 4.,  ..., 2., 2., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[38.,  5.,  3.,  2.],\n",
      "        [46.,  6.,  0.,  4.],\n",
      "        [42.,  5.,  3.,  4.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [53.,  2.,  3.,  2.],\n",
      "        [47.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([5.5336e-05, 2.3030e-06, 3.0288e-06,  ..., 5.4883e-03, 4.3785e-03,\n",
      "        3.9273e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3eb90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90729.31401045548, bestParams: [0.04714876, 0.012392071, 0.053447075, 7013.6914, 12085.93, 22692.54, 17837.424]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.33117250e-02, 2.04074664e-02, 4.59170420e-02, 5.82361142e+03,\n",
      "        1.80858056e+04, 2.06137097e+04, 9.83484979e+03],\n",
      "       [3.33117247e-02, 2.04074666e-02, 4.59170423e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484977e+03],\n",
      "       [3.33117250e-02, 2.04074665e-02, 4.59170422e-02, 5.82361140e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484981e+03],\n",
      "       [3.33117246e-02, 2.04074667e-02, 4.59170427e-02, 5.82361135e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484984e+03],\n",
      "       [3.33117235e-02, 2.04074668e-02, 4.59170428e-02, 5.82361134e+03,\n",
      "        1.80858056e+04, 2.06137097e+04, 9.83484973e+03],\n",
      "       [3.33117244e-02, 2.04074666e-02, 4.59170425e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484982e+03],\n",
      "       [3.33117253e-02, 2.04074665e-02, 4.59170425e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484977e+03],\n",
      "       [3.33117247e-02, 2.04074666e-02, 4.59170427e-02, 5.82361137e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484979e+03]]), array([90493.42080322, 90493.42080323, 90493.42080334, 90493.42080338,\n",
      "       90493.4208034 , 90493.42080347, 90493.42080347, 90493.42080351]))\n",
      "           fun: 90493.42080322158\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1276\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.33117250e-02, 2.04074664e-02, 4.59170420e-02, 5.82361142e+03,\n",
      "       1.80858056e+04, 2.06137097e+04, 9.83484979e+03])\n",
      "best ll: 90732.75782383714, bestParams: [0.026286537, 0.090551235, 0.06254556, 6272.722, 16600.713, 17853.037, 18413.832]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379185e-02, 3.65881725e-02, 4.13337161e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379184e-02, 3.65881725e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379192e-02, 3.65881712e-02, 4.13337149e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379215e-02, 3.65881670e-02, 4.13337104e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379220e-02, 3.65881662e-02, 4.13337095e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04]]), array([90476.45793291, 90476.45793291, 90476.45793292, 90476.45793292,\n",
      "       90476.45793305, 90476.45793305, 90476.45793305, 90476.45793306]))\n",
      "           fun: 90476.45793290669\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2009\n",
      "           nit: 867\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "       2.20264360e+04, 2.27778555e+04, 1.56540855e+04])\n",
      "minPrevious 90493.42080322158\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379185e-02, 3.65881725e-02, 4.13337161e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379184e-02, 3.65881725e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379192e-02, 3.65881712e-02, 4.13337149e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379215e-02, 3.65881670e-02, 4.13337104e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379220e-02, 3.65881662e-02, 4.13337095e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04]]), array([90476.45793291, 90476.45793291, 90476.45793292, 90476.45793292,\n",
      "       90476.45793305, 90476.45793305, 90476.45793305, 90476.45793306]))\n",
      "           fun: 90476.45793290669\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2009\n",
      "           nit: 867\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "       2.20264360e+04, 2.27778555e+04, 1.56540855e+04])\n",
      "best ll: 90768.5476276376, bestParams: [0.035219885, 0.09352289, 0.08136546, 7144.487, 12225.303, 11796.263, 16765.65]\n",
      "epoch 2\n",
      " final_simplex: (array([[4.65238400e-02, 6.44146076e-02, 4.12197981e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146078e-02, 4.12197982e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146078e-02, 4.12197982e-02, 5.96552759e+03,\n",
      "        1.68314529e+04, 1.52391460e+04, 1.52451012e+04],\n",
      "       [4.65238401e-02, 6.44146081e-02, 4.12197979e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238401e-02, 6.44146082e-02, 4.12197980e-02, 5.96552759e+03,\n",
      "        1.68314529e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146084e-02, 4.12197976e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451012e+04],\n",
      "       [4.65238401e-02, 6.44146083e-02, 4.12197978e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146084e-02, 4.12197976e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451012e+04]]), array([90515.26528606, 90515.26528614, 90515.26528617, 90515.26528672,\n",
      "       90515.26528676, 90515.26528692, 90515.26528698, 90515.26528702]))\n",
      "           fun: 90515.26528606444\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1692\n",
      "           nit: 718\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.65238400e-02, 6.44146076e-02, 4.12197981e-02, 5.96552759e+03,\n",
      "       1.68314530e+04, 1.52391460e+04, 1.52451011e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 91066.53966861677, bestParams: [0.074466266, 0.08731467, 0.05386589, 5332.576, 21387.4, 14033.31, 14331.92]\n",
      "epoch 3\n",
      " final_simplex: (array([[6.01747648e-02, 4.74827058e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747647e-02, 4.74827060e-02, 4.25113519e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747646e-02, 4.74827057e-02, 4.25113525e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267154e+04],\n",
      "       [6.01747648e-02, 4.74827057e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747647e-02, 4.74827060e-02, 4.25113524e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267154e+04],\n",
      "       [6.01747649e-02, 4.74827058e-02, 4.25113522e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747649e-02, 4.74827055e-02, 4.25113523e-02, 6.63523070e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267156e+04],\n",
      "       [6.01747651e-02, 4.74827060e-02, 4.25113520e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04]]), array([90504.39416636, 90504.39416637, 90504.39416639, 90504.3941664 ,\n",
      "       90504.39416647, 90504.39416659, 90504.39416662, 90504.39416662]))\n",
      "           fun: 90504.39416636349\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1256\n",
      "           nit: 502\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.01747648e-02, 4.74827058e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "       1.67311435e+04, 1.85195322e+04, 1.85267155e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90970.57307666962, bestParams: [0.0472617, 0.06842829, 0.05356198, 8647.348, 17162.938, 13426.564, 15939.611]\n",
      "epoch 4\n",
      " final_simplex: (array([[4.82379986e-02, 6.64176122e-02, 5.29707453e-02, 6.53249533e+03,\n",
      "        1.67371434e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379985e-02, 6.64176126e-02, 5.29707455e-02, 6.53249532e+03,\n",
      "        1.67371435e+04, 1.62008374e+04, 1.69415655e+04],\n",
      "       [4.82379985e-02, 6.64176125e-02, 5.29707455e-02, 6.53249531e+03,\n",
      "        1.67371435e+04, 1.62008374e+04, 1.69415655e+04],\n",
      "       [4.82379987e-02, 6.64176129e-02, 5.29707456e-02, 6.53249531e+03,\n",
      "        1.67371434e+04, 1.62008374e+04, 1.69415654e+04],\n",
      "       [4.82379989e-02, 6.64176128e-02, 5.29707456e-02, 6.53249531e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379995e-02, 6.64176129e-02, 5.29707460e-02, 6.53249531e+03,\n",
      "        1.67371434e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379992e-02, 6.64176132e-02, 5.29707460e-02, 6.53249530e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415654e+04],\n",
      "       [4.82379995e-02, 6.64176132e-02, 5.29707461e-02, 6.53249529e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415655e+04]]), array([90529.94631074, 90529.94631171, 90529.94631177, 90529.94631258,\n",
      "       90529.9463127 , 90529.94631417, 90529.94631475, 90529.94631492]))\n",
      "           fun: 90529.94631074075\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1416\n",
      "           nit: 580\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.82379986e-02, 6.64176122e-02, 5.29707453e-02, 6.53249533e+03,\n",
      "       1.67371434e+04, 1.62008373e+04, 1.69415655e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90676.96857508212, bestParams: [0.019758662, 0.040811747, 0.07994546, 5986.399, 18685.148, 19524.918, 7057.7544]\n",
      "epoch 5\n",
      " final_simplex: (array([[2.16419345e-02, 3.82889994e-02, 4.21537846e-02, 5.67924004e+03,\n",
      "        1.92461813e+04, 1.89292301e+04, 9.56055409e+03],\n",
      "       [2.16419346e-02, 3.82889993e-02, 4.21537843e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292300e+04, 9.56055415e+03],\n",
      "       [2.16419345e-02, 3.82889994e-02, 4.21537847e-02, 5.67924006e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055411e+03],\n",
      "       [2.16419346e-02, 3.82889994e-02, 4.21537843e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055413e+03],\n",
      "       [2.16419346e-02, 3.82889995e-02, 4.21537839e-02, 5.67924004e+03,\n",
      "        1.92461813e+04, 1.89292300e+04, 9.56055416e+03],\n",
      "       [2.16419345e-02, 3.82889994e-02, 4.21537847e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055411e+03],\n",
      "       [2.16419346e-02, 3.82889994e-02, 4.21537842e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055413e+03],\n",
      "       [2.16419345e-02, 3.82889995e-02, 4.21537854e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292302e+04, 9.56055403e+03]]), array([90489.89028648, 90489.89028649, 90489.8902865 , 90489.89028651,\n",
      "       90489.89028664, 90489.89029371, 90489.89029371, 90489.89029372]))\n",
      "           fun: 90489.89028647794\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1144\n",
      "           nit: 370\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.16419345e-02, 3.82889994e-02, 4.21537846e-02, 5.67924004e+03,\n",
      "       1.92461813e+04, 1.89292301e+04, 9.56055409e+03])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90614.04184293446, bestParams: [0.045280494, 0.037793145, 0.059227735, 7774.5674, 18537.154, 16869.389, 16223.571]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.63254603e-02, 4.03578762e-02, 4.26819493e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254605e-02, 4.03578763e-02, 4.26819491e-02, 6.80712184e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04],\n",
      "       [4.63254611e-02, 4.03578752e-02, 4.26819506e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254615e-02, 4.03578750e-02, 4.26819507e-02, 6.80712185e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254623e-02, 4.03578738e-02, 4.26819521e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254625e-02, 4.03578735e-02, 4.26819527e-02, 6.80712185e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04],\n",
      "       [4.63254627e-02, 4.03578731e-02, 4.26819533e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254631e-02, 4.03578727e-02, 4.26819538e-02, 6.80712185e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04]]), array([90481.01067873, 90481.01067887, 90481.01067918, 90481.01067943,\n",
      "       90481.01067984, 90481.01068004, 90481.01068014, 90481.01068039]))\n",
      "           fun: 90481.0106787277\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1407\n",
      "           nit: 591\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.63254603e-02, 4.03578762e-02, 4.26819493e-02, 6.80712183e+03,\n",
      "       1.93045360e+04, 2.10435576e+04, 1.53310997e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 91118.26744689574, bestParams: [0.16203003, 0.019491551, 0.10167087, 9075.078, 17631.64, 23901.205, 12888.103]\n",
      "epoch 7\n",
      " final_simplex: (array([[5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136007e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136009e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136009e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136010e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136010e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04]]), array([90512.80037146, 90512.80037147, 90512.80037148, 90512.80037158,\n",
      "       90512.80037168, 90512.80037168, 90512.8003717 , 90512.80037172]))\n",
      "           fun: 90512.80037145794\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2992\n",
      "           nit: 1354\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "       2.06886979e+04, 2.46288633e+04, 2.07469199e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90838.88955760052, bestParams: [0.01900933, 0.062275536, 0.047462903, 11755.048, 22521.502, 21961.916, 23298.01]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299854e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299854e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219301e-02, 5.02727421e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727421e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04],\n",
      "       [2.01924312e-02, 6.12219301e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04]]), array([90532.29920238, 90532.29920238, 90532.2992024 , 90532.29920254,\n",
      "       90532.29920259, 90532.2992027 , 90532.2992027 , 90532.29920271]))\n",
      "           fun: 90532.2992023793\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2184\n",
      "           nit: 1013\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "       2.50541339e+04, 2.34886631e+04, 2.30431254e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90645.41395072266, bestParams: [0.03879742, 0.05967664, 0.0748788, 9502.963, 20872.686, 20331.674, 22603.602]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04],\n",
      "       [4.06434334e-02, 5.88736021e-02, 5.93604534e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04],\n",
      "       [4.06434335e-02, 5.88736021e-02, 5.93604534e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434334e-02, 5.88736020e-02, 5.93604535e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434335e-02, 5.88736020e-02, 5.93604536e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434334e-02, 5.88736019e-02, 5.93604537e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434333e-02, 5.88736020e-02, 5.93604536e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04]]), array([90534.19459469, 90534.19459469, 90534.19459501, 90534.19459519,\n",
      "       90534.1945955 , 90534.19459563, 90534.19459592, 90534.19459592]))\n",
      "           fun: 90534.1945946857\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1561\n",
      "           nit: 650\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "       2.27999522e+04, 2.37345303e+04, 2.21734048e+04])\n",
      "minPrevious 90476.45793290669\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0330, 0.0366, 0.0413], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8823, 0.0643, 0.0280, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8625, 0.0789, 0.0259, 0.0327], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8854, 0.0280, 0.0632, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8602, 0.0258, 0.0814, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7355, 0.0985, 0.0995, 0.0613], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7058, 0.1106, 0.1127, 0.0709], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4515, 3.4402, 6.3490],\n",
      "        [3.4732, 3.5567, 6.1192],\n",
      "        [2.5983, 1.4514, 4.2065],\n",
      "        ...,\n",
      "        [2.9968, 3.2012, 6.9698],\n",
      "        [3.0024, 3.0444, 5.9488],\n",
      "        [3.8132, 4.7613, 6.0924]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.432267189025879\n",
      "Run: 0, 3\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  0.],\n",
      "        [45.,  6.,  2.,  3.],\n",
      "        [35.,  6.,  2.,  3.],\n",
      "        ...,\n",
      "        [52.,  0.,  0.,  0.],\n",
      "        [49.,  2.,  0.,  0.],\n",
      "        [45.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "n tensor([45., 56., 46.,  ..., 52., 51., 49.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 6.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 2.,  ..., 0., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 3., 3.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  0.],\n",
      "        [45.,  6.,  2.,  3.],\n",
      "        [35.,  6.,  2.,  3.],\n",
      "        ...,\n",
      "        [52.,  0.,  0.,  0.],\n",
      "        [49.,  2.,  0.,  0.],\n",
      "        [45.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([7.8009e-02, 1.5891e-05, 2.8535e-06,  ..., 2.6907e-02, 3.3099e-02,\n",
      "        2.7306e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3e8c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90687.73814175435, bestParams: [0.020037124, 0.0016247494, 0.040445533, 5294.021, 10814.926, 12456.389, 21372.918]\n",
      "epoch 0\n",
      " final_simplex: (array([[6.23123949e-02, 6.27163447e-03, 4.18681284e-02, 1.50217719e+03,\n",
      "        4.00664783e+03, 5.09986993e+03, 3.23227687e+03],\n",
      "       [6.23123948e-02, 6.27163447e-03, 4.18681283e-02, 1.50217718e+03,\n",
      "        4.00664785e+03, 5.09986989e+03, 3.23227688e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681282e-02, 1.50217718e+03,\n",
      "        4.00664787e+03, 5.09986996e+03, 3.23227683e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681282e-02, 1.50217718e+03,\n",
      "        4.00664788e+03, 5.09986997e+03, 3.23227683e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681281e-02, 1.50217718e+03,\n",
      "        4.00664789e+03, 5.09986998e+03, 3.23227682e+03],\n",
      "       [6.23123947e-02, 6.27163449e-03, 4.18681278e-02, 1.50217718e+03,\n",
      "        4.00664791e+03, 5.09986998e+03, 3.23227682e+03],\n",
      "       [6.23123950e-02, 6.27163449e-03, 4.18681283e-02, 1.50217718e+03,\n",
      "        4.00664785e+03, 5.09986993e+03, 3.23227683e+03],\n",
      "       [6.23123948e-02, 6.27163449e-03, 4.18681280e-02, 1.50217718e+03,\n",
      "        4.00664789e+03, 5.09986997e+03, 3.23227682e+03]]), array([90272.52946674, 90272.52946678, 90272.52946686, 90272.52946687,\n",
      "       90272.52946696, 90272.52946701, 90272.52946703, 90272.52946704]))\n",
      "           fun: 90272.52946674361\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1461\n",
      "           nit: 666\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.23123949e-02, 6.27163447e-03, 4.18681284e-02, 1.50217719e+03,\n",
      "       4.00664783e+03, 5.09986993e+03, 3.23227687e+03])\n",
      "best ll: 90497.28227752695, bestParams: [0.06955907, 0.049383625, 0.019450903, 993.1664, 3395.9521, 4111.0713, 3434.7034]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "        3.48913750e+03, 3.62500697e+03, 2.81886087e+03],\n",
      "       [4.14664508e-02, 3.51992356e-02, 3.96515439e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500699e+03, 2.81886085e+03],\n",
      "       [4.14664512e-02, 3.51992344e-02, 3.96515438e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500696e+03, 2.81886087e+03],\n",
      "       [4.14664522e-02, 3.51992339e-02, 3.96515431e-02, 1.18685429e+03,\n",
      "        3.48913748e+03, 3.62500698e+03, 2.81886091e+03],\n",
      "       [4.14664516e-02, 3.51992308e-02, 3.96515449e-02, 1.18685428e+03,\n",
      "        3.48913748e+03, 3.62500705e+03, 2.81886082e+03],\n",
      "       [4.14664515e-02, 3.51992312e-02, 3.96515447e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500707e+03, 2.81886080e+03],\n",
      "       [4.14664519e-02, 3.51992301e-02, 3.96515453e-02, 1.18685429e+03,\n",
      "        3.48913751e+03, 3.62500700e+03, 2.81886079e+03],\n",
      "       [4.14664531e-02, 3.51992354e-02, 3.96515419e-02, 1.18685429e+03,\n",
      "        3.48913745e+03, 3.62500700e+03, 2.81886093e+03]]), array([90173.52423769, 90173.52423776, 90173.52423781, 90173.52423785,\n",
      "       90173.52423792, 90173.52423796, 90173.52423814, 90173.52423952]))\n",
      "           fun: 90173.52423769064\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1084\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "       3.48913750e+03, 3.62500697e+03, 2.81886087e+03])\n",
      "minPrevious 90272.52946674361\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "        3.48913750e+03, 3.62500697e+03, 2.81886087e+03],\n",
      "       [4.14664508e-02, 3.51992356e-02, 3.96515439e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500699e+03, 2.81886085e+03],\n",
      "       [4.14664512e-02, 3.51992344e-02, 3.96515438e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500696e+03, 2.81886087e+03],\n",
      "       [4.14664522e-02, 3.51992339e-02, 3.96515431e-02, 1.18685429e+03,\n",
      "        3.48913748e+03, 3.62500698e+03, 2.81886091e+03],\n",
      "       [4.14664516e-02, 3.51992308e-02, 3.96515449e-02, 1.18685428e+03,\n",
      "        3.48913748e+03, 3.62500705e+03, 2.81886082e+03],\n",
      "       [4.14664515e-02, 3.51992312e-02, 3.96515447e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500707e+03, 2.81886080e+03],\n",
      "       [4.14664519e-02, 3.51992301e-02, 3.96515453e-02, 1.18685429e+03,\n",
      "        3.48913751e+03, 3.62500700e+03, 2.81886079e+03],\n",
      "       [4.14664531e-02, 3.51992354e-02, 3.96515419e-02, 1.18685429e+03,\n",
      "        3.48913745e+03, 3.62500700e+03, 2.81886093e+03]]), array([90173.52423769, 90173.52423776, 90173.52423781, 90173.52423785,\n",
      "       90173.52423792, 90173.52423796, 90173.52423814, 90173.52423952]))\n",
      "           fun: 90173.52423769064\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1084\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "       3.48913750e+03, 3.62500697e+03, 2.81886087e+03])\n",
      "best ll: 90579.49768806256, bestParams: [0.03288942, 0.02397951, 0.07897693, 8103.033, 16135.493, 20025.127, 11541.397]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.42412644e-02, 2.66188892e-02, 4.06631400e-02, 6.36961886e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707348e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631401e-02, 6.36961884e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631400e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412646e-02, 2.66188891e-02, 4.06631403e-02, 6.36961884e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631402e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631403e-02, 6.36961883e+03,\n",
      "        1.97342763e+04, 2.11661146e+04, 1.37707349e+04],\n",
      "       [3.42412646e-02, 2.66188891e-02, 4.06631406e-02, 6.36961883e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412644e-02, 2.66188891e-02, 4.06631404e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707348e+04]]), array([90179.97233838, 90179.9723385 , 90179.97233857, 90179.97233863,\n",
      "       90179.97233866, 90179.97233875, 90179.97233881, 90179.97233886]))\n",
      "           fun: 90179.97233838026\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1185\n",
      "           nit: 451\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.42412644e-02, 2.66188892e-02, 4.06631400e-02, 6.36961886e+03,\n",
      "       1.97342764e+04, 2.11661147e+04, 1.37707348e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90290.6061973017, bestParams: [0.03196858, 0.025042191, 0.034106273, 8508.276, 24321.596, 20359.771, 22960.518]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.41951284e-02, 2.69611168e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757822e+04],\n",
      "       [3.41951285e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951284e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951286e-02, 2.69611168e-02, 3.76004125e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04]]), array([90177.91638654, 90177.91638655, 90177.91638656, 90177.91638657,\n",
      "       90177.91638659, 90177.9163866 , 90177.9163866 , 90177.91638661]))\n",
      "           fun: 90177.91638654124\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1191\n",
      "           nit: 457\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.41951284e-02, 2.69611168e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "       2.34625869e+04, 2.45893096e+04, 1.64757822e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90575.35435100387, bestParams: [0.0060032983, 0.026933348, 0.054366462, 7137.234, 10640.545, 9179.854, 21404.568]\n",
      "epoch 4\n",
      " final_simplex: (array([[8.03986655e-03, 2.82214893e-02, 4.14128756e-02, 4.25668422e+03,\n",
      "        1.54685785e+04, 1.41980696e+04, 6.95569755e+03],\n",
      "       [8.03986660e-03, 2.82214881e-02, 4.14128762e-02, 4.25668422e+03,\n",
      "        1.54685784e+04, 1.41980697e+04, 6.95569753e+03],\n",
      "       [8.03986647e-03, 2.82214902e-02, 4.14128754e-02, 4.25668422e+03,\n",
      "        1.54685786e+04, 1.41980695e+04, 6.95569755e+03],\n",
      "       [8.03986655e-03, 2.82214896e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569747e+03],\n",
      "       [8.03986653e-03, 2.82214897e-02, 4.14128750e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569756e+03],\n",
      "       [8.03986652e-03, 2.82214897e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685786e+04, 1.41980696e+04, 6.95569756e+03],\n",
      "       [8.03986652e-03, 2.82214894e-02, 4.14128750e-02, 4.25668422e+03,\n",
      "        1.54685785e+04, 1.41980696e+04, 6.95569755e+03],\n",
      "       [8.03986650e-03, 2.82214895e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569751e+03]]), array([90268.35024825, 90268.35024842, 90268.35024844, 90268.35024859,\n",
      "       90268.3502486 , 90268.3502487 , 90268.35024901, 90268.35024905]))\n",
      "           fun: 90268.35024824677\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1183\n",
      "           nit: 456\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.03986655e-03, 2.82214893e-02, 4.14128756e-02, 4.25668422e+03,\n",
      "       1.54685785e+04, 1.41980696e+04, 6.95569755e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90520.96658633223, bestParams: [0.006762284, 0.055848576, 0.053748373, 5909.411, 13514.936, 18434.523, 10014.059]\n",
      "epoch 5\n",
      " final_simplex: (array([[8.16848907e-03, 4.04653276e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848907e-03, 4.04653277e-02, 4.27240406e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848906e-03, 4.04653277e-02, 4.27240406e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751150e+04],\n",
      "       [8.16848904e-03, 4.04653280e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848902e-03, 4.04653284e-02, 4.27240407e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848900e-03, 4.04653289e-02, 4.27240411e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453744e+04, 1.08751149e+04],\n",
      "       [8.16848899e-03, 4.04653285e-02, 4.27240409e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751150e+04],\n",
      "       [8.16848898e-03, 4.04653292e-02, 4.27240411e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453744e+04, 1.08751149e+04]]), array([90267.56486031, 90267.56486033, 90267.5648605 , 90267.56486061,\n",
      "       90267.56486088, 90267.56486105, 90267.56486109, 90267.56486112]))\n",
      "           fun: 90267.56486031177\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1342\n",
      "           nit: 543\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.16848907e-03, 4.04653276e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "       1.78493877e+04, 1.54453745e+04, 1.08751149e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90581.20782424859, bestParams: [0.10886746, 0.06707341, 0.07024887, 10999.218, 23754.08, 24885.004, 19561.732]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.83275297e-02, 5.67416707e-02, 3.65272603e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573896e+04, 3.13480199e+04],\n",
      "       [4.83275299e-02, 5.67416707e-02, 3.65272602e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573896e+04, 3.13480199e+04],\n",
      "       [4.83275332e-02, 5.67416700e-02, 3.65272598e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480198e+04],\n",
      "       [4.83275290e-02, 5.67416709e-02, 3.65272605e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275295e-02, 5.67416707e-02, 3.65272600e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275297e-02, 5.67416707e-02, 3.65272600e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275298e-02, 5.67416707e-02, 3.65272599e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480200e+04],\n",
      "       [4.83275303e-02, 5.67416706e-02, 3.65272598e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04]]), array([90189.04135044, 90189.04135049, 90189.0413505 , 90189.04135052,\n",
      "       90189.04135053, 90189.04135054, 90189.04135061, 90189.04135062]))\n",
      "           fun: 90189.04135044114\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1331\n",
      "           nit: 546\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83275297e-02, 5.67416707e-02, 3.65272603e-02, 1.05765347e+04,\n",
      "       2.91787862e+04, 2.91573896e+04, 3.13480199e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90555.35314912771, bestParams: [0.075666025, 0.008240507, 0.07280902, 4451.4316, 14403.895, 18652.873, 7124.4673]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.75345528e-02, 1.18217802e-02, 4.36060567e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302072e+03],\n",
      "       [3.75345531e-02, 1.18217801e-02, 4.36060564e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302069e+03],\n",
      "       [3.75345538e-02, 1.18217800e-02, 4.36060561e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249052e+04, 8.93302064e+03],\n",
      "       [3.75345535e-02, 1.18217800e-02, 4.36060565e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249052e+04, 8.93302072e+03],\n",
      "       [3.75345529e-02, 1.18217799e-02, 4.36060556e-02, 4.78113062e+03,\n",
      "        1.46175004e+04, 1.68249053e+04, 8.93302074e+03],\n",
      "       [3.75345543e-02, 1.18217799e-02, 4.36060568e-02, 4.78113064e+03,\n",
      "        1.46175002e+04, 1.68249052e+04, 8.93302079e+03],\n",
      "       [3.75345536e-02, 1.18217798e-02, 4.36060554e-02, 4.78113063e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302072e+03],\n",
      "       [3.75345542e-02, 1.18217797e-02, 4.36060553e-02, 4.78113064e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302075e+03]]), array([90221.61895767, 90221.61895817, 90221.61895843, 90221.61895862,\n",
      "       90221.61895898, 90221.61895898, 90221.61895918, 90221.61895972]))\n",
      "           fun: 90221.61895766677\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1194\n",
      "           nit: 489\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.75345528e-02, 1.18217802e-02, 4.36060567e-02, 4.78113062e+03,\n",
      "       1.46175003e+04, 1.68249053e+04, 8.93302072e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90395.4796038286, bestParams: [0.06134892, 0.003452808, 0.03632547, 3497.0854, 10186.098, 13472.928, 3790.0637]\n",
      "epoch 8\n",
      " final_simplex: (array([[3.49284716e-02, 4.18222349e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580012e+03],\n",
      "       [3.49284732e-02, 4.18222342e-03, 4.69575910e-02, 3.10646349e+03,\n",
      "        9.64244548e+03, 1.13777085e+04, 4.91580008e+03],\n",
      "       [3.49284699e-02, 4.18222349e-03, 4.69575907e-02, 3.10646349e+03,\n",
      "        9.64244538e+03, 1.13777085e+04, 4.91580018e+03],\n",
      "       [3.49284715e-02, 4.18222344e-03, 4.69575909e-02, 3.10646349e+03,\n",
      "        9.64244541e+03, 1.13777085e+04, 4.91580014e+03],\n",
      "       [3.49284719e-02, 4.18222343e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "        9.64244541e+03, 1.13777085e+04, 4.91580014e+03],\n",
      "       [3.49284714e-02, 4.18222340e-03, 4.69575908e-02, 3.10646349e+03,\n",
      "        9.64244538e+03, 1.13777086e+04, 4.91580016e+03],\n",
      "       [3.49284753e-02, 4.18222328e-03, 4.69575913e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580006e+03],\n",
      "       [3.49284752e-02, 4.18222327e-03, 4.69575913e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580007e+03]]), array([90285.22832312, 90285.22832343, 90285.22832362, 90285.22832367,\n",
      "       90285.22832372, 90285.22832417, 90285.22832441, 90285.22832463]))\n",
      "           fun: 90285.22832312356\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 492\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.49284716e-02, 4.18222349e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "       9.64244544e+03, 1.13777085e+04, 4.91580012e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90804.47701967844, bestParams: [0.02829881, 0.04583288, 0.060337245, 3230.8723, 12052.119, 7720.8174, 1496.0844]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809893e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809893e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809891e+03, 5.06995532e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809891e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167376e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995534e+03, 3.69568086e+03]]), array([90177.73267181, 90177.73267182, 90177.73267233, 90177.73267234,\n",
      "       90177.73267234, 90177.73267235, 90177.73267237, 90177.73267239]))\n",
      "           fun: 90177.73267181247\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1430\n",
      "           nit: 545\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "       5.11809893e+03, 5.06995534e+03, 3.69568086e+03])\n",
      "minPrevious 90173.52423769064\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0415, 0.0352, 0.0397], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8723, 0.0624, 0.0276, 0.0250], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8661, 0.0763, 0.0259, 0.0318], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8843, 0.0280, 0.0639, 0.0256], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8633, 0.0259, 0.0792, 0.0316], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7430, 0.0978, 0.0982, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7028, 0.1122, 0.1146, 0.0705], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4822, 2.8212, 6.3377],\n",
      "        [4.2235, 4.4837, 6.1296],\n",
      "        [1.2765, 2.0591, 4.8962],\n",
      "        ...,\n",
      "        [4.5062, 4.2377, 5.8085],\n",
      "        [1.4207, 1.4554, 5.4347],\n",
      "        [4.4840, 3.6525, 6.3723]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.543172121047974\n",
      "Run: 0, 4\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[49., 11.,  0.,  0.],\n",
      "        [39.,  2.,  1.,  1.],\n",
      "        [35.,  3.,  1.,  4.],\n",
      "        ...,\n",
      "        [42.,  4.,  2.,  0.],\n",
      "        [43.,  0.,  1.,  4.],\n",
      "        [55.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([60., 43., 43.,  ..., 48., 48., 57.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([11.,  2.,  3.,  ...,  4.,  0.,  1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 4.,  ..., 0., 4., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[49., 11.,  0.,  0.],\n",
      "        [39.,  2.,  1.,  1.],\n",
      "        [35.,  3.,  1.,  4.],\n",
      "        ...,\n",
      "        [42.,  4.,  2.,  0.],\n",
      "        [43.,  0.,  1.,  4.],\n",
      "        [55.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([9.3661e-08, 2.4138e-02, 3.4307e-05,  ..., 4.7683e-03, 1.8925e-04,\n",
      "        5.4601e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3ed40>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91158.47332401684, bestParams: [0.014721362, 0.040411327, 0.04527418, 4070.2559, 20366.186, 16429.271, 14589.068]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.72872707e-02, 4.17161449e-02, 4.35534533e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534529e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514173e+04, 1.15286872e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534536e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514175e+04, 1.15286870e+04],\n",
      "       [1.72872708e-02, 4.17161450e-02, 4.35534534e-02, 5.36272838e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161450e-02, 4.35534530e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534535e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514175e+04, 1.15286871e+04],\n",
      "       [1.72872706e-02, 4.17161451e-02, 4.35534529e-02, 5.36272841e+03,\n",
      "        1.76994581e+04, 1.59514173e+04, 1.15286872e+04],\n",
      "       [1.72872706e-02, 4.17161446e-02, 4.35534535e-02, 5.36272842e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04]]), array([90634.76874514, 90634.76874517, 90634.7687452 , 90634.76874525,\n",
      "       90634.76874526, 90634.76874527, 90634.76874536, 90634.76874539]))\n",
      "           fun: 90634.76874513857\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1217\n",
      "           nit: 489\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.72872707e-02, 4.17161449e-02, 4.35534533e-02, 5.36272840e+03,\n",
      "       1.76994581e+04, 1.59514174e+04, 1.15286871e+04])\n",
      "best ll: 91029.49863072427, bestParams: [0.000116868476, 0.083636425, 0.05230697, 6775.021, 20220.621, 12728.145, 23588.809]\n",
      "epoch 1\n",
      " final_simplex: (array([[1.18818834e-04, 8.64093273e-02, 5.59627736e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818831e-04, 8.64093286e-02, 5.59627736e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818831e-04, 8.64093282e-02, 5.59627739e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008582e+04],\n",
      "       [1.18818830e-04, 8.64093284e-02, 5.59627741e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818829e-04, 8.64093286e-02, 5.59627741e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008582e+04],\n",
      "       [1.18818827e-04, 8.64093296e-02, 5.59627742e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818824e-04, 8.64093300e-02, 5.59627745e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008580e+04],\n",
      "       [1.18818824e-04, 8.64093304e-02, 5.59627745e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04]]), array([90829.02245938, 90829.02246006, 90829.02246008, 90829.02246026,\n",
      "       90829.02246044, 90829.02246087, 90829.02246132, 90829.02246156]))\n",
      "           fun: 90829.02245937861\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1663\n",
      "           nit: 713\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.18818834e-04, 8.64093273e-02, 5.59627736e-02, 7.16703301e+03,\n",
      "       1.82555166e+04, 1.55257759e+04, 1.81008581e+04])\n",
      "minPrevious 90634.76874513857\n",
      "best ll: 90847.93749848523, bestParams: [0.07447942, 0.020183373, 0.01751763, 5548.3296, 16806.486, 18398.387, 15708.237]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368230e+03],\n",
      "       [3.32608952e-02, 2.91607544e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786958e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598481e+04, 9.34368237e+03],\n",
      "       [3.32608968e-02, 2.91607543e-02, 3.74786956e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368236e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786957e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368233e+03],\n",
      "       [3.32608950e-02, 2.91607544e-02, 3.74786960e-02, 4.76599757e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608951e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117015e+04, 1.59598482e+04, 9.34368238e+03],\n",
      "       [3.32608951e-02, 2.91607543e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03]]), array([90610.2728004 , 90610.27280042, 90610.27280048, 90610.27280051,\n",
      "       90610.27280056, 90610.27280063, 90610.27280069, 90610.27280072]))\n",
      "           fun: 90610.27280040468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "       1.59117016e+04, 1.59598482e+04, 9.34368230e+03])\n",
      "minPrevious 90634.76874513857\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368230e+03],\n",
      "       [3.32608952e-02, 2.91607544e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786958e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598481e+04, 9.34368237e+03],\n",
      "       [3.32608968e-02, 2.91607543e-02, 3.74786956e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368236e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786957e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368233e+03],\n",
      "       [3.32608950e-02, 2.91607544e-02, 3.74786960e-02, 4.76599757e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608951e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117015e+04, 1.59598482e+04, 9.34368238e+03],\n",
      "       [3.32608951e-02, 2.91607543e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03]]), array([90610.2728004 , 90610.27280042, 90610.27280048, 90610.27280051,\n",
      "       90610.27280056, 90610.27280063, 90610.27280069, 90610.27280072]))\n",
      "           fun: 90610.27280040468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "       1.59117016e+04, 1.59598482e+04, 9.34368230e+03])\n",
      "best ll: 90890.4621477907, bestParams: [0.028222447, 0.017594956, 0.0381772, 3712.175, 18208.807, 12144.222, 4784.1777]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.32745082e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086204e+03],\n",
      "       [3.32745080e-02, 2.12040114e-02, 4.29595582e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595581e-02, 3.36413636e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086202e+03],\n",
      "       [3.32745081e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086205e+03],\n",
      "       [3.32745080e-02, 2.12040113e-02, 4.29595581e-02, 3.36413636e+03,\n",
      "        1.12159341e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595582e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086205e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595583e-02, 3.36413636e+03,\n",
      "        1.12159339e+04, 1.19742536e+04, 5.79086203e+03]]), array([90628.72181675, 90628.72181677, 90628.72181677, 90628.72181681,\n",
      "       90628.72181681, 90628.72181685, 90628.7218169 , 90628.7218169 ]))\n",
      "           fun: 90628.72181674631\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1181\n",
      "           nit: 436\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32745082e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "       1.12159340e+04, 1.19742536e+04, 5.79086204e+03])\n",
      "minPrevious 90610.27280040468\n",
      "best ll: 90804.34225338264, bestParams: [0.023374725, 0.09260894, 0.04005881, 8117.6123, 16497.006, 16204.368, 24964.37]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274795e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190240e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819772e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190242e-02, 3.86819771e-02, 6.92017778e+03,\n",
      "        2.38232316e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190238e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274795e+04],\n",
      "       [2.53037902e-02, 4.64190240e-02, 3.86819774e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472489e+04, 1.47274796e+04]]), array([90610.97812776, 90610.97812779, 90610.9781278 , 90610.9781278 ,\n",
      "       90610.97812784, 90610.97812801, 90610.97814434, 90610.97814438]))\n",
      "           fun: 90610.97812776301\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1231\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "       2.38232317e+04, 2.13472490e+04, 1.47274795e+04])\n",
      "minPrevious 90610.27280040468\n",
      "best ll: 91012.84705452244, bestParams: [0.06232762, 0.034690365, 0.038248792, 3659.6003, 12318.186, 6756.515, 8484.942]\n",
      "epoch 5\n",
      " final_simplex: (array([[4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861992e+03],\n",
      "       [4.83273467e-02, 4.23176213e-02, 4.03140866e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861993e+03],\n",
      "       [4.83273481e-02, 4.23176224e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273481e-02, 4.23176225e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273487e-02, 4.23176230e-02, 4.03140823e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862000e+03],\n",
      "       [4.83273490e-02, 4.23176232e-02, 4.03140817e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273491e-02, 4.23176233e-02, 4.03140815e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273494e-02, 4.23176235e-02, 4.03140810e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862002e+03]]), array([90604.5572683 , 90604.55726843, 90604.55726955, 90604.55726956,\n",
      "       90604.55727007, 90604.55727031, 90604.55727036, 90604.55727057]))\n",
      "           fun: 90604.5572682951\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 3106\n",
      "           nit: 1429\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "       9.51034532e+03, 9.65504541e+03, 7.93861992e+03])\n",
      "minPrevious 90610.27280040468\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861992e+03],\n",
      "       [4.83273467e-02, 4.23176213e-02, 4.03140866e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861993e+03],\n",
      "       [4.83273481e-02, 4.23176224e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273481e-02, 4.23176225e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273487e-02, 4.23176230e-02, 4.03140823e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862000e+03],\n",
      "       [4.83273490e-02, 4.23176232e-02, 4.03140817e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273491e-02, 4.23176233e-02, 4.03140815e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273494e-02, 4.23176235e-02, 4.03140810e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862002e+03]]), array([90604.5572683 , 90604.55726843, 90604.55726955, 90604.55726956,\n",
      "       90604.55727007, 90604.55727031, 90604.55727036, 90604.55727057]))\n",
      "           fun: 90604.5572682951\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 3106\n",
      "           nit: 1429\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "       9.51034532e+03, 9.65504541e+03, 7.93861992e+03])\n",
      "best ll: 90973.150105765, bestParams: [0.0043483237, 0.1723103, 0.063694075, 5563.539, 10523.814, 9726.051, 20610.318]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.48004476e-03, 1.69499920e-01, 6.10019645e-02, 5.98757017e+03,\n",
      "        1.11423656e+04, 9.44868017e+03, 1.84977817e+04],\n",
      "       [4.48004475e-03, 1.69499920e-01, 6.10019649e-02, 5.98757013e+03,\n",
      "        1.11423657e+04, 9.44868016e+03, 1.84977817e+04],\n",
      "       [4.48004478e-03, 1.69499921e-01, 6.10019649e-02, 5.98757011e+03,\n",
      "        1.11423657e+04, 9.44868014e+03, 1.84977817e+04],\n",
      "       [4.48004476e-03, 1.69499921e-01, 6.10019650e-02, 5.98757014e+03,\n",
      "        1.11423657e+04, 9.44868013e+03, 1.84977817e+04],\n",
      "       [4.48004475e-03, 1.69499922e-01, 6.10019654e-02, 5.98757014e+03,\n",
      "        1.11423656e+04, 9.44868012e+03, 1.84977818e+04],\n",
      "       [4.48004474e-03, 1.69499924e-01, 6.10019654e-02, 5.98757012e+03,\n",
      "        1.11423656e+04, 9.44868008e+03, 1.84977818e+04],\n",
      "       [4.48004471e-03, 1.69499924e-01, 6.10019651e-02, 5.98757016e+03,\n",
      "        1.11423657e+04, 9.44868010e+03, 1.84977816e+04],\n",
      "       [4.48004469e-03, 1.69499924e-01, 6.10019655e-02, 5.98757013e+03,\n",
      "        1.11423657e+04, 9.44868009e+03, 1.84977817e+04]]), array([90875.20110852, 90875.2011087 , 90875.20110879, 90875.20110889,\n",
      "       90875.20110966, 90875.20111022, 90875.2011103 , 90875.20111065]))\n",
      "           fun: 90875.20110852493\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1082\n",
      "           nit: 377\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.48004476e-03, 1.69499920e-01, 6.10019645e-02, 5.98757017e+03,\n",
      "       1.11423656e+04, 9.44868017e+03, 1.84977817e+04])\n",
      "minPrevious 90604.5572682951\n",
      "best ll: 91007.53714748367, bestParams: [0.03484704, 0.027896117, 0.062791444, 4148.296, 18361.578, 16205.281, 10942.79]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529420e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334977e+04],\n",
      "       [3.58243337e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111420e+04, 1.57094699e+04, 1.04334975e+04]]), array([90602.51359827, 90602.51359829, 90602.51359829, 90602.51359829,\n",
      "       90602.51359833, 90602.51359836, 90602.51359864, 90602.51360201]))\n",
      "           fun: 90602.51359826833\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1241\n",
      "           nit: 441\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "       1.57111421e+04, 1.57094699e+04, 1.04334976e+04])\n",
      "minPrevious 90604.5572682951\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529420e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334977e+04],\n",
      "       [3.58243337e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111420e+04, 1.57094699e+04, 1.04334975e+04]]), array([90602.51359827, 90602.51359829, 90602.51359829, 90602.51359829,\n",
      "       90602.51359833, 90602.51359836, 90602.51359864, 90602.51360201]))\n",
      "           fun: 90602.51359826833\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1241\n",
      "           nit: 441\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "       1.57111421e+04, 1.57094699e+04, 1.04334976e+04])\n",
      "best ll: 91015.41612460106, bestParams: [0.12024945, 0.09470742, 0.06604782, 6515.7124, 9441.274, 11384.588, 14921.515]\n",
      "epoch 8\n",
      " final_simplex: (array([[1.15905749e-01, 8.86839476e-02, 6.41709445e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839473e-02, 6.41709447e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839465e-02, 6.41709450e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181450e+04, 1.75717270e+04],\n",
      "       [1.15905750e-01, 8.86839466e-02, 6.41709449e-02, 5.67383150e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839466e-02, 6.41709453e-02, 5.67383149e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839466e-02, 6.41709455e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181452e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839461e-02, 6.41709455e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717270e+04],\n",
      "       [1.15905749e-01, 8.86839464e-02, 6.41709457e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04]]), array([90791.50925081, 90791.50925131, 90791.509252  , 90791.50925231,\n",
      "       90791.50925269, 90791.50925337, 90791.50925357, 90791.50925369]))\n",
      "           fun: 90791.50925081424\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1149\n",
      "           nit: 380\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.15905749e-01, 8.86839476e-02, 6.41709445e-02, 5.67383148e+03,\n",
      "       1.04222081e+04, 1.12181451e+04, 1.75717269e+04])\n",
      "minPrevious 90602.51359826833\n",
      "best ll: 91011.46463348175, bestParams: [0.06312266, 0.029164523, 0.039597854, 8029.851, 24910.959, 18420.938, 11092.687]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093559e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093560e-02, 3.06041703e-02, 4.03519653e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04]]), array([90610.3734693 , 90610.37346932, 90610.37346938, 90610.37346949,\n",
      "       90610.3734696 , 90610.37346963, 90610.37346964, 90610.37346966]))\n",
      "           fun: 90610.37346929763\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2680\n",
      "           nit: 1248\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "       2.11833428e+04, 2.21593122e+04, 1.38361985e+04])\n",
      "minPrevious 90602.51359826833\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0358, 0.0335, 0.0445], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8858, 0.0647, 0.0281, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8600, 0.0815, 0.0258, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8860, 0.0281, 0.0646, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8600, 0.0258, 0.0816, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7406, 0.0995, 0.0989, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7059, 0.1114, 0.1115, 0.0713], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.0054, 3.8620, 6.9140],\n",
      "        [2.8371, 3.1236, 4.0172],\n",
      "        [3.2060, 4.0941, 6.7157],\n",
      "        ...,\n",
      "        [2.7681, 3.9681, 4.6108],\n",
      "        [2.3565, 2.2976, 6.9109],\n",
      "        [2.9001, 2.6971, 4.8654]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.674013376235962\n",
      "Run: 0, 5\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  1.],\n",
      "        [51.,  2.,  1.,  1.],\n",
      "        [47.,  3.,  1.,  1.],\n",
      "        ...,\n",
      "        [48.,  2.,  3.,  1.],\n",
      "        [59.,  2.,  0.,  1.],\n",
      "        [63.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "n tensor([44., 55., 52.,  ..., 54., 62., 66.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 3.,  ..., 2., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 3., 0., 3.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 1., 1.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  1.],\n",
      "        [51.,  2.,  1.,  1.],\n",
      "        [47.,  3.,  1.,  1.],\n",
      "        ...,\n",
      "        [48.,  2.,  3.,  1.],\n",
      "        [59.,  2.,  0.,  1.],\n",
      "        [63.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0248, 0.0290, 0.0136,  ..., 0.0106, 0.0165, 0.0126],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad035f0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91090.3604514042, bestParams: [0.043571133, 0.095463604, 0.0505203, 5832.7603, 16079.994, 12313.426, 8391.266]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.59893537e-02, 5.64996138e-02, 4.31957835e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996138e-02, 4.31957836e-02, 5.33859644e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893539e-02, 5.64996138e-02, 4.31957834e-02, 5.33859642e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996138e-02, 4.31957836e-02, 5.33859643e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996140e-02, 4.31957838e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996140e-02, 4.31957838e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893535e-02, 5.64996143e-02, 4.31957837e-02, 5.33859643e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028398e+04],\n",
      "       [3.59893536e-02, 5.64996143e-02, 4.31957839e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028398e+04]]), array([90799.07161255, 90799.07161264, 90799.07161274, 90799.07161275,\n",
      "       90799.07161278, 90799.0716128 , 90799.07161297, 90799.07161297]))\n",
      "           fun: 90799.07161254974\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.59893537e-02, 5.64996138e-02, 4.31957835e-02, 5.33859643e+03,\n",
      "       1.57706471e+04, 1.39949641e+04, 1.36028399e+04])\n",
      "best ll: 91093.57377619602, bestParams: [0.04420233, 0.06357479, 0.03340114, 4500.3525, 14206.233, 8924.385, 19454.049]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.49744082e-02, 6.21665645e-02, 4.15310181e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744086e-02, 6.21665646e-02, 4.15310186e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128040e+04],\n",
      "       [4.49744083e-02, 6.21665648e-02, 4.15310179e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128040e+04],\n",
      "       [4.49744083e-02, 6.21665651e-02, 4.15310180e-02, 4.61027368e+03,\n",
      "        1.30328999e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744086e-02, 6.21665651e-02, 4.15310186e-02, 4.61027367e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744088e-02, 6.21665655e-02, 4.15310183e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128039e+04],\n",
      "       [4.49744091e-02, 6.21665658e-02, 4.15310189e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744092e-02, 6.21665660e-02, 4.15310189e-02, 4.61027367e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128039e+04]]), array([90804.01018453, 90804.01018466, 90804.01018486, 90804.01018504,\n",
      "       90804.01018508, 90804.01018544, 90804.01018563, 90804.0101859 ]))\n",
      "           fun: 90804.01018452992\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1264\n",
      "           nit: 490\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.49744082e-02, 6.21665645e-02, 4.15310181e-02, 4.61027368e+03,\n",
      "       1.30329000e+04, 1.18758442e+04, 1.20128039e+04])\n",
      "minPrevious 90799.07161254974\n",
      "best ll: 91258.20962960232, bestParams: [0.0017469097, 0.01823081, 0.084255494, 10602.629, 13127.086, 18705.941, 23800.89]\n",
      "epoch 2\n",
      " final_simplex: (array([[2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294313e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864185e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864181e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864183e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864184e+03],\n",
      "       [2.11020782e-03, 2.95814602e-02, 5.19149978e-02, 6.74294313e+03,\n",
      "        2.45263191e+04, 2.07048135e+04, 9.00864183e+03]]), array([90955.06447395, 90955.06447396, 90955.06447396, 90955.06447397,\n",
      "       90955.06447398, 90955.06447399, 90955.06447401, 90955.06447402]))\n",
      "           fun: 90955.06447394771\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1358\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294313e+03,\n",
      "       2.45263190e+04, 2.07048135e+04, 9.00864185e+03])\n",
      "minPrevious 90799.07161254974\n",
      "best ll: 91230.90592004443, bestParams: [0.1362636, 0.18482453, 0.031719703, 2449.1853, 4716.1143, 3088.015, 11587.606]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "        7.21950271e+03, 6.88453503e+03, 5.45878630e+03],\n",
      "       [3.67651936e-02, 4.28943901e-02, 4.23365698e-02, 2.39682393e+03,\n",
      "        7.21950274e+03, 6.88453506e+03, 5.45878628e+03],\n",
      "       [3.67651929e-02, 4.28943907e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950270e+03, 6.88453500e+03, 5.45878628e+03],\n",
      "       [3.67651926e-02, 4.28943908e-02, 4.23365705e-02, 2.39682392e+03,\n",
      "        7.21950270e+03, 6.88453498e+03, 5.45878633e+03],\n",
      "       [3.67651912e-02, 4.28943931e-02, 4.23365699e-02, 2.39682394e+03,\n",
      "        7.21950278e+03, 6.88453496e+03, 5.45878628e+03],\n",
      "       [3.67651901e-02, 4.28943919e-02, 4.23365704e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453499e+03, 5.45878620e+03],\n",
      "       [3.67651903e-02, 4.28943912e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453498e+03, 5.45878626e+03],\n",
      "       [3.67651909e-02, 4.28943884e-02, 4.23365714e-02, 2.39682393e+03,\n",
      "        7.21950273e+03, 6.88453499e+03, 5.45878636e+03]]), array([90793.71585391, 90793.71585413, 90793.71585419, 90793.71585449,\n",
      "       90793.71585464, 90793.71585486, 90793.7158549 , 90793.7158549 ]))\n",
      "           fun: 90793.71585391468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1238\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "       7.21950271e+03, 6.88453503e+03, 5.45878630e+03])\n",
      "minPrevious 90799.07161254974\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "        7.21950271e+03, 6.88453503e+03, 5.45878630e+03],\n",
      "       [3.67651936e-02, 4.28943901e-02, 4.23365698e-02, 2.39682393e+03,\n",
      "        7.21950274e+03, 6.88453506e+03, 5.45878628e+03],\n",
      "       [3.67651929e-02, 4.28943907e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950270e+03, 6.88453500e+03, 5.45878628e+03],\n",
      "       [3.67651926e-02, 4.28943908e-02, 4.23365705e-02, 2.39682392e+03,\n",
      "        7.21950270e+03, 6.88453498e+03, 5.45878633e+03],\n",
      "       [3.67651912e-02, 4.28943931e-02, 4.23365699e-02, 2.39682394e+03,\n",
      "        7.21950278e+03, 6.88453496e+03, 5.45878628e+03],\n",
      "       [3.67651901e-02, 4.28943919e-02, 4.23365704e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453499e+03, 5.45878620e+03],\n",
      "       [3.67651903e-02, 4.28943912e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453498e+03, 5.45878626e+03],\n",
      "       [3.67651909e-02, 4.28943884e-02, 4.23365714e-02, 2.39682393e+03,\n",
      "        7.21950273e+03, 6.88453499e+03, 5.45878636e+03]]), array([90793.71585391, 90793.71585413, 90793.71585419, 90793.71585449,\n",
      "       90793.71585464, 90793.71585486, 90793.7158549 , 90793.7158549 ]))\n",
      "           fun: 90793.71585391468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1238\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "       7.21950271e+03, 6.88453503e+03, 5.45878630e+03])\n",
      "best ll: 91326.84358438406, bestParams: [0.02248766, 0.032484304, 0.052385617, 8575.685, 11063.958, 10108.009, 22795.377]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.84420417e-02, 3.46959567e-02, 4.26539702e-02, 4.46333716e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539702e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930251e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539704e-02, 4.46333716e+03,\n",
      "        1.44521197e+04, 1.37119075e+04, 9.14930251e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539703e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930248e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539703e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930251e+03],\n",
      "       [2.84420416e-02, 3.46959568e-02, 4.26539705e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420416e-02, 3.46959568e-02, 4.26539705e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420418e-02, 3.46959566e-02, 4.26539705e-02, 4.46333716e+03,\n",
      "        1.44521198e+04, 1.37119075e+04, 9.14930237e+03]]), array([90801.40632214, 90801.40632216, 90801.40632217, 90801.40632218,\n",
      "       90801.40632219, 90801.40632224, 90801.40632224, 90801.40632478]))\n",
      "           fun: 90801.40632214482\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1364\n",
      "           nit: 549\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.84420417e-02, 3.46959567e-02, 4.26539702e-02, 4.46333716e+03,\n",
      "       1.44521197e+04, 1.37119076e+04, 9.14930242e+03])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91152.77248384545, bestParams: [0.029007705, 0.047266837, 0.042739347, 3103.6965, 9688.097, 14387.982, 6064.706]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.05385898e-02, 4.40237968e-02, 4.16521419e-02, 3.36519154e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03],\n",
      "       [3.05385899e-02, 4.40237969e-02, 4.16521414e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845911e+03],\n",
      "       [3.05385899e-02, 4.40237970e-02, 4.16521414e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845912e+03],\n",
      "       [3.05385898e-02, 4.40237970e-02, 4.16521415e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845910e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521424e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845895e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521419e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845903e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521421e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03],\n",
      "       [3.05385892e-02, 4.40237968e-02, 4.16521421e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03]]), array([90798.38403306, 90798.3840331 , 90798.38403313, 90798.38403316,\n",
      "       90798.38403323, 90798.38403329, 90798.3840333 , 90798.38403332]))\n",
      "           fun: 90798.38403306226\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1259\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.05385898e-02, 4.40237968e-02, 4.16521419e-02, 3.36519154e+03,\n",
      "       1.10735933e+04, 1.00880013e+04, 6.82845902e+03])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91270.70408583432, bestParams: [0.015127707, 0.041919302, 0.03150278, 4334.455, 22769.922, 24498.379, 190.21886]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.75785932e-02, 1.95895246e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895245e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233751e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895247e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895246e-02, 4.58603911e-02, 5.09205005e+03,\n",
      "        2.27880383e+04, 2.20233750e+04, 2.36272117e+02],\n",
      "       [1.75785931e-02, 1.95895251e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895251e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895247e-02, 4.58603912e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895250e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02]]), array([90949.33571342, 90949.33571344, 90949.33571346, 90949.33571348,\n",
      "       90949.33571358, 90949.3357136 , 90949.3357136 , 90949.33571367]))\n",
      "           fun: 90949.33571342296\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1312\n",
      "           nit: 515\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.75785932e-02, 1.95895246e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "       2.27880384e+04, 2.20233750e+04, 2.36272116e+02])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91344.40237445639, bestParams: [0.03907052, 0.037808415, 0.034087338, 9922.918, 22659.93, 13472.755, 21920.426]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.74444807e-02, 4.19909125e-02, 4.05683430e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04],\n",
      "       [3.74444808e-02, 4.19909125e-02, 4.05683430e-02, 6.81299451e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909126e-02, 4.05683430e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444807e-02, 4.19909125e-02, 4.05683429e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04],\n",
      "       [3.74444808e-02, 4.19909127e-02, 4.05683430e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909127e-02, 4.05683429e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909126e-02, 4.05683429e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444807e-02, 4.19909125e-02, 4.05683428e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04]]), array([90794.23716006, 90794.23716007, 90794.23716007, 90794.23716008,\n",
      "       90794.23716009, 90794.23716009, 90794.2371601 , 90794.23716011]))\n",
      "           fun: 90794.2371600552\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1301\n",
      "           nit: 543\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.74444807e-02, 4.19909125e-02, 4.05683430e-02, 6.81299449e+03,\n",
      "       2.13149873e+04, 2.03928135e+04, 1.47412558e+04])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91361.03540276109, bestParams: [0.045425393, 0.07026239, 0.050605606, 5734.493, 18005.092, 5601.4487, 22472.11]\n",
      "epoch 8\n",
      " final_simplex: (array([[5.31215249e-02, 7.05228155e-02, 4.47838949e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215248e-02, 7.05228156e-02, 4.47838951e-02, 4.51425556e+03,\n",
      "        1.17898264e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228154e-02, 4.47838952e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215251e-02, 7.05228153e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228152e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215250e-02, 7.05228154e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898264e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215251e-02, 7.05228155e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228155e-02, 4.47838958e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939907e+04]]), array([90817.22476695, 90817.22476704, 90817.22476722, 90817.22476724,\n",
      "       90817.22476725, 90817.22476726, 90817.22476734, 90817.22476763]))\n",
      "           fun: 90817.22476694567\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1196\n",
      "           nit: 465\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.31215249e-02, 7.05228155e-02, 4.47838949e-02, 4.51425556e+03,\n",
      "       1.17898265e+04, 1.08016156e+04, 1.24939908e+04])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91309.75771624263, bestParams: [0.02029038, 0.014870982, 0.010115627, 4392.174, 19204.947, 19952.209, 9782.406]\n",
      "epoch 9\n",
      " final_simplex: (array([[2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587151e+02,\n",
      "        8.13689375e+02, 7.66991520e+02, 4.17404243e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689369e+02, 7.66991516e+02, 4.17404245e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689365e+02, 7.66991513e+02, 4.17404247e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689378e+02, 7.66991522e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587148e+02,\n",
      "        8.13689380e+02, 7.66991520e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587147e+02,\n",
      "        8.13689364e+02, 7.66991510e+02, 4.17404239e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587146e+02,\n",
      "        8.13689362e+02, 7.66991506e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587146e+02,\n",
      "        8.13689362e+02, 7.66991507e+02, 4.17404237e+02]]), array([90811.60778462, 90811.60778465, 90811.60778467, 90811.60778474,\n",
      "       90811.60778501, 90811.60778518, 90811.60778533, 90811.60778536]))\n",
      "           fun: 90811.60778462133\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1301\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587151e+02,\n",
      "       8.13689375e+02, 7.66991520e+02, 4.17404243e+02])\n",
      "minPrevious 90793.71585391468\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0368, 0.0429, 0.0423], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8815, 0.0637, 0.0279, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8660, 0.0782, 0.0259, 0.0299], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8880, 0.0282, 0.0649, 0.0260], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8691, 0.0260, 0.0749, 0.0299], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7411, 0.0987, 0.0971, 0.0616], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7086, 0.1125, 0.1095, 0.0694], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9130, 3.9638, 4.5806],\n",
      "        [4.8477, 3.1204, 4.6859],\n",
      "        [2.5043, 3.4648, 5.4998],\n",
      "        ...,\n",
      "        [2.2138, 3.9310, 6.0372],\n",
      "        [3.0004, 1.5042, 4.5456],\n",
      "        [3.2652, 3.3443, 5.2215]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.484266996383667\n",
      "Run: 0, 6\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[51.,  4.,  1.,  2.],\n",
      "        [40.,  2.,  0.,  0.],\n",
      "        [55.,  3.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  1.,  2.,  1.],\n",
      "        [59.,  0.,  4.,  0.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([58., 42., 61.,  ..., 52., 63., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 2., 3.,  ..., 1., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 0., 2.,  ..., 2., 4., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 1.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[51.,  4.,  1.,  2.],\n",
      "        [40.,  2.,  0.,  0.],\n",
      "        [55.,  3.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  1.,  2.,  1.],\n",
      "        [59.,  0.,  4.,  0.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0020, 0.0418, 0.0140,  ..., 0.0283, 0.0060, 0.0503],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad03950>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90705.78630343798, bestParams: [0.042797178, 0.03189743, 0.0427665, 7865.0444, 19529.307, 18785.924, 20957.984]\n",
      "epoch 0\n",
      " final_simplex: (array([[4.53094590e-02, 3.29430425e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289733e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675401e-02, 7.16461646e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718439e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718441e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04]]), array([90617.68016446, 90617.68016449, 90617.68016451, 90617.68016452,\n",
      "       90617.68016454, 90617.68016455, 90617.68016455, 90617.68016455]))\n",
      "           fun: 90617.68016446201\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1139\n",
      "           nit: 416\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.53094590e-02, 3.29430425e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "       2.07289734e+04, 2.24192353e+04, 1.77718440e+04])\n",
      "best ll: 91238.05435765057, bestParams: [0.05948744, 0.04102097, 0.013038766, 4660.9634, 18500.773, 21041.572, 23418.262]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.42696088e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799659e+03],\n",
      "       [3.42696092e-02, 3.41024516e-02, 3.87974592e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799652e+03],\n",
      "       [3.42696087e-02, 3.41024514e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799661e+03],\n",
      "       [3.42696086e-02, 3.41024513e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799663e+03],\n",
      "       [3.42696086e-02, 3.41024513e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799663e+03],\n",
      "       [3.42696085e-02, 3.41024512e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799664e+03],\n",
      "       [3.42696089e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799657e+03],\n",
      "       [3.42696082e-02, 3.41024511e-02, 3.87974589e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799669e+03]]), array([90618.91761162, 90618.91761169, 90618.91761169, 90618.91761183,\n",
      "       90618.91761185, 90618.91761194, 90618.91761205, 90618.91761219]))\n",
      "           fun: 90618.91761162136\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1909\n",
      "           nit: 848\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.42696088e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "       1.46360708e+04, 1.49596490e+04, 9.92799659e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90799.13652237343, bestParams: [0.08314967, 0.07155339, 0.06358579, 7604.4014, 13512.055, 14740.179, 23051.545]\n",
      "epoch 2\n",
      " final_simplex: (array([[8.04633027e-02, 7.18090937e-02, 5.02449341e-02, 7.23852176e+03,\n",
      "        1.58024603e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633030e-02, 7.18090935e-02, 5.02449344e-02, 7.23852175e+03,\n",
      "        1.58024603e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633039e-02, 7.18090933e-02, 5.02449343e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286440e+04],\n",
      "       [8.04633037e-02, 7.18090932e-02, 5.02449345e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286440e+04],\n",
      "       [8.04633047e-02, 7.18090929e-02, 5.02449349e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633055e-02, 7.18090926e-02, 5.02449354e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633062e-02, 7.18090923e-02, 5.02449354e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840773e+04, 2.23286441e+04],\n",
      "       [8.04633062e-02, 7.18090921e-02, 5.02449357e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04]]), array([90698.9332218 , 90698.93322237, 90698.93322263, 90698.93322275,\n",
      "       90698.933224  , 90698.93322516, 90698.93322544, 90698.93322595]))\n",
      "           fun: 90698.93322179955\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1389\n",
      "           nit: 554\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.04633027e-02, 7.18090937e-02, 5.02449341e-02, 7.23852176e+03,\n",
      "       1.58024603e+04, 1.67840772e+04, 2.23286441e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91004.02822016623, bestParams: [0.16847368, 0.006867244, 0.057000216, 9718.201, 20643.424, 24615.924, 21438.463]\n",
      "epoch 3\n",
      " final_simplex: (array([[1.02033897e-01, 7.74125429e-03, 5.54624499e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125427e-03, 5.54624498e-02, 9.58666804e+03,\n",
      "        1.95816961e+04, 2.80791649e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033898e-01, 7.74125426e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624499e-02, 9.58666804e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624498e-02, 9.58666805e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624498e-02, 9.58666804e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04]]), array([90777.40346946, 90777.40346956, 90777.40346965, 90777.40347029,\n",
      "       90777.40348193, 90777.40348194, 90777.40348196, 90777.40348204]))\n",
      "           fun: 90777.40346946282\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1171\n",
      "           nit: 404\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.02033897e-01, 7.74125429e-03, 5.54624499e-02, 9.58666803e+03,\n",
      "       1.95816962e+04, 2.80791648e+04, 2.53911261e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91187.95797366982, bestParams: [0.025342675, 0.00792712, 0.07620231, 7194.6675, 7506.416, 14323.318, 16886.123]\n",
      "epoch 4\n",
      " final_simplex: (array([[4.70038040e-02, 1.84890042e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "        7.18730002e+03, 8.35538060e+03, 5.06572632e+03],\n",
      "       [4.70038039e-02, 1.84890042e-02, 4.10251852e-02, 2.37962911e+03,\n",
      "        7.18730004e+03, 8.35538056e+03, 5.06572636e+03],\n",
      "       [4.70038041e-02, 1.84890043e-02, 4.10251854e-02, 2.37962910e+03,\n",
      "        7.18729996e+03, 8.35538056e+03, 5.06572631e+03],\n",
      "       [4.70038043e-02, 1.84890043e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "        7.18729999e+03, 8.35538061e+03, 5.06572625e+03],\n",
      "       [4.70038041e-02, 1.84890041e-02, 4.10251853e-02, 2.37962912e+03,\n",
      "        7.18730005e+03, 8.35538060e+03, 5.06572628e+03],\n",
      "       [4.70038039e-02, 1.84890042e-02, 4.10251854e-02, 2.37962909e+03,\n",
      "        7.18730002e+03, 8.35538059e+03, 5.06572628e+03],\n",
      "       [4.70038044e-02, 1.84890041e-02, 4.10251855e-02, 2.37962911e+03,\n",
      "        7.18729996e+03, 8.35538050e+03, 5.06572636e+03],\n",
      "       [4.70038042e-02, 1.84890042e-02, 4.10251853e-02, 2.37962910e+03,\n",
      "        7.18729999e+03, 8.35538054e+03, 5.06572629e+03]]), array([90641.67199394, 90641.67199403, 90641.6719941 , 90641.67199412,\n",
      "       90641.67199429, 90641.67199461, 90641.67199472, 90641.67199474]))\n",
      "           fun: 90641.67199393519\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1292\n",
      "           nit: 503\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.70038040e-02, 1.84890042e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "       7.18730002e+03, 8.35538060e+03, 5.06572632e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90934.9975112686, bestParams: [0.059806045, 0.055613108, 0.043168016, 2348.8328, 6146.4946, 8322.338, 10317.607]\n",
      "epoch 5\n",
      " final_simplex: (array([[5.42056891e-02, 4.70911906e-02, 4.19282268e-02, 2.83251915e+03,\n",
      "        7.79437423e+03, 8.19122192e+03, 7.15410411e+03],\n",
      "       [5.42056896e-02, 4.70911906e-02, 4.19282266e-02, 2.83251915e+03,\n",
      "        7.79437421e+03, 8.19122190e+03, 7.15410413e+03],\n",
      "       [5.42056846e-02, 4.70911897e-02, 4.19282289e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122191e+03, 7.15410401e+03],\n",
      "       [5.42056853e-02, 4.70911896e-02, 4.19282286e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122192e+03, 7.15410403e+03],\n",
      "       [5.42056859e-02, 4.70911898e-02, 4.19282282e-02, 2.83251916e+03,\n",
      "        7.79437423e+03, 8.19122191e+03, 7.15410403e+03],\n",
      "       [5.42056850e-02, 4.70911905e-02, 4.19282288e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122186e+03, 7.15410404e+03],\n",
      "       [5.42056864e-02, 4.70911897e-02, 4.19282281e-02, 2.83251916e+03,\n",
      "        7.79437420e+03, 8.19122190e+03, 7.15410405e+03],\n",
      "       [5.42056863e-02, 4.70911901e-02, 4.19282281e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122190e+03, 7.15410405e+03]]), array([90626.22011514, 90626.22011537, 90626.22012032, 90626.22012065,\n",
      "       90626.22012113, 90626.22012132, 90626.22012138, 90626.22012175]))\n",
      "           fun: 90626.22011513563\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1256\n",
      "           nit: 501\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.42056891e-02, 4.70911906e-02, 4.19282268e-02, 2.83251915e+03,\n",
      "       7.79437423e+03, 8.19122192e+03, 7.15410411e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90970.36604372214, bestParams: [0.054490186, 0.02661631, 0.0485164, 5726.952, 16087.912, 22577.627, 24207.025]\n",
      "epoch 6\n",
      " final_simplex: (array([[5.10958411e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958412e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636176e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958411e-02, 3.04632786e-02, 4.19672827e-02, 7.06673511e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958418e-02, 3.04632787e-02, 4.19672826e-02, 7.06673511e+03,\n",
      "        1.98636178e+04, 2.25615731e+04, 1.60116670e+04],\n",
      "       [5.10958411e-02, 3.04632785e-02, 4.19672830e-02, 7.06673513e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116672e+04],\n",
      "       [5.10958419e-02, 3.04632787e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636176e+04, 2.25615731e+04, 1.60116671e+04],\n",
      "       [5.10958414e-02, 3.04632786e-02, 4.19672828e-02, 7.06673512e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958415e-02, 3.04632785e-02, 4.19672829e-02, 7.06673512e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04]]), array([90621.57495985, 90621.57495994, 90621.57496008, 90621.57496039,\n",
      "       90621.5749604 , 90621.57496041, 90621.57496041, 90621.57496047]))\n",
      "           fun: 90621.57495984525\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1245\n",
      "           nit: 492\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.10958411e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "       1.98636177e+04, 2.25615730e+04, 1.60116671e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90804.903153182, bestParams: [0.014491759, 0.01909757, 0.026884345, 5839.411, 24984.732, 21505.56, 5679.6772]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.54264133e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "        8.02301535e+03, 8.15135230e+03, 5.64047497e+03],\n",
      "       [3.54264126e-02, 3.62265995e-02, 4.01003738e-02, 2.57159949e+03,\n",
      "        8.02301536e+03, 8.15135231e+03, 5.64047505e+03],\n",
      "       [3.54264131e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "        8.02301538e+03, 8.15135232e+03, 5.64047498e+03],\n",
      "       [3.54264143e-02, 3.62266000e-02, 4.01003715e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047488e+03],\n",
      "       [3.54264139e-02, 3.62266001e-02, 4.01003719e-02, 2.57159949e+03,\n",
      "        8.02301538e+03, 8.15135232e+03, 5.64047489e+03],\n",
      "       [3.54264141e-02, 3.62266000e-02, 4.01003716e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047490e+03],\n",
      "       [3.54264137e-02, 3.62265999e-02, 4.01003720e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047495e+03],\n",
      "       [3.54264137e-02, 3.62266000e-02, 4.01003719e-02, 2.57159949e+03,\n",
      "        8.02301537e+03, 8.15135233e+03, 5.64047494e+03]]), array([90617.76238034, 90617.76238038, 90617.76238043, 90617.76238056,\n",
      "       90617.76238057, 90617.7623806 , 90617.76238062, 90617.7623807 ]))\n",
      "           fun: 90617.76238033785\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1396\n",
      "           nit: 595\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.54264133e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "       8.02301535e+03, 8.15135230e+03, 5.64047497e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91071.9845670912, bestParams: [0.031488296, 0.07208441, 0.074685715, 6185.3647, 13709.426, 18131.521, 23476.797]\n",
      "epoch 8\n",
      " final_simplex: (array([[4.05461957e-02, 6.34717350e-02, 4.05830887e-02, 6.92152710e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461958e-02, 6.34717351e-02, 4.05830884e-02, 6.92152710e+03,\n",
      "        1.97748038e+04, 1.88326454e+04, 1.90989072e+04],\n",
      "       [4.05461960e-02, 6.34717351e-02, 4.05830884e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989071e+04],\n",
      "       [4.05461959e-02, 6.34717351e-02, 4.05830885e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461962e-02, 6.34717354e-02, 4.05830879e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989071e+04],\n",
      "       [4.05461953e-02, 6.34717350e-02, 4.05830889e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461959e-02, 6.34717353e-02, 4.05830882e-02, 6.92152708e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461954e-02, 6.34717352e-02, 4.05830887e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326454e+04, 1.90989073e+04]]), array([90642.89946052, 90642.89946059, 90642.8994606 , 90642.89946067,\n",
      "       90642.89946078, 90642.89946086, 90642.89946098, 90642.899461  ]))\n",
      "           fun: 90642.89946051945\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1339\n",
      "           nit: 563\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05461957e-02, 6.34717350e-02, 4.05830887e-02, 6.92152710e+03,\n",
      "       1.97748038e+04, 1.88326455e+04, 1.90989072e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90978.47709523376, bestParams: [0.052268486, 0.059164874, 0.029479917, 3384.196, 9466.865, 13828.556, 13715.061]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228951e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202685e+03],\n",
      "       [4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202684e+03],\n",
      "       [4.94145725e-02, 3.66047327e-02, 4.05901828e-02, 4.08228951e+03,\n",
      "        1.18931871e+04, 1.29963842e+04, 9.45202687e+03],\n",
      "       [4.94145723e-02, 3.66047329e-02, 4.05901829e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202687e+03],\n",
      "       [4.94145725e-02, 3.66047330e-02, 4.05901828e-02, 4.08228951e+03,\n",
      "        1.18931871e+04, 1.29963842e+04, 9.45202685e+03],\n",
      "       [4.94145724e-02, 3.66047332e-02, 4.05901828e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202689e+03],\n",
      "       [4.94145725e-02, 3.66047332e-02, 4.05901829e-02, 4.08228951e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202689e+03],\n",
      "       [4.94145724e-02, 3.66047334e-02, 4.05901830e-02, 4.08228952e+03,\n",
      "        1.18931871e+04, 1.29963843e+04, 9.45202682e+03]]), array([90618.74920601, 90618.74920613, 90618.74920624, 90618.74920633,\n",
      "       90618.74920639, 90618.74920644, 90618.74920651, 90618.7492066 ]))\n",
      "           fun: 90618.74920601156\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1229\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228951e+03,\n",
      "       1.18931870e+04, 1.29963842e+04, 9.45202685e+03])\n",
      "minPrevious 90617.68016446201\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0453, 0.0329, 0.0414], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8794, 0.0631, 0.0279, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8663, 0.0752, 0.0260, 0.0325], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8795, 0.0279, 0.0647, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8611, 0.0258, 0.0808, 0.0323], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7352, 0.0984, 0.0988, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6986, 0.1126, 0.1175, 0.0713], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.1919, 3.2663, 5.4709],\n",
      "        [4.1986, 3.8897, 7.2400],\n",
      "        [3.3917, 2.4035, 5.7041],\n",
      "        ...,\n",
      "        [4.9667, 4.5339, 5.2203],\n",
      "        [3.8287, 3.7274, 4.9386],\n",
      "        [3.6731, 2.6413, 5.4393]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 17.216406106948853\n",
      "Run: 0, 7\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[57.,  3.,  2.,  0.],\n",
      "        [54.,  1.,  1.,  0.],\n",
      "        [40.,  2.,  2.,  3.],\n",
      "        ...,\n",
      "        [59.,  0.,  1.,  0.],\n",
      "        [57.,  2.,  0.,  2.],\n",
      "        [46.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([62., 56., 47.,  ..., 60., 61., 48.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 2.,  ..., 0., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 2.,  ..., 1., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 3.,  ..., 0., 2., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[57.,  3.,  2.,  0.],\n",
      "        [54.,  1.,  1.,  0.],\n",
      "        [40.,  2.,  2.,  3.],\n",
      "        ...,\n",
      "        [59.,  0.,  1.,  0.],\n",
      "        [57.,  2.,  0.,  2.],\n",
      "        [46.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0211, 0.0565, 0.0007,  ..., 0.0278, 0.0058, 0.0361],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7d8437830>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90698.00966445002, bestParams: [0.03601381, 0.05376842, 0.037697803, 4858.81, 17559.475, 15117.588, 10296.187]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695246e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397107e-02, 5.12695245e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708269e-02, 4.24062757e-02, 4.20397107e-02, 5.12695246e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498577e+04],\n",
      "       [3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695247e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498577e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397106e-02, 5.12695245e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062758e-02, 4.20397103e-02, 5.12695247e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397105e-02, 5.12695248e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062755e-02, 4.20397105e-02, 5.12695246e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04]]), array([90642.85781501, 90642.85781503, 90642.85781505, 90642.85781506,\n",
      "       90642.85781507, 90642.8578153 , 90642.85781912, 90642.85781919]))\n",
      "           fun: 90642.85781500832\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 451\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695246e+03,\n",
      "       1.55116198e+04, 1.47037155e+04, 1.20498578e+04])\n",
      "best ll: 90989.10931874896, bestParams: [0.055018455, 0.058657233, 0.013274319, 6479.689, 24181.266, 18899.627, 20080.443]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.85959234e-02, 2.70830341e-02, 3.75888685e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959248e-02, 2.70830345e-02, 3.75888666e-02, 5.60836646e+03,\n",
      "        1.79338975e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959256e-02, 2.70830349e-02, 3.75888652e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959263e-02, 2.70830352e-02, 3.75888641e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154940e+04],\n",
      "       [3.85959273e-02, 2.70830354e-02, 3.75888626e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959274e-02, 2.70830356e-02, 3.75888624e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959275e-02, 2.70830356e-02, 3.75888623e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959273e-02, 2.70830360e-02, 3.75888620e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154940e+04]]), array([90650.21241961, 90650.21242353, 90650.21242637, 90650.21242847,\n",
      "       90650.21243156, 90650.21243183, 90650.21243221, 90650.2124325 ]))\n",
      "           fun: 90650.21241961051\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1903\n",
      "           nit: 830\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.85959234e-02, 2.70830341e-02, 3.75888685e-02, 5.60836646e+03,\n",
      "       1.79338974e+04, 1.86206826e+04, 1.15154939e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91231.4553234166, bestParams: [0.0892526, 0.12577815, 0.064923555, 8575.71, 16426.484, 17164.031, 13682.164]\n",
      "epoch 2\n",
      " final_simplex: (array([[6.24537414e-02, 6.15992439e-02, 4.87048961e-02, 8.10050348e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666122e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537410e-02, 6.15992442e-02, 4.87048963e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537408e-02, 6.15992444e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385009e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537410e-02, 6.15992443e-02, 4.87048963e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537413e-02, 6.15992439e-02, 4.87048963e-02, 8.10050348e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666121e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048965e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666122e+04]]), array([90678.49280484, 90678.49280488, 90678.49280488, 90678.4928049 ,\n",
      "       90678.49280491, 90678.49280492, 90678.49280495, 90678.49280495]))\n",
      "           fun: 90678.49280484293\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1336\n",
      "           nit: 527\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.24537414e-02, 6.15992439e-02, 4.87048961e-02, 8.10050348e+03,\n",
      "       1.87385010e+04, 1.77667491e+04, 2.46666122e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91162.11827079224, bestParams: [0.028731208, 0.08052614, 0.038748782, 6678.704, 9787.624, 20217.812, 20754.006]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.70904892e-02, 3.81834950e-02, 4.32858909e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550785e+04, 1.31698874e+04],\n",
      "       [3.70904891e-02, 3.81834947e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550785e+04, 1.31698875e+04],\n",
      "       [3.70904891e-02, 3.81834950e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550784e+04, 1.31698875e+04],\n",
      "       [3.70904892e-02, 3.81834948e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698873e+04],\n",
      "       [3.70904892e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698874e+04],\n",
      "       [3.70904891e-02, 3.81834949e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698875e+04],\n",
      "       [3.70904891e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550784e+04, 1.31698874e+04],\n",
      "       [3.70904890e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550784e+04, 1.31698875e+04]]), array([90642.60568465, 90642.60568466, 90642.60568467, 90642.60568468,\n",
      "       90642.60568469, 90642.60568473, 90642.60568474, 90642.60568475]))\n",
      "           fun: 90642.60568464609\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1275\n",
      "           nit: 507\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.70904892e-02, 3.81834950e-02, 4.32858909e-02, 5.98454029e+03,\n",
      "       1.81339736e+04, 1.72550785e+04, 1.31698874e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91382.86227142713, bestParams: [0.061809793, 0.19442773, 0.026268564, 4953.1294, 21892.15, 9520.106, 16782.123]\n",
      "epoch 4\n",
      " final_simplex: (array([[6.27800301e-02, 1.23767454e-01, 3.50697812e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800298e-02, 1.23767455e-01, 3.50697812e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800299e-02, 1.23767454e-01, 3.50697811e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604067e+04],\n",
      "       [6.27800297e-02, 1.23767455e-01, 3.50697811e-02, 5.48175073e+03,\n",
      "        1.28766665e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767454e-01, 3.50697811e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767455e-01, 3.50697810e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604065e+04],\n",
      "       [6.27800302e-02, 1.23767454e-01, 3.50697809e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767455e-01, 3.50697810e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04]]), array([90777.06158995, 90777.06159034, 90777.06159078, 90777.0615909 ,\n",
      "       90777.06159123, 90777.06159134, 90777.06159178, 90777.06159179]))\n",
      "           fun: 90777.06158994799\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 491\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.27800301e-02, 1.23767454e-01, 3.50697812e-02, 5.48175072e+03,\n",
      "       1.28766666e+04, 1.04008147e+04, 1.94604066e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91244.41189886695, bestParams: [0.10861425, 0.073448956, 0.058375053, 7751.9844, 24126.418, 15650.825, 13502.183]\n",
      "epoch 5\n",
      " final_simplex: (array([[4.98106413e-02, 4.31442532e-02, 4.55770178e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106415e-02, 4.31442537e-02, 4.55770179e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106417e-02, 4.31442545e-02, 4.55770180e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106419e-02, 4.31442552e-02, 4.55770181e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106422e-02, 4.31442562e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106423e-02, 4.31442564e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106423e-02, 4.31442564e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106424e-02, 4.31442567e-02, 4.55770184e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04]]), array([90645.14444341, 90645.14444347, 90645.14444356, 90645.14444367,\n",
      "       90645.14444379, 90645.14444382, 90645.14444382, 90645.14444386]))\n",
      "           fun: 90645.14444341193\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 4867\n",
      "           nit: 2501\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.98106413e-02, 4.31442532e-02, 4.55770178e-02, 8.17344313e+03,\n",
      "       2.22304248e+04, 2.16693584e+04, 2.17261576e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 90929.83437789878, bestParams: [0.042998888, 0.0036338635, 0.08923576, 6261.846, 20105.752, 21534.959, 8484.541]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.07350802e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004541e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790768e-03, 4.90472196e-02, 6.49933175e+03,\n",
      "        1.96476728e+04, 2.31004541e+04, 1.06442170e+04],\n",
      "       [4.07350803e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350800e-02, 4.32790766e-03, 4.90472198e-02, 6.49933176e+03,\n",
      "        1.96476727e+04, 2.31004541e+04, 1.06442172e+04],\n",
      "       [4.07350800e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476727e+04, 2.31004541e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790766e-03, 4.90472196e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790766e-03, 4.90472196e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350801e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04]]), array([90729.51111848, 90729.51111852, 90729.51111854, 90729.51111854,\n",
      "       90729.51111856, 90729.51111859, 90729.51111859, 90729.51111861]))\n",
      "           fun: 90729.51111847878\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1384\n",
      "           nit: 534\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.07350802e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "       1.96476728e+04, 2.31004541e+04, 1.06442171e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91338.66029620953, bestParams: [0.029967176, 0.105418496, 0.045315336, 5352.596, 2545.1953, 7796.2197, 16043.894]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.44726379e-02, 3.49043068e-02, 4.37101311e-02, 2.02821194e+03,\n",
      "        6.23612173e+03, 6.14653739e+03, 4.45542382e+03],\n",
      "       [3.44726355e-02, 3.49043034e-02, 4.37101328e-02, 2.02821196e+03,\n",
      "        6.23612174e+03, 6.14653748e+03, 4.45542375e+03],\n",
      "       [3.44726365e-02, 3.49043101e-02, 4.37101292e-02, 2.02821195e+03,\n",
      "        6.23612173e+03, 6.14653742e+03, 4.45542384e+03],\n",
      "       [3.44726357e-02, 3.49043114e-02, 4.37101301e-02, 2.02821195e+03,\n",
      "        6.23612168e+03, 6.14653744e+03, 4.45542382e+03],\n",
      "       [3.44726353e-02, 3.49043095e-02, 4.37101309e-02, 2.02821194e+03,\n",
      "        6.23612172e+03, 6.14653741e+03, 4.45542374e+03],\n",
      "       [3.44726354e-02, 3.49043147e-02, 4.37101280e-02, 2.02821196e+03,\n",
      "        6.23612170e+03, 6.14653740e+03, 4.45542391e+03],\n",
      "       [3.44726344e-02, 3.49043115e-02, 4.37101279e-02, 2.02821195e+03,\n",
      "        6.23612180e+03, 6.14653744e+03, 4.45542372e+03],\n",
      "       [3.44726337e-02, 3.49043122e-02, 4.37101303e-02, 2.02821194e+03,\n",
      "        6.23612172e+03, 6.14653737e+03, 4.45542377e+03]]), array([90642.45046539, 90642.45046608, 90642.45046658, 90642.45046711,\n",
      "       90642.45046727, 90642.45046771, 90642.45046814, 90642.45046855]))\n",
      "           fun: 90642.45046539283\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1428\n",
      "           nit: 638\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.44726379e-02, 3.49043068e-02, 4.37101311e-02, 2.02821194e+03,\n",
      "       6.23612173e+03, 6.14653739e+03, 4.45542382e+03])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 90822.19754322112, bestParams: [0.010888182, 0.014153072, 0.046646245, 3893.9783, 13470.374, 10266.924, 8581.38]\n",
      "epoch 8\n",
      " final_simplex: (array([[3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "        1.12126544e+03, 1.14623685e+03, 8.33927990e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580955e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623686e+03, 8.33927984e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903620e+02,\n",
      "        1.12126543e+03, 1.14623683e+03, 8.33927991e+02],\n",
      "       [3.82086249e-02, 3.13148454e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623682e+03, 8.33927983e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623684e+03, 8.33927993e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903611e+02,\n",
      "        1.12126540e+03, 1.14623683e+03, 8.33927973e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903626e+02,\n",
      "        1.12126544e+03, 1.14623684e+03, 8.33928033e+02],\n",
      "       [3.82086251e-02, 3.13148453e-02, 4.25580949e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623685e+03, 8.33928012e+02]]), array([90635.50396325, 90635.5039651 , 90635.5039652 , 90635.50396555,\n",
      "       90635.50396556, 90635.50396586, 90635.50397008, 90635.50397061]))\n",
      "           fun: 90635.50396325192\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 561\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "       1.12126544e+03, 1.14623685e+03, 8.33927990e+02])\n",
      "minPrevious 90642.85781500832\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "        1.12126544e+03, 1.14623685e+03, 8.33927990e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580955e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623686e+03, 8.33927984e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903620e+02,\n",
      "        1.12126543e+03, 1.14623683e+03, 8.33927991e+02],\n",
      "       [3.82086249e-02, 3.13148454e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623682e+03, 8.33927983e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623684e+03, 8.33927993e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903611e+02,\n",
      "        1.12126540e+03, 1.14623683e+03, 8.33927973e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903626e+02,\n",
      "        1.12126544e+03, 1.14623684e+03, 8.33928033e+02],\n",
      "       [3.82086251e-02, 3.13148453e-02, 4.25580949e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623685e+03, 8.33928012e+02]]), array([90635.50396325, 90635.5039651 , 90635.5039652 , 90635.50396555,\n",
      "       90635.50396556, 90635.50396586, 90635.50397008, 90635.50397061]))\n",
      "           fun: 90635.50396325192\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 561\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "       1.12126544e+03, 1.14623685e+03, 8.33927990e+02])\n",
      "best ll: 90795.9848434706, bestParams: [0.023895113, 0.04085701, 0.05497067, 7981.157, 15722.58, 17191.658, 21199.53]\n",
      "epoch 9\n",
      " final_simplex: (array([[2.82889394e-02, 4.02806717e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889394e-02, 4.02806719e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889396e-02, 4.02806716e-02, 4.32251584e-02, 6.71342930e+03,\n",
      "        2.14952765e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889396e-02, 4.02806717e-02, 4.32251585e-02, 6.71342930e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889395e-02, 4.02806717e-02, 4.32251589e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889396e-02, 4.02806717e-02, 4.32251583e-02, 6.71342930e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889395e-02, 4.02806718e-02, 4.32251588e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889395e-02, 4.02806717e-02, 4.32251587e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04]]), array([90649.70138782, 90649.70138796, 90649.70139572, 90649.70139578,\n",
      "       90649.70139578, 90649.70139579, 90649.7013958 , 90649.7013958 ]))\n",
      "           fun: 90649.70138781719\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1123\n",
      "           nit: 377\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.82889394e-02, 4.02806717e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "       2.14952764e+04, 1.98861867e+04, 1.47146669e+04])\n",
      "minPrevious 90635.50396325192\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0382, 0.0313, 0.0426], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8729, 0.0646, 0.0277, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8656, 0.0769, 0.0261, 0.0314], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8894, 0.0282, 0.0649, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8639, 0.0260, 0.0787, 0.0314], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7354, 0.0989, 0.0981, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7093, 0.1098, 0.1113, 0.0696], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.0017, 4.0782, 5.5325],\n",
      "        [2.8935, 2.9939, 5.7539],\n",
      "        [3.9443, 2.9939, 5.9781],\n",
      "        ...,\n",
      "        [4.9808, 4.8651, 7.1442],\n",
      "        [3.4877, 2.3421, 6.7752],\n",
      "        [2.0068, 2.9318, 5.2629]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.899680852890015\n",
      "Run: 0, 8\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[32.,  4.,  0.,  2.],\n",
      "        [48.,  2.,  2.,  0.],\n",
      "        [50.,  7.,  1.,  3.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [49.,  0.,  1.,  1.],\n",
      "        [50.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([38., 52., 61.,  ..., 70., 51., 53.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 2., 7.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 1.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 3.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[32.,  4.,  0.,  2.],\n",
      "        [48.,  2.,  2.,  0.],\n",
      "        [50.,  7.,  1.,  3.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [49.,  0.,  1.,  1.],\n",
      "        [50.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([3.4400e-04, 3.5403e-02, 9.0049e-06,  ..., 5.4883e-03, 2.6479e-02,\n",
      "        3.8102e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7d8437680>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90866.38670202054, bestParams: [0.04227104, 0.043204933, 0.035604723, 4999.505, 6446.358, 10356.963, 18687.867]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.78586233e-02, 4.97323902e-02, 4.39350770e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147190e+04, 8.49245920e+03],\n",
      "       [3.78586235e-02, 4.97323902e-02, 4.39350773e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147190e+04, 8.49245919e+03],\n",
      "       [3.78586232e-02, 4.97323905e-02, 4.39350767e-02, 3.58313190e+03,\n",
      "        1.04477020e+04, 1.02147190e+04, 8.49245911e+03],\n",
      "       [3.78586227e-02, 4.97323902e-02, 4.39350774e-02, 3.58313190e+03,\n",
      "        1.04477020e+04, 1.02147191e+04, 8.49245916e+03],\n",
      "       [3.78586228e-02, 4.97323899e-02, 4.39350782e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245925e+03],\n",
      "       [3.78586223e-02, 4.97323901e-02, 4.39350782e-02, 3.58313191e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245913e+03],\n",
      "       [3.78586225e-02, 4.97323904e-02, 4.39350773e-02, 3.58313189e+03,\n",
      "        1.04477020e+04, 1.02147191e+04, 8.49245911e+03],\n",
      "       [3.78586225e-02, 4.97323902e-02, 4.39350780e-02, 3.58313191e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245913e+03]]), array([90487.06109292, 90487.06109304, 90487.06109312, 90487.06109314,\n",
      "       90487.06109322, 90487.06109331, 90487.06109333, 90487.06109339]))\n",
      "           fun: 90487.06109292197\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1122\n",
      "           nit: 395\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.78586233e-02, 4.97323902e-02, 4.39350770e-02, 3.58313192e+03,\n",
      "       1.04477019e+04, 1.02147190e+04, 8.49245920e+03])\n",
      "best ll: 90778.79449381144, bestParams: [0.08165928, 0.087960355, 0.063273296, 6014.191, 7127.5513, 11117.987, 22590.318]\n",
      "epoch 1\n",
      " final_simplex: (array([[8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994274e-02, 7.17538081e-02, 4.81073032e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994274e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994276e-02, 7.17538080e-02, 4.81073031e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04],\n",
      "       [8.64994276e-02, 7.17538083e-02, 4.81073030e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04],\n",
      "       [8.64994279e-02, 7.17538081e-02, 4.81073029e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04]]), array([90562.47709194, 90562.47709201, 90562.47709202, 90562.47709211,\n",
      "       90562.47709213, 90562.47709218, 90562.47709236, 90562.47709241]))\n",
      "           fun: 90562.47709193993\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1227\n",
      "           nit: 471\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "       1.14898833e+04, 1.26010591e+04, 1.55118784e+04])\n",
      "minPrevious 90487.06109292197\n",
      "best ll: 90970.5610899757, bestParams: [0.09997445, 0.12198489, 0.051259637, 7826.5796, 23443.818, 14464.848, 18766.902]\n",
      "epoch 2\n",
      " final_simplex: (array([[8.71740907e-02, 9.11163488e-02, 5.16494257e-02, 8.27206657e+03,\n",
      "        1.61201928e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740909e-02, 9.11163489e-02, 5.16494256e-02, 8.27206655e+03,\n",
      "        1.61201928e+04, 1.78121709e+04, 2.57831929e+04],\n",
      "       [8.71740908e-02, 9.11163492e-02, 5.16494255e-02, 8.27206658e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740912e-02, 9.11163500e-02, 5.16494251e-02, 8.27206657e+03,\n",
      "        1.61201928e+04, 1.78121709e+04, 2.57831930e+04],\n",
      "       [8.71740911e-02, 9.11163504e-02, 5.16494251e-02, 8.27206659e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740911e-02, 9.11163502e-02, 5.16494252e-02, 8.27206659e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740914e-02, 9.11163510e-02, 5.16494248e-02, 8.27206657e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740915e-02, 9.11163513e-02, 5.16494247e-02, 8.27206658e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831931e+04]]), array([90589.73553078, 90589.73553096, 90589.73553098, 90589.73553157,\n",
      "       90589.73553194, 90589.73553196, 90589.73553245, 90589.73553278]))\n",
      "           fun: 90589.73553077558\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1493\n",
      "           nit: 613\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.71740907e-02, 9.11163488e-02, 5.16494257e-02, 8.27206657e+03,\n",
      "       1.61201928e+04, 1.78121708e+04, 2.57831930e+04])\n",
      "minPrevious 90487.06109292197\n",
      "best ll: 90702.98167128472, bestParams: [0.03473026, 0.046426747, 0.061863348, 9696.083, 24623.559, 19582.648, 17360.992]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639317e-02, 4.45271009e-02, 4.57781923e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639318e-02, 4.45271006e-02, 4.57781931e-02, 8.53728467e+03,\n",
      "        2.49527256e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639319e-02, 4.45271002e-02, 4.57781944e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639321e-02, 4.45270995e-02, 4.57781964e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639323e-02, 4.45270990e-02, 4.57781979e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639324e-02, 4.45270989e-02, 4.57781981e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966649e+04, 1.98905847e+04],\n",
      "       [3.66639324e-02, 4.45270987e-02, 4.57781989e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04]]), array([90482.69509499, 90482.69509598, 90482.69509679, 90482.69509802,\n",
      "       90482.69510007, 90482.69510157, 90482.69510186, 90482.69510255]))\n",
      "           fun: 90482.69509499139\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1646\n",
      "           nit: 743\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "       2.49527257e+04, 2.45966650e+04, 1.98905847e+04])\n",
      "minPrevious 90487.06109292197\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639317e-02, 4.45271009e-02, 4.57781923e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639318e-02, 4.45271006e-02, 4.57781931e-02, 8.53728467e+03,\n",
      "        2.49527256e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639319e-02, 4.45271002e-02, 4.57781944e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639321e-02, 4.45270995e-02, 4.57781964e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639323e-02, 4.45270990e-02, 4.57781979e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639324e-02, 4.45270989e-02, 4.57781981e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966649e+04, 1.98905847e+04],\n",
      "       [3.66639324e-02, 4.45270987e-02, 4.57781989e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04]]), array([90482.69509499, 90482.69509598, 90482.69509679, 90482.69509802,\n",
      "       90482.69510007, 90482.69510157, 90482.69510186, 90482.69510255]))\n",
      "           fun: 90482.69509499139\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1646\n",
      "           nit: 743\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "       2.49527257e+04, 2.45966650e+04, 1.98905847e+04])\n",
      "best ll: 90867.56193183556, bestParams: [0.0098387115, 0.062886804, 0.053461675, 6239.042, 23488.914, 22569.387, 434.96948]\n",
      "epoch 4\n",
      " final_simplex: (array([[1.15378583e-02, 2.04791823e-02, 4.61124020e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670302e+04, 6.11843483e+02],\n",
      "       [1.15378583e-02, 2.04791820e-02, 4.61124014e-02, 5.84323512e+03,\n",
      "        2.64481986e+04, 2.49670302e+04, 6.11843490e+02],\n",
      "       [1.15378582e-02, 2.04791827e-02, 4.61124012e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843491e+02],\n",
      "       [1.15378581e-02, 2.04791822e-02, 4.61124010e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843498e+02],\n",
      "       [1.15378580e-02, 2.04791818e-02, 4.61124008e-02, 5.84323512e+03,\n",
      "        2.64481986e+04, 2.49670302e+04, 6.11843501e+02],\n",
      "       [1.15378578e-02, 2.04791817e-02, 4.61124003e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843513e+02],\n",
      "       [1.15378578e-02, 2.04791814e-02, 4.61124005e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843513e+02],\n",
      "       [1.15378578e-02, 2.04791806e-02, 4.61124008e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670302e+04, 6.11843515e+02]]), array([90612.29504722, 90612.29504755, 90612.29504758, 90612.29504799,\n",
      "       90612.29504825, 90612.29504873, 90612.29504883, 90612.29504907]))\n",
      "           fun: 90612.29504722435\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1277\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.15378583e-02, 2.04791823e-02, 4.61124020e-02, 5.84323512e+03,\n",
      "       2.64481985e+04, 2.49670302e+04, 6.11843483e+02])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90725.9879271773, bestParams: [0.043563887, 0.012296107, 0.08686379, 4552.979, 12478.696, 12336.921, 8655.909]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.38270526e-02, 2.14812023e-02, 4.24158900e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403708e+03],\n",
      "       [3.38270531e-02, 2.14812022e-02, 4.24158901e-02, 4.15356910e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403705e+03],\n",
      "       [3.38270544e-02, 2.14812014e-02, 4.24158909e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212583e+04, 6.94403701e+03],\n",
      "       [3.38270549e-02, 2.14812012e-02, 4.24158914e-02, 4.15356913e+03,\n",
      "        1.34924801e+04, 1.44212583e+04, 6.94403698e+03],\n",
      "       [3.38270561e-02, 2.14812008e-02, 4.24158918e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403707e+03],\n",
      "       [3.38270559e-02, 2.14812006e-02, 4.24158918e-02, 4.15356913e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403715e+03],\n",
      "       [3.38270568e-02, 2.14812003e-02, 4.24158922e-02, 4.15356911e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403715e+03],\n",
      "       [3.38270567e-02, 2.14812002e-02, 4.24158924e-02, 4.15356912e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403709e+03]]), array([90506.88456244, 90506.8845628 , 90506.88456515, 90506.88456571,\n",
      "       90506.88456661, 90506.8845673 , 90506.8845681 , 90506.88456827]))\n",
      "           fun: 90506.88456243879\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1294\n",
      "           nit: 525\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38270526e-02, 2.14812023e-02, 4.24158900e-02, 4.15356911e+03,\n",
      "       1.34924801e+04, 1.44212582e+04, 6.94403708e+03])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90707.96802735567, bestParams: [0.01074106, 0.056317706, 0.062326808, 6906.7803, 14660.881, 12282.025, 20889.7]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948854e-02, 4.49989146e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948855e-02, 4.49989148e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948855e-02, 4.49989147e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778318e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948857e-02, 4.49989150e-02, 5.80778323e+03,\n",
      "        1.99696317e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948856e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948856e-02, 4.49989148e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04]]), array([90513.85897781, 90513.85897782, 90513.85897782, 90513.8589779 ,\n",
      "       90513.85897801, 90513.85897812, 90513.85897819, 90513.85897819]))\n",
      "           fun: 90513.85897780894\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1223\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "       1.99696318e+04, 1.68266749e+04, 1.13317168e+04])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 91208.12679174251, bestParams: [0.018939186, 0.13372447, 0.09658249, 7547.9326, 16754.46, 12379.46, 9450.32]\n",
      "epoch 7\n",
      " final_simplex: (array([[2.38771336e-02, 4.86939481e-02, 4.37289625e-02, 6.16011838e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658889e+04],\n",
      "       [2.38771335e-02, 4.86939479e-02, 4.37289625e-02, 6.16011839e+03,\n",
      "        1.88306626e+04, 1.72063936e+04, 1.41658889e+04],\n",
      "       [2.38771332e-02, 4.86939487e-02, 4.37289632e-02, 6.16011841e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771331e-02, 4.86939495e-02, 4.37289634e-02, 6.16011841e+03,\n",
      "        1.88306626e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771334e-02, 4.86939500e-02, 4.37289621e-02, 6.16011839e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771332e-02, 4.86939498e-02, 4.37289632e-02, 6.16011840e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771332e-02, 4.86939496e-02, 4.37289630e-02, 6.16011839e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771331e-02, 4.86939479e-02, 4.37289631e-02, 6.16011840e+03,\n",
      "        1.88306626e+04, 1.72063937e+04, 1.41658888e+04]]), array([90493.66767072, 90493.66767083, 90493.667671  , 90493.66767111,\n",
      "       90493.66767112, 90493.66767118, 90493.66767124, 90493.66767134]))\n",
      "           fun: 90493.6676707186\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1261\n",
      "           nit: 515\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.38771336e-02, 4.86939481e-02, 4.37289625e-02, 6.16011838e+03,\n",
      "       1.88306625e+04, 1.72063936e+04, 1.41658889e+04])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90946.33073211275, bestParams: [0.06552671, 0.03858188, 0.027416045, 5274.589, 17153.447, 15913.322, 3718.8213]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.66046495e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111184e+03],\n",
      "       [2.66046496e-02, 3.30193378e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046496e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046495e-02, 3.30193379e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111182e+03],\n",
      "       [2.66046494e-02, 3.30193379e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046494e-02, 3.30193379e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314351e+04, 1.28060088e+04, 6.71111184e+03],\n",
      "       [2.66046493e-02, 3.30193377e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060087e+04, 6.71111188e+03],\n",
      "       [2.66046494e-02, 3.30193377e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060087e+04, 6.71111185e+03]]), array([90491.11260967, 90491.11260969, 90491.1126097 , 90491.11260972,\n",
      "       90491.11260973, 90491.11260974, 90491.11260981, 90491.11260981]))\n",
      "           fun: 90491.11260967342\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1209\n",
      "           nit: 424\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.66046495e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "       1.31314350e+04, 1.28060088e+04, 6.71111184e+03])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90979.13690442877, bestParams: [0.03663157, 0.05130152, 0.088229544, 6370.648, 15553.35, 12778.411, 7697.9907]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.97788087e-02, 4.67508439e-02, 4.20900894e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412336e+04],\n",
      "       [3.97788089e-02, 4.67508438e-02, 4.20900895e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412336e+04],\n",
      "       [3.97788088e-02, 4.67508436e-02, 4.20900896e-02, 5.37312917e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412336e+04],\n",
      "       [3.97788087e-02, 4.67508442e-02, 4.20900896e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412335e+04],\n",
      "       [3.97788087e-02, 4.67508442e-02, 4.20900894e-02, 5.37312917e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412335e+04],\n",
      "       [3.97788085e-02, 4.67508446e-02, 4.20900899e-02, 5.37312915e+03,\n",
      "        1.61818613e+04, 1.60830102e+04, 1.16412335e+04],\n",
      "       [3.97788087e-02, 4.67508439e-02, 4.20900892e-02, 5.37312918e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412336e+04],\n",
      "       [3.97788084e-02, 4.67508448e-02, 4.20900899e-02, 5.37312916e+03,\n",
      "        1.61818613e+04, 1.60830102e+04, 1.16412335e+04]]), array([90485.31169553, 90485.31169555, 90485.31169556, 90485.31169564,\n",
      "       90485.31169573, 90485.31169573, 90485.31169582, 90485.31169587]))\n",
      "           fun: 90485.31169552742\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1246\n",
      "           nit: 478\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97788087e-02, 4.67508439e-02, 4.20900894e-02, 5.37312916e+03,\n",
      "       1.61818614e+04, 1.60830103e+04, 1.16412336e+04])\n",
      "minPrevious 90482.69509499139\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0367, 0.0445, 0.0458], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8773, 0.0628, 0.0278, 0.0251], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8679, 0.0761, 0.0260, 0.0300], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8874, 0.0282, 0.0652, 0.0261], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8687, 0.0261, 0.0751, 0.0301], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7379, 0.0985, 0.0987, 0.0616], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7085, 0.1116, 0.1107, 0.0692], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7394, 3.1648, 4.3888],\n",
      "        [3.2083, 2.9599, 5.7800],\n",
      "        [2.2675, 2.0366, 4.9875],\n",
      "        ...,\n",
      "        [3.8538, 3.8462, 5.9722],\n",
      "        [3.6667, 5.0235, 5.9005],\n",
      "        [5.0420, 4.6122, 7.5952]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.200846195220947\n",
      "Run: 0, 9\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[50.,  1.,  1.,  2.],\n",
      "        [61.,  3.,  1.,  1.],\n",
      "        [52.,  2.,  1.,  1.],\n",
      "        ...,\n",
      "        [53.,  0.,  1.,  1.],\n",
      "        [56.,  1.,  1.,  0.],\n",
      "        [47.,  2.,  1.,  2.]], dtype=torch.float64)\n",
      "n tensor([54., 66., 56.,  ..., 55., 58., 52.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 2.,  ..., 0., 1., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 1., 0., 2.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[50.,  1.,  1.,  2.],\n",
      "        [61.,  3.,  1.,  1.],\n",
      "        [52.,  2.,  1.,  1.],\n",
      "        ...,\n",
      "        [53.,  0.,  1.,  1.],\n",
      "        [56.,  1.,  1.,  0.],\n",
      "        [47.,  2.,  1.,  2.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0115, 0.0177, 0.0291,  ..., 0.0234, 0.0528, 0.0082],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3f200>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90761.7781549094, bestParams: [0.04600825, 0.034627862, 0.03320431, 3705.6182, 7804.2446, 11532.189, 11376.845]\n",
      "epoch 0\n",
      " final_simplex: (array([[4.79401002e-02, 3.59860707e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126223e+03],\n",
      "       [4.79401001e-02, 3.59860709e-02, 4.02713562e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126223e+03],\n",
      "       [4.79401002e-02, 3.59860711e-02, 4.02713562e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126226e+03],\n",
      "       [4.79401004e-02, 3.59860708e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043620e+04, 7.70126228e+03],\n",
      "       [4.79401003e-02, 3.59860708e-02, 4.02713564e-02, 3.34189612e+03,\n",
      "        9.83545166e+03, 1.05043621e+04, 7.70126227e+03],\n",
      "       [4.79401006e-02, 3.59860705e-02, 4.02713567e-02, 3.34189612e+03,\n",
      "        9.83545165e+03, 1.05043620e+04, 7.70126230e+03],\n",
      "       [4.79401005e-02, 3.59860707e-02, 4.02713564e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126229e+03],\n",
      "       [4.79401005e-02, 3.59860705e-02, 4.02713563e-02, 3.34189612e+03,\n",
      "        9.83545165e+03, 1.05043621e+04, 7.70126227e+03]]), array([90616.66706736, 90616.66706748, 90616.66706754, 90616.66706756,\n",
      "       90616.66706758, 90616.66706764, 90616.66706774, 90616.66706778]))\n",
      "           fun: 90616.66706735565\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1129\n",
      "           nit: 411\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.79401002e-02, 3.59860707e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "       9.83545164e+03, 1.05043621e+04, 7.70126223e+03])\n",
      "best ll: 91516.6859835903, bestParams: [0.026306985, 0.08133267, 0.024871472, 6414.625, 13429.396, 3964.474, 20765.12]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.28815934e-02, 8.33975562e-02, 4.81044641e-02, 2.66958385e+03,\n",
      "        7.24460965e+03, 6.30083680e+03, 7.38755573e+03],\n",
      "       [3.28815935e-02, 8.33975565e-02, 4.81044639e-02, 2.66958386e+03,\n",
      "        7.24460964e+03, 6.30083682e+03, 7.38755570e+03],\n",
      "       [3.28815934e-02, 8.33975568e-02, 4.81044637e-02, 2.66958386e+03,\n",
      "        7.24460973e+03, 6.30083679e+03, 7.38755579e+03],\n",
      "       [3.28815934e-02, 8.33975564e-02, 4.81044642e-02, 2.66958386e+03,\n",
      "        7.24460969e+03, 6.30083679e+03, 7.38755583e+03],\n",
      "       [3.28815934e-02, 8.33975567e-02, 4.81044638e-02, 2.66958386e+03,\n",
      "        7.24460967e+03, 6.30083680e+03, 7.38755576e+03],\n",
      "       [3.28815935e-02, 8.33975571e-02, 4.81044636e-02, 2.66958386e+03,\n",
      "        7.24460967e+03, 6.30083682e+03, 7.38755564e+03],\n",
      "       [3.28815934e-02, 8.33975570e-02, 4.81044637e-02, 2.66958386e+03,\n",
      "        7.24460966e+03, 6.30083681e+03, 7.38755572e+03],\n",
      "       [3.28815934e-02, 8.33975569e-02, 4.81044638e-02, 2.66958385e+03,\n",
      "        7.24460973e+03, 6.30083679e+03, 7.38755575e+03]]), array([90672.74759503, 90672.74759516, 90672.74759536, 90672.74759546,\n",
      "       90672.7475955 , 90672.74759568, 90672.74759569, 90672.74759581]))\n",
      "           fun: 90672.74759502892\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1175\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.28815934e-02, 8.33975562e-02, 4.81044641e-02, 2.66958385e+03,\n",
      "       7.24460965e+03, 6.30083680e+03, 7.38755573e+03])\n",
      "minPrevious 90616.66706735565\n",
      "best ll: 91198.52576890608, bestParams: [0.06617981, 0.0026062375, 0.052282184, 5632.2466, 15811.634, 23665.295, 21685.236]\n",
      "epoch 2\n",
      " final_simplex: (array([[5.97788174e-02, 2.86239567e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788175e-02, 2.86239567e-03, 5.14519103e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788175e-02, 2.86239566e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766147e+04, 1.54040265e+04],\n",
      "       [5.97788177e-02, 2.86239567e-03, 5.14519102e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766145e+04, 1.54040266e+04],\n",
      "       [5.97788177e-02, 2.86239565e-03, 5.14519106e-02, 7.10048604e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04],\n",
      "       [5.97788175e-02, 2.86239568e-03, 5.14519099e-02, 7.10048600e+03,\n",
      "        1.78954599e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788178e-02, 2.86239566e-03, 5.14519104e-02, 7.10048604e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04],\n",
      "       [5.97788177e-02, 2.86239566e-03, 5.14519103e-02, 7.10048602e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04]]), array([90761.99558966, 90761.99558975, 90761.99558987, 90761.99558988,\n",
      "       90761.99558996, 90761.99559001, 90761.99559002, 90761.99559008]))\n",
      "           fun: 90761.99558965943\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1259\n",
      "           nit: 478\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.97788174e-02, 2.86239567e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "       1.78954598e+04, 2.16766146e+04, 1.54040265e+04])\n",
      "minPrevious 90616.66706735565\n",
      "best ll: 90782.52717622745, bestParams: [0.028903035, 0.05556211, 0.03673761, 6341.9014, 12760.6875, 16858.322, 19627.572]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5c67a24bbe10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    586\u001b[0m                       callback=callback, **options)\n\u001b[1;32m    587\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mxbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxbar\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mfxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mdoshrink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0ma1Both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1Both\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0ma21\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "resSim = {\n",
    "        \"allRes\": None,\n",
    "        \"nEpochs\": None,\n",
    "        \"bestRes\": {\n",
    "            \"pis\": None,\n",
    "            \"alphas\": None,\n",
    "            \"PDV_c1true\": None,\n",
    "            \"PDV_c2true\": None,\n",
    "            \"PDV_cBothTrue\": None,\n",
    "            \"PDV_c1inferred\": None,\n",
    "            \"PDV_c2inferred\": None,\n",
    "            \"PDV_cBothInferred\": None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cached6NormalSimResNonAnnealing = []\n",
    "\n",
    "rrsSim = tensor([[2, 2, 1.5]])\n",
    "pisSim = tensor([[.05, .05, .05]])\n",
    "\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(5e5)\n",
    "i = 0\n",
    "for rrsSimRun in rrsSim:\n",
    "    for pisSimRun in pisSim:\n",
    "        afMeanRun = 1e-4\n",
    "        generatingFn = genData.v6normal\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        # needs tensor for shapes, otherwise \"gamma_cpu not implemente for long\", e.g rrShape=50.0 doesn't work...\n",
    "        paramsRun = genData.genParams(rrMeans=rrsSimRun, pis=pisSimRun, afMean=afMeanRun, rrShape=tensor(50.), afShape=tensor(50.), nCases=nCases, nCtrls=nCtrls)[0]\n",
    "        \n",
    "        pDsRun = paramsRun[\"pDs\"]\n",
    "        pisRun = paramsRun[\"diseaseFractions\"]\n",
    "        print(\"params are:\", paramsRun)\n",
    "        \n",
    "        cached6NormalSimResNonAnnealing.append({\"params\": paramsRun, \"runs\": []})\n",
    "        for y in range(0, 10):\n",
    "            start = time.time()\n",
    "            r = generatingFn(**paramsRun)\n",
    "            print(\"took\", time.time() - start)\n",
    "            \n",
    "            resPointer = {\n",
    "                **r,\n",
    "                \"generatingFn\": generatingFn,\n",
    "                \"results\": None,\n",
    "            }\n",
    "\n",
    "            cached6NormalSimResNonAnnealing[i][\"runs\"].append(resPointer)\n",
    "            \n",
    "            print(f\"Run: {i}, {y}\")\n",
    "            \n",
    "            xsRun = resPointer[\"altCounts\"]\n",
    "            afsRun = resPointer[\"afs\"]\n",
    "            affectedGenesRun = resPointer[\"affectedGenes\"]\n",
    "            unaffectedGenesRun = resPointer[\"unaffectedGenes\"]\n",
    "\n",
    "            runCostFnIdx = 16\n",
    "\n",
    "            nEpochsRun = 10\n",
    "            print(\"nEpochsRun\", nEpochsRun)\n",
    "            \n",
    "            res = likelihoods.fitFnBivariate(xsRun, pDsRun, nEpochs=nEpochsRun, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "            bestRes = res[\"params\"][-1]\n",
    "\n",
    "            inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "            inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "            #### Calculate actual ###\n",
    "            component1Afs = afsRun[affectedGenesRun[0]]\n",
    "            c1true = (component1Afs / afMeanRun).mean(0)\n",
    "\n",
    "            component2Afs = afsRun[affectedGenesRun[1]]\n",
    "            c2true = (component2Afs / afMeanRun).mean(0)\n",
    "\n",
    "            componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "            cBothTrue = (componentBothAfs / afMeanRun).mean(0)\n",
    "\n",
    "            ### calculate inferred values\n",
    "            pds = tensor([1-pDsRun.sum(), *pDsRun])\n",
    "            alphas = inferredAlphas.numpy()\n",
    "            c1inferred = Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            c2inferred = Dirichlet(tensor([alphas[0], alphas[0], alphas[2], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            cBothInferred = Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0)\n",
    "\n",
    "            print(f\"\\n\\nrun {i} results for rrs: {rrsSimRun}, pis: {pisSimRun}\")\n",
    "            print(\"Inferred pis:\", inferredPis)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c1true)\n",
    "            print(\"P(D|V) inferred in component 1:\", c1inferred)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c2true)\n",
    "            print(\"P(D|V) inferred in component both:\", c2inferred)\n",
    "            print(\"\\nP(D|V) true ans in component both:\", cBothTrue)\n",
    "            print(\"P(D|V) inferred in component both:\", cBothInferred,\"\\n\\n\")\n",
    "\n",
    "            resToStore = copy.deepcopy(resSim)\n",
    "            resToStore[\"allRes\"] = res\n",
    "            resToStore[\"nEpochs\"] = nEpochsRun\n",
    "            br = resToStore[\"bestRes\"]\n",
    "            br[\"pis\"] = inferredPis\n",
    "            br[\"alphas\"] = inferredAlphas\n",
    "            br[\"PDV_c1true\"] = c1true\n",
    "            br[\"PDV_c2true\"] = c2true\n",
    "            br[\"PDV_cBothTrue\"] = cBothTrue\n",
    "            br[\"PDV_c1inferred\"] = c1inferred\n",
    "            br[\"PDV_c2inferred\"] = c2inferred\n",
    "            br[\"PDV_cBothInferred\"] = cBothInferred\n",
    "\n",
    "            resPointer[\"results\"] = resToStore\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([1.5000, 1.5000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.8293, 2.6289, 3.8956],\n",
      "        [2.4995, 2.3651, 2.9228],\n",
      "        [2.9986, 3.1782, 5.7793],\n",
      "        ...,\n",
      "        [1.6170, 2.4270, 3.9871],\n",
      "        [2.6860, 2.5748, 3.5131],\n",
      "        [3.5057, 4.4161, 3.9715]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.05718994140625\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  0.],\n",
      "        [44.,  6.,  1.,  1.],\n",
      "        [50.,  2.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  3.,  2.,  0.],\n",
      "        [53.,  1.,  1.,  3.],\n",
      "        [53.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "n tensor([50., 52., 55.,  ..., 53., 58., 55.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 6., 2.,  ..., 3., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 2.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 0., 3., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  0.],\n",
      "        [44.,  6.,  1.,  1.],\n",
      "        [50.,  2.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  3.,  2.,  0.],\n",
      "        [53.,  1.,  1.,  3.],\n",
      "        [53.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0164, 0.0003, 0.0222,  ..., 0.0175, 0.0025, 0.0234],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa6304e8440>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89254.57939981687, bestParams: [0.09598137, 0.18161891, 0.066081025, 8628.348, 19064.254, 11141.051, 24336.697]\n",
      "epoch 0\n",
      "     fun: 89087.15867372246\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 17512\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.06655157e-01, 8.05196165e-03, 8.52313234e-02, 1.51882047e+04,\n",
      "       1.59563997e+04, 2.49997166e+04, 2.49999993e+04])\n",
      "took 263.1990089416504\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([1.5000, 1.5000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.9067, 0.0081, 0.0852], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8974, 0.0550, 0.0281, 0.0220], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.9248, 0.0291, 0.0277, 0.0183], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8934, 0.0280, 0.0558, 0.0223], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.9098, 0.0273, 0.0449, 0.0180], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7746, 0.0863, 0.0874, 0.0510], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8119, 0.0657, 0.0802, 0.0423], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.0191, 2.4042, 5.8232],\n",
      "        [1.0840, 2.3261, 4.9498],\n",
      "        [3.7891, 1.8827, 4.6055],\n",
      "        ...,\n",
      "        [4.0709, 3.3965, 6.2600],\n",
      "        [1.4524, 3.2465, 4.9516],\n",
      "        [2.2135, 1.7095, 4.1531]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.519060134887695\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  2.],\n",
      "        [45.,  6.,  4.,  3.],\n",
      "        [54.,  5.,  1.,  0.],\n",
      "        ...,\n",
      "        [59.,  3.,  2.,  3.],\n",
      "        [44.,  1.,  3.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([45., 58., 60.,  ..., 67., 48., 45.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 5.,  ..., 3., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 4., 1.,  ..., 2., 3., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 0.,  ..., 3., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  2.],\n",
      "        [45.,  6.,  4.,  3.],\n",
      "        [54.,  5.,  1.,  0.],\n",
      "        ...,\n",
      "        [59.,  3.,  2.,  3.],\n",
      "        [44.,  1.,  3.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([6.2383e-03, 3.4287e-06, 3.3784e-03,  ..., 1.4544e-03, 2.2402e-02,\n",
      "        4.3776e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa6411153b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89545.34098332483, bestParams: [0.019650858, 0.005765289, 0.015805295, 8096.601, 15435.601, 23816.336, 12740.194]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-087714822751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunSim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1387c87bde79>\u001b[0m in \u001b[0;36mrunSim\u001b[0;34m(rrs, pis, nCases, nCtrls, afMean, rrShape, afShape, generatingFn, fitMethod)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitMethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx, method)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Nelder-Mead'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adaptive\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"annealing\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"basinhopping\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasinhopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mdual_annealing\u001b[0;34m(func, bounds, args, maxiter, local_search_options, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0)\u001b[0m\n\u001b[1;32m    663\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;31m# starting strategy chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, step, temperature)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 self.energy_state.current_location, j, temperature)\n\u001b[1;32m    290\u001b[0m             \u001b[0;31m# Calling the objective function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_visit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_energy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;31m# We have got a better energy value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0maBothBoth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malphaBoth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mh3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBoth1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBoth2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBothBoth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mh0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runSim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN\n",
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([1.5000, 1.5000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9334, 2.5262, 4.5972],\n",
      "        [2.9295, 2.6827, 4.2659],\n",
      "        [3.4033, 4.0980, 4.6098],\n",
      "        ...,\n",
      "        [3.2606, 1.8734, 3.4271],\n",
      "        [2.4874, 2.7894, 4.5732],\n",
      "        [3.8228, 2.9923, 4.2592]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.798516273498535\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  1.],\n",
      "        [51.,  0.,  2.,  3.],\n",
      "        [41.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [55.,  1.,  4.,  0.],\n",
      "        [40.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([51., 56., 44.,  ..., 60., 42., 43.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 0.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 2.,  ..., 4., 1., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 1.,  ..., 0., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  1.],\n",
      "        [51.,  0.,  2.,  3.],\n",
      "        [41.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [55.,  1.,  4.,  0.],\n",
      "        [40.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0093, 0.0012, 0.0201,  ..., 0.0102, 0.0836, 0.0409],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa60809c050>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89504.27484045511, bestParams: [0.01460946, 0.02944035, 0.03863643, 3142.4583, 3569.245, 5062.629, 6662.2]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112738e+03,\n",
      "        5.21052634e+03, 4.99263541e+03, 2.62354673e+03],\n",
      "       [1.98604401e-02, 3.41540280e-02, 3.55878742e-02, 1.65112738e+03,\n",
      "        5.21052633e+03, 4.99263546e+03, 2.62354667e+03],\n",
      "       [1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112737e+03,\n",
      "        5.21052636e+03, 4.99263542e+03, 2.62354672e+03],\n",
      "       [1.98604400e-02, 3.41540281e-02, 3.55878741e-02, 1.65112738e+03,\n",
      "        5.21052634e+03, 4.99263542e+03, 2.62354670e+03],\n",
      "       [1.98604401e-02, 3.41540283e-02, 3.55878742e-02, 1.65112737e+03,\n",
      "        5.21052638e+03, 4.99263537e+03, 2.62354673e+03],\n",
      "       [1.98604401e-02, 3.41540280e-02, 3.55878744e-02, 1.65112737e+03,\n",
      "        5.21052634e+03, 4.99263546e+03, 2.62354667e+03],\n",
      "       [1.98604400e-02, 3.41540281e-02, 3.55878747e-02, 1.65112738e+03,\n",
      "        5.21052627e+03, 4.99263541e+03, 2.62354677e+03],\n",
      "       [1.98604400e-02, 3.41540282e-02, 3.55878745e-02, 1.65112738e+03,\n",
      "        5.21052630e+03, 4.99263539e+03, 2.62354675e+03]]), array([89097.20969999, 89097.20970001, 89097.20970011, 89097.20970015,\n",
      "       89097.20970023, 89097.20970029, 89097.2097003 , 89097.20970032]))\n",
      "           fun: 89097.20969998793\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1187\n",
      "           nit: 474\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112738e+03,\n",
      "       5.21052634e+03, 4.99263541e+03, 2.62354673e+03])\n",
      "best ll: 89661.97322291948, bestParams: [0.03616922, 0.032769334, 0.045829535, 10727.266, 24210.703, 12838.759, 15205.117]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514215e-02, 7.07864376e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259062e+04],\n",
      "       [4.19236529e-02, 3.25639602e-02, 3.48514220e-02, 7.07864378e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236527e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514220e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041261e+04, 2.08219659e+04, 1.43259061e+04]]), array([89076.07821087, 89076.07821088, 89076.07821092, 89076.07821098,\n",
      "       89076.07821101, 89076.07821117, 89076.07821118, 89076.07821121]))\n",
      "           fun: 89076.07821086713\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1248\n",
      "           nit: 473\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "       1.96041260e+04, 2.08219659e+04, 1.43259061e+04])\n",
      "minPrevious 89097.20969998793\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514215e-02, 7.07864376e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259062e+04],\n",
      "       [4.19236529e-02, 3.25639602e-02, 3.48514220e-02, 7.07864378e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236527e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514220e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041261e+04, 2.08219659e+04, 1.43259061e+04]]), array([89076.07821087, 89076.07821088, 89076.07821092, 89076.07821098,\n",
      "       89076.07821101, 89076.07821117, 89076.07821118, 89076.07821121]))\n",
      "           fun: 89076.07821086713\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1248\n",
      "           nit: 473\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "       1.96041260e+04, 2.08219659e+04, 1.43259061e+04])\n",
      "best ll: 89396.0603735198, bestParams: [0.02752898, 0.02535716, 0.018690322, 5718.255, 12018.066, 19256.404, 19616.584]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.03046914e-02, 2.79128625e-02, 2.73070996e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259645e+03],\n",
      "       [3.03046915e-02, 2.79128625e-02, 2.73070995e-02, 4.82605052e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259643e+03],\n",
      "       [3.03046916e-02, 2.79128625e-02, 2.73070995e-02, 4.82605052e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259641e+03],\n",
      "       [3.03046916e-02, 2.79128625e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259646e+03],\n",
      "       [3.03046915e-02, 2.79128626e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259648e+03],\n",
      "       [3.03046916e-02, 2.79128626e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259646e+03],\n",
      "       [3.03046918e-02, 2.79128627e-02, 2.73070993e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259651e+03],\n",
      "       [3.03046916e-02, 2.79128624e-02, 2.73070996e-02, 4.82605052e+03,\n",
      "        1.52177117e+04, 1.57090374e+04, 7.96259636e+03]]), array([89090.52106561, 89090.52106562, 89090.52106564, 89090.52106565,\n",
      "       89090.52106566, 89090.52106567, 89090.52106586, 89090.52107062]))\n",
      "           fun: 89090.52106561436\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1246\n",
      "           nit: 440\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.03046914e-02, 2.79128625e-02, 2.73070996e-02, 4.82605053e+03,\n",
      "       1.52177116e+04, 1.57090374e+04, 7.96259645e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89159.98797501124, bestParams: [0.07087075, 0.035208993, 0.046770897, 7998.9688, 20401.977, 21096.521, 20626.426]\n",
      "epoch 3\n",
      " final_simplex: (array([[6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623725e+04],\n",
      "       [6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730239e+04, 1.97623725e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623724e+04],\n",
      "       [6.71874810e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874810e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874811e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623724e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04]]), array([89100.40359353, 89100.40359355, 89100.40359361, 89100.40359362,\n",
      "       89100.40359366, 89100.40359367, 89100.40359371, 89100.40359375]))\n",
      "           fun: 89100.40359352919\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1309\n",
      "           nit: 496\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "       1.97499805e+04, 2.14730240e+04, 1.97623725e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89266.87360477714, bestParams: [0.02102224, 0.0073940502, 0.04933069, 9835.428, 20614.709, 23006.111, 24559.834]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.81792183e-02, 1.00385350e-02, 4.10791068e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436391e+03],\n",
      "       [2.81792178e-02, 1.00385350e-02, 4.10791081e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436387e+03],\n",
      "       [2.81792169e-02, 1.00385350e-02, 4.10791109e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436386e+03],\n",
      "       [2.81792169e-02, 1.00385350e-02, 4.10791111e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436397e+03],\n",
      "       [2.81792162e-02, 1.00385350e-02, 4.10791133e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436397e+03],\n",
      "       [2.81792161e-02, 1.00385351e-02, 4.10791135e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436386e+03],\n",
      "       [2.81792156e-02, 1.00385350e-02, 4.10791151e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436393e+03],\n",
      "       [2.81792146e-02, 1.00385351e-02, 4.10791183e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436391e+03]]), array([89131.49405002, 89131.49405098, 89131.49405308, 89131.49405339,\n",
      "       89131.49405506, 89131.49405509, 89131.4940564 , 89131.4940588 ]))\n",
      "           fun: 89131.49405001549\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2322\n",
      "           nit: 1097\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.81792183e-02, 1.00385350e-02, 4.10791068e-02, 7.92193726e+03,\n",
      "       2.46257826e+04, 2.70287627e+04, 8.82436391e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89362.65263565104, bestParams: [0.012687951, 0.011631452, 0.07809705, 6797.328, 13523.173, 17862.2, 14069.145]\n",
      "epoch 5\n",
      " final_simplex: (array([[1.84218776e-02, 1.37973849e-02, 3.77607203e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083500e+03],\n",
      "       [1.84218775e-02, 1.37973850e-02, 3.77607202e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083503e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607205e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083504e+03],\n",
      "       [1.84218776e-02, 1.37973850e-02, 3.77607202e-02, 5.59975530e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083499e+03],\n",
      "       [1.84218777e-02, 1.37973848e-02, 3.77607207e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083490e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607205e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083495e+03],\n",
      "       [1.84218776e-02, 1.37973850e-02, 3.77607202e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083502e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607204e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083499e+03]]), array([89133.97795553, 89133.97795554, 89133.97795572, 89133.9779627 ,\n",
      "       89133.97796275, 89133.97796276, 89133.97796276, 89133.97796277]))\n",
      "           fun: 89133.97795552979\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1228\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.84218776e-02, 1.37973849e-02, 3.77607203e-02, 5.59975531e+03,\n",
      "       1.89100468e+04, 1.95686277e+04, 5.99083500e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89212.69924155968, bestParams: [0.025522236, 0.07102064, 0.04095869, 6469.978, 23772.977, 16247.678, 7731.7466]\n",
      "epoch 6\n",
      " final_simplex: (array([[2.70476141e-02, 4.01468282e-02, 3.26248241e-02, 6.48001244e+03,\n",
      "        1.99119150e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476140e-02, 4.01468277e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394004e+04],\n",
      "       [2.70476141e-02, 4.01468286e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476141e-02, 4.01468292e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394002e+04],\n",
      "       [2.70476141e-02, 4.01468287e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394003e+04],\n",
      "       [2.70476141e-02, 4.01468291e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394002e+04],\n",
      "       [2.70476141e-02, 4.01468290e-02, 3.26248239e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476142e-02, 4.01468298e-02, 3.26248239e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394002e+04]]), array([89083.15977387, 89083.15977388, 89083.15977389, 89083.15977391,\n",
      "       89083.15977393, 89083.15977395, 89083.15977396, 89083.15977396]))\n",
      "           fun: 89083.15977387255\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 540\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.70476141e-02, 4.01468282e-02, 3.26248241e-02, 6.48001244e+03,\n",
      "       1.99119150e+04, 1.85927180e+04, 1.18394003e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89330.68493643744, bestParams: [0.082257316, 0.027428642, 0.07051255, 7407.681, 12604.67, 11728.0625, 22984.412]\n",
      "epoch 7\n",
      " final_simplex: (array([[7.22722643e-02, 4.08138975e-02, 3.35494221e-02, 6.23642624e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722643e-02, 4.08138976e-02, 3.35494214e-02, 6.23642621e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722637e-02, 4.08138975e-02, 3.35494209e-02, 6.23642626e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722640e-02, 4.08138976e-02, 3.35494211e-02, 6.23642624e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722644e-02, 4.08138975e-02, 3.35494216e-02, 6.23642623e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722642e-02, 4.08138974e-02, 3.35494214e-02, 6.23642625e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722651e-02, 4.08138974e-02, 3.35494229e-02, 6.23642620e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722644e-02, 4.08138975e-02, 3.35494217e-02, 6.23642623e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04]]), array([89092.78697749, 89092.78697752, 89092.78697752, 89092.78697755,\n",
      "       89092.78697766, 89092.78697766, 89092.78697766, 89092.78697769]))\n",
      "           fun: 89092.78697748706\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1211\n",
      "           nit: 458\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.22722643e-02, 4.08138975e-02, 3.35494221e-02, 6.23642624e+03,\n",
      "       1.45974907e+04, 1.66629287e+04, 1.42103738e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89389.45489296163, bestParams: [0.060271375, 0.042252373, 0.050650936, 6876.2065, 11556.726, 21871.658, 21758.736]\n",
      "epoch 8\n",
      " final_simplex: (array([[6.51869746e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869748e-02, 5.30897589e-02, 3.51516079e-02, 7.05962329e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869746e-02, 5.30897590e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869746e-02, 5.30897590e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869748e-02, 5.30897588e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123699e+04, 1.75684742e+04],\n",
      "       [6.51869746e-02, 5.30897591e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869747e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869747e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04]]), array([89093.22690281, 89093.22690282, 89093.22690284, 89093.22690284,\n",
      "       89093.22690285, 89093.22690287, 89093.22690287, 89093.2269029 ]))\n",
      "           fun: 89093.22690280867\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1255\n",
      "           nit: 513\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.51869746e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "       1.66074072e+04, 1.75123700e+04, 1.75684742e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89479.24696850716, bestParams: [0.0029611788, 0.048730392, 0.018831836, 9358.529, 19040.064, 23882.67, 18005.031]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.08114659e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147293e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532136e-02, 3.99157607e-02, 6.77894951e+03,\n",
      "        2.23243264e+04, 1.88557299e+04, 9.53147285e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147293e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157607e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147291e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147294e+03]]), array([89195.54214277, 89195.54214282, 89195.54214284, 89195.54214284,\n",
      "       89195.54214303, 89195.54216626, 89195.54216627, 89195.54216628]))\n",
      "           fun: 89195.5421427736\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1323\n",
      "           nit: 487\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.08114659e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "       2.23243264e+04, 1.88557300e+04, 9.53147293e+03])\n",
      "minPrevious 89076.07821086713\n",
      "took 407.44111680984497\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([1.5000, 1.5000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0419, 0.0326, 0.0349], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8933, 0.0569, 0.0280, 0.0227], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8708, 0.0723, 0.0261, 0.0307], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8975, 0.0281, 0.0563, 0.0225], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8670, 0.0260, 0.0765, 0.0305], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7772, 0.0856, 0.0853, 0.0511], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7218, 0.1037, 0.1075, 0.0670], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[4.4937, 4.8385, 5.2157],\n",
      "        [3.3180, 2.5832, 3.6836],\n",
      "        [4.3122, 2.5246, 4.8452],\n",
      "        ...,\n",
      "        [2.7396, 4.5652, 3.7115],\n",
      "        [1.9112, 3.0687, 5.9062],\n",
      "        [1.3352, 2.5593, 3.5319]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-879fdf1954c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunSim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitMethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1387c87bde79>\u001b[0m in \u001b[0;36mrunSim\u001b[0;34m(rrs, pis, nCases, nCtrls, afMean, rrShape, afShape, generatingFn, fitMethod)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneratingFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparamsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/genData.py\u001b[0m in \u001b[0;36mv6normal\u001b[0;34m(nCases, nCtrls, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mmarginalAlleleCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalProbability\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotalSamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0maltCountsGene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarginalAlleleCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0maltCounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsGene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/distributions/multinomial.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# samples.shape is (total_count, sample_shape, batch_shape), need to change it to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# (sample_shape, batch_shape, total_count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mshifted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mshifted_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshifted_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshifted_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runSim(fitMethod='nelder-mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f646b1ec66d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./mvln-sim-mvln.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf_should_read_directly\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = np.load(\"./mvln-sim-mvln.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resByParams = []\n",
    "for runSet in res:\n",
    "    params = (runSet[\"params\"][\"diseaseFractions\"], runSet[\"params\"][\"rrMeans\"], runSet[\"params\"][\"rrShape\"])\n",
    "#     print(\"param\", params)\n",
    "    res = []\n",
    "#     if params not in resByParam:\n",
    "#         resByParams[params] = []\n",
    "    \n",
    "    for run in runSet[\"runs\"]:\n",
    "        if run is None or \"results\" not in run or run[\"results\"] is None:\n",
    "            print(f\"no results found for {params}\")\n",
    "            continue\n",
    "        res.append(run[\"results\"])\n",
    "    resByParams.append([params, res])\n",
    "\n",
    "np.save(\"mvln-sim-mvln-results2\", resByParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resByParams = np.load(\"mvln-sim-mvln-results.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[(tensor([0.0500, 0.0500, 0.0500]), tensor([2.0000, 2.0000, 1.5000]), tensor(50.)),\n",
       "        list([{'allRes': {'lls': [90916.4783589971, 90708.31368424412, 90689.04874179952, 90677.23983613223], 'params': [array([3.87333861e-02, 1.40812486e-01, 7.59025824e-02, 9.31141067e+03,\n",
       "       2.18500134e+04, 1.68652588e+04, 2.63598593e+04]), array([1.67543257e-02, 3.13060638e-02, 4.29277051e-02, 2.50496081e+03,\n",
       "       8.64518025e+03, 8.37694873e+03, 4.74332877e+03]), array([4.07980539e-02, 5.92690249e-02, 4.06981218e-02, 4.76417261e+03,\n",
       "       1.30584069e+04, 1.28133394e+04, 1.26034808e+04]), array([3.56317955e-02, 3.20989858e-02, 4.08777915e-02, 5.02625412e+03,\n",
       "       1.52388589e+04, 1.62573997e+04, 1.10763793e+04])], 'llTrajectory': [90916.4783589971, 90708.31368424412, 90727.26669070916, 90689.04874179952, 90677.23983613223, 90676.96371994552, 90738.01226968745, 90784.31279984681, 90787.42281897092, 90677.4934384852]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0356, 0.0321, 0.0409], dtype=torch.float64), 'alphas': tensor([ 5026.2541, 15238.8589, 16257.3997, 11076.3793], dtype=torch.float64), 'PDV_c1true': tensor([0.8812, 0.0628, 0.0279, 0.0251], dtype=torch.float64), 'PDV_c2true': tensor([0.8833, 0.0281, 0.0651, 0.0261], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7405, 0.0993, 0.0996, 0.0623], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8622, 0.0785, 0.0259, 0.0335], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8577, 0.0257, 0.0832, 0.0333], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7032, 0.1105, 0.1148, 0.0715], dtype=torch.float64)}}, {'allRes': {'lls': [90645.57342181327, 90644.31351623876, 90641.27069583946], 'params': [array([3.63755073e-02, 4.57749896e-02, 4.18899664e-02, 1.42087064e+03,\n",
       "       4.35121665e+03, 4.00355358e+03, 3.50070375e+03]), array([4.66029047e-02, 4.53761282e-02, 4.29744549e-02, 6.07873461e+03,\n",
       "       1.78237112e+04, 1.71242042e+04, 1.58362642e+04]), array([4.33810405e-02, 4.52988838e-02, 4.13633647e-02, 6.96476709e+02,\n",
       "       2.04656915e+03, 1.91605097e+03, 1.77271015e+03])], 'llTrajectory': [90645.57342181327, 90651.2118646526, 90719.94317753878, 90644.31351623876, 90666.92657482934, 90653.34651654988, 90641.27069583946, 90651.3464135098, 90680.92933323765, 90792.21030335355]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0434, 0.0453, 0.0414], dtype=torch.float64), 'alphas': tensor([ 696.4767, 2046.5691, 1916.0510, 1772.7101], dtype=torch.float64), 'PDV_c1true': tensor([0.8797, 0.0642, 0.0279, 0.0257], dtype=torch.float64), 'PDV_c2true': tensor([0.8793, 0.0278, 0.0627, 0.0251], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7303, 0.0996, 0.0971, 0.0614], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8686, 0.0767, 0.0261, 0.0286], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8730, 0.0261, 0.0721, 0.0288], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7034, 0.1153, 0.1118, 0.0695], dtype=torch.float64)}}, {'allRes': {'lls': [90748.6465155581, 90711.14503326186], 'params': [array([6.27341823e-02, 4.63341146e-02, 3.75087980e-02, 6.10706763e+03,\n",
       "       1.62508186e+04, 1.74873704e+04, 1.57440691e+04]), array([3.54220726e-02, 4.85500888e-02, 4.49141211e-02, 2.28821775e+02,\n",
       "       6.42604102e+02, 6.38308739e+02, 5.08927552e+02])], 'llTrajectory': [90748.6465155581, 90711.14503326186, 90744.77986211523, 90876.14512541448, 90742.77190618007, 90800.03142956684, 90875.49917612775, 90747.52190318814, 90775.94721973015, 90878.82993506195]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0354, 0.0486, 0.0449], dtype=torch.float64), 'alphas': tensor([228.8218, 642.6041, 638.3087, 508.9276], dtype=torch.float64), 'PDV_c1true': tensor([0.8907, 0.0641, 0.0282, 0.0257], dtype=torch.float64), 'PDV_c2true': tensor([0.8856, 0.0281, 0.0643, 0.0257], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7492, 0.0969, 0.0963, 0.0615], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8712, 0.0735, 0.0262, 0.0291], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8716, 0.0263, 0.0729, 0.0293], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7170, 0.1081, 0.1075, 0.0673], dtype=torch.float64)}}, {'allRes': {'lls': [90933.72918146176, 90838.29602316262], 'params': [array([9.06864522e-02, 6.50148984e-02, 5.37885695e-02, 7.24642505e+03,\n",
       "       1.56345132e+04, 1.71235809e+04, 2.05677764e+04]), array([3.85649052e-02, 4.20795687e-02, 4.01053337e-02, 1.89342510e+03,\n",
       "       5.93866294e+03, 5.77638420e+03, 4.21878917e+03])], 'llTrajectory': [90933.72918146176, 90838.29602316262, 90868.60640369028, 90882.07712309291, 90847.74550284173, 90896.76813160375, 91157.13067761659, 90877.09566313706, 90838.3988977742, 90894.50289291705]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0386, 0.0421, 0.0401], dtype=torch.float64), 'alphas': tensor([1893.4251, 5938.6629, 5776.3842, 4218.7892], dtype=torch.float64), 'PDV_c1true': tensor([0.8888, 0.0641, 0.0282, 0.0256], dtype=torch.float64), 'PDV_c2true': tensor([0.8769, 0.0278, 0.0635, 0.0254], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7435, 0.0972, 0.0976, 0.0616], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8615, 0.0811, 0.0258, 0.0315], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8636, 0.0258, 0.0790, 0.0316], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7040, 0.1134, 0.1116, 0.0710], dtype=torch.float64)}}, {'allRes': {'lls': [90747.7696123132, 90585.67194419992, 90566.73709957347], 'params': [array([5.91826890e-02, 1.44589234e-01, 6.69387920e-02, 7.98395162e+03,\n",
       "       1.52393288e+04, 1.31918445e+04, 2.25971498e+04]), array([3.23620186e-02, 2.38361870e-02, 3.69261663e-02, 6.10035669e+03,\n",
       "       2.08475809e+04, 2.21919581e+04, 9.74581440e+03]), array([3.78255556e-02, 3.46743998e-02, 4.08244155e-02, 3.95583458e+03,\n",
       "       1.26977546e+04, 1.28829457e+04, 7.45632495e+03])], 'llTrajectory': [90747.7696123132, 90749.95843612179, 90585.67194419992, 90878.04322170046, 90566.73709957347, 90566.96453252305, 90861.6203819377, 90571.64204209404, 90615.46630737893, 90606.66331600855]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0378, 0.0347, 0.0408], dtype=torch.float64), 'alphas': tensor([ 3955.8346, 12697.7546, 12882.9457,  7456.3249], dtype=torch.float64), 'PDV_c1true': tensor([0.8825, 0.0635, 0.0280, 0.0254], dtype=torch.float64), 'PDV_c2true': tensor([0.8835, 0.0280, 0.0631, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7426, 0.0973, 0.0990, 0.0610], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8581, 0.0826, 0.0257, 0.0336], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8570, 0.0257, 0.0838, 0.0335], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7106, 0.1086, 0.1096, 0.0712], dtype=torch.float64)}}, {'allRes': {'lls': [90830.07972194639, 90562.237920496], 'params': [array([1.69463338e-01, 1.98575139e-01, 6.22025970e-02, 4.41316805e+03,\n",
       "       6.28159370e+03, 5.39738695e+03, 1.63099014e+04]), array([4.85819986e-02, 4.43267999e-02, 4.25625903e-02, 2.84641270e+02,\n",
       "       7.71902383e+02, 7.79988251e+02, 7.35633621e+02])], 'llTrajectory': [90830.07972194639, 90562.237920496, 90774.41540520656, 90774.76133135978, 90857.23196144999, 90587.14554848513, 90638.69745056726, 90581.18297009883, 90642.92672963747, 90596.53639301992]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0486, 0.0443, 0.0426], dtype=torch.float64), 'alphas': tensor([284.6413, 771.9024, 779.9883, 735.6336], dtype=torch.float64), 'PDV_c1true': tensor([0.8809, 0.0633, 0.0279, 0.0253], dtype=torch.float64), 'PDV_c2true': tensor([0.8849, 0.0280, 0.0629, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7376, 0.1000, 0.0991, 0.0615], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8736, 0.0712, 0.0264, 0.0288], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8738, 0.0261, 0.0714, 0.0286], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7067, 0.1122, 0.1130, 0.0681], dtype=torch.float64)}}, {'allRes': {'lls': [90541.19690546543, 90485.83852292394, 90450.04864336646], 'params': [array([1.05198885e-01, 5.61385155e-02, 4.30683468e-02, 7.16649842e+03,\n",
       "       1.50831749e+04, 1.90234287e+04, 2.11213115e+04]), array([1.45415926e-02, 3.60020275e-02, 4.32792564e-02, 5.79867892e+03,\n",
       "       2.10841845e+04, 1.86303955e+04, 1.00095742e+04]), array([4.04756141e-02, 2.69877192e-02, 4.02918327e-02, 5.89913599e+03,\n",
       "       1.83048623e+04, 1.99880264e+04, 1.21531034e+04])], 'llTrajectory': [90541.19690546543, 90485.83852292394, 90640.86004954319, 90450.04864336646, 90702.5564634097, 90557.9040388632, 90460.6229193173, 90467.91167992419, 90520.90760929213, 90557.50718726793]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0405, 0.0270, 0.0403], dtype=torch.float64), 'alphas': tensor([ 5899.1360, 18304.8623, 19988.0264, 12153.1034], dtype=torch.float64), 'PDV_c1true': tensor([0.8760, 0.0640, 0.0278, 0.0256], dtype=torch.float64), 'PDV_c2true': tensor([0.8838, 0.0280, 0.0630, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7420, 0.0999, 0.0992, 0.0621], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8593, 0.0800, 0.0258, 0.0349], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8530, 0.0256, 0.0868, 0.0346], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7038, 0.1090, 0.1150, 0.0722], dtype=torch.float64)}}, {'allRes': {'lls': [90757.56968553299, 90527.69242737578, 90521.27001448293], 'params': [array([1.61995075e-03, 1.05690047e-01, 5.31147218e-02, 7.83678126e+03,\n",
       "       2.34720398e+04, 1.67885869e+04, 1.81920206e+04]), array([3.75891039e-02, 3.93849894e-02, 4.27479940e-02, 3.83229961e+03,\n",
       "       1.20099977e+04, 1.13342312e+04, 9.03855526e+03]), array([3.71189801e-02, 3.75458264e-02, 4.12923202e-02, 9.18698687e+02,\n",
       "       2.84332494e+03, 2.78552088e+03, 2.18573783e+03])], 'llTrajectory': [90757.56968553299, 90527.69242737578, 90711.2276505137, 90521.27001448293, 90578.02820961754, 90562.84654239606, 90559.02988606176, 90559.19154174202, 90661.38357505882, 90574.89262462722]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0371, 0.0375, 0.0413], dtype=torch.float64), 'alphas': tensor([ 918.6987, 2843.3249, 2785.5209, 2185.7378], dtype=torch.float64), 'PDV_c1true': tensor([0.8806, 0.0645, 0.0280, 0.0258], dtype=torch.float64), 'PDV_c2true': tensor([0.8815, 0.0279, 0.0636, 0.0254], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7461, 0.1002, 0.0990, 0.0622], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8627, 0.0800, 0.0259, 0.0314], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8642, 0.0259, 0.0785, 0.0314], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.6999, 0.1150, 0.1135, 0.0715], dtype=torch.float64)}}, {'allRes': {'lls': [90897.96160983646, 90822.30100460075, 90813.7933164202], 'params': [array([4.94523337e-02, 8.98534427e-02, 5.08059703e-02, 9.33431412e+03,\n",
       "       2.31980772e+04, 2.01782677e+04, 2.67851825e+04]), array([5.22288505e-02, 3.94783721e-02, 3.29460235e-02, 6.27854966e+03,\n",
       "       1.81322217e+04, 2.01847985e+04, 1.56110186e+04]), array([4.59210324e-02, 3.17754408e-02, 3.75392591e-02, 2.79599712e+03,\n",
       "       8.37452682e+03, 9.36512056e+03, 6.22258891e+03])], 'llTrajectory': [90897.96160983646, 90822.30100460075, 90813.7933164202, 91195.13795952266, 90824.4409889472, 90948.83020724998, 90833.29153831744, 90914.45047672343, 90828.49674330515, 90894.21608835603]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0459, 0.0318, 0.0375], dtype=torch.float64), 'alphas': tensor([2795.9971, 8374.5268, 9365.1206, 6222.5889], dtype=torch.float64), 'PDV_c1true': tensor([0.8817, 0.0646, 0.0280, 0.0258], dtype=torch.float64), 'PDV_c2true': tensor([0.8855, 0.0281, 0.0642, 0.0257], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7387, 0.0989, 0.0991, 0.0620], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8621, 0.0774, 0.0258, 0.0346], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8541, 0.0256, 0.0859, 0.0344], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7009, 0.1097, 0.1173, 0.0721], dtype=torch.float64)}}, {'allRes': {'lls': [90674.24682333917, 90639.08503812845, 90635.38566081121], 'params': [array([8.25512430e-02, 4.47077237e-02, 3.81560217e-02, 4.85958175e+03,\n",
       "       1.15702661e+04, 1.34392115e+04, 1.46426684e+04]), array([3.22876832e-02, 3.94240441e-02, 4.00764617e-02, 7.08816185e+03,\n",
       "       2.15671201e+04, 2.13042256e+04, 1.77545086e+04]), array([4.38503233e-02, 4.14981181e-02, 4.02783387e-02, 4.39219918e+03,\n",
       "       1.27983245e+04, 1.36739819e+04, 1.11025385e+04])], 'llTrajectory': [90674.24682333917, 90639.08503812845, 90824.46248323756, 90645.51300320614, 90877.98499150135, 90635.38566081121, 90641.18017866093, 90640.17212894236, 90647.75311221162, 90634.58400619372]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0439, 0.0415, 0.0403], dtype=torch.float64), 'alphas': tensor([ 4392.1992, 12798.3245, 13673.9819, 11102.5385], dtype=torch.float64), 'PDV_c1true': tensor([0.8838, 0.0650, 0.0281, 0.0260], dtype=torch.float64), 'PDV_c2true': tensor([0.8842, 0.0280, 0.0629, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7435, 0.0991, 0.0996, 0.0620], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8659, 0.0758, 0.0260, 0.0323], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8616, 0.0258, 0.0804, 0.0322], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.6969, 0.1137, 0.1179, 0.0715], dtype=torch.float64)}}])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resByParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.subplot([1,len(resByParams)])\n",
    "i = 0\n",
    "with open(\"mvln-sim-mvln-res.tsv\", \"w\") as file:\n",
    "    file.write(f\"Notes: 15000 samples1, 15000 samples2, 6000 samplesBoth; rrs generated from normal distribution with. 1 variance, .4 covariance, and individual effect rr summed with shared-effect rr in genes affecting both conditions\\n\")\n",
    "    file.write(f\"\\tmean\\tstd\\n\")\n",
    "    for res in resByParams:\n",
    "        i += 1\n",
    "\n",
    "        paramsRun = res[0]\n",
    "        resRun = res[1]\n",
    "\n",
    "        pis = tensor([x[\"bestRes\"][\"pis\"].numpy() for x in resRun])\n",
    "        PDV_c1true = tensor([x[\"bestRes\"][\"PDV_c1true\"].numpy() for x in resRun])\n",
    "        PDV_c2true = tensor([x[\"bestRes\"][\"PDV_c2true\"].numpy() for x in resRun])\n",
    "        PDV_c3true = tensor([x[\"bestRes\"][\"PDV_cBothTrue\"].numpy() for x in resRun])\n",
    "        PDV_c1inferred = tensor([x[\"bestRes\"][\"PDV_c1inferred\"].numpy() for x in resRun])\n",
    "        PDV_c2inferred = tensor([x[\"bestRes\"][\"PDV_c2inferred\"].numpy() for x in resRun])\n",
    "        PDV_c3inferred = tensor([x[\"bestRes\"][\"PDV_cBothInferred\"].numpy() for x in resRun])\n",
    "\n",
    "        file.write(f\"\\n\\ntrue params: \\t{paramsRun} \\n\\n\")\n",
    "\n",
    "        file.write(f\"pi\\t {pis.mean(0).numpy()} \\t  {pis.std(0).numpy()} \\n\")\n",
    "\n",
    "        file.write(f\"PDV_c1inferred \\t {PDV_c1inferred.mean(0).numpy()}\\t {PDV_c1inferred.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c1true \\t {PDV_c1true.mean(0).numpy()} \\t {PDV_c1true.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c2inferred \\t {PDV_c2inferred.mean(0).numpy()} \\t {PDV_c2inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c2true \\t {PDV_c2true.mean(0).numpy()} \\t {PDV_c2true.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3inferred \\t {PDV_c3inferred.mean(0).numpy()} \\t {PDV_c3inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3true \\t {PDV_c3true.mean(0).numpy()} \\t {PDV_c3true.std(0).numpy()}\\n\")\n",
    "\n",
    "    #     plt.figure(i)\n",
    "    #     plt.plot(t, s1)\n",
    "    #     plt.plot(t, 2*s1)\n",
    "        # plt.subplot(222)\n",
    "        # plt.plot(t, 2*s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Tensor is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5cb54c57e780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mvln-sim-mvn.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached6NormalSimRes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Tensor is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open('./mvln-sim-mvn.json', 'w') as outfile:\n",
    "    json.dump(cached6NormalSimRes, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 5\n"
     ]
    }
   ],
   "source": [
    "def one(a, b, c, d = 5):\n",
    "    print(a, b, c, d)\n",
    "    \n",
    "def two(*args, **kwargs):\n",
    "    one(*args, **kwargs)\n",
    "    \n",
    "two(1, 2, c = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size = multiprocessing.cpu_count()\n",
    "os.system('taskset -cp 0-%d %s' % (pool_size, os.getpid()))\n",
    "\n",
    "genData.runSim(fitMethod=\"nelder-mead\", mt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('taskset -p %s' %os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool size: 12\n",
      "Built-in: 0.00014591217041015625\n",
      "Pool    : 1.7946691513061523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "def compute_something(t):\n",
    "    a = 0.\n",
    "    for i in range(10000000):\n",
    "        a = math.sqrt(t)\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Pool size:\", pool_size)\n",
    "pool = multiprocessing.Pool(processes=pool_size)\n",
    "\n",
    "inputs = range(10)\n",
    "\n",
    "tic = time.time()\n",
    "builtin_outputs = map(compute_something, inputs)\n",
    "print('Built-in:', time.time() - tic)\n",
    "\n",
    "tic = time.time()\n",
    "pool_outputs = pool.map(compute_something, inputs)\n",
    "print('Pool    :', time.time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "seed 426\n",
      "r is tensor([0.0901, 0.3060, 0.4284])\n",
      "None\n",
      "seed 549\n",
      "r is tensor([0.1975, 0.4509, 0.1906])\n",
      "None\n",
      "seed 47\n",
      "r is tensor([0.0360, 0.0345, 0.2392])\n",
      "None\n",
      "seed 992\n",
      "r is tensor([0.2402, 0.4320, 0.4001])\n",
      "None\n",
      "seed 419\n",
      "r is tensor([0.1488, 0.4900, 0.2033])\n",
      "None\n",
      "seed 62\n",
      "r is tensor([0.3242, 0.4162, 0.1136])\n",
      "None\n",
      "seed 945\n",
      "r is tensor([0.1849, 0.2026, 0.3619])\n",
      "None\n",
      "seed 530\n",
      "r is tensor([0.1196, 0.0993, 0.4660])\n",
      "None\n",
      "seed 791\n",
      "r is tensor([0.1833, 0.3470, 0.0177])\n",
      "None\n",
      "seed 30\n",
      "r is tensor([0.4514, 0.3757, 0.2411])\n"
     ]
    }
   ],
   "source": [
    "# import torch \n",
    "# import pyro\n",
    "# from torch.multiprocessing import Process\n",
    "# from torch.distributions import Uniform\n",
    "# import time\n",
    "# import numpy as np\n",
    "# def writer():\n",
    "#     message = f\"I am Process {i}\"\n",
    "#     print(torch.utils.data.get_worker_info())\n",
    "#     x = np.random.seed()\n",
    "#     x = np.random.randint(1000)\n",
    "#     print('seed', x)\n",
    "#     torch.manual_seed(x)\n",
    "#     pis = Uniform(1/100, .5).rsample([3])\n",
    "#     print(\"r is\", pis)\n",
    "#     time.sleep(1)\n",
    "\n",
    "# def reader(i,q):\n",
    "#     message = q.get()\n",
    "#     print(\"got message\", message)\n",
    "\n",
    "# for i in range(10):\n",
    "   \n",
    "#     Process(target=writer, args=()).start()\n",
    "#     time.sleep(.5)\n",
    "#    # Create multiprocessing pool\n",
    "#     p = Pool(10)\n",
    "#    # Create a group of parallel readers and start them\n",
    "#    # Number of readers is matching the number of writers\n",
    "#    # However, the number of simultaneously running\n",
    "#    # readers is constrained to the pool size\n",
    "#     readers = []\n",
    "#     for i in range(10):\n",
    "#         readers.append(p.apply_async(reader, (i,q,)))\n",
    "#     # Wait for the asynchrounous reader threads to finish\n",
    "#     [r.get() for r in readers]\n",
    "    \n",
    "    \n",
    "#     # Establish communication queues\n",
    "#     tasks = torch.multiprocessing.JoinableQueue()\n",
    "#     results = torch.multiprocessing.Queue()\n",
    "    \n",
    "#     # Start consumers\n",
    "#     num_consumers = torch.multiprocessing.cpu_count()\n",
    "#     print('Creating %d consumers' % num_consumers)\n",
    "#     consumers = [ Consumer(tasks, results)\n",
    "#                   for i in range(num_consumers) ]\n",
    "#     for w in consumers:\n",
    "#         w.start()\n",
    "    \n",
    "#     # Enqueue jobs\n",
    "#     for i in range(nEpochs):\n",
    "#         tasks.put(Task(altCountsByGene, pDs, 1, minLLThresholdCount, K, debug, costFnIdx, method))\n",
    "    \n",
    "#     # Add a poison pill for each consumer\n",
    "#     for i in range(nEpochs):\n",
    "#         tasks.put(None)\n",
    "\n",
    "#     # Wait for all of the tasks to finish\n",
    "#     tasks.join()\n",
    "    \n",
    "#     # Start printing results\n",
    "#     while nEpochs:\n",
    "#         result = results.get()\n",
    "#         print('Result:', result)\n",
    "#         num_jobs -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e0d0c7993644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msmoke_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'CI'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.3.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT is  True\n",
      "pDs are: tensor([0.0446, 0.0446, 0.0179])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(300000.), 'pDs': tensor([0.0446, 0.0446, 0.0179]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([1.5000, 1.5000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(300000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0446, 0.0446, 0.0179])\n",
      "\n",
      "\n",
      "test tensor 1.0,0.4,0.4,0.4,1.0,0.4,0.4,0.4,1.0\n",
      "tensor([[4.0103, 4.1868, 6.2500],\n",
      "        [3.3129, 4.4713, 5.1891],\n",
      "        [2.3431, 3.4354, 5.1669],\n",
      "        ...,\n",
      "        [2.1873, 2.7176, 4.4710],\n",
      "        [3.5895, 2.7138, 3.8816],\n",
      "        [3.3634, 3.6205, 4.9512]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 336000\n",
      "took 7.830695152282715\n",
      "Run: 0, 0\n",
      "fit method is nelder-mead\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff33816fa70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-225:\n",
      "Process ForkPoolWorker-227:\n",
      "Process ForkPoolWorker-231:\n",
      "Process ForkPoolWorker-233:\n",
      "Process ForkPoolWorker-228:\n",
      "Process ForkPoolWorker-226:\n",
      "Process ForkPoolWorker-234:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-224:\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 129, in jointLikelihood\n",
      "    h1 = pi1 * effect1Likelihood(n, pDsAll, alpha0, alpha1, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 131, in jointLikelihood\n",
      "    h3 = piBoth * effectBothLikelihood(n, pDsAll, alpha0, alpha1, alpha2, alphaBoth, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 129, in jointLikelihood\n",
      "    h1 = pi1 * effect1Likelihood(n, pDsAll, alpha0, alpha1, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 72, in effect1Likelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 83, in effectBothLikelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 72, in effect1Likelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 161, in log_prob\n",
      "    return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 162, in log_prob\n",
      "    _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 162, in log_prob\n",
      "    _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "Process ForkPoolWorker-229:\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "Process ForkPoolWorker-223:\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 130, in jointLikelihood\n",
      "    h2 = pi2 * effect2Likelihood(n, pDsAll, alpha0, alpha2, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 130, in jointLikelihood\n",
      "    h2 = pi2 * effect2Likelihood(n, pDsAll, alpha0, alpha2, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 130, in jointLikelihood\n",
      "    h2 = pi2 * effect2Likelihood(n, pDsAll, alpha0, alpha2, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 77, in effect2Likelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 77, in effect2Likelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 129, in jointLikelihood\n",
      "    h1 = pi1 * effect1Likelihood(n, pDsAll, alpha0, alpha1, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 77, in effect2Likelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 131, in jointLikelihood\n",
      "    h3 = piBoth * effectBothLikelihood(n, pDsAll, alpha0, alpha1, alpha2, alphaBoth, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 161, in log_prob\n",
      "    return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 72, in effect1Likelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 162, in log_prob\n",
      "    _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 162, in log_prob\n",
      "    _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 161, in log_prob\n",
      "    return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 83, in effectBothLikelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 162, in log_prob\n",
      "    _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-232:\n",
      "Process ForkPoolWorker-230:\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 149, in processor\n",
      "    r = fitFnBivariate(*args, **kwargs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 131, in jointLikelihood\n",
      "    h3 = piBoth * effectBothLikelihood(n, pDsAll, alpha0, alpha1, alpha2, alphaBoth, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 208, in fitFnBivariate\n",
      "    ll = costFn(fnArgs)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 129, in jointLikelihood\n",
      "    h1 = pi1 * effect1Likelihood(n, pDsAll, alpha0, alpha1, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 131, in jointLikelihood\n",
      "    h3 = piBoth * effectBothLikelihood(n, pDsAll, alpha0, alpha1, alpha2, alphaBoth, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 83, in effectBothLikelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 83, in effectBothLikelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 72, in effect1Likelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 131, in jointLikelihood\n",
      "    h3 = piBoth * effectBothLikelihood(n, pDsAll, alpha0, alpha1, alpha2, alphaBoth, altCountsFlat)\n",
      "  File \"/Users/alexkotlar/projects/tada/mvl/likelihoods.py\", line 83, in effectBothLikelihood\n",
      "    return torch.exp(DirichletMultinomial(total_count=n, concentration=alphas).log_prob(altCounts))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 162, in log_prob\n",
      "    _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 162, in log_prob\n",
      "    _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 162, in log_prob\n",
      "    _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 162, in log_prob\n",
      "    _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\", line 28, in _log_beta_1\n",
      "    return torch.lgamma(1 + value) + torch.lgamma(alpha) - torch.lgamma(value + alpha)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-3bf8cc15babb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunSim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitMethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nelder-mead\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/tada/mvl/genData.py\u001b[0m in \u001b[0;36mrunSim\u001b[0;34m(rrs, pis, nCases, nCtrls, afMean, rrShape, afShape, generatingFn, fitMethod, nEpochs, mt, covShared, covSingle)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitFnBivariateMT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitMethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m                     \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                     \u001b[0mbestLL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariateMT\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx, method)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 processor, (i, *args), callback=lambda res: results.append(res)))\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Wait for the asynchrounous reader threads to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 processor, (i, *args), callback=lambda res: results.append(res)))\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Wait for the asynchrounous reader threads to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "genData.runSim(fitMethod=\"nelder-mead\", mt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.distributions import DirichletMultinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c19e38a749ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, concentration, total_count, is_sparse, validate_args)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtotal_count_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "DirichletMultinomial(total_count=1000, concentration=[1, 1, 1, 1]).log_prob([10, 10, 10, 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0446, 0.0446, 0.0179])\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(300000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0446, 0.0446, 0.0179])\n",
      "\n",
      "\n",
      "test tensor 1.0,0.4,0.4,0.4,1.0,0.4,0.4,0.4,1.0\n",
      "tensor([[4.3004, 4.5279, 4.6280],\n",
      "        [2.8897, 3.4723, 5.9054],\n",
      "        [2.6317, 3.3074, 5.0648],\n",
      "        ...,\n",
      "        [2.2534, 3.4058, 4.8345],\n",
      "        [2.9521, 2.5474, 4.0645],\n",
      "        [2.7626, 2.7038, 5.4264]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 336000\n"
     ]
    }
   ],
   "source": [
    "rrs = tensor([1.5, 1.5, 1.5])\n",
    "pis = tensor([.05, .05, .05])\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(3e5)\n",
    "afMean = 1e-4\n",
    "rrShape=tensor(50.)\n",
    "afShape=tensor(50.)\n",
    "generatingFn =  genData.v6normal\n",
    "fitMethod = 'nelder-mead'\n",
    "nEpochs=20\n",
    "mt = True\n",
    "covShared=tensor([[1,.4,.4], [.4, 1, .4], [.4, .4, 1]])\n",
    "covSingle=tensor([[1, 0], [0, 1]])\n",
    "\n",
    "params = genData.genParams(rrMeans=rrs, pis=pis, afMean=afMean, rrShape=rrShape, afShape=afShape, nCases=nCases, nCtrls=nCtrls)[0]\n",
    "testData = generatingFn(**params, covShared=covShared, covSingle=covSingle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nGenes': 20000,\n",
       " 'nCases': tensor([15000., 15000.,  6000.]),\n",
       " 'nCtrls': tensor(300000.),\n",
       " 'pDs': tensor([0.0446, 0.0446, 0.0179]),\n",
       " 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]),\n",
       " 'rrShape': tensor(50.),\n",
       " 'rrMeans': tensor([1.5000, 1.5000, 1.5000]),\n",
       " 'afShape': tensor(50.),\n",
       " 'afMean': 0.0001}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariateMT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maltCountsByGene\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpDs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/projects/tada/mvl/likelihoods.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = likelihoods.fitFnBivariateMT(params[\"altCount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "pd1, pd2, pdBoth, pdCtrl:  tensor([0.8929, 0.0446, 0.0446, 0.0179])\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7ff398b02a70>\n",
      "best ll: 88769.99735620736, bestParams: [0.044902038, 0.011119992, 0.042243265, 8594.884, 21392.426, 19517.309, 17096.941]\n",
      "best ll: 88781.87549157774, bestParams: [0.022722656, 0.028252989, 0.034672335, 6250.936, 23407.08, 22325.86, 16255.849]\n",
      "best ll: 88762.38501412391, bestParams: [0.05202409, 0.020662291, 0.046768084, 7496.6787, 19853.828, 17184.148, 13143.313]\n",
      "best ll: 88806.2944691051, bestParams: [0.07485883, 0.031005993, 0.04748448, 7149.705, 17427.662, 13652.0625, 15487.956]\n",
      "best ll: 88862.70411320365, bestParams: [0.02409247, 0.035015922, 0.03899422, 9087.229, 17044.63, 14062.806, 23850.662]\n",
      "best ll: 88779.49153968948, bestParams: [0.045282964, 0.057715017, 0.054651625, 5562.2686, 16213.085, 11107.515, 13883.186]\n",
      "best ll: 88925.79695995254, bestParams: [0.054578874, 0.19436975, 0.05377717, 9765.341, 11897.331, 13847.808, 24442.414]\n",
      "best ll: 88934.96388610531, bestParams: [0.00984885, 0.021109447, 0.036835544, 7557.41, 14797.894, 11121.248, 20215.203]\n",
      "best ll: 88756.84293722353, bestParams: [0.036087442, 0.022639541, 0.048606273, 8502.578, 18277.068, 16809.32, 21180.078]\n",
      "best ll: 88826.08904924558, bestParams: [0.0506632, 0.010690068, 0.044857763, 8627.749, 17252.943, 20155.438, 15388.142]\n",
      "best ll: 88869.8259015006, bestParams: [0.02047772, 0.04872602, 0.08229899, 10208.486, 20435.17, 18037.596, 21307.785]\n",
      "best ll: 88787.60086095476, bestParams: [0.056599677, 0.022660723, 0.04496477, 2167.408, 4998.408, 6566.812, 2897.3113]\n",
      "Epoch took 123.19565796852112\n",
      "Epoch took 125.38469505310059\n",
      "Epoch took 134.08755588531494\n",
      "Epoch took 135.97127389907837\n",
      "Epoch took 139.46546483039856\n",
      "Epoch took 145.37480568885803\n",
      "Epoch took 146.803484916687\n",
      "Epoch took 147.60323214530945\n",
      "Epoch took 150.531152009964\n",
      "Epoch took 153.33337092399597\n",
      "Epoch took 156.10063314437866\n",
      "Epoch took 159.0107021331787\n",
      "Got results\n",
      "[{'lls': [88658.88416279141], 'params': [array([4.06874948e-02, 4.42210625e-02, 4.17260480e-02, 1.59000908e+02,\n",
      "       4.02009577e+02, 3.90089968e+02, 3.72843536e+02])], 'llTrajectory': [88658.88416279141]}, {'lls': [88658.88416279151], 'params': [array([4.06874977e-02, 4.42210625e-02, 4.17260429e-02, 1.59001356e+02,\n",
      "       4.02010787e+02, 3.90091123e+02, 3.72844481e+02])], 'llTrajectory': [88658.88416279151]}, {'lls': [88658.88416279145], 'params': [array([4.06875479e-02, 4.42210265e-02, 4.17260489e-02, 1.59001240e+02,\n",
      "       4.02010325e+02, 3.90090801e+02, 3.72844293e+02])], 'llTrajectory': [88658.88416279145]}, {'lls': [88658.88416279145], 'params': [array([4.06875363e-02, 4.42210501e-02, 4.17260540e-02, 1.59001011e+02,\n",
      "       4.02009713e+02, 3.90090183e+02, 3.72843792e+02])], 'llTrajectory': [88658.88416279145]}, {'lls': [88658.88416279148], 'params': [array([4.06874981e-02, 4.42210998e-02, 4.17260582e-02, 1.59001194e+02,\n",
      "       4.02010277e+02, 3.90090557e+02, 3.72844205e+02])], 'llTrajectory': [88658.88416279148]}, {'lls': [88658.88416279144], 'params': [array([4.06875421e-02, 4.42210928e-02, 4.17260370e-02, 1.59001189e+02,\n",
      "       4.02010168e+02, 3.90090528e+02, 3.72844327e+02])], 'llTrajectory': [88658.88416279144]}, {'lls': [88658.88416279154], 'params': [array([4.06875312e-02, 4.42210217e-02, 4.17260583e-02, 1.59001231e+02,\n",
      "       4.02010373e+02, 3.90090853e+02, 3.72844216e+02])], 'llTrajectory': [88658.88416279154]}, {'lls': [88658.88416279142], 'params': [array([4.06875001e-02, 4.42210738e-02, 4.17260650e-02, 1.59000874e+02,\n",
      "       4.02009373e+02, 3.90089693e+02, 3.72843489e+02])], 'llTrajectory': [88658.88416279142]}, {'lls': [88658.88416279167], 'params': [array([4.06875471e-02, 4.42210867e-02, 4.17260791e-02, 1.59001414e+02,\n",
      "       4.02010654e+02, 3.90091059e+02, 3.72844562e+02])], 'llTrajectory': [88658.88416279167]}, {'lls': [88658.88416279142], 'params': [array([4.06875211e-02, 4.42210561e-02, 4.17260625e-02, 1.59001085e+02,\n",
      "       4.02009941e+02, 3.90090384e+02, 3.72843864e+02])], 'llTrajectory': [88658.88416279142]}, {'lls': [88658.88416279144], 'params': [array([4.06875252e-02, 4.42211002e-02, 4.17260402e-02, 1.59001128e+02,\n",
      "       4.02009992e+02, 3.90090426e+02, 3.72844262e+02])], 'llTrajectory': [88658.88416279144]}, {'lls': [88658.8841627915], 'params': [array([4.06875448e-02, 4.42210307e-02, 4.17260716e-02, 1.59001137e+02,\n",
      "       4.02009993e+02, 3.90090528e+02, 3.72844067e+02])], 'llTrajectory': [88658.8841627915]}]\n"
     ]
    }
   ],
   "source": [
    "testFit = likelihoods.fitFnBivariateMT(testData[\"altCounts\"], params[\"pDs\"], nEpochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestLL = None\n",
    "bestParams = None\n",
    "for x in testFit:\n",
    "    if bestLL is None or x[\"lls\"][0] < bestLL:\n",
    "        bestParams = x[\"params\"][0]\n",
    "        bestLL = x[\"lls\"][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88658.88416279141"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4.0687e-02, 4.4221e-02, 4.1726e-02, 1.5900e+02, 4.0201e+02, 3.9009e+02,\n",
       "        3.7284e+02], dtype=torch.float64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestParams = tensor(bestParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0687e-02, 4.4221e-02, 4.1726e-02, 1.5900e+02, 4.0201e+02, 3.9009e+02,\n",
       "        3.7284e+02], dtype=torch.float64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCounts = testData[\"altCounts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "testUnaffectedGenes = testData[\"unaffectedGenes\"]\n",
    "testAffectedGenes = testData[\"affectedGenes\"]\n",
    "testAllPDs = tensor([1-params[\"pDs\"].sum(), *params[\"pDs\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesFactor(n, altCount,pDs,rrMeans,rrsShape,afMeans,afShape,alpha0, alpha1, alpha2, alphaBoth):\n",
    "bfsUnaffected = []\n",
    "for unaffectedGene in testUnaffectedGenes:\n",
    "    testCount = testCounts[unaffectedGene]\n",
    "    bfsUnaffected.append(bayes.bayesFactor(testCount.sum(), testCount, testAllPDs, bestParams[0:3], bestParams[3:]))\n",
    "bfsUnaffected = tensor(bfsUnaffected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0125e-01, 8.5311e-06, 1.6218e-04,  ..., 3.2103e-04, 1.1671e-04,\n",
       "        5.6422e-03], dtype=torch.float64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfsUnaffected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bfsUnaffected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-64ff8b083210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbfsUnaffected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bfsUnaffected' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesFactor(n, altCount,pDs,rrMeans,rrsShape,afMeans,afShape,alpha0, alpha1, alpha2, alphaBoth):\n",
    "bfsAffected1 = []\n",
    "for affectedGene in testAffectedGenes[0]:\n",
    "    print(affectedGene, \"count:\", testCounts[affectedGene])\n",
    "    testCount = testCounts[affectedGene]\n",
    "    bfsAffected.append(bayes.bayesFactor(testCount.sum(), testCount, testAllPDs, bestParams[0:3], bestParams[3:]))\n",
    "bfsAffected1 = tensor(bfsAffected1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 count: tensor([27.,  5.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  8.507990624958355 0.9929259704437408 1.1011605754837361 max is bf1\n",
      "1001 count: tensor([27.,  1.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.7831355588613914 3.9680669560560147 0.16022523954973203 max is bf2\n",
      "1002 count: tensor([24.,  0.,  5.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.15970660319136384 8.322358666428165 0.0740468383501618 max is bf2\n",
      "1003 count: tensor([21.,  1.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.55250387085329 15.614736793822905 4.009810419576124 max is bf2\n",
      "1004 count: tensor([28.,  0.,  0.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.5417786248275871 0.5766991103987299 0.0014611549488473359 max is bf2\n",
      "1005 count: tensor([27.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.386773588064856 4.06769416253703 0.10893903805115321 max is bf2\n",
      "1006 count: tensor([21.,  0.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.18938562889156788 0.20622900772462505 0.0006421326351400891 max is bf2\n",
      "1007 count: tensor([22.,  0.,  6.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.5128028976820789 48.041129514719174 2.2243684671735804 max is bf2\n",
      "1008 count: tensor([26.,  1.,  2.,  3.], dtype=torch.float64)\n",
      "bfs are:  2.164862289573332 5.003079459851104 0.3546860074839202 max is bf2\n",
      "1009 count: tensor([36.,  1.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.09010470218784025 0.4952315167015442 0.00044220617641629786 max is bf2\n",
      "1010 count: tensor([29.,  0.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.15501654248726832 0.9520587223943043 0.0019897002377104833 max is bf2\n",
      "1011 count: tensor([23.,  7.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  46.354400918661945 6.910837433748969 112.28060359924518 max is bfBoth\n",
      "1012 count: tensor([28.,  0.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.3729707573053781 2.2310452054425625 0.01276160354574956 max is bf2\n",
      "1013 count: tensor([31.,  0.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.2944060384845393 1.780219313627607 0.004846138774791792 max is bf2\n",
      "1014 count: tensor([32.,  3.,  1.,  3.], dtype=torch.float64)\n",
      "bfs are:  6.252539538668691 1.270206447529684 0.15001599393388804 max is bf1\n",
      "1015 count: tensor([19.,  3.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  3.9544020500282056 7.931616391189335 16.958593521383985 max is bfBoth\n",
      "1016 count: tensor([26.,  3.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.972453650648589 0.4092983840348914 0.049675750617680106 max is bf1\n",
      "1017 count: tensor([32.,  1.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.2759596913118378 0.2979983202435283 0.000758651349489488 max is bf2\n",
      "1018 count: tensor([36.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.11025271203093331 0.12400955950028807 5.07887392261128e-05 max is bf2\n",
      "1019 count: tensor([22.,  0.,  5.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.8666708790233328 42.68291189029853 3.10403792442196 max is bf2\n",
      "1020 count: tensor([28.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.18808193216752814 0.20555431365269955 0.0006072987451932921 max is bf2\n",
      "1021 count: tensor([31.,  2.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.6045808107365304 0.2790466440195027 0.0031222091453634634 max is bf1\n",
      "1022 count: tensor([27.,  3.,  2.,  3.], dtype=torch.float64)\n",
      "bfs are:  8.683311928218895 3.9547920599418553 2.3585034617293887 max is bf1\n",
      "1023 count: tensor([29.,  0.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.07912171033689278 0.4989687192978651 0.00044820635567698205 max is bf2\n",
      "1024 count: tensor([22.,  1.,  6.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.2757737593102703 82.7342933524421 30.910940608904678 max is bf2\n",
      "1025 count: tensor([28.,  1.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1659611752317912 0.8865439908197337 0.005615556078804037 max is bf2\n",
      "1026 count: tensor([28.,  1.,  0.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.0666601282125692 0.4507171514709187 0.004330906429511991 max is bf1\n",
      "1027 count: tensor([23.,  2.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.0459837398599316 1.0701944196401896 0.13088524275898764 max is bf2\n",
      "1028 count: tensor([31.,  0.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.10116734636349996 0.11436125108161406 2.7588046370609115e-05 max is bf2\n",
      "1029 count: tensor([22.,  2.,  5.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.588917137191921 13.632198533292849 6.030799882849333 max is bf2\n",
      "1030 count: tensor([35.,  0.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.11747751408312365 0.3230361415661122 0.00010340940284817012 max is bf2\n",
      "1031 count: tensor([28.,  0.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.1880818965465379 0.50430316204932 0.0009130354199150576 max is bf2\n",
      "1032 count: tensor([29.,  2.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.3620233024748616 1.3922871552139884 0.0811760103032472 max is bf2\n",
      "1033 count: tensor([29.,  0.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.15501654248726832 0.9520587223943043 0.0019897002377104833 max is bf2\n",
      "1034 count: tensor([31.,  2.,  7.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.5918146804183785 17.96150113214385 0.6780055052149481 max is bf2\n",
      "1035 count: tensor([29.,  0.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.15322117978573024 2.015346605486769 0.0061011112515173506 max is bf2\n",
      "1036 count: tensor([29.,  2.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.3190787981991399 0.3426452516741866 0.00400545474089283 max is bf2\n",
      "1037 count: tensor([19.,  6.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  127.63497755007052 3.279249306938422 98.2253256684264 max is bf1\n",
      "1038 count: tensor([26.,  0.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.4381096314774021 5.57198593792082 0.07598297575166224 max is bf2\n",
      "1039 count: tensor([26.,  1.,  0.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.2431006393096062 0.5214367997637901 0.00828201469352077 max is bf1\n",
      "1040 count: tensor([24.,  1.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.4589850531754104 2.353197752124344 0.09444329487994839 max is bf2\n",
      "1041 count: tensor([24.,  0.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.23084449859907127 2.98135073845191 0.031619371447326884 max is bf2\n",
      "1042 count: tensor([20.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.3418915758380011 0.3626437964451355 0.008290288556561685 max is bf2\n",
      "1043 count: tensor([23.,  2.,  5.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.4290204593307807 12.305251777538064 4.236502478286787 max is bf2\n",
      "1044 count: tensor([23.,  2.,  4.,  3.], dtype=torch.float64)\n",
      "bfs are:  6.595191369580909 28.103435675345757 29.52349837388612 max is bfBoth\n",
      "1045 count: tensor([26.,  3.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.723586483076417 1.7480954752216178 0.45585305879668436 max is bf2\n",
      "1046 count: tensor([22.,  2.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.608735246755592 2.5996546149495035 0.8701950649938534 max is bf1\n",
      "1047 count: tensor([27.,  2.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.7256841610314404 1.6136007015426046 0.10462411995936463 max is bf2\n",
      "1048 count: tensor([24.,  0.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.23084449859907127 2.98135073845191 0.031619371447326884 max is bf2\n",
      "1049 count: tensor([26.,  0.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.4916652270123193 1.2792836698951155 0.008154611998093815 max is bf2\n",
      "1050 count: tensor([31.,  2.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.2728082476722473 0.2950702974905281 0.002104803188574223 max is bf2\n",
      "1051 count: tensor([28.,  1.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.7152953135014859 3.637406223164786 0.11467098844634477 max is bf2\n",
      "1052 count: tensor([35.,  1.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.09691845989442666 0.5308197232889691 0.0006033316531822715 max is bf2\n",
      "1053 count: tensor([32.,  2.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.4831942103287421 0.5107513319830822 0.006667080624429854 max is bf2\n",
      "1054 count: tensor([25.,  2.,  5.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.5643180196250466 21.74141721675859 9.718818221373274 max is bf2\n",
      "1055 count: tensor([28.,  1.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1659611752317912 0.8865439908197337 0.005615556078804037 max is bf2\n",
      "1056 count: tensor([25.,  2.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.2077369569726106 0.9746695644770027 0.10344341512188385 max is bf1\n",
      "1057 count: tensor([24.,  2.,  3.,  3.], dtype=torch.float64)\n",
      "bfs are:  5.386952177247357 11.354755888064291 6.570976810669033 max is bf2\n",
      "1058 count: tensor([34.,  0.,  6.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.34931926189086593 33.38733637816422 0.17402538982148508 max is bf2\n",
      "1059 count: tensor([22.,  2.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.6295336456141523 5.612298879863278 2.7094630224993033 max is bf2\n",
      "1060 count: tensor([27.,  3.,  5.,  2.], dtype=torch.float64)\n",
      "bfs are:  4.403204721230518 17.2114214207874 14.819572608615779 max is bf2\n",
      "1061 count: tensor([29.,  1., 10.,  0.], dtype=torch.float64)\n",
      "bfs are:  1.4562359583619144 494.59202563109335 19.272808890240068 max is bf2\n",
      "1062 count: tensor([23.,  3.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  5.2004191309859795 5.0999589574887 5.990643778152142 max is bfBoth\n",
      "1063 count: tensor([24.,  2.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.413307299368696 1.0615182677674582 0.14492405126352612 max is bf1\n",
      "1064 count: tensor([34.,  3.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.8628497397617675 0.42042546836244826 0.010669338925057108 max is bf1\n",
      "1065 count: tensor([40.,  5.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  2.5172850998043605 0.30733198421536534 0.015177900595763716 max is bf1\n",
      "1066 count: tensor([27.,  0.,  0.,  4.], dtype=torch.float64)\n",
      "bfs are:  4.107975616639153 4.197348921279344 0.05027214317531953 max is bf2\n",
      "1067 count: tensor([27.,  3.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.8083808776757093 0.37661948328805533 0.0356111904518304 max is bf1\n",
      "1068 count: tensor([28.,  3.,  0.,  4.], dtype=torch.float64)\n",
      "bfs are:  32.4745695127325 2.595760401509712 0.992938199275877 max is bf1\n",
      "1069 count: tensor([30.,  0.,  5.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.18284302050150222 9.482769996123091 0.04421858072863176 max is bf2\n",
      "1070 count: tensor([16.,  2.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  4.948386210851262 10.327268552787393 23.129026258317342 max is bfBoth\n",
      "1071 count: tensor([28.,  0.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.16596114380026916 2.175030676425584 0.008442634935521732 max is bf2\n",
      "1072 count: tensor([22.,  3.,  5.,  3.], dtype=torch.float64)\n",
      "bfs are:  19.34718670187741 72.82213093764601 426.474587692322 max is bfBoth\n",
      "1073 count: tensor([33.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1337486628644188 0.14884328003926783 0.0001268871742982154 max is bf2\n",
      "1074 count: tensor([20.,  0.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1602592312981022 2.093394959462309 0.026781421038623413 max is bf2\n",
      "1075 count: tensor([24.,  2.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.413307299368696 1.0615182677674582 0.14492405126352612 max is bf1\n",
      "1076 count: tensor([27.,  2.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.7922740406081561 3.574255273715239 0.32846370876236286 max is bf2\n",
      "1077 count: tensor([20.,  0.,  7.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.9187921713081201 153.30369577636404 15.639039569299818 max is bf2\n",
      "1078 count: tensor([25.,  2.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.9480798381817706 4.203694050818817 0.9565181933893979 max is bf2\n",
      "1079 count: tensor([23.,  1.,  0.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.6855041275480785 0.29086857464426225 0.00467377707363603 max is bf1\n",
      "1080 count: tensor([33.,  4.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  2.4280511404133334 0.24994527935135338 0.015786664295808765 max is bf1\n",
      "1081 count: tensor([22.,  0.,  5.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.19147183102330098 9.904081191791368 0.14630281701878023 max is bf2\n",
      "1082 count: tensor([24.,  1.,  7.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.5996602544289658 41.38479898157463 2.5214515104681263 max is bf2\n",
      "1083 count: tensor([23.,  1.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.137792218275524 5.681601093844499 0.6241031962446514 max is bf2\n",
      "1084 count: tensor([30.,  1.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.6145041382388285 1.4696530184025303 0.01949651229154817 max is bf2\n",
      "1085 count: tensor([26.,  0.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.09871980031152756 1.3187806413082963 0.00363685147445452 max is bf2\n",
      "1086 count: tensor([30.,  3.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.2631028603348042 2.636425170276362 0.36587615248312816 max is bf2\n",
      "1087 count: tensor([25.,  1.,  0.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.3440641252110848 0.56171011138511 0.01148930597704644 max is bf1\n",
      "1088 count: tensor([33.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.22182815269210068 0.5485928828442698 0.0016293695620425515 max is bf2\n",
      "1089 count: tensor([26.,  1.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.27463569079772704 0.120993441462513 0.00039035672557984617 max is bf1\n",
      "1090 count: tensor([27.,  3.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.5649611416163933 1.5929421554533443 0.32431687217077504 max is bf2\n",
      "1091 count: tensor([27.,  2.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.40832471456873476 1.8915727415394779 0.07455471860355485 max is bf2\n",
      "1092 count: tensor([24.,  1.,  2.,  4.], dtype=torch.float64)\n",
      "bfs are:  7.284300204301073 16.422428147261165 3.569210131959048 max is bf2\n",
      "1093 count: tensor([25.,  2.,  5.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.1600159684568507 10.061614136521165 2.1047983345140473 max is bf2\n",
      "1094 count: tensor([29.,  1.,  0.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.44333225017197486 0.1923355001251454 0.0006752447309156501 max is bf1\n",
      "1095 count: tensor([32.,  3.,  0.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.5733124722621787 0.13548938960184995 0.0024390289672572376 max is bf1\n",
      "1096 count: tensor([36.,  1.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.37661894368712456 3.996271769780722 0.025826599302770235 max is bf2\n",
      "1097 count: tensor([37.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.0881239939099781 0.2269769284304438 0.00010912130092570238 max is bf2\n",
      "1098 count: tensor([31.,  1.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.5657758479450109 1.3579500579931045 0.014094521101366123 max is bf2\n",
      "1099 count: tensor([26.,  1.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.38454283666916145 1.9860365788356014 0.048221458870381984 max is bf2\n",
      "1100 count: tensor([23.,  3.,  0.,  1.], dtype=torch.float64)\n",
      "bfs are:  3.259961268525176 0.2716962193350635 0.04627049080042955 max is bf1\n",
      "1101 count: tensor([34.,  0.,  5.,  3.], dtype=torch.float64)\n",
      "bfs are:  0.6625564971033865 33.38732989954001 0.2539855590523675 max is bf2\n",
      "1102 count: tensor([32.,  4.,  8.,  3.], dtype=torch.float64)\n",
      "bfs are:  31.521862345616814 344.5081852446197 1292.3976424523328 max is bfBoth\n",
      "1103 count: tensor([22.,  2.,  5.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.8030914210590763 7.074667381047715 1.3481638113137506 max is bf2\n",
      "1104 count: tensor([24.,  3.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  1.0655401491534982 1.101626736632613 0.20343255322870923 max is bf2\n",
      "1105 count: tensor([32.,  2.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.2199913235848263 0.5523552543410792 0.0103651816243024 max is bf1\n",
      "1106 count: tensor([23.,  1.,  3.,  3.], dtype=torch.float64)\n",
      "bfs are:  2.8782865540377998 14.091180330208388 3.060240021431416 max is bf2\n",
      "1107 count: tensor([25.,  0.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.10536974980142041 0.6547819706466038 0.0016141333526461473 max is bf2\n",
      "1108 count: tensor([30.,  0.,  0.,  3.], dtype=torch.float64)\n",
      "bfs are:  1.1750184350784898 1.2351550145588948 0.003763503060399613 max is bf2\n",
      "1109 count: tensor([26.,  3.,  4.,  3.], dtype=torch.float64)\n",
      "bfs are:  10.17208799575313 20.05711035737479 31.553723468058884 max is bfBoth\n",
      "1110 count: tensor([29.,  2.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.36268020185244054 0.1706572346959993 0.0013435211504105446 max is bf1\n",
      "1111 count: tensor([29.,  1.,  1.,  4.], dtype=torch.float64)\n",
      "bfs are:  5.183380581263636 5.213886311778082 0.22067865524271413 max is bf2\n",
      "1112 count: tensor([36.,  3.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.8463046474701077 0.3880167290020796 0.008762979262668882 max is bf1\n",
      "1113 count: tensor([29.,  3.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.6736003900298092 0.7091322633765671 0.03778556603054785 max is bf2\n",
      "1114 count: tensor([31.,  3.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.6051467461281484 1.3016944420878627 0.060490584386004 max is bf2\n",
      "1115 count: tensor([32.,  1.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.5032061886290542 2.5955855660357847 0.03072486256028543 max is bf2\n",
      "1116 count: tensor([28.,  1.,  2.,  5.], dtype=torch.float64)\n",
      "bfs are:  14.781448443664404 33.28432920029832 4.746310816446231 max is bf2\n",
      "1117 count: tensor([22.,  0.,  3.,  3.], dtype=torch.float64)\n",
      "bfs are:  1.601716566992737 19.680559490139792 1.4529161882791288 max is bf2\n",
      "1118 count: tensor([34.,  3.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.43742637623769903 0.4687094456136135 0.007397772713150778 max is bf2\n",
      "1119 count: tensor([25.,  2.,  7.,  3.], dtype=torch.float64)\n",
      "bfs are:  11.449037990269979 317.41693001599026 515.2585982959007 max is bfBoth\n",
      "1120 count: tensor([30.,  0.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.08351830294657368 0.23162497142917984 0.00010928217596126055 max is bf2\n",
      "1121 count: tensor([37.,  2.,  0.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.5212866535183539 0.09981773166998063 0.00016914905252975697 max is bf1\n",
      "1122 count: tensor([30.,  0.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.10725418867838285 0.12079957237449106 3.7445488553119114e-05 max is bf2\n",
      "1123 count: tensor([27.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.35495692301581944 0.859102318882054 0.011230763582375472 max is bf2\n",
      "1124 count: tensor([32.,  2.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.0479125387861898 1.0826682878913474 0.03032620562546898 max is bf2\n",
      "1125 count: tensor([33.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1337486628644188 0.14884328003926783 0.0001268871742982154 max is bf2\n",
      "1126 count: tensor([23.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.28262065136699704 3.00766588154576 0.09449435690883017 max is bf2\n",
      "1127 count: tensor([27.,  1.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.8549972658644808 8.78958730656198 0.5030214489764188 max is bf2\n",
      "1128 count: tensor([26.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.38527499061404624 0.929079022765618 0.015606628876598683 max is bf2\n",
      "1129 count: tensor([24.,  0.,  6.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.21300684472803932 20.640639418404742 0.2487764087947959 max is bf2\n",
      "1130 count: tensor([28.,  1.,  2.,  5.], dtype=torch.float64)\n",
      "bfs are:  14.781448443664404 33.28432920029832 4.746310816446231 max is bf2\n",
      "1131 count: tensor([32.,  3.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.0222874625828013 0.4946285218888153 0.02035883077332903 max is bf1\n",
      "1132 count: tensor([38.,  0.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.06891161663201792 0.07987850709842508 3.432420778423784e-06 max is bf2\n",
      "1133 count: tensor([26.,  2.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.4475421932491301 2.0657577312894553 0.10439625104248053 max is bf2\n",
      "1134 count: tensor([37.,  2.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.38697167637699664 0.18242678761036604 0.00047546252816632015 max is bf1\n",
      "1135 count: tensor([29.,  0.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.3680132160282864 9.59976982141403 0.08811059526579657 max is bf2\n",
      "1136 count: tensor([22.,  4.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  5.905918977465693 1.333642668746936 1.8962228403411225 max is bf1\n",
      "1137 count: tensor([25.,  2.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.9621141835850731 4.309237203145109 0.6503480485290604 max is bf2\n",
      "1138 count: tensor([27.,  0.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.45520442610557244 1.1887733749269682 0.005890714395930232 max is bf2\n",
      "1139 count: tensor([22.,  1.,  5.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.7607047513525811 15.213574702053476 1.969931232935988 max is bf2\n",
      "1140 count: tensor([33.,  2.,  0.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.6860766342375576 0.1295326618559379 0.0005797850085143588 max is bf1\n",
      "1141 count: tensor([28.,  1.,  5.,  3.], dtype=torch.float64)\n",
      "bfs are:  2.25864173565038 44.23516217777701 5.480192480666687 max is bf2\n",
      "1142 count: tensor([36.,  2.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.4158372418417577 0.19535280459559898 0.0006474458168047388 max is bf1\n",
      "1143 count: tensor([26.,  3.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  1.001849980616261 0.21346178187944984 0.011147479152152215 max is bf1\n",
      "1144 count: tensor([27.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.19837450125072395 2.1422836302397004 0.024633476992221962 max is bf2\n",
      "1145 count: tensor([25.,  2.,  3.,  3.], dtype=torch.float64)\n",
      "bfs are:  4.856378417109823 10.273517878194346 4.636794896529706 max is bf2\n",
      "1146 count: tensor([31.,  2.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.3237016939053765 0.597186335715974 0.01430844445603839 max is bf1\n",
      "1147 count: tensor([24.,  0.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.5753770434039176 1.4860575832445242 0.01572716666601992 max is bf2\n",
      "1148 count: tensor([24.,  0.,  7.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.3060714373081108 53.212728762955884 0.853937767022495 max is bf2\n",
      "1149 count: tensor([19.,  3.,  3.,  3.], dtype=torch.float64)\n",
      "bfs are:  20.456342611552458 19.381209890593478 123.2493210034528 max is bfBoth\n",
      "1150 count: tensor([22.,  0.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.2678202004416793 1.6028983048484193 0.019679770198351296 max is bf2\n",
      "1151 count: tensor([23.,  1.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.5022799819845203 2.565680753317573 0.1326058111128203 max is bf2\n",
      "1152 count: tensor([29.,  0.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.16728098770000557 4.464154747911775 0.019154222085915842 max is bf2\n",
      "1153 count: tensor([30.,  3.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.5575189075781672 2.5718530406334956 0.5381229284365072 max is bf2\n",
      "1154 count: tensor([33.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.11598189351149402 0.2945461214915805 0.0003740304390719319 max is bf2\n",
      "1155 count: tensor([25.,  3.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.9004425665049611 1.9205023349108987 0.6421374395242792 max is bf2\n",
      "1156 count: tensor([29.,  1.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1532212088044197 0.8214566543261226 0.004058108947926542 max is bf2\n",
      "1157 count: tensor([23.,  0.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.6234225999800805 1.6041555135364958 0.021911935019711955 max is bf2\n",
      "1158 count: tensor([24.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.2582596546723378 2.758578822576729 0.06729990442454245 max is bf2\n",
      "1159 count: tensor([26.,  1.,  0.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.2431006393096062 0.5214367997637901 0.00828201469352077 max is bf1\n",
      "1160 count: tensor([33.,  2.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.22599585422164356 0.5271908313395485 0.0033555701978133733 max is bf2\n",
      "1161 count: tensor([30.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.15385601222420647 1.6795726749362654 0.009191216734919003 max is bf2\n",
      "1162 count: tensor([23.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.24691507400586918 0.6046059132366203 0.00937463311089209 max is bf2\n",
      "1163 count: tensor([32.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.24852257174411796 2.6607535538722638 0.020890197954938777 max is bf2\n",
      "1164 count: tensor([25.,  0.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.10536974980142041 0.6547819706466038 0.0016141333526461473 max is bf2\n",
      "1165 count: tensor([27.,  1.,  5.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.4640801122037896 9.451630745801019 0.3512389121337461 max is bf2\n",
      "1166 count: tensor([27.,  0.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.18028992416431475 1.0992338352864606 0.0037890187781248526 max is bf2\n",
      "1167 count: tensor([36.,  0.,  5.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.23289945256878383 12.056355513369414 0.028415761360417 max is bf2\n",
      "1168 count: tensor([30.,  0.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.08351830294657368 0.23162497142917984 0.00010928217596126055 max is bf2\n",
      "1169 count: tensor([33.,  0.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.060352116352576 0.38613842324095077 0.00012860340558596025 max is bf2\n",
      "1170 count: tensor([32.,  1.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.5032061886290542 2.5955855660357847 0.03072486256028543 max is bf2\n",
      "1171 count: tensor([27.,  0.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.18028992416431475 1.0992338352864606 0.0037890187781248526 max is bf2\n",
      "1172 count: tensor([23.,  1.,  6.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.46346815619113707 17.762851786928067 1.043322367395048 max is bf2\n",
      "1173 count: tensor([27.,  0.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.10125194770646763 2.754556275603014 0.008342598003335245 max is bf2\n",
      "1174 count: tensor([31.,  2.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.5242701176087133 0.5522056937303685 0.009203461768090785 max is bf2\n",
      "1175 count: tensor([21.,  1.,  6.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.5459431326892807 92.21843990796646 44.27274851760546 max is bf2\n",
      "1176 count: tensor([31.,  0.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.10116734636349996 0.11436125108161406 2.7588046370609115e-05 max is bf2\n",
      "1177 count: tensor([34.,  0.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.054817531080946155 0.753762744876243 0.0002857150408364698 max is bf2\n",
      "1178 count: tensor([29.,  5.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  17.599737770266767 0.8860565306407012 0.8656208701087428 max is bf1\n",
      "1179 count: tensor([30.,  0.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.14395877399932577 0.8873517465121992 0.0014463263421839974 max is bf2\n",
      "1180 count: tensor([27.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.386773588064856 4.06769416253703 0.10893903805115321 max is bf2\n",
      "1181 count: tensor([27.,  1.,  0.,  3.], dtype=torch.float64)\n",
      "bfs are:  2.897224786064638 1.1958330406821995 0.029223704139323573 max is bf1\n",
      "1182 count: tensor([28.,  2.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.3416066534698628 0.7827919812011997 0.016995822530043607 max is bf2\n",
      "1183 count: tensor([38.,  4.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.3380443019419153 0.31977744852637796 0.009175997771427706 max is bf1\n",
      "1184 count: tensor([26.,  1.,  5.,  3.], dtype=torch.float64)\n",
      "bfs are:  2.789612472281067 54.246627849224446 10.967323619746962 max is bf2\n",
      "1185 count: tensor([31.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.2584095966792608 0.6345279249813368 0.0030755294761362407 max is bf2\n",
      "1186 count: tensor([19.,  1.,  5.,  3.], dtype=torch.float64)\n",
      "bfs are:  6.066209263600615 114.99729520349348 133.48043578713416 max is bfBoth\n",
      "1187 count: tensor([23.,  1.,  5.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.54215400602341 30.260313420611823 6.487936287542145 max is bf2\n",
      "1188 count: tensor([26.,  1.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.431550295868482 0.45597820802593064 0.005175202513194494 max is bf2\n",
      "1189 count: tensor([20.,  6., 10.,  2.], dtype=torch.float64)\n",
      "bfs are:  1030.5197033392208 8230.903578939271 3183677.525641942 max is bfBoth\n",
      "1190 count: tensor([27.,  0.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.10156711686737496 0.2785935587726519 0.00027979623361666287 max is bf2\n",
      "1191 count: tensor([28.,  1.,  0.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.47553642802911955 0.20555427472260077 0.0009273001296945849 max is bf1\n",
      "1192 count: tensor([20.,  1.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.6627257167697093 3.3475952553379997 0.37201074499902853 max is bf2\n",
      "1193 count: tensor([25.,  5.,  6.,  2.], dtype=torch.float64)\n",
      "bfs are:  37.04886739672906 65.64144607226409 999.5348990678764 max is bfBoth\n",
      "1194 count: tensor([30.,  2.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.2886724290280239 0.6662643596780672 0.008827165903513373 max is bf2\n",
      "1195 count: tensor([33.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.22182815269210068 0.5485928828442698 0.0016293695620425515 max is bf2\n",
      "1196 count: tensor([31.,  1.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1310021528101328 0.7074006080144473 0.002132472142544653 max is bf2\n",
      "1197 count: tensor([27.,  3.,  4.,  4.], dtype=torch.float64)\n",
      "bfs are:  24.57243534540165 47.77549834981831 110.22858516910478 max is bfBoth\n",
      "1198 count: tensor([26.,  1.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1953172554074672 1.035779576788835 0.01082112903700402 max is bf2\n",
      "1199 count: tensor([25.,  2.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.4432840468647881 1.0047617925194365 0.046134425144516385 max is bf2\n",
      "1200 count: tensor([21.,  0.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1474279882524014 1.9330893160557503 0.019095182102663647 max is bf2\n",
      "1201 count: tensor([25.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.4186269536066576 1.0058050041276236 0.021733906224739044 max is bf2\n",
      "1202 count: tensor([34.,  3.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.0140523532738497 0.21653096557737816 0.0036738405438260196 max is bf1\n",
      "1203 count: tensor([21.,  0.,  6.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.5680613805414042 53.0218489930996 3.161517742704778 max is bf2\n",
      "1204 count: tensor([26.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.4239211924171764 4.44226673405279 0.15254335845849817 max is bf2\n",
      "1205 count: tensor([22.,  2.,  0.,  3.], dtype=torch.float64)\n",
      "bfs are:  9.353328013946127 1.6259676905583829 0.47926024189094973 max is bf1\n",
      "1206 count: tensor([26.,  4.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  2.0352739449041075 0.4788602381253103 0.10745792289961316 max is bf1\n",
      "1207 count: tensor([27.,  3.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.5649611416163933 1.5929421554533443 0.32431687217077504 max is bf2\n",
      "1208 count: tensor([30.,  3.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.9464699085847768 0.08309944168855313 0.0010492199911321244 max is bf1\n",
      "1209 count: tensor([19.,  1.,  5.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.3743807147771423 45.90913836944092 27.012843640240945 max is bf2\n",
      "1210 count: tensor([32.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.14291143391435512 0.15847104050914348 0.0001728499781045347 max is bf2\n",
      "1211 count: tensor([26.,  0.,  4.,  4.], dtype=torch.float64)\n",
      "bfs are:  3.3124129855611013 82.34124504748517 5.8737175708583065 max is bf2\n",
      "1212 count: tensor([30.,  3.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.2162399812628062 0.5843172275486409 0.039167243124986394 max is bf1\n",
      "1213 count: tensor([21.,  2.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.4386110505009484 6.349678703496173 2.6183320900689537 max is bf2\n",
      "1214 count: tensor([27.,  0.,  6.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.3128436175422609 29.84617525314679 0.3966050933819802 max is bf2\n",
      "1215 count: tensor([34.,  0.,  5.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.06878957493092021 3.7158248029585947 0.002796092916927146 max is bf2\n",
      "1216 count: tensor([30.,  2.,  3.,  3.], dtype=torch.float64)\n",
      "bfs are:  2.9421682542210275 6.336092295605972 0.8383451577331731 max is bf2\n",
      "1217 count: tensor([26.,  0.,  1.,  3.], dtype=torch.float64)\n",
      "bfs are:  1.2437713927612855 3.1728057968576957 0.03998548660857842 max is bf2\n",
      "1218 count: tensor([27.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1802899583095767 0.4480484628292536 0.002520237768741895 max is bf2\n",
      "1219 count: tensor([30.,  2.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.5547571585839229 1.2468722744133782 0.038597662885816675 max is bf2\n",
      "1220 count: tensor([26.,  2.,  2.,  3.], dtype=torch.float64)\n",
      "bfs are:  4.456050404146497 4.417570389104537 1.0734788064604908 max is bf1\n",
      "1221 count: tensor([25.,  0.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.21222517454915166 2.7510189197094084 0.022656170461897975 max is bf2\n",
      "1222 count: tensor([29.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.15501657184598303 0.38805978618806547 0.001323434372113173 max is bf2\n",
      "1223 count: tensor([34.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.20583295876492516 0.5108379095729753 0.0011895317714002884 max is bf2\n",
      "1224 count: tensor([37.,  2.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.17461530875019163 0.19290225359839835 0.00032052786944723776 max is bf2\n",
      "1225 count: tensor([30.,  1.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.14160473484804953 0.7619174512109433 0.002938710359657435 max is bf2\n",
      "1226 count: tensor([26.,  2., 10.,  2.], dtype=torch.float64)\n",
      "bfs are:  16.791826888445183 2303.7951897551025 3224.8641830651636 max is bfBoth\n",
      "1227 count: tensor([26.,  3.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.8817453936760118 3.8721720096523162 1.4311344879286063 max is bf2\n",
      "1228 count: tensor([27.,  2.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.853710493357499 0.8243640492079416 0.053045889335881294 max is bf1\n",
      "1229 count: tensor([35.,  2.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.2018299290791992 0.22141503963976955 0.0005955033887900888 max is bf2\n",
      "1230 count: tensor([21.,  2.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.380107320269294 0.6140716477376307 0.08481426676031736 max is bf1\n",
      "1231 count: tensor([20.,  0.,  4.,  3.], dtype=torch.float64)\n",
      "bfs are:  2.2015678890225 54.48413609364743 9.413705995303033 max is bf2\n",
      "1232 count: tensor([28.,  0.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.18206874717841454 4.8413188080193175 0.026605973094631915 max is bf2\n",
      "1233 count: tensor([23.,  2.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.5302671552718006 1.1931014433595124 0.09075157179256742 max is bf2\n",
      "1234 count: tensor([35.,  1.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.15529771867046516 0.07069506128605924 2.4109048635392086e-05 max is bf1\n",
      "1235 count: tensor([23.,  2.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.1600843592312449 0.5200466050847534 0.043068594720641985 max is bf1\n",
      "1236 count: tensor([29.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.15501657184598303 0.38805978618806547 0.001323434372113173 max is bf2\n",
      "1237 count: tensor([24.,  0.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.11348050589281518 0.7025590707532776 0.0022353470336493324 max is bf2\n",
      "1238 count: tensor([20.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.6444765464049227 1.5198383820151262 0.11763601034747614 max is bf2\n",
      "1239 count: tensor([22.,  2.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.5706415321523284 0.5972311384713029 0.040698752892627525 max is bf2\n",
      "1240 count: tensor([29.,  0.,  1.,  4.], dtype=torch.float64)\n",
      "bfs are:  2.6843203352520564 6.802409095890477 0.07559144805664539 max is bf2\n",
      "1241 count: tensor([24.,  2.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.0653579163049685 0.47935730508371344 0.030792618084946283 max is bf1\n",
      "1242 count: tensor([31.,  0.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.33788188035640276 0.8952841813729748 0.0016378474134513415 max is bf2\n",
      "1243 count: tensor([26.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.21637284159435316 2.328167465863334 0.03436241373528926 max is bf2\n",
      "1244 count: tensor([22.,  0.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1541850459277022 4.117887203106731 0.044175506169234886 max is bf2\n",
      "1245 count: tensor([23.,  2.,  5.,  3.], dtype=torch.float64)\n",
      "bfs are:  7.951787255889862 65.61855668318618 95.55039082062682 max is bfBoth\n",
      "1246 count: tensor([36.,  1.,  0.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.6016968488505331 0.2616267658561154 0.00035144127869704366 max is bf1\n",
      "1247 count: tensor([26.,  1.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.27463569079772704 0.120993441462513 0.00039035672557984617 max is bf1\n",
      "1248 count: tensor([43.,  0.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.0567867959089854 1.5910446206198 0.00023760023849627652 max is bf2\n",
      "1249 count: tensor([25.,  1.,  6.,  3.], dtype=torch.float64)\n",
      "bfs are:  4.042694571366555 145.650037975562 51.313545008014984 max is bf2\n",
      "1250 count: tensor([25.,  2.,  1.,  3.], dtype=torch.float64)\n",
      "bfs are:  5.557586713410419 2.405437417750552 0.505286215591848 max is bf1\n",
      "1251 count: tensor([27.,  0.,  2.,  3.], dtype=torch.float64)\n",
      "bfs are:  1.013050074678611 5.919361096459106 0.08611161022159305 max is bf2\n",
      "1252 count: tensor([25.,  0.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.4783781328988515 6.0619329151407175 0.10622077530061817 max is bf2\n",
      "1253 count: tensor([36.,  2.,  6.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.49615331005862495 8.316133618906541 0.16643593557736805 max is bf2\n",
      "1254 count: tensor([27.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.386773588064856 4.06769416253703 0.10893903805115321 max is bf2\n",
      "1255 count: tensor([26.,  0.,  9.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.6226527088149293 320.1524429516042 5.301676717725376 max is bf2\n",
      "1256 count: tensor([37.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.16390058893821635 1.785605318101419 0.004216234107511883 max is bf2\n",
      "1257 count: tensor([24.,  1.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.23084454231890703 1.2152005993975905 0.021031390661217376 max is bf2\n",
      "1258 count: tensor([23.,  1.,  5.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.34749552300610853 7.162027324483101 0.31053878082681496 max is bf2\n",
      "1259 count: tensor([28.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.16709148843079183 0.41676878648436294 0.0018243982821271557 max is bf2\n",
      "1260 count: tensor([32.,  2.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.0679184679007059 4.793213889618786 0.27910605826621193 max is bf2\n",
      "1261 count: tensor([28.,  2.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.7659182671436439 0.34971291035256097 0.008221884917390532 max is bf1\n",
      "1262 count: tensor([24.,  1.,  8.,  2.], dtype=torch.float64)\n",
      "bfs are:  3.9204856447358005 447.642720097381 178.4192442458922 max is bf2\n",
      "1263 count: tensor([31.,  2.,  6.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.7339558969082194 27.91956521291786 3.9594907784788385 max is bf2\n",
      "1264 count: tensor([30.,  0.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.14160470802941355 1.8692742226536192 0.004418165966051124 max is bf2\n",
      "1265 count: tensor([23.,  1.,  6.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.036782007159917 74.31571835056764 21.631500183590774 max is bf2\n",
      "1266 count: tensor([28.,  3.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.6597380263129247 0.3469160559455746 0.025583189115763197 max is bf1\n",
      "1267 count: tensor([24.,  0.,  4.,  5.], dtype=torch.float64)\n",
      "bfs are:  12.359858048190302 300.3122731049648 62.05993970055172 max is bf2\n",
      "1268 count: tensor([39.,  3.,  6.,  4.], dtype=torch.float64)\n",
      "bfs are:  8.963500699388154 65.35188368592381 17.17074829978388 max is bf2\n",
      "1269 count: tensor([26.,  0.,  0.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.6252119580023499 0.6606270070708486 0.002772797150496787 max is bf2\n",
      "1270 count: tensor([37.,  5.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  8.285896680641113 0.4289169297503862 0.06152471606668541 max is bf1\n",
      "1271 count: tensor([26.,  3.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.723586483076417 1.7480954752216178 0.45585305879668436 max is bf2\n",
      "1272 count: tensor([36.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.11025271203093331 0.12400955950028807 5.07887392261128e-05 max is bf2\n",
      "1273 count: tensor([27.,  3.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.5649611416163933 1.5929421554533443 0.32431687217077504 max is bf2\n",
      "1274 count: tensor([28.,  2.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.4895820935655457 1.5172315717619682 0.11318312549246835 max is bf2\n",
      "1275 count: tensor([34.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.11123880610890677 1.23166953272469 0.0025413210106481807 max is bf2\n",
      "1276 count: tensor([34.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1081308854588311 0.27558456079305366 0.00027408444489683255 max is bf2\n",
      "1277 count: tensor([25.,  0.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.10673773132352127 1.4206370192080389 0.005045257818217814 max is bf2\n",
      "1278 count: tensor([29.,  1.,  4.,  3.], dtype=torch.float64)\n",
      "bfs are:  1.7295072267162486 17.55434898439633 1.2236637544034357 max is bf2\n",
      "1279 count: tensor([28.,  0.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.40247908812949407 10.46125707628074 0.12285196727370838 max is bf2\n",
      "1280 count: tensor([34.,  4.,  0.,  3.], dtype=torch.float64)\n",
      "bfs are:  15.428068177590056 0.620190552887413 0.08613169859964499 max is bf1\n",
      "1281 count: tensor([26.,  1.,  6.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.6685388679980145 25.226166123478805 1.6335808465020418 max is bf2\n",
      "1282 count: tensor([22.,  0.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.27402124266667166 3.5127518672099978 0.06199236672452962 max is bf2\n",
      "1283 count: tensor([30.,  2.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.2948878224312782 0.3178103134842747 0.002900580416456039 max is bf2\n",
      "1284 count: tensor([26.,  1.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.9727603015432956 1.0047583780744207 0.024263324828602814 max is bf2\n",
      "1285 count: tensor([25.,  2.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.9480798381817706 4.203694050818817 0.9565181933893979 max is bf2\n",
      "1286 count: tensor([17.,  2.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.911473332219774 4.095832883965135 3.3515148190404216 max is bf2\n",
      "1287 count: tensor([30.,  2.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.5694236648589209 0.5976293161836 0.01273086216948398 max is bf2\n",
      "1288 count: tensor([25.,  2.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.2077369569726106 0.9746695644770027 0.10344341512188385 max is bf1\n",
      "1289 count: tensor([29.,  3.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.2944936918713577 1.3270968876730596 0.16522115427969564 max is bf2\n",
      "1290 count: tensor([28.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.32736836331399694 0.7952169004751976 0.008098960779224444 max is bf2\n",
      "1291 count: tensor([27.,  0.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.0911245073834608 0.5704665861234813 0.0008470216383042585 max is bf2\n",
      "1292 count: tensor([30.,  2.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.2886724290280239 0.6662643596780672 0.008827165903513373 max is bf2\n",
      "1293 count: tensor([21.,  1.,  5.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.8426765784495576 16.790859595638192 2.7998834890646824 max is bf2\n",
      "1294 count: tensor([22.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.2678202511643747 0.6533424449874158 0.013089853346831793 max is bf2\n",
      "1295 count: tensor([28.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.18808193216752814 0.20555431365269955 0.0006072987451932921 max is bf2\n",
      "1296 count: tensor([22.,  1.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.550275986012426 2.8004394585150876 0.18660243161403792 max is bf2\n",
      "1297 count: tensor([33.,  2.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.23418847596212586 0.255108496835354 0.0011150932794379846 max is bf2\n",
      "1298 count: tensor([27.,  1.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.7923119166899509 1.8745325227296743 0.05225280839454133 max is bf2\n",
      "1299 count: tensor([38.,  2.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.2599121735006601 0.051289602004044026 2.910390590001973e-05 max is bf1\n",
      "1300 count: tensor([30.,  1.,  7.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.6205020697977958 42.60435164284679 1.390977922944929 max is bf2\n",
      "1301 count: tensor([25.,  1.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.4666004123553455 0.49119580769031573 0.007179350359495005 max is bf2\n",
      "1302 count: tensor([29.,  4.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  1.7798412743171328 0.1854938857775493 0.013312968764944616 max is bf1\n",
      "1303 count: tensor([24.,  2.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.154527423604045 2.1628980014965333 0.4370410389924799 max is bf2\n",
      "1304 count: tensor([20.,  1.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.6627257167697093 3.3475952553379997 0.37201074499902853 max is bf2\n",
      "1305 count: tensor([30.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.2956732808184746 3.1432157083297185 0.04018951143805733 max is bf2\n",
      "1306 count: tensor([35.,  2.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.20376253242417092 0.9710686293908589 0.005440306864856672 max is bf2\n",
      "1307 count: tensor([24.,  2.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.0653579163049685 0.47935730508371344 0.030792618084946283 max is bf1\n",
      "1308 count: tensor([22.,  1.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.4014832039408176 14.147933482061768 2.8212069589773856 max is bf2\n",
      "1309 count: tensor([29.,  1.,  6.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.4949373507289877 18.876569626298974 0.585439210471877 max is bf2\n",
      "1310 count: tensor([29.,  2.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.36268020185244054 0.1706572346959993 0.0013435211504105446 max is bf1\n",
      "1311 count: tensor([29.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.16728101938149398 1.8195925274739333 0.012740288913449298 max is bf2\n",
      "1312 count: tensor([26.,  0.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.09871980031152756 1.3187806413082963 0.00363685147445452 max is bf2\n",
      "1313 count: tensor([33.,  3.,  5.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.0948432641115105 4.471503903685149 0.42093837293824116 max is bf2\n",
      "1314 count: tensor([23.,  2.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.5776879711275815 0.26588782684069867 0.009516919106242966 max is bf1\n",
      "1315 count: tensor([30.,  0.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.14160470802941355 1.8692742226536192 0.004418165966051124 max is bf2\n",
      "1316 count: tensor([32.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.24852257174411796 2.6607535538722638 0.020890197954938777 max is bf2\n",
      "1317 count: tensor([22.,  0.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.7048697670446722 17.924524998477285 0.9445328107102089 max is bf2\n",
      "1318 count: tensor([27.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1802899583095767 0.4480484628292536 0.002520237768741895 max is bf2\n",
      "1319 count: tensor([38.,  0.,  0.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.13055876194387317 0.14736669953390075 1.4841480063745674e-05 max is bf2\n",
      "1320 count: tensor([33.,  4.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  1.0473755208415687 0.5410390749707712 0.03178857464444605 max is bf1\n",
      "1321 count: tensor([29.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1753446871569995 0.1923355365517292 0.00044222497619893426 max is bf2\n",
      "1322 count: tensor([22.,  0.,  4.,  3.], dtype=torch.float64)\n",
      "bfs are:  1.7919365271501433 44.67605978212516 4.649294104377467 max is bf2\n",
      "1323 count: tensor([25.,  3.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  1.3842573711667907 0.11933579643870405 0.005278616997322556 max is bf1\n",
      "1324 count: tensor([26.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.194730758746536 0.482161776086452 0.0034888062407558698 max is bf2\n",
      "1325 count: tensor([25.,  3.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  1.0885767713285461 0.23109006138707455 0.015524061503018962 max is bf1\n",
      "1326 count: tensor([32.,  4.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  1.8363080360851634 0.07856605138162914 0.0017629979977451717 max is bf1\n",
      "1327 count: tensor([45.,  0.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.03549663925382366 0.10377966117648552 1.2908144192984939e-06 max is bf2\n",
      "1328 count: tensor([21.,  0.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.3395986698352104 8.800889228917844 0.2819509534486812 max is bf2\n",
      "1329 count: tensor([27.,  3.,  6.,  1.], dtype=torch.float64)\n",
      "bfs are:  2.6053444217244333 19.372064580167425 10.619776823033796 max is bf2\n",
      "1330 count: tensor([26.,  2.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.7953823744839609 1.7621887074312959 0.146501336158965 max is bf2\n",
      "1331 count: tensor([32.,  0.,  5.,  3.], dtype=torch.float64)\n",
      "bfs are:  0.7998164888290165 40.024861981071204 0.49185440767723004 max is bf2\n",
      "1332 count: tensor([29.,  0.,  1.,  3.], dtype=torch.float64)\n",
      "bfs are:  0.9757056839533853 2.516290621208688 0.014995243143167842 max is bf2\n",
      "1333 count: tensor([20.,  4.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  8.007511301640545 0.7863976113845706 1.2584882329914715 max is bf1\n",
      "1334 count: tensor([24.,  2.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.413307299368696 1.0615182677674582 0.14492405126352612 max is bf1\n",
      "1335 count: tensor([21.,  2.,  0.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.7202543361911402 0.31081224278046066 0.02839455875569811 max is bf1\n",
      "1336 count: tensor([21.,  3.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  3.1791314015994114 6.423971596184985 8.272815445184872 max is bfBoth\n",
      "1337 count: tensor([29.,  1.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.6540417539580309 3.3378648698474858 0.0822431197150802 max is bf2\n",
      "1338 count: tensor([26.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.4239211924171764 4.44226673405279 0.15254335845849817 max is bf2\n",
      "1339 count: tensor([28.,  2.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.4581859557338093 3.1807568186214747 0.3444435536184417 max is bf2\n",
      "1340 count: tensor([23.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.24691507400586918 0.6046059132366203 0.00937463311089209 max is bf2\n",
      "1341 count: tensor([30.,  3.,  7.,  0.], dtype=torch.float64)\n",
      "bfs are:  1.3729347747420413 19.005987557366044 2.885393250059856 max is bf2\n",
      "1342 count: tensor([31.,  2.,  3.,  3.], dtype=torch.float64)\n",
      "bfs are:  2.6705645131825038 5.771444367033827 0.599312350456997 max is bf2\n",
      "1343 count: tensor([22.,  1.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.4014832039408176 14.147933482061768 2.8212069589773856 max is bf2\n",
      "1344 count: tensor([26.,  2.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.8007994920409799 0.8284137693759563 0.047595782548871195 max is bf2\n",
      "1345 count: tensor([31.,  4.,  5.,  0.], dtype=torch.float64)\n",
      "bfs are:  1.5604249415425306 3.144302756687859 0.5960378907184385 max is bf2\n",
      "1346 count: tensor([25.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.23626058076576342 2.5328841728094917 0.04803710557602354 max is bf2\n",
      "1347 count: tensor([20.,  1.,  3.,  3.], dtype=torch.float64)\n",
      "bfs are:  3.9126782976274415 18.9442754580742 8.786826905422298 max is bf2\n",
      "1348 count: tensor([25.,  1.,  8.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.8239891166296835 99.19276654863582 6.188825112768321 max is bf2\n",
      "1349 count: tensor([27.,  1.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.7831355588613914 3.9680669560560147 0.16022523954973203 max is bf2\n",
      "1350 count: tensor([30.,  0.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.15385598308529108 4.120632624101068 0.01381841556156367 max is bf2\n",
      "1351 count: tensor([28.,  0.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.16596114380026916 2.175030676425584 0.008442634935521732 max is bf2\n",
      "1352 count: tensor([32.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.12452277425616926 0.3151102329680367 0.000511436519809349 max is bf2\n",
      "1353 count: tensor([28.,  1.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.37029784988035924 0.394136353911654 0.0027062639548267346 max is bf2\n",
      "1354 count: tensor([19.,  5.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  50.545321562841 24.340476322706213 863.3126244303926 max is bfBoth\n",
      "1355 count: tensor([22.,  2.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.9273389922551973 12.677325470210143 8.636918037152439 max is bf2\n",
      "1356 count: tensor([31.,  1.,  3.,  3.], dtype=torch.float64)\n",
      "bfs are:  1.3351824991751036 6.7272929689846475 0.2025279364004775 max is bf2\n",
      "1357 count: tensor([26.,  1.,  2.,  3.], dtype=torch.float64)\n",
      "bfs are:  2.164862289573332 5.003079459851104 0.3546860074839202 max is bf2\n",
      "1358 count: tensor([40.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.08630643406747045 0.09844101015979405 1.5388055998199895e-05 max is bf2\n",
      "1359 count: tensor([21.,  1.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.6035427533226503 3.0600920154455262 0.26317522822663747 max is bf2\n",
      "1360 count: tensor([33.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.12045078578103376 1.3289849620992529 0.003493960949013336 max is bf2\n",
      "1361 count: tensor([33.,  1.,  6.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.17938895218673293 7.125618625775407 0.03577170963918081 max is bf2\n",
      "1362 count: tensor([34.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.12529108038271447 0.13992951598819534 9.333020832905484e-05 max is bf2\n",
      "1363 count: tensor([19.,  1.,  8.,  1.], dtype=torch.float64)\n",
      "bfs are:  3.2000735593676395 367.06943659047516 238.30890686890743 max is bf2\n",
      "1364 count: tensor([28.,  2.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.7013416994074533 0.7593476633703747 0.03810833059707342 max is bf1\n",
      "1365 count: tensor([17.,  2.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.8934196956010445 0.9175185473211369 0.22783950655270072 max is bf2\n",
      "1366 count: tensor([29.,  1.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.3435381645676548 0.36698638234905034 0.001963147396550227 max is bf2\n",
      "1367 count: tensor([26.,  4.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  9.285511892368309 9.036104536875012 20.80743969849431 max is bfBoth\n",
      "1368 count: tensor([23.,  0.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1251749182135771 1.6536826715480117 0.009772439596539863 max is bf2\n",
      "1369 count: tensor([27.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1802899583095767 0.4480484628292536 0.002520237768741895 max is bf2\n",
      "1370 count: tensor([27.,  2.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.3722002689749917 0.8498157016067327 0.023657780516111292 max is bf2\n",
      "1371 count: tensor([33.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.22182815269210068 0.5485928828442698 0.0016293695620425515 max is bf2\n",
      "1372 count: tensor([34.,  4.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.8730616158011335 1.917884340772791 0.29798030087021926 max is bf2\n",
      "1373 count: tensor([21.,  3.,  5.,  2.], dtype=torch.float64)\n",
      "bfs are:  8.724758216499945 33.376208122535154 126.48845825501587 max is bfBoth\n",
      "1374 count: tensor([29.,  1.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.29729571068103705 1.5521981863959646 0.017878700913427185 max is bf2\n",
      "1375 count: tensor([20.,  0.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.183837816206582 4.873087013116208 0.08738408015152965 max is bf2\n",
      "1376 count: tensor([25.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.4651525218866905 4.856632366462421 0.2140644754225894 max is bf2\n",
      "1377 count: tensor([25.,  1.,  7.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.0489249698023766 70.7529820280216 7.838822471131312 max is bf2\n",
      "1378 count: tensor([27.,  1.,  5.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.2391790840542756 5.002006211847874 0.07972423606680884 max is bf2\n",
      "1379 count: tensor([30.,  5.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  3.3201699049694 0.40217326635084905 0.09151817139930085 max is bf1\n",
      "1380 count: tensor([21.,  1.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.6035427533226503 3.0600920154455262 0.26317522822663747 max is bf2\n",
      "1381 count: tensor([28.,  3.,  5.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.951224284657364 3.9202385904228745 0.5272816839431338 max is bf2\n",
      "1382 count: tensor([31.,  2.,  3.,  3.], dtype=torch.float64)\n",
      "bfs are:  2.6705645131825038 5.771444367033827 0.599312350456997 max is bf2\n",
      "1383 count: tensor([25.,  2.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.8727426794727231 1.9265620964901977 0.2055856904586865 max is bf2\n",
      "1384 count: tensor([28.,  0.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.09338227332318703 2.5497192307896235 0.006016187014379037 max is bf2\n",
      "1385 count: tensor([26.,  2.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.8007994920409799 0.8284137693759563 0.047595782548871195 max is bf2\n",
      "1386 count: tensor([23.,  6.,  5.,  2.], dtype=torch.float64)\n",
      "bfs are:  90.82629483783131 45.47019616452469 2117.555171273637 max is bfBoth\n",
      "1387 count: tensor([27.,  1.,  5.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.2391790840542756 5.002006211847874 0.07972423606680884 max is bf2\n",
      "1388 count: tensor([23.,  3.,  8.,  1.], dtype=torch.float64)\n",
      "bfs are:  8.785429177662728 200.79119364730406 516.8477352653596 max is bfBoth\n",
      "1389 count: tensor([31.,  0.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.2944060384845393 1.780219313627607 0.004846138774791792 max is bf2\n",
      "1390 count: tensor([28.,  2.,  5.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.855848264013677 7.503624411663818 0.7494060893123503 max is bf2\n",
      "1391 count: tensor([31.,  1.,  7.,  5.], dtype=torch.float64)\n",
      "bfs are:  21.75992062764508 1389.0896414803085 515.4480709804303 max is bf2\n",
      "1392 count: tensor([34.,  1.,  5.,  3.], dtype=torch.float64)\n",
      "bfs are:  1.2320429716193186 24.64035559830265 0.7197803707395662 max is bf2\n",
      "1393 count: tensor([28.,  2.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.34560941500123005 0.3697944222070506 0.0055426939018203844 max is bf2\n",
      "1394 count: tensor([30.,  3.,  1.,  3.], dtype=torch.float64)\n",
      "bfs are:  7.509578664843046 1.514855789913297 0.2907660498423108 max is bf1\n",
      "1395 count: tensor([26.,  1.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1953172554074672 1.035779576788835 0.01082112903700402 max is bf2\n",
      "1396 count: tensor([31.,  0.,  5.,  3.], dtype=torch.float64)\n",
      "bfs are:  0.880194287678659 43.89325242134422 0.6865892794790761 max is bf2\n",
      "1397 count: tensor([29.,  1.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.22517761372760714 0.1003089193039393 0.00015152818964760258 max is bf1\n",
      "1398 count: tensor([36.,  2.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.34898990230439947 1.6250700914790839 0.016864291987885086 max is bf2\n",
      "1399 count: tensor([24.,  1.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.031494474879634 2.4138006968082104 0.14275731403962716 max is bf2\n",
      "1400 count: tensor([30.,  1.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.5986765052202307 3.066231110207222 0.05910988579250873 max is bf2\n",
      "1401 count: tensor([30.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.2956732808184746 3.1432157083297185 0.04018951143805733 max is bf2\n",
      "1402 count: tensor([25.,  1.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.056968896360326 1.0877341752891478 0.03378928471323809 max is bf2\n",
      "1403 count: tensor([27.,  3.,  5.,  1.], dtype=torch.float64)\n",
      "bfs are:  2.0207112184517504 8.080946013286837 3.245878924407707 max is bf2\n",
      "1404 count: tensor([26.,  0.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.4916652270123193 1.2792836698951155 0.008154611998093815 max is bf2\n",
      "1405 count: tensor([21.,  3.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  2.8416561398449356 2.8298680720332974 2.585275788777896 max is bf1\n",
      "1406 count: tensor([28.,  0.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.1670914567851988 1.0224928542372373 0.0027428679291673862 max is bf2\n",
      "1407 count: tensor([20.,  0.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.3728994684163883 9.627754615473961 0.398551128662093 max is bf2\n",
      "1408 count: tensor([19.,  0.,  5.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.182371701774228 57.58646595229972 8.974106579071183 max is bf2\n",
      "1409 count: tensor([26.,  0.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.09871980031152756 1.3187806413082963 0.00363685147445452 max is bf2\n",
      "1410 count: tensor([30.,  3.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.2162399812628062 0.5843172275486409 0.039167243124986394 max is bf1\n",
      "1411 count: tensor([28.,  2.,  6.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.1034627215060342 17.988079174030812 2.4518861003948036 max is bf2\n",
      "1412 count: tensor([27.,  1.,  6.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.3128436767919795 12.16532143956435 0.26379893955324607 max is bf2\n",
      "1413 count: tensor([35.,  3.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.4024875598806728 0.432777190529855 0.0053716232843732765 max is bf2\n",
      "1414 count: tensor([24.,  2.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.9587020659574329 2.1085944344643446 0.2891312154328412 max is bf2\n",
      "1415 count: tensor([28.,  1.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.24035188293468204 0.10667597884987938 0.0002072946377537793 max is bf1\n",
      "1416 count: tensor([28.,  3.,  6.,  1.], dtype=torch.float64)\n",
      "bfs are:  2.334581171524503 17.42025219772614 7.487165223487036 max is bf2\n",
      "1417 count: tensor([28.,  0.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.08486920475233933 0.5332616866766791 0.0006155128544070359 max is bf2\n",
      "1418 count: tensor([25.,  1.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.0382834148942153 10.597009368712069 0.9959670093926664 max is bf2\n",
      "1419 count: tensor([27.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1802899583095767 0.4480484628292536 0.002520237768741895 max is bf2\n",
      "1420 count: tensor([33.,  1.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.17512473408120002 0.07915261057214479 4.414309270319359e-05 max is bf1\n",
      "1421 count: tensor([27.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.19837450125072395 2.1422836302397004 0.024633476992221962 max is bf2\n",
      "1422 count: tensor([26.,  0.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.10990021794989657 2.9789239261051286 0.011593141459146198 max is bf2\n",
      "1423 count: tensor([13.,  2.,  6.,  3.], dtype=torch.float64)\n",
      "bfs are:  36.88090570957052 545.4358976359437 13486.38732413412 max is bfBoth\n",
      "1424 count: tensor([19.,  1.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.8315310226079098 8.491314159528955 1.7129856249681532 max is bf2\n",
      "1425 count: tensor([29.,  5.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  3.6445566825051716 0.43990164758729666 0.12781265528449315 max is bf1\n",
      "1426 count: tensor([26.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.21637284159435316 2.328167465863334 0.03436241373528926 max is bf2\n",
      "1427 count: tensor([22.,  3.,  8.,  2.], dtype=torch.float64)\n",
      "bfs are:  21.91129544395483 487.75039714926857 3436.280050374702 max is bfBoth\n",
      "1428 count: tensor([22.,  2.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.608735246755592 2.5996546149495035 0.8701950649938534 max is bf1\n",
      "1429 count: tensor([27.,  0.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.1799473117902556 2.3497663299663505 0.011707333762669244 max is bf2\n",
      "1430 count: tensor([29.,  0.,  5.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.4373482698152975 22.091852765460253 0.2819516790800251 max is bf2\n",
      "1431 count: tensor([28.,  1.,  0.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.0666601282125692 0.4507171514709187 0.004330906429511991 max is bf1\n",
      "1432 count: tensor([28.,  1.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.24035188293468204 0.10667597884987938 0.0002072946377537793 max is bf1\n",
      "1433 count: tensor([24.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.2582596546723378 2.758578822576729 0.06729990442454245 max is bf2\n",
      "1434 count: tensor([32.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.12452277425616926 0.3151102329680367 0.000511436519809349 max is bf2\n",
      "1435 count: tensor([31.,  1.,  7.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.5605790667278875 38.624945105817915 0.9906987634714353 max is bf2\n",
      "1436 count: tensor([23.,  0.,  3.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1251749182135771 1.6536826715480117 0.009772439596539863 max is bf2\n",
      "1437 count: tensor([34.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1081308854588311 0.27558456079305366 0.00027408444489683255 max is bf2\n",
      "1438 count: tensor([39.,  1.,  0.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.1234376721906553 0.05698967123342281 7.35802621874858e-06 max is bf1\n",
      "1439 count: tensor([25.,  0.,  4.,  4.], dtype=torch.float64)\n",
      "bfs are:  3.6700108712241883 90.90252015515782 8.305422722060726 max is bf2\n",
      "1440 count: tensor([29.,  2.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.326942000897081 2.904817760521094 0.24611092621916822 max is bf2\n",
      "1441 count: tensor([25.,  1.,  7.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.5405982866355256 37.443999361501895 1.7792565447199362 max is bf2\n",
      "1442 count: tensor([27.,  2.,  6.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.6706510519887323 42.40256892554409 15.819058531289638 max is bf2\n",
      "1443 count: tensor([34.,  6.,  1.,  1.], dtype=torch.float64)\n",
      "bfs are:  12.235934971768383 0.33934834036482536 0.11861481428264144 max is bf1\n",
      "1444 count: tensor([29.,  0.,  6.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.13465611202150754 13.286663133335333 0.046207734564439426 max is bf2\n",
      "1445 count: tensor([28.,  1.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.7152953135014859 3.637406223164786 0.11467098844634477 max is bf2\n",
      "1446 count: tensor([25.,  4.,  3.,  2.], dtype=torch.float64)\n",
      "bfs are:  9.56013833661548 4.56915609523016 9.478151369484051 max is bf1\n",
      "1447 count: tensor([36.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.09425534844639565 0.2419208351886231 0.00014804495907700895 max is bf2\n",
      "1448 count: tensor([23.,  0.,  8.,  2.], dtype=torch.float64)\n",
      "bfs are:  2.2767618815185853 652.5665932632379 87.46541083277766 max is bf2\n",
      "1449 count: tensor([26.,  2.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  1.7874929020473018 1.8075711342428649 0.2214465016267768 max is bf2\n",
      "1450 count: tensor([25.,  2.,  5.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.1600159684568507 10.061614136521165 2.1047983345140473 max is bf2\n",
      "1451 count: tensor([23.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.28262065136699704 3.00766588154576 0.09449435690883017 max is bf2\n",
      "1452 count: tensor([30.,  1.,  1.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.16363044926665765 0.18014022405073474 0.0003226812518265225 max is bf2\n",
      "1453 count: tensor([22.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.5405234241637613 1.2843035651211285 0.05946884480351362 max is bf2\n",
      "1454 count: tensor([27.,  0.,  3.,  4.], dtype=torch.float64)\n",
      "bfs are:  2.7547816111626333 33.87371223222864 1.331073862493869 max is bf2\n",
      "1455 count: tensor([30.,  1.,  1.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.7052498474002254 0.7390983174998204 0.006589227777408496 max is bf2\n",
      "1456 count: tensor([31.,  2.,  4.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.5444707420751527 2.4915387078835916 0.08597304565167285 max is bf2\n",
      "1457 count: tensor([28.,  3.,  3.,  1.], dtype=torch.float64)\n",
      "bfs are:  1.4225282793043705 1.4531625810770958 0.23123459972825378 max is bf2\n",
      "1458 count: tensor([18.,  3.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  2.189306473736665 4.491718700674117 5.363301167515629 max is bfBoth\n",
      "1459 count: tensor([31.,  1.,  2.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.5657758479450109 1.3579500579931045 0.014094521101366123 max is bf2\n",
      "1460 count: tensor([32.,  3.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.5370415369133614 0.2668399925025019 0.0046909540084732245 max is bf1\n",
      "1461 count: tensor([29.,  3.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.6881036504718182 0.33825844599344396 0.01241622442026277 max is bf1\n",
      "1462 count: tensor([37.,  1.,  0.,  1.], dtype=torch.float64)\n",
      "bfs are:  0.2618521174834966 0.11689949317335543 5.737335716015489e-05 max is bf1\n",
      "1463 count: tensor([29.,  1.,  4.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.16728101938149398 1.8195925274739333 0.012740288913449298 max is bf2\n",
      "1464 count: tensor([31.,  1.,  4.,  2.], dtype=torch.float64)\n",
      "bfs are:  0.5875757275350365 6.1270377529185405 0.13166229584257702 max is bf2\n",
      "1465 count: tensor([28.,  1.,  2.,  0.], dtype=torch.float64)\n",
      "bfs are:  0.16709148843079183 0.41676878648436294 0.0018243982821271557 max is bf2\n",
      "1466 count: tensor([17.,  2.,  5.,  0.], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-46005f81863c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffectedGene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"count:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maffectedGene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtestCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maffectedGene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbfsAffected2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbayesFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestCount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestAllPDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbfsAffected2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbfsAffected2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/bayes.py\u001b[0m in \u001b[0;36mbayesFactor\u001b[0;34m(n, altCount, pDs, pis, alphas)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meffect1Likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meffect2Likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlBoth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meffectBothLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# these all have the same denominator, seems like I shoudl be able to add them?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36meffectBothLikelihood\u001b[0;34m(n, pDs, alpha0, alpha1, alpha2, alphaBoth, altCounts)\u001b[0m\n\u001b[1;32m     81\u001b[0m                            alpha2 + alphaBoth, alpha1 + alpha2 + alphaBoth])\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlikelihoodBivariateFast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsByGene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0m\u001b[1;32m    162\u001b[0m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# bayesFactor(n, altCount,pDs,rrMeans,rrsShape,afMeans,afShape,alpha0, alpha1, alpha2, alphaBoth):\n",
    "bfsAffected2 = []\n",
    "for affectedGene in testAffectedGenes[1]:\n",
    "    print(affectedGene, \"count:\", testCounts[affectedGene])\n",
    "    testCount = testCounts[affectedGene]\n",
    "    bfsAffected2.append(bayes.bayesFactor(testCount.sum(), testCount, testAllPDs, bestParams[0:3], bestParams[3:]))\n",
    "bfsAffected2 = tensor(bfsAffected2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfsAffected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
