{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyro\n",
    "# import torch\n",
    "# import torch.tensor as tensor\n",
    "# import pyro.distributions as dist\n",
    "# # from torch.distributions import Binomial, Gamma, Uniform\n",
    "# from pyro.distributions import Binomial, Bernoulli, Categorical, Dirichlet, DirichletMultinomial, Beta, BetaBinomial, Uniform, Gamma, Multinomial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "from skopt import gp_minimize \n",
    "from scipy.stats import binom as ScipyBinom\n",
    "from matplotlib import pyplot\n",
    "from torch import tensor\n",
    "\n",
    "from collections import namedtuple\n",
    "import time\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvl import genData, likelihoods, bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([2.0000, 2.0000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[4.3519, 2.7890, 5.5548],\n",
      "        [2.8917, 4.4436, 5.2706],\n",
      "        [3.8678, 4.4712, 5.3107],\n",
      "        ...,\n",
      "        [4.7168, 4.2715, 6.7835],\n",
      "        [4.6791, 3.9330, 4.3859],\n",
      "        [2.6210, 1.9142, 4.4797]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.120481967926025\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[39., 10.,  0.,  3.],\n",
      "        [42.,  3.,  2.,  1.],\n",
      "        [50.,  3.,  2.,  0.],\n",
      "        ...,\n",
      "        [45.,  3.,  5.,  0.],\n",
      "        [60.,  0.,  1.,  2.],\n",
      "        [40.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "n tensor([52., 48., 55.,  ..., 53., 63., 42.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([10.,  3.,  3.,  ...,  3.,  0.,  1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 2.,  ..., 5., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 0.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[39., 10.,  0.,  3.],\n",
      "        [42.,  3.,  2.,  1.],\n",
      "        [50.,  3.,  2.,  0.],\n",
      "        ...,\n",
      "        [45.,  3.,  5.,  0.],\n",
      "        [60.,  0.,  1.,  2.],\n",
      "        [40.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([4.9863e-09, 7.6293e-03, 1.8464e-02,  ..., 8.1738e-04, 6.4453e-03,\n",
      "        3.3431e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8ac3320>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91056.366085773, bestParams: [0.021506596, 0.032269087, 0.032386456, 7456.216, 13592.753, 24910.842, 18917.502]\n",
      "epoch 0\n",
      "     fun: 90678.94727806201\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18988\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.49893948e-02, 4.43790738e-02, 4.08915328e-02, 8.60818913e+03,\n",
      "       2.44622045e+04, 2.48735515e+04, 2.14801207e+04])\n",
      "best ll: 91026.39509861523, bestParams: [0.11172657, 0.090561226, 0.053274393, 6340.836, 12428.718, 19741.955, 19129.791]\n",
      "epoch 1\n",
      "     fun: 90680.17847220492\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18535\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.87069860e-02, 4.87180474e-02, 4.18491463e-02, 9.10768397e+03,\n",
      "       2.46671325e+04, 2.48377120e+04, 2.38725486e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90935.85000957745, bestParams: [0.049423933, 0.009214227, 0.066587955, 8144.4087, 14092.45, 19146.107, 19184.744]\n",
      "epoch 2\n",
      "     fun: 90679.69408391253\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24517\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.51746074e-02, 4.28823114e-02, 4.09115182e-02, 8.49052334e+03,\n",
      "       2.41057989e+04, 2.49310807e+04, 2.09977006e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90968.04260795636, bestParams: [0.04376411, 0.00947107, 0.026495688, 2897.8872, 12433.758, 12579.159, 2175.1257]\n",
      "epoch 3\n",
      "     fun: 90682.20345662584\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21464\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.62273012e-02, 4.13341282e-02, 4.08307518e-02, 7.30724926e+03,\n",
      "       2.05368423e+04, 2.18005268e+04, 1.80006693e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 91230.94646826506, bestParams: [0.027580375, 0.03263207, 0.086327404, 9526.828, 13395.509, 20715.258, 16864.232]\n",
      "epoch 4\n",
      "     fun: 90680.42392596879\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21184\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93687837e-02, 4.50462777e-02, 4.14165165e-02, 8.13320033e+03,\n",
      "       2.20223509e+04, 2.30949390e+04, 2.09459093e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90891.22837955202, bestParams: [0.022499898, 0.05500002, 0.05387609, 7606.9336, 16116.186, 22950.53, 17725.414]\n",
      "epoch 5\n",
      "     fun: 91005.564852588\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19023\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.05560857e-01, 2.51295019e-02, 6.86739003e-02, 1.10150214e+04,\n",
      "       1.19546860e+04, 2.49755966e+04, 2.49999999e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90793.50734448066, bestParams: [0.04312596, 0.061409917, 0.055109084, 7393.3057, 17826.643, 19793.965, 14590.254]\n",
      "epoch 6\n",
      "     fun: 90682.98088077307\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29244\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.58835926e-02, 4.48804886e-02, 4.12324058e-02, 7.13580347e+03,\n",
      "       1.99591999e+04, 2.03665212e+04, 1.80069887e+04])\n",
      "minPrevious 90678.94727806201\n",
      "best ll: 90774.11209833511, bestParams: [0.029333118, 0.048051648, 0.034722798, 7021.4785, 19031.883, 23899.84, 18605.693]\n",
      "epoch 7\n",
      "     fun: 90677.6685678917\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18468\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.81858369e-02, 4.78172584e-02, 4.15692111e-02, 8.98392723e+03,\n",
      "       2.45434465e+04, 2.48292644e+04, 2.33467772e+04])\n",
      "minPrevious 90678.94727806201\n",
      "better by at >= 1; new ll:      fun: 90677.6685678917\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18468\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.81858369e-02, 4.78172584e-02, 4.15692111e-02, 8.98392723e+03,\n",
      "       2.45434465e+04, 2.48292644e+04, 2.33467772e+04])\n",
      "best ll: 90875.25550642482, bestParams: [0.052991223, 0.082086444, 0.03636626, 6475.547, 23251.305, 18497.258, 20307.602]\n",
      "epoch 8\n",
      "     fun: 90682.68245423601\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23101\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.50358851e-02, 4.28777768e-02, 4.09910386e-02, 4.24521045e+03,\n",
      "       1.20207836e+04, 1.24023136e+04, 1.05078487e+04])\n",
      "minPrevious 90677.6685678917\n",
      "best ll: 91548.96528524201, bestParams: [0.10768495, 0.22162051, 0.123172745, 3700.1165, 5095.398, 5719.5654, 14934.215]\n",
      "epoch 9\n",
      "     fun: 90684.1404879048\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18986\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.07374035e-02, 5.12185329e-02, 4.29776595e-02, 9.51878104e+03,\n",
      "       2.49567942e+04, 2.49907370e+04, 2.49999993e+04])\n",
      "minPrevious 90677.6685678917\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0482, 0.0478, 0.0416], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8889, 0.0632, 0.0281, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8732, 0.0716, 0.0262, 0.0290], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8816, 0.0280, 0.0648, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8726, 0.0261, 0.0723, 0.0289], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7458, 0.0981, 0.0993, 0.0618], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7052, 0.1128, 0.1135, 0.0685], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4189, 2.2110, 5.3853],\n",
      "        [2.8835, 1.5863, 4.1315],\n",
      "        [3.3437, 2.7164, 3.9165],\n",
      "        ...,\n",
      "        [3.8215, 3.8713, 6.7122],\n",
      "        [2.9858, 2.3850, 5.4729],\n",
      "        [3.9595, 3.6556, 5.0114]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.392677068710327\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[51.,  1.,  1.,  0.],\n",
      "        [49.,  6.,  3.,  0.],\n",
      "        [51.,  3.,  4.,  2.],\n",
      "        ...,\n",
      "        [52.,  1.,  2.,  0.],\n",
      "        [40.,  2.,  1.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 58., 60.,  ..., 55., 43., 45.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 3.,  ..., 1., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 4.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 2.,  ..., 0., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[51.,  1.,  1.,  0.],\n",
      "        [49.,  6.,  3.,  0.],\n",
      "        [51.,  3.,  4.,  2.],\n",
      "        ...,\n",
      "        [52.,  1.,  2.,  0.],\n",
      "        [40.,  2.,  1.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0623, 0.0003, 0.0009,  ..., 0.0464, 0.0503, 0.0438],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc680>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91239.19500249799, bestParams: [0.07369001, 0.04880978, 0.06687576, 4858.3516, 16533.74, 12923.512, 14745.741]\n",
      "epoch 0\n",
      "     fun: 90861.78577540864\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 28688\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.39126641e-02, 4.43361706e-02, 4.16877774e-02, 6.30811938e+03,\n",
      "       1.80875402e+04, 1.85093776e+04, 1.54715766e+04])\n",
      "best ll: 91471.4697084639, bestParams: [0.015408821, 0.025966937, 0.018776404, 6470.502, 16699.875, 22305.629, 7609.0425]\n",
      "epoch 1\n",
      "     fun: 90860.74902260769\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21083\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.31587597e-02, 4.55204559e-02, 4.21324394e-02, 8.65442240e+03,\n",
      "       2.47671562e+04, 2.49529431e+04, 2.13176385e+04])\n",
      "minPrevious 90861.78577540864\n",
      "better by at >= 1; new ll:      fun: 90860.74902260769\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21083\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.31587597e-02, 4.55204559e-02, 4.21324394e-02, 8.65442240e+03,\n",
      "       2.47671562e+04, 2.49529431e+04, 2.13176385e+04])\n",
      "best ll: 91429.35879988143, bestParams: [0.036266495, 0.03656501, 0.00981962, 4553.329, 23323.432, 16778.275, 3984.7922]\n",
      "epoch 2\n",
      "     fun: 90860.63394312932\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18826\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97057539e-02, 4.15170068e-02, 4.13327845e-02, 6.41557828e+03,\n",
      "       1.93464752e+04, 1.95896200e+04, 1.48570035e+04])\n",
      "minPrevious 90860.74902260769\n",
      "best ll: 91222.69810706898, bestParams: [0.03356081, 0.050940458, 0.040049728, 7300.6055, 11934.092, 23776.432, 21303.281]\n",
      "epoch 3\n",
      "     fun: 90859.43670833748\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22341\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56721447e-02, 4.79972960e-02, 4.25334885e-02, 8.95537658e+03,\n",
      "       2.48353903e+04, 2.49872164e+04, 2.28056060e+04])\n",
      "minPrevious 90860.74902260769\n",
      "better by at >= 1; new ll:      fun: 90859.43670833748\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22341\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56721447e-02, 4.79972960e-02, 4.25334885e-02, 8.95537658e+03,\n",
      "       2.48353903e+04, 2.49872164e+04, 2.28056060e+04])\n",
      "best ll: 91364.8767937252, bestParams: [0.22571534, 0.056864273, 0.07466884, 3741.4695, 6438.2812, 5871.1465, 15020.482]\n",
      "epoch 4\n",
      "     fun: 90860.23925054408\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22079\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.20028461e-02, 4.19424135e-02, 4.15822628e-02, 5.57662948e+03,\n",
      "       1.63079514e+04, 1.68432533e+04, 1.32242383e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91071.14442199793, bestParams: [0.09720786, 0.055112377, 0.06380207, 4636.733, 11534.753, 14002.477, 10913.797]\n",
      "epoch 5\n",
      "     fun: 90860.33036181553\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24815\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.16976590e-02, 4.24385731e-02, 4.17443828e-02, 4.79041325e+03,\n",
      "       1.40148252e+04, 1.43427167e+04, 1.13953899e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91144.26979706812, bestParams: [0.08022128, 0.08162482, 0.048925202, 8952.077, 16154.056, 24275.29, 19940.611]\n",
      "epoch 6\n",
      "     fun: 90858.7804887991\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16708\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.20979808e-02, 4.37486171e-02, 4.17546498e-02, 8.45101922e+03,\n",
      "       2.46176087e+04, 2.49695229e+04, 2.03637448e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91115.36426809937, bestParams: [0.05724043, 0.021042777, 0.07642279, 6261.3833, 16376.353, 23784.773, 8266.063]\n",
      "epoch 7\n",
      "     fun: 90859.69647791091\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19043\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.34963888e-02, 4.37891214e-02, 4.20289844e-02, 8.15363124e+03,\n",
      "       2.33686949e+04, 2.39683522e+04, 1.98420756e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91651.64624185565, bestParams: [0.046107255, 0.09424183, 0.00989835, 2757.5513, 14618.052, 10251.086, 9000.875]\n",
      "epoch 8\n",
      "     fun: 90859.06008520466\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20575\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44481442e-02, 4.75969522e-02, 4.21778176e-02, 8.81335975e+03,\n",
      "       2.48539057e+04, 2.48395582e+04, 2.23569747e+04])\n",
      "minPrevious 90859.43670833748\n",
      "best ll: 91065.11635174009, bestParams: [0.0242683, 0.053031314, 0.058199123, 5144.2104, 20661.969, 15971.761, 13266.957]\n",
      "epoch 9\n",
      "     fun: 90861.08577821162\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20001\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.19851050e-02, 4.17801837e-02, 4.15084630e-02, 7.28268698e+03,\n",
      "       2.13122623e+04, 2.20660360e+04, 1.72448063e+04])\n",
      "minPrevious 90859.43670833748\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0457, 0.0480, 0.0425], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8782, 0.0624, 0.0278, 0.0249], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8721, 0.0725, 0.0262, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8817, 0.0280, 0.0644, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8718, 0.0261, 0.0729, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7358, 0.0987, 0.0983, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7057, 0.1127, 0.1130, 0.0687], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.9071, 4.0096, 5.7722],\n",
      "        [3.1442, 3.7642, 4.7613],\n",
      "        [1.9910, 3.6197, 4.2653],\n",
      "        ...,\n",
      "        [2.0181, 4.2217, 4.7949],\n",
      "        [2.6019, 2.7535, 6.2110],\n",
      "        [2.9164, 2.6361, 4.6614]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.5227882862091064\n",
      "Run: 0, 2\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[27.,  4.,  2.,  2.],\n",
      "        [48.,  1.,  1.,  0.],\n",
      "        [41.,  2.,  1.,  3.],\n",
      "        ...,\n",
      "        [48.,  3.,  0.,  1.],\n",
      "        [49.,  2.,  3.,  1.],\n",
      "        [37.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([35., 50., 47.,  ..., 52., 55., 39.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 1., 2.,  ..., 3., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 0., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 3.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[27.,  4.,  2.,  2.],\n",
      "        [48.,  1.,  1.,  0.],\n",
      "        [41.,  2.,  1.,  3.],\n",
      "        ...,\n",
      "        [48.,  3.,  0.,  1.],\n",
      "        [49.,  2.,  3.,  1.],\n",
      "        [37.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([9.1044e-05, 6.8182e-02, 1.1450e-03,  ..., 9.4407e-03, 1.1078e-02,\n",
      "        8.8612e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc290>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91007.93332294546, bestParams: [0.0857708, 0.027353209, 0.056023873, 8389.133, 21786.912, 16894.488, 17575.045]\n",
      "epoch 0\n",
      "     fun: 90741.29185131165\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16482\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.23376169e-02, 4.93065527e-02, 4.38559895e-02, 9.47084934e+03,\n",
      "       2.48940172e+04, 2.48822170e+04, 2.49999981e+04])\n",
      "best ll: 91224.73436774276, bestParams: [0.043282628, 0.04283247, 0.015615053, 3965.399, 15119.752, 11289.01, 20118.45]\n",
      "epoch 1\n",
      "     fun: 90968.17657566987\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 39572\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.99538244e-02, 2.93838522e-01, 5.58080675e-02, 5.08857742e+03,\n",
      "       9.48498524e+03, 6.15838872e+03, 1.74503829e+04])\n",
      "minPrevious 90741.29185131165\n",
      "best ll: 90881.52796996137, bestParams: [0.057814863, 0.036603197, 0.048284452, 6125.3677, 14977.148, 11782.217, 16754.512]\n",
      "epoch 2\n",
      "     fun: 90729.455342717\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19418\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.65090442e-02, 4.45915397e-02, 4.23747175e-02, 8.80405812e+03,\n",
      "       2.49621024e+04, 2.48324605e+04, 2.18698763e+04])\n",
      "minPrevious 90741.29185131165\n",
      "better by at >= 1; new ll:      fun: 90729.455342717\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19418\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.65090442e-02, 4.45915397e-02, 4.23747175e-02, 8.80405812e+03,\n",
      "       2.49621024e+04, 2.48324605e+04, 2.18698763e+04])\n",
      "best ll: 91326.07627551297, bestParams: [0.095849864, 0.09590016, 0.092939384, 7666.34, 6450.7437, 15030.143, 23817.498]\n",
      "epoch 3\n",
      "     fun: 90729.30744291696\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22517\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.37379352e-02, 4.05152351e-02, 4.17252985e-02, 8.39802978e+03,\n",
      "       2.47668799e+04, 2.49916565e+04, 1.98267634e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91016.03464464155, bestParams: [0.06892339, 0.08220619, 0.041249212, 10588.921, 24391.959, 19792.424, 22084.648]\n",
      "epoch 4\n",
      "     fun: 90959.0438262211\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19051\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.16422571e-02, 8.50540140e-01, 5.78171661e-02, 5.56689535e+03,\n",
      "       9.72820890e+03, 5.85802465e+03, 1.96208622e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91027.85668282304, bestParams: [0.03505238, 0.044490505, 0.027420068, 6133.5425, 23373.82, 13148.674, 14960.702]\n",
      "epoch 5\n",
      "     fun: 90735.7505212659\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18858\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.04506841e-02, 4.75836595e-02, 4.31450513e-02, 9.25332768e+03,\n",
      "       2.49542178e+04, 2.49510328e+04, 2.40224887e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91344.33768614761, bestParams: [0.053518336, 0.08740302, 0.067629404, 6031.661, 18487.89, 9499.573, 9493.0]\n",
      "epoch 6\n",
      "     fun: 90742.86427037211\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 15856\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.25172955e-02, 4.97425219e-02, 4.43748053e-02, 9.57142437e+03,\n",
      "       2.49836514e+04, 2.48985330e+04, 2.49999996e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91210.99558153439, bestParams: [0.015522353, 0.020422507, 0.02180805, 5947.9175, 24499.941, 23246.885, 23200.797]\n",
      "epoch 7\n",
      "     fun: 90731.14997350496\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23205\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.28252218e-02, 3.99237022e-02, 4.15478607e-02, 6.40159151e+03,\n",
      "       1.90431847e+04, 1.92309877e+04, 1.49437001e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91095.22483766638, bestParams: [0.07067214, 0.03771307, 0.054919243, 6992.266, 20875.805, 19603.213, 6386.5703]\n",
      "epoch 8\n",
      "     fun: 90730.85085085777\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20929\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.53289295e-02, 4.27071902e-02, 4.20085505e-02, 8.40268795e+03,\n",
      "       2.42169186e+04, 2.42700284e+04, 2.04402196e+04])\n",
      "minPrevious 90729.455342717\n",
      "best ll: 91393.03288045904, bestParams: [0.017872097, 0.053617258, 0.039089, 1954.1438, 5562.4053, 1457.8615, 7767.6426]\n",
      "epoch 9\n",
      "     fun: 90733.01401258064\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 31233\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.60272951e-02, 4.06109139e-02, 4.20647643e-02, 6.14139763e+03,\n",
      "       1.75751538e+04, 1.81183570e+04, 1.47902926e+04])\n",
      "minPrevious 90729.455342717\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0465, 0.0446, 0.0424], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8839, 0.0639, 0.0280, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8704, 0.0741, 0.0261, 0.0295], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8829, 0.0280, 0.0636, 0.0254], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8708, 0.0261, 0.0737, 0.0295], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7400, 0.0995, 0.0966, 0.0611], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7060, 0.1126, 0.1124, 0.0690], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.8960, 3.3836, 5.0518],\n",
      "        [3.8514, 4.7767, 6.8971],\n",
      "        [4.0691, 2.5010, 4.6004],\n",
      "        ...,\n",
      "        [4.4449, 3.2959, 3.9365],\n",
      "        [4.3674, 3.9315, 8.1608],\n",
      "        [3.6398, 2.5625, 7.4278]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.356298923492432\n",
      "Run: 0, 3\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[48.,  2.,  1.,  0.],\n",
      "        [41.,  3.,  2.,  2.],\n",
      "        [55.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [58.,  2.,  2.,  1.],\n",
      "        [48.,  2.,  0.,  0.],\n",
      "        [35.,  2.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([51., 48., 59.,  ..., 63., 50., 39.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 3.,  ..., 2., 2., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 0.,  ..., 2., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 1.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[48.,  2.,  1.,  0.],\n",
      "        [41.,  3.,  2.,  2.],\n",
      "        [55.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [58.,  2.,  2.,  1.],\n",
      "        [48.,  2.,  0.,  0.],\n",
      "        [35.,  2.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0487, 0.0019, 0.0098,  ..., 0.0257, 0.0341, 0.0266],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad03b00>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91021.23597877396, bestParams: [0.02387655, 0.09362935, 0.0531731, 8440.324, 13937.0, 11477.793, 16246.775]\n",
      "epoch 0\n",
      "     fun: 90367.46646443212\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18738\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.85798503e-02, 3.12189972e-02, 4.14406663e-02, 7.79360605e+03,\n",
      "       2.38725780e+04, 2.46992225e+04, 1.68480061e+04])\n",
      "best ll: 90814.01155907288, bestParams: [0.092853814, 0.079595976, 0.09696471, 9648.206, 12964.165, 13710.112, 22609.943]\n",
      "epoch 1\n",
      "     fun: 90370.16992066184\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20256\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.06782851e-02, 3.05888247e-02, 4.18256058e-02, 3.30614673e+03,\n",
      "       9.80870940e+03, 1.04315332e+04, 7.28013746e+03])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90693.35079318719, bestParams: [0.05039767, 0.07389942, 0.05925788, 5015.5117, 11736.682, 7729.9805, 10372.028]\n",
      "epoch 2\n",
      "     fun: 90544.51615211637\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26660\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([1.15173636e-01, 8.27076011e-01, 5.75481400e-02, 4.88184316e+03,\n",
      "       7.22753220e+03, 5.23483166e+03, 1.76610229e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90928.8394107176, bestParams: [0.08049662, 0.08387433, 0.06717268, 7118.226, 9401.673, 19610.592, 16397.375]\n",
      "epoch 3\n",
      "     fun: 90369.26401926341\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27176\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.55837197e-02, 3.36905447e-02, 4.29108512e-02, 6.71586563e+03,\n",
      "       1.85568972e+04, 1.98110040e+04, 1.60601036e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 90849.15617868747, bestParams: [0.041133363, 0.06851273, 0.07244423, 6477.3115, 20420.096, 20529.924, 4543.0527]\n",
      "epoch 4\n",
      "     fun: 90369.74538215327\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 25662\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.46136940e-02, 3.52382008e-02, 4.29644138e-02, 7.05933251e+03,\n",
      "       1.96641948e+04, 2.05584337e+04, 1.69372313e+04])\n",
      "minPrevious 90367.46646443212\n",
      "best ll: 91003.55947153617, bestParams: [0.020014536, 0.16380043, 0.05750044, 6207.0884, 6395.382, 14223.492, 21751.719]\n",
      "epoch 5\n",
      "     fun: 90366.05074559979\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19246\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44379285e-02, 3.86546502e-02, 4.30928573e-02, 8.90523070e+03,\n",
      "       2.47945943e+04, 2.48658296e+04, 2.19264077e+04])\n",
      "minPrevious 90367.46646443212\n",
      "better by at >= 1; new ll:      fun: 90366.05074559979\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19246\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.44379285e-02, 3.86546502e-02, 4.30928573e-02, 8.90523070e+03,\n",
      "       2.47945943e+04, 2.48658296e+04, 2.19264077e+04])\n",
      "best ll: 90749.3357777144, bestParams: [0.054987807, 0.042462654, 0.019732246, 3481.5046, 8180.3594, 12040.532, 16030.645]\n",
      "epoch 6\n",
      "     fun: 90370.04277355093\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19775\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13956855e-02, 2.99751012e-02, 4.19297763e-02, 3.18547370e+03,\n",
      "       9.37089224e+03, 1.01267621e+04, 6.99713684e+03])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90595.93835730849, bestParams: [0.049502358, 0.05059789, 0.035600856, 5736.8604, 11006.914, 12817.075, 13380.541]\n",
      "epoch 7\n",
      "     fun: 90369.03492576667\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29654\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.43124944e-02, 3.33712831e-02, 4.27940979e-02, 6.64796216e+03,\n",
      "       1.85760876e+04, 1.98131480e+04, 1.58021285e+04])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90746.22974235666, bestParams: [0.111383274, 0.080073506, 0.042195205, 10159.44, 15388.807, 19346.172, 23211.58]\n",
      "epoch 8\n",
      "     fun: 90366.30277732995\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19017\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.62580895e-02, 3.77157167e-02, 4.32366444e-02, 8.81877383e+03,\n",
      "       2.40797226e+04, 2.47941350e+04, 2.18330276e+04])\n",
      "minPrevious 90366.05074559979\n",
      "best ll: 90855.43160734844, bestParams: [0.07542367, 0.05570492, 0.015105497, 9331.249, 23335.158, 21321.234, 19561.578]\n",
      "epoch 9\n",
      "     fun: 90554.8816047398\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19215\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.37802480e-01, 6.55243135e-02, 5.54580874e-02, 5.84354058e+03,\n",
      "       6.36484808e+03, 1.06079831e+04, 2.04911301e+04])\n",
      "minPrevious 90366.05074559979\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0444, 0.0387, 0.0431], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8801, 0.0644, 0.0279, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8718, 0.0728, 0.0261, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8782, 0.0278, 0.0636, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8716, 0.0262, 0.0730, 0.0292], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7428, 0.0992, 0.0988, 0.0623], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7085, 0.1115, 0.1117, 0.0683], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7070, 3.3558, 5.7385],\n",
      "        [6.1712, 4.8968, 6.0728],\n",
      "        [5.5908, 6.0105, 9.0300],\n",
      "        ...,\n",
      "        [3.5412, 2.9084, 6.2405],\n",
      "        [4.0371, 3.8411, 6.2719],\n",
      "        [4.3172, 3.5554, 6.5065]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.310091972351074\n",
      "Run: 0, 4\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[46.,  3.,  2.,  2.],\n",
      "        [45.,  3.,  0.,  3.],\n",
      "        [54.,  5.,  1.,  4.],\n",
      "        ...,\n",
      "        [48.,  1.,  0.,  0.],\n",
      "        [40.,  2.,  1.,  1.],\n",
      "        [40.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 51., 64.,  ..., 49., 44., 42.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 5.,  ..., 1., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 1.,  ..., 0., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 4.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[46.,  3.,  2.,  2.],\n",
      "        [45.,  3.,  0.,  3.],\n",
      "        [54.,  5.,  1.,  4.],\n",
      "        ...,\n",
      "        [48.,  1.,  0.,  0.],\n",
      "        [40.,  2.,  1.,  1.],\n",
      "        [40.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.8431e-03, 4.8473e-04, 3.3705e-05,  ..., 4.8727e-02, 2.4768e-02,\n",
      "        8.3579e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdc950>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91345.08023811383, bestParams: [0.06884586, 0.015770206, 0.08335171, 3087.4746, 10631.862, 13740.989, 2484.048]\n",
      "epoch 0\n",
      "     fun: 90879.9946159658\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23081\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.24280571e-02, 4.00968936e-02, 3.89581658e-02, 6.72886260e+03,\n",
      "       2.08850194e+04, 2.07802951e+04, 1.66012855e+04])\n",
      "best ll: 90987.4655751705, bestParams: [0.028817432, 0.02610038, 0.034790974, 7775.3364, 23897.207, 21864.736, 15247.122]\n",
      "epoch 1\n",
      "     fun: 90879.06292379234\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19756\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.14930094e-02, 3.82729929e-02, 3.86535609e-02, 7.50684449e+03,\n",
      "       2.37203578e+04, 2.38252110e+04, 1.80371150e+04])\n",
      "minPrevious 90879.9946159658\n",
      "best ll: 91464.60088640705, bestParams: [0.07165316, 0.0929115, 0.01606413, 4874.1367, 14892.382, 17925.348, 7632.4253]\n",
      "epoch 2\n",
      "     fun: 90879.14375478897\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27109\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.03898485e-02, 3.80772820e-02, 3.84634180e-02, 6.62194224e+03,\n",
      "       2.12415051e+04, 2.11538949e+04, 1.57061265e+04])\n",
      "minPrevious 90879.9946159658\n",
      "best ll: 91336.19074409138, bestParams: [0.029090187, 0.039958116, 0.025319178, 4308.908, 9381.063, 14304.205, 7759.76]\n",
      "epoch 3\n",
      "     fun: 90878.55891398477\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20515\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.09047276e-02, 3.79882333e-02, 3.86226516e-02, 5.33505945e+03,\n",
      "       1.69919902e+04, 1.70332626e+04, 1.26987930e+04])\n",
      "minPrevious 90879.9946159658\n",
      "better by at >= 1; new ll:      fun: 90878.55891398477\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20515\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.09047276e-02, 3.79882333e-02, 3.86226516e-02, 5.33505945e+03,\n",
      "       1.69919902e+04, 1.70332626e+04, 1.26987930e+04])\n",
      "best ll: 91335.93185690074, bestParams: [0.035876945, 0.06610922, 0.025485078, 4390.421, 22124.35, 10895.839, 7541.019]\n",
      "epoch 4\n",
      "     fun: 90880.92135410193\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 17484\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.59090218e-02, 4.33322652e-02, 3.96535940e-02, 8.43861685e+03,\n",
      "       2.49337275e+04, 2.48150587e+04, 2.19508901e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91250.95231934264, bestParams: [0.115218244, 0.048142098, 0.051294174, 6320.828, 14317.023, 12362.9, 13260.78]\n",
      "epoch 5\n",
      "     fun: 90878.97808052332\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19609\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.07574831e-02, 3.74625089e-02, 3.83613486e-02, 6.68112794e+03,\n",
      "       2.13446230e+04, 2.15390941e+04, 1.58039078e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91213.35925044058, bestParams: [0.15606245, 0.072391056, 0.046264574, 6354.5464, 13673.771, 19265.758, 22482.443]\n",
      "epoch 6\n",
      "     fun: 90883.28559989628\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19491\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93288901e-02, 4.60300073e-02, 4.03575042e-02, 8.80576916e+03,\n",
      "       2.49172318e+04, 2.48990628e+04, 2.38112812e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91046.46063479605, bestParams: [0.03268646, 0.011289387, 0.026305977, 6561.8726, 20767.113, 23554.947, 11815.014]\n",
      "epoch 7\n",
      "     fun: 90881.05394528931\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18450\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26334934e-02, 3.93476535e-02, 3.90612840e-02, 2.50669000e+03,\n",
      "       7.75529940e+03, 7.77798697e+03, 6.15010134e+03])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91213.77202473817, bestParams: [0.12363709, 0.07303361, 0.03884344, 5911.851, 10551.361, 9712.845, 17378.764]\n",
      "epoch 8\n",
      "     fun: 90879.20283692765\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19674\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.23063429e-02, 3.91398095e-02, 3.88485271e-02, 6.98045708e+03,\n",
      "       2.17313652e+04, 2.18296056e+04, 1.70652713e+04])\n",
      "minPrevious 90878.55891398477\n",
      "best ll: 91373.61481849875, bestParams: [0.119453534, 0.015104396, 0.048940077, 3980.3694, 9912.681, 20019.787, 4480.772]\n",
      "epoch 9\n",
      "     fun: 90964.70890373456\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16833\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.88640777e-02, 5.48396144e-02, 4.41396663e-02, 7.52303449e+03,\n",
      "       1.61309726e+04, 1.82623724e+04, 2.37081847e+04])\n",
      "minPrevious 90878.55891398477\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0409, 0.0380, 0.0386], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8845, 0.0643, 0.0281, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8593, 0.0821, 0.0257, 0.0329], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8793, 0.0279, 0.0645, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8591, 0.0257, 0.0823, 0.0329], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7472, 0.0997, 0.1000, 0.0626], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6948, 0.1160, 0.1162, 0.0730], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.2669, 1.9767, 5.1363],\n",
      "        [3.5628, 2.9073, 6.2435],\n",
      "        [3.7832, 3.7930, 6.8343],\n",
      "        ...,\n",
      "        [1.9421, 1.4840, 5.1770],\n",
      "        [4.2826, 3.2783, 5.4505],\n",
      "        [3.5943, 2.8795, 6.1372]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.476979970932007\n",
      "Run: 0, 5\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[42.,  5.,  3.,  3.],\n",
      "        [39.,  4.,  0.,  3.],\n",
      "        [43.,  1.,  3.,  0.],\n",
      "        ...,\n",
      "        [54.,  2.,  1.,  1.],\n",
      "        [47.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "n tensor([53., 46., 47.,  ..., 58., 49., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 4., 1.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 3.,  ..., 1., 1., 3.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 0.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[42.,  5.,  3.,  3.],\n",
      "        [39.,  4.,  0.,  3.],\n",
      "        [43.,  1.,  3.,  0.],\n",
      "        ...,\n",
      "        [54.,  2.,  1.,  1.],\n",
      "        [47.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.0043e-05, 1.0708e-04, 2.2014e-02,  ..., 2.9246e-02, 7.0167e-02,\n",
      "        1.6781e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdcdd0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90857.78330615468, bestParams: [0.065798305, 0.01862657, 0.08375965, 6535.119, 18724.98, 18402.521, 23863.832]\n",
      "epoch 0\n",
      "     fun: 90574.54329233595\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16861\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([8.85348671e-01, 5.79907422e-02, 5.65029340e-02, 4.43107258e+03,\n",
      "       4.70193766e+03, 8.01621143e+03, 1.52672211e+04])\n",
      "best ll: 90647.02931454076, bestParams: [0.006345086, 0.025668247, 0.041042943, 3689.1306, 14496.478, 9464.404, 3974.9004]\n",
      "epoch 1\n",
      "     fun: 90346.79818100025\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22437\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.38988240e-02, 3.73832477e-02, 4.08481269e-02, 5.29178931e+03,\n",
      "       1.53774819e+04, 1.54631092e+04, 1.26597146e+04])\n",
      "minPrevious 90574.54329233595\n",
      "better by at >= 1; new ll:      fun: 90346.79818100025\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 22437\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.38988240e-02, 3.73832477e-02, 4.08481269e-02, 5.29178931e+03,\n",
      "       1.53774819e+04, 1.54631092e+04, 1.26597146e+04])\n",
      "best ll: 90701.66978014109, bestParams: [0.051171403, 0.004164878, 0.037289176, 9557.071, 24102.58, 17367.414, 20774.168]\n",
      "epoch 2\n",
      "     fun: 90346.5671615596\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19326\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.93206864e-02, 4.19921320e-02, 4.19359552e-02, 9.13554443e+03,\n",
      "       2.47502305e+04, 2.48801472e+04, 2.34591945e+04])\n",
      "minPrevious 90346.79818100025\n",
      "best ll: 91283.78536810011, bestParams: [0.10908244, 0.048394613, 0.10494098, 7852.6562, 4134.3623, 18254.262, 22675.844]\n",
      "epoch 3\n",
      "     fun: 90350.25783864367\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.12992497e-02, 4.44887911e-02, 4.23193013e-02, 9.43948030e+03,\n",
      "       2.49271977e+04, 2.48737002e+04, 2.48733863e+04])\n",
      "minPrevious 90346.79818100025\n",
      "best ll: 90471.10462045555, bestParams: [0.0154586835, 0.069063015, 0.03530776, 5670.462, 21156.191, 15531.642, 14583.196]\n",
      "epoch 4\n",
      "     fun: 90343.67707197007\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21977\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.74123918e-02, 4.08289397e-02, 4.13656120e-02, 8.98044189e+03,\n",
      "       2.49493444e+04, 2.49868195e+04, 2.25900515e+04])\n",
      "minPrevious 90346.79818100025\n",
      "better by at >= 1; new ll:      fun: 90343.67707197007\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21977\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.74123918e-02, 4.08289397e-02, 4.13656120e-02, 8.98044189e+03,\n",
      "       2.49493444e+04, 2.49868195e+04, 2.25900515e+04])\n",
      "best ll: 90477.84335776992, bestParams: [0.04298072, 0.021439154, 0.036853362, 3680.7407, 9893.799, 10063.484, 6246.7983]\n",
      "epoch 5\n",
      "     fun: 90343.78822780929\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19929\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.27018839e-02, 3.55948896e-02, 4.04254643e-02, 8.00020766e+03,\n",
      "       2.37514479e+04, 2.40988899e+04, 1.86050897e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90690.74806032187, bestParams: [0.05707956, 0.04165197, 0.05212749, 5306.5737, 9165.7705, 7847.644, 21851.729]\n",
      "epoch 6\n",
      "     fun: 90347.22406009762\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 27937\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.34300152e-02, 3.88849780e-02, 4.11301663e-02, 5.86526976e+03,\n",
      "       1.70700458e+04, 1.67733265e+04, 1.41632998e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90533.48503693526, bestParams: [0.05087774, 0.042099502, 0.04017582, 8607.724, 23974.309, 19314.508, 15243.791]\n",
      "epoch 7\n",
      "     fun: 90344.29825837338\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18976\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.23100412e-02, 3.51282897e-02, 4.02434122e-02, 8.19614332e+03,\n",
      "       2.44955698e+04, 2.49282104e+04, 1.89051281e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 91039.73336329563, bestParams: [0.010360104, 0.0056551113, 0.017288163, 4754.299, 16049.336, 10335.417, 10871.316]\n",
      "epoch 8\n",
      "     fun: 90605.03752168667\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 15852\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.06037770e-01, 3.14303850e-02, 6.25201762e-02, 9.78926227e+03,\n",
      "       1.04937148e+04, 2.09762757e+04, 2.49999997e+04])\n",
      "minPrevious 90343.67707197007\n",
      "best ll: 90869.42943766556, bestParams: [0.058097538, 0.054223366, 0.0151370205, 7250.6963, 17291.744, 14349.171, 17670.531]\n",
      "epoch 9\n",
      "     fun: 90346.44614650698\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21311\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.12671383e-02, 3.59230494e-02, 4.02898373e-02, 5.12029022e+03,\n",
      "       1.54464584e+04, 1.53887553e+04, 1.18023848e+04])\n",
      "minPrevious 90343.67707197007\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0474, 0.0408, 0.0414], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8833, 0.0641, 0.0280, 0.0256], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8721, 0.0726, 0.0261, 0.0291], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8836, 0.0280, 0.0633, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8720, 0.0262, 0.0728, 0.0291], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7439, 0.0981, 0.0983, 0.0618], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7069, 0.1122, 0.1124, 0.0685], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.5321, 2.1588, 5.2563],\n",
      "        [3.0922, 2.8446, 5.8659],\n",
      "        [2.4312, 3.2523, 5.2012],\n",
      "        ...,\n",
      "        [5.0824, 4.3565, 4.4788],\n",
      "        [1.8716, 3.1835, 5.8296],\n",
      "        [4.0581, 4.7861, 4.6592]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.654811859130859\n",
      "Run: 0, 6\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[38.,  1.,  2.,  0.],\n",
      "        [53.,  2.,  1.,  1.],\n",
      "        [45.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [52.,  1.,  1.,  0.],\n",
      "        [49.,  1.,  2.,  1.],\n",
      "        [55.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([41., 57., 49.,  ..., 54., 53., 58.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 3.,  ..., 1., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 0.,  ..., 1., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 0., 1., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[38.,  1.,  2.,  0.],\n",
      "        [53.,  2.,  1.,  1.],\n",
      "        [45.,  3.,  0.,  1.],\n",
      "        ...,\n",
      "        [52.,  1.,  1.,  0.],\n",
      "        [49.,  1.,  2.,  1.],\n",
      "        [55.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0499, 0.0292, 0.0091,  ..., 0.0603, 0.0286, 0.0355],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bdcef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91089.27396093101, bestParams: [0.0075157364, 0.016659165, 0.0528355, 6167.8413, 16675.133, 23120.914, 2626.2808]\n",
      "epoch 0\n",
      "     fun: 90528.09146807808\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21301\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.22089041e-02, 4.04911316e-02, 4.09398703e-02, 7.87634233e+03,\n",
      "       2.31800900e+04, 2.34644446e+04, 1.90780530e+04])\n",
      "best ll: 90732.33126287756, bestParams: [0.025354784, 0.034044795, 0.03233444, 3831.9717, 18235.803, 15221.045, 8825.367]\n",
      "epoch 1\n",
      "     fun: 90527.19937601546\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19413\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.15413749e-02, 3.99949216e-02, 4.07060772e-02, 7.98855681e+03,\n",
      "       2.37755273e+04, 2.40322552e+04, 1.91271434e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 91108.88783821915, bestParams: [0.086679004, 0.067132905, 0.09949029, 7799.4536, 21237.266, 20044.95, 20242.219]\n",
      "epoch 2\n",
      "     fun: 90528.26860756558\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19659\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26203286e-02, 3.91555797e-02, 4.07703934e-02, 7.61654461e+03,\n",
      "       2.23785640e+04, 2.30843006e+04, 1.83011955e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 90664.09878557731, bestParams: [0.07736944, 0.06300846, 0.045417767, 1886.3728, 4232.271, 3625.2512, 6741.4614]\n",
      "epoch 3\n",
      "     fun: 90748.34990709391\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 16844\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([7.70603984e-02, 8.70443592e-01, 5.24885454e-02, 5.72624408e+03,\n",
      "       1.07173118e+04, 6.06026139e+03, 2.05226559e+04])\n",
      "minPrevious 90528.09146807808\n",
      "best ll: 91160.88386263404, bestParams: [0.033290174, 0.055628516, 0.014551205, 3497.17, 22058.719, 12795.54, 5477.151]\n",
      "epoch 4\n",
      "     fun: 90526.43683545549\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18563\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.91724795e-02, 3.97801077e-02, 4.02951177e-02, 8.10570623e+03,\n",
      "       2.49413083e+04, 2.46312383e+04, 1.89534248e+04])\n",
      "minPrevious 90528.09146807808\n",
      "better by at >= 1; new ll:      fun: 90526.43683545549\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18563\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.91724795e-02, 3.97801077e-02, 4.02951177e-02, 8.10570623e+03,\n",
      "       2.49413083e+04, 2.46312383e+04, 1.89534248e+04])\n",
      "best ll: 91032.47008508065, bestParams: [0.12150022, 0.06901591, 0.044288684, 6986.347, 7713.5996, 20299.445, 23289.34]\n",
      "epoch 5\n",
      "     fun: 90527.10680973373\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19381\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.03379565e-02, 3.91045966e-02, 4.04755411e-02, 7.92413194e+03,\n",
      "       2.40087260e+04, 2.41783579e+04, 1.86340368e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 91151.68239117, bestParams: [0.02094275, 0.085978635, 0.05017864, 8948.37, 7969.455, 22098.55, 24430.57]\n",
      "epoch 6\n",
      "     fun: 90532.97349945629\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21698\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.71214153e-02, 4.57389432e-02, 4.20915576e-02, 9.02832071e+03,\n",
      "       2.47487861e+04, 2.49622212e+04, 2.35201731e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90674.02727068722, bestParams: [0.03838533, 0.010670561, 0.028407924, 4872.6216, 17658.736, 17240.87, 10353.156]\n",
      "epoch 7\n",
      "     fun: 90530.28907951455\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20557\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13376010e-02, 4.08275025e-02, 4.08953581e-02, 6.64909977e+03,\n",
      "       1.97295238e+04, 1.97269175e+04, 1.60526526e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90743.39248618434, bestParams: [0.04231918, 0.031651355, 0.027624661, 2601.6572, 11065.2, 12116.015, 5007.5166]\n",
      "epoch 8\n",
      "     fun: 90527.06941824801\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20300\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.10153887e-02, 4.13760606e-02, 4.07297194e-02, 8.06086496e+03,\n",
      "       2.41232330e+04, 2.38660672e+04, 1.94393666e+04])\n",
      "minPrevious 90526.43683545549\n",
      "best ll: 90981.63954946902, bestParams: [0.05607572, 0.03384001, 0.036304813, 11815.16, 23425.008, 23078.727, 23863.035]\n",
      "epoch 9\n",
      "     fun: 90528.45840234167\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20521\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.11606709e-02, 4.21507169e-02, 4.10246844e-02, 8.36091333e+03,\n",
      "       2.48268749e+04, 2.44381077e+04, 2.03805812e+04])\n",
      "minPrevious 90526.43683545549\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0392, 0.0398, 0.0403], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8763, 0.0643, 0.0278, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8630, 0.0796, 0.0259, 0.0315], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8857, 0.0281, 0.0657, 0.0263], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8639, 0.0259, 0.0787, 0.0315], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7398, 0.0976, 0.0982, 0.0613], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7016, 0.1140, 0.1132, 0.0712], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9121, 3.6197, 4.2672],\n",
      "        [2.9923, 3.6857, 6.1465],\n",
      "        [3.8417, 2.6237, 5.0056],\n",
      "        ...,\n",
      "        [3.7917, 3.6148, 4.5259],\n",
      "        [3.2769, 4.1533, 5.7003],\n",
      "        [4.0090, 3.2273, 4.1458]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.512847900390625\n",
      "Run: 0, 7\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[50.,  5.,  1.,  4.],\n",
      "        [45.,  2.,  2.,  1.],\n",
      "        [38.,  4.,  1.,  5.],\n",
      "        ...,\n",
      "        [56.,  2.,  2.,  0.],\n",
      "        [42.,  3.,  0.,  0.],\n",
      "        [51.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "n tensor([60., 50., 48.,  ..., 60., 45., 55.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 2., 4.,  ..., 2., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 1.,  ..., 2., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 1., 5.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[50.,  5.,  1.,  4.],\n",
      "        [45.,  2.,  2.,  1.],\n",
      "        [38.,  4.,  1.,  5.],\n",
      "        ...,\n",
      "        [56.,  2.,  2.,  0.],\n",
      "        [42.,  3.,  0.,  0.],\n",
      "        [51.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([2.2155e-05, 1.9104e-02, 1.7708e-06,  ..., 3.6563e-02, 1.6772e-02,\n",
      "        2.8963e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bccef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91243.91071417881, bestParams: [0.040498573, 0.039992083, 0.033642173, 6753.6836, 15692.065, 21096.775, 11753.506]\n",
      "epoch 0\n",
      "     fun: 91035.2144862661\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21164\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.56112050e-02, 5.15920592e-02, 4.19819102e-02, 8.88284249e+03,\n",
      "       2.49907590e+04, 2.48726630e+04, 2.23069026e+04])\n",
      "best ll: 91357.54566372334, bestParams: [0.040997185, 0.04618633, 0.0838608, 10846.453, 19839.768, 20632.074, 23618.115]\n",
      "epoch 1\n",
      "     fun: 91032.30772549672\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26802\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.40870682e-02, 4.61593746e-02, 4.11538469e-02, 8.28519028e+03,\n",
      "       2.40384533e+04, 2.47662828e+04, 1.98040363e+04])\n",
      "minPrevious 91035.2144862661\n",
      "better by at >= 1; new ll:      fun: 91032.30772549672\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 26802\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.40870682e-02, 4.61593746e-02, 4.11538469e-02, 8.28519028e+03,\n",
      "       2.40384533e+04, 2.47662828e+04, 1.98040363e+04])\n",
      "best ll: 91302.02347668094, bestParams: [0.072848134, 0.03889845, 0.056128502, 6435.528, 21272.988, 18763.773, 8352.756]\n",
      "epoch 2\n",
      "     fun: 91031.9209379922\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 24570\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.36019089e-02, 4.66654380e-02, 4.10921218e-02, 7.96267313e+03,\n",
      "       2.31950003e+04, 2.36841385e+04, 1.90482360e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91338.92905650586, bestParams: [0.07102878, 0.008142718, 0.04293678, 6779.5894, 16760.775, 23199.021, 24335.203]\n",
      "epoch 3\n",
      "     fun: 91033.0256424332\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19511\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.05025247e-02, 4.48221899e-02, 4.04081393e-02, 5.73947926e+03,\n",
      "       1.73768584e+04, 1.75574538e+04, 1.31654564e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91237.5362622957, bestParams: [0.04897804, 0.02517828, 0.053476565, 6121.2505, 24571.582, 21428.121, 6433.1235]\n",
      "epoch 4\n",
      "     fun: 91033.0525860195\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20408\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.13719928e-02, 4.36648545e-02, 4.02826805e-02, 6.16702916e+03,\n",
      "       1.86390630e+04, 1.91395485e+04, 1.41040120e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91642.97852024857, bestParams: [0.002547079, 0.031438496, 0.04191702, 10740.871, 20333.883, 15887.142, 24783.443]\n",
      "epoch 5\n",
      "     fun: 91034.54627224465\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 23137\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.26251794e-02, 4.60197835e-02, 4.10425927e-02, 6.91119423e+03,\n",
      "       2.02861702e+04, 2.07257963e+04, 1.63576711e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91317.27160636887, bestParams: [0.08740924, 0.015501036, 0.038114674, 9618.194, 22194.303, 20528.768, 23597.967]\n",
      "epoch 6\n",
      "     fun: 91034.88282504663\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 20439\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.59857350e-02, 5.16670146e-02, 4.19960060e-02, 8.87733643e+03,\n",
      "       2.48689759e+04, 2.48395651e+04, 2.23461119e+04])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91663.3816547386, bestParams: [0.11510229, 0.022979988, 0.07719361, 4350.521, 11100.692, 16230.497, 16443.652]\n",
      "epoch 7\n",
      "     fun: 91033.37773956737\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19850\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.01523012e-02, 4.31942038e-02, 4.02496093e-02, 4.25476136e+03,\n",
      "       1.30677735e+04, 1.33156742e+04, 9.56380154e+03])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91600.56161983634, bestParams: [0.021486541, 0.04493397, 0.05444471, 8626.893, 24781.225, 17456.62, 8928.072]\n",
      "epoch 8\n",
      "     fun: 91033.31471153395\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 31986\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.08887799e-02, 4.39664510e-02, 4.02960859e-02, 4.10381194e+03,\n",
      "       1.24499251e+04, 1.26908510e+04, 9.37283927e+03])\n",
      "minPrevious 91032.30772549672\n",
      "best ll: 91558.65006552348, bestParams: [0.13935027, 0.023656605, 0.10880936, 7721.089, 14432.105, 18207.133, 15296.897]\n",
      "epoch 9\n",
      "     fun: 91034.43093651239\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19058\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.61504895e-02, 5.08239462e-02, 4.18637993e-02, 8.83570464e+03,\n",
      "       2.47664960e+04, 2.49518926e+04, 2.21539923e+04])\n",
      "minPrevious 91032.30772549672\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0441, 0.0462, 0.0412], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8834, 0.0644, 0.0280, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8673, 0.0756, 0.0260, 0.0311], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8760, 0.0278, 0.0650, 0.0260], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8654, 0.0259, 0.0776, 0.0311], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7375, 0.0976, 0.0992, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7045, 0.1118, 0.1137, 0.0700], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[5.3702, 4.2106, 6.4728],\n",
      "        [2.3497, 1.9903, 3.4842],\n",
      "        [3.2499, 2.2078, 5.5362],\n",
      "        ...,\n",
      "        [2.0072, 3.2786, 5.4871],\n",
      "        [4.0390, 2.2470, 6.6010],\n",
      "        [3.4164, 3.2387, 5.0540]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.588237047195435\n",
      "Run: 0, 8\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  2.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [58.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [51.,  1.,  0.,  0.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([47., 54., 61.,  ..., 52., 54., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 5., 0.,  ..., 1., 5., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 2.,  ..., 0., 2., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  2.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [58.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [51.,  1.,  0.,  0.],\n",
      "        [46.,  5.,  2.,  1.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0106, 0.0011, 0.0168,  ..., 0.0420, 0.0011, 0.0503],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7e8bcce60>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91167.15270193382, bestParams: [0.014420534, 0.012763254, 0.08490746, 10409.463, 14869.195, 12726.8955, 24758.049]\n",
      "epoch 0\n",
      "     fun: 90664.13815521165\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 18871\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([4.50519321e-02, 4.80974897e-02, 4.37722990e-02, 9.33124432e+03,\n",
      "       2.49952647e+04, 2.48946095e+04, 2.44922474e+04])\n",
      "best ll: 91064.46507395245, bestParams: [0.13599314, 0.0092406655, 0.06631607, 5395.3354, 13053.832, 21606.041, 11194.925]\n",
      "epoch 1\n",
      "     fun: 90658.51054391943\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21778\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97539028e-02, 3.85180081e-02, 4.21989798e-02, 5.29648514e+03,\n",
      "       1.53948253e+04, 1.60815565e+04, 1.24519796e+04])\n",
      "minPrevious 90664.13815521165\n",
      "better by at >= 1; new ll:      fun: 90658.51054391943\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 21778\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.97539028e-02, 3.85180081e-02, 4.21989798e-02, 5.29648514e+03,\n",
      "       1.53948253e+04, 1.60815565e+04, 1.24519796e+04])\n",
      "best ll: 91161.8533601003, bestParams: [0.034372266, 0.032068986, 0.05270397, 8083.9736, 19698.992, 9210.703, 19556.129]\n",
      "epoch 2\n",
      "     fun: 90657.06766549514\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.92766030e-02, 4.08158908e-02, 4.23739920e-02, 7.79916973e+03,\n",
      "       2.27167344e+04, 2.30158405e+04, 1.86388333e+04])\n",
      "minPrevious 90658.51054391943\n",
      "better by at >= 1; new ll:      fun: 90657.06766549514\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 19625\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.92766030e-02, 4.08158908e-02, 4.23739920e-02, 7.79916973e+03,\n",
      "       2.27167344e+04, 2.30158405e+04, 1.86388333e+04])\n",
      "best ll: 91063.24965752647, bestParams: [0.021735504, 0.06495616, 0.022336451, 6890.512, 21746.352, 12447.272, 18961.99]\n",
      "epoch 3\n",
      "     fun: 90659.63845924352\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 29426\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([3.96169439e-02, 4.09057274e-02, 4.24696771e-02, 5.79042445e+03,\n",
      "       1.67475000e+04, 1.69853353e+04, 1.39198936e+04])\n",
      "minPrevious 90657.06766549514\n",
      "best ll: 90977.47848692283, bestParams: [0.059151612, 0.05514521, 0.0882875, 7970.9907, 15740.975, 12443.312, 21263.242]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8d3d1ca8ed6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[0;31m#         fnArgs = [probs[0], probs[1], probs[2], *alphas]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m         \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mdual_annealing\u001b[0;34m(func, bounds, args, maxiter, local_search_options, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;31m# Possible local search at the end of the strategy chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_local_search\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mlocal_search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;31m# Global energy has improved, let's see if LS improves further\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             e, x = self.minimizer_wrapper.local_search(self.energy_state.xbest,\n\u001b[0;32m--> 318\u001b[0;31m                                                        self.energy_state.ebest)\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mebest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_improved_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mlocal_search\u001b[0;34m(self, x, e)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Run local search from the given x location where energy value is e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mx_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mmres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'njev'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnjev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 600\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0ma1Both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1Both\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0ma21\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "resSim = {\n",
    "        \"allRes\": None,\n",
    "        \"nEpochs\": None,\n",
    "        \"bestRes\": {\n",
    "            \"pis\": None,\n",
    "            \"alphas\": None,\n",
    "            \"PDV_c1true\": None,\n",
    "            \"PDV_c2true\": None,\n",
    "            \"PDV_cBothTrue\": None,\n",
    "            \"PDV_c1inferred\": None,\n",
    "            \"PDV_c2inferred\": None,\n",
    "            \"PDV_cBothInferred\": None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cached6NormalSimRes = []\n",
    "\n",
    "rrsSim = tensor([[2, 2, 1.5]])\n",
    "pisSim = tensor([[.05, .05, .05]])\n",
    "\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(5e5)\n",
    "i = 0\n",
    "for rrsSimRun in rrsSim:\n",
    "    for pisSimRun in pisSim:\n",
    "        afMeanRun = 1e-4\n",
    "        generatingFn = genData.v6normal\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        # needs tensor for shapes, otherwise \"gamma_cpu not implemente for long\", e.g rrShape=50.0 doesn't work...\n",
    "        paramsRun = genData.genParams(rrMeans=rrsSimRun, pis=pisSimRun, afMean=afMeanRun, rrShape=tensor(50.), afShape=tensor(50.), nCases=nCases, nCtrls=nCtrls)[0]\n",
    "        \n",
    "        pDsRun = paramsRun[\"pDs\"]\n",
    "        pisRun = paramsRun[\"diseaseFractions\"]\n",
    "        print(\"params are:\", paramsRun)\n",
    "        \n",
    "        cached6NormalSimRes.append({\"params\": paramsRun, \"runs\": []})\n",
    "        for y in range(0, 10):\n",
    "            start = time.time()\n",
    "            r = generatingFn(**paramsRun)\n",
    "            print(\"took\", time.time() - start)\n",
    "            \n",
    "            resPointer = {\n",
    "                **r,\n",
    "                \"generatingFn\": generatingFn,\n",
    "                \"results\": None,\n",
    "            }\n",
    "\n",
    "            cached6NormalSimRes[i][\"runs\"].append(resPointer)\n",
    "            \n",
    "            print(f\"Run: {i}, {y}\")\n",
    "            \n",
    "            xsRun = resPointer[\"altCounts\"]\n",
    "            afsRun = resPointer[\"afs\"]\n",
    "            affectedGenesRun = resPointer[\"affectedGenes\"]\n",
    "            unaffectedGenesRun = resPointer[\"unaffectedGenes\"]\n",
    "\n",
    "            runCostFnIdx = 16\n",
    "\n",
    "            nEpochsRun = 10\n",
    "            print(\"nEpochsRun\", nEpochsRun)\n",
    "            \n",
    "            res = likelihoods.fitFnBivariateAnnealing(xsRun, pDsRun, nEpochs=nEpochsRun, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "            bestRes = res[\"params\"][-1]\n",
    "\n",
    "            inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "            inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "            #### Calculate actual ###\n",
    "            component1Afs = afsRun[affectedGenesRun[0]]\n",
    "            c1true = (component1Afs / afMeanRun).mean(0)\n",
    "\n",
    "            component2Afs = afsRun[affectedGenesRun[1]]\n",
    "            c2true = (component2Afs / afMeanRun).mean(0)\n",
    "\n",
    "            componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "            cBothTrue = (componentBothAfs / afMeanRun).mean(0)\n",
    "\n",
    "            ### calculate inferred values\n",
    "            pds = tensor([1-pDsRun.sum(), *pDsRun])\n",
    "            alphas = inferredAlphas.numpy()\n",
    "            c1inferred = Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            c2inferred = Dirichlet(tensor([alphas[0], alphas[0], alphas[2], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            cBothInferred = Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0)\n",
    "\n",
    "            print(f\"\\n\\nrun {i} results for rrs: {rrsSimRun}, pis: {pisSimRun}\")\n",
    "            print(\"Inferred pis:\", inferredPis)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c1true)\n",
    "            print(\"P(D|V) inferred in component 1:\", c1inferred)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c2true)\n",
    "            print(\"P(D|V) inferred in component both:\", c2inferred)\n",
    "            print(\"\\nP(D|V) true ans in component both:\", cBothTrue)\n",
    "            print(\"P(D|V) inferred in component both:\", cBothInferred,\"\\n\\n\")\n",
    "\n",
    "            resToStore = copy.deepcopy(resSim)\n",
    "            resToStore[\"allRes\"] = res\n",
    "            resToStore[\"nEpochs\"] = nEpochsRun\n",
    "            br = resToStore[\"bestRes\"]\n",
    "            br[\"pis\"] = inferredPis\n",
    "            br[\"alphas\"] = inferredAlphas\n",
    "            br[\"PDV_c1true\"] = c1true\n",
    "            br[\"PDV_c2true\"] = c2true\n",
    "            br[\"PDV_cBothTrue\"] = cBothTrue\n",
    "            br[\"PDV_c1inferred\"] = c1inferred\n",
    "            br[\"PDV_c2inferred\"] = c2inferred\n",
    "            br[\"PDV_cBothInferred\"] = cBothInferred\n",
    "\n",
    "            resPointer[\"results\"] = resToStore\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([2.0000, 2.0000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.0478, 2.3230, 4.9419],\n",
      "        [1.1123, 3.1260, 6.4751],\n",
      "        [3.7432, 4.8883, 4.0865],\n",
      "        ...,\n",
      "        [2.3440, 2.6389, 4.7504],\n",
      "        [3.1413, 3.7973, 5.2277],\n",
      "        [2.2387, 4.0079, 4.0649]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.850098848342896\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[45.,  5.,  3.,  2.],\n",
      "        [41.,  4.,  3.,  1.],\n",
      "        [37.,  7.,  1.,  0.],\n",
      "        ...,\n",
      "        [74.,  1.,  4.,  0.],\n",
      "        [34.,  0.,  0.,  1.],\n",
      "        [47.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([55., 49., 45.,  ..., 79., 35., 47.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 4., 7.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 3., 1.,  ..., 4., 0., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 0.,  ..., 0., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[45.,  5.,  3.,  2.],\n",
      "        [41.,  4.,  3.,  1.],\n",
      "        [37.,  7.,  1.,  0.],\n",
      "        ...,\n",
      "        [74.,  1.,  4.,  0.],\n",
      "        [34.,  0.,  0.,  1.],\n",
      "        [47.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([1.5210e-04, 1.0985e-03, 4.9528e-05,  ..., 1.1274e-02, 3.6850e-02,\n",
      "        3.8093e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3eef0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91172.32504614866, bestParams: [0.013028687, 0.04237689, 0.055741724, 11929.878, 23005.342, 24812.355, 19184.58]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.44827568e-02, 4.20886696e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886697e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204496e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886697e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204496e+03,\n",
      "        2.80864800e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886695e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04],\n",
      "       [1.44827568e-02, 4.20886694e-02, 5.23620101e-02, 8.85204495e+03,\n",
      "        2.80864801e+04, 2.54391201e+04, 1.98356475e+04]]), array([90708.23269808, 90708.23269813, 90708.23269813, 90708.23269813,\n",
      "       90708.23269818, 90708.2326982 , 90708.23269824, 90708.23269824]))\n",
      "           fun: 90708.2326980827\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1318\n",
      "           nit: 493\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.44827568e-02, 4.20886696e-02, 5.23620101e-02, 8.85204497e+03,\n",
      "       2.80864800e+04, 2.54391201e+04, 1.98356475e+04])\n",
      "best ll: 90890.87945008784, bestParams: [0.02896374, 0.014520663, 0.032099355, 7064.519, 15548.0, 21440.451, 23799.553]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528250e+04],\n",
      "       [3.38261325e-02, 1.79584957e-02, 3.97524944e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528248e+04],\n",
      "       [3.38261324e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519285e+04, 2.19081534e+04, 1.22528248e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524946e-02, 6.01717407e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04]]), array([90656.19387572, 90656.19387581, 90656.19387586, 90656.19387586,\n",
      "       90656.19387591, 90656.19387599, 90656.19387611, 90656.19387612]))\n",
      "           fun: 90656.19387571645\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1376\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "       1.88519284e+04, 2.19081534e+04, 1.22528249e+04])\n",
      "minPrevious 90708.2326980827\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081534e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261326e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528250e+04],\n",
      "       [3.38261325e-02, 1.79584957e-02, 3.97524944e-02, 6.01717407e+03,\n",
      "        1.88519284e+04, 2.19081533e+04, 1.22528248e+04],\n",
      "       [3.38261324e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519285e+04, 2.19081534e+04, 1.22528248e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524946e-02, 6.01717407e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04],\n",
      "       [3.38261325e-02, 1.79584956e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "        1.88519283e+04, 2.19081533e+04, 1.22528249e+04]]), array([90656.19387572, 90656.19387581, 90656.19387586, 90656.19387586,\n",
      "       90656.19387591, 90656.19387599, 90656.19387611, 90656.19387612]))\n",
      "           fun: 90656.19387571645\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1376\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38261325e-02, 1.79584957e-02, 3.97524945e-02, 6.01717408e+03,\n",
      "       1.88519284e+04, 2.19081534e+04, 1.22528249e+04])\n",
      "best ll: 91084.1192014738, bestParams: [0.09653744, 0.018029423, 0.09406014, 7974.054, 10447.645, 17449.232, 18952.387]\n",
      "epoch 2\n",
      " final_simplex: (array([[9.36961198e-02, 2.15226793e-02, 4.20764994e-02, 6.46469647e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961197e-02, 2.15226793e-02, 4.20764980e-02, 6.46469647e+03,\n",
      "        1.42865571e+04, 1.95487746e+04, 1.90451599e+04],\n",
      "       [9.36961201e-02, 2.15226793e-02, 4.20765002e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451600e+04],\n",
      "       [9.36961203e-02, 2.15226793e-02, 4.20764994e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487746e+04, 1.90451598e+04],\n",
      "       [9.36961203e-02, 2.15226792e-02, 4.20764988e-02, 6.46469647e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961206e-02, 2.15226793e-02, 4.20765004e-02, 6.46469645e+03,\n",
      "        1.42865569e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961209e-02, 2.15226792e-02, 4.20765011e-02, 6.46469645e+03,\n",
      "        1.42865569e+04, 1.95487745e+04, 1.90451599e+04],\n",
      "       [9.36961205e-02, 2.15226792e-02, 4.20764990e-02, 6.46469646e+03,\n",
      "        1.42865570e+04, 1.95487745e+04, 1.90451599e+04]]), array([90681.43851664, 90681.43851693, 90681.43851704, 90681.43851723,\n",
      "       90681.43851748, 90681.43851752, 90681.43851769, 90681.43851779]))\n",
      "           fun: 90681.43851663727\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.36961198e-02, 2.15226793e-02, 4.20764994e-02, 6.46469647e+03,\n",
      "       1.42865570e+04, 1.95487745e+04, 1.90451599e+04])\n",
      "minPrevious 90656.19387571645\n",
      "best ll: 91034.65410804498, bestParams: [0.027997645, 0.11145982, 0.04767258, 7647.5757, 20896.21, 12109.757, 15794.455]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.29898119e-02, 8.95420892e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420892e-02, 4.67567476e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898118e-02, 8.95420892e-02, 4.67567477e-02, 6.32456128e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420894e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816320e+04, 1.92698622e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567478e-02, 6.32456126e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698622e+04],\n",
      "       [3.29898118e-02, 8.95420895e-02, 4.67567478e-02, 6.32456125e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698623e+04],\n",
      "       [3.29898119e-02, 8.95420898e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "        1.68206514e+04, 1.47816319e+04, 1.92698622e+04]]), array([90716.56485695, 90716.56485706, 90716.56485719, 90716.56485742,\n",
      "       90716.56485758, 90716.56485805, 90716.56485833, 90716.56487249]))\n",
      "           fun: 90716.56485695229\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1182\n",
      "           nit: 442\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.29898119e-02, 8.95420892e-02, 4.67567477e-02, 6.32456127e+03,\n",
      "       1.68206514e+04, 1.47816319e+04, 1.92698623e+04])\n",
      "minPrevious 90656.19387571645\n",
      "best ll: 90939.13863356014, bestParams: [0.07707118, 0.018570729, 0.07501205, 5894.602, 8311.181, 11558.4, 19163.01]\n",
      "epoch 4\n",
      " final_simplex: (array([[6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350208e-02, 2.24385760e-02, 3.93378972e-02, 4.60124344e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539976e+04],\n",
      "       [6.84350208e-02, 2.24385761e-02, 3.93378969e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350213e-02, 2.24385761e-02, 3.93378970e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539976e+04],\n",
      "       [6.84350210e-02, 2.24385763e-02, 3.93378962e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350214e-02, 2.24385761e-02, 3.93378967e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350228e-02, 2.24385758e-02, 3.93378974e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350233e-02, 2.24385756e-02, 3.93378983e-02, 4.60124348e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04]]), array([90648.44593427, 90648.44593435, 90648.44593449, 90648.44593476,\n",
      "       90648.44593506, 90648.4459351 , 90648.44593574, 90648.4459358 ]))\n",
      "           fun: 90648.44593427246\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1147\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "       1.17104156e+04, 1.52903364e+04, 1.15539975e+04])\n",
      "minPrevious 90656.19387571645\n",
      "better by at >= 1; new ll:  final_simplex: (array([[6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350208e-02, 2.24385760e-02, 3.93378972e-02, 4.60124344e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539976e+04],\n",
      "       [6.84350208e-02, 2.24385761e-02, 3.93378969e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350213e-02, 2.24385761e-02, 3.93378970e-02, 4.60124346e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539976e+04],\n",
      "       [6.84350210e-02, 2.24385763e-02, 3.93378962e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350214e-02, 2.24385761e-02, 3.93378967e-02, 4.60124346e+03,\n",
      "        1.17104155e+04, 1.52903364e+04, 1.15539975e+04],\n",
      "       [6.84350228e-02, 2.24385758e-02, 3.93378974e-02, 4.60124347e+03,\n",
      "        1.17104156e+04, 1.52903365e+04, 1.15539975e+04],\n",
      "       [6.84350233e-02, 2.24385756e-02, 3.93378983e-02, 4.60124348e+03,\n",
      "        1.17104156e+04, 1.52903364e+04, 1.15539975e+04]]), array([90648.44593427, 90648.44593435, 90648.44593449, 90648.44593476,\n",
      "       90648.44593506, 90648.4459351 , 90648.44593574, 90648.4459358 ]))\n",
      "           fun: 90648.44593427246\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1147\n",
      "           nit: 432\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.84350206e-02, 2.24385761e-02, 3.93378971e-02, 4.60124346e+03,\n",
      "       1.17104156e+04, 1.52903364e+04, 1.15539975e+04])\n",
      "best ll: 91166.87153988995, bestParams: [0.068626955, 0.11146803, 0.06459778, 7812.6924, 19519.297, 9904.601, 17612.63]\n",
      "epoch 5\n",
      " final_simplex: (array([[7.59170859e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170857e-02, 1.01934340e-01, 4.47969147e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170858e-02, 1.01934340e-01, 4.47969150e-02, 6.65456055e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170859e-02, 1.01934340e-01, 4.47969144e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628879e+04, 2.17700551e+04],\n",
      "       [7.59170856e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934341e-01, 4.47969147e-02, 6.65456053e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04],\n",
      "       [7.59170855e-02, 1.01934341e-01, 4.47969147e-02, 6.65456053e+03,\n",
      "        1.49096890e+04, 1.34628878e+04, 2.17700551e+04]]), array([90735.31638244, 90735.31638259, 90735.31638261, 90735.31638276,\n",
      "       90735.31638288, 90735.31638291, 90735.31638307, 90735.31638314]))\n",
      "           fun: 90735.31638244262\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1236\n",
      "           nit: 471\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.59170859e-02, 1.01934340e-01, 4.47969146e-02, 6.65456054e+03,\n",
      "       1.49096890e+04, 1.34628878e+04, 2.17700551e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90917.66287739587, bestParams: [0.13892789, 0.10014813, 0.035001487, 4701.4688, 7708.276, 10219.709, 22012.11]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.36648091e-01, 9.30464598e-02, 3.80847363e-02, 4.89947091e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648091e-01, 9.30464598e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464601e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151964e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464605e-02, 3.80847362e-02, 4.89947092e+03,\n",
      "        8.76151962e+03, 1.02069802e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464605e-02, 3.80847362e-02, 4.89947093e+03,\n",
      "        8.76151957e+03, 1.02069801e+04, 1.80163115e+04],\n",
      "       [1.36648090e-01, 9.30464604e-02, 3.80847362e-02, 4.89947091e+03,\n",
      "        8.76151963e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464608e-02, 3.80847361e-02, 4.89947093e+03,\n",
      "        8.76151964e+03, 1.02069801e+04, 1.80163114e+04],\n",
      "       [1.36648090e-01, 9.30464607e-02, 3.80847360e-02, 4.89947093e+03,\n",
      "        8.76151961e+03, 1.02069801e+04, 1.80163114e+04]]), array([90782.8870678 , 90782.88706813, 90782.88706825, 90782.88706835,\n",
      "       90782.88706844, 90782.8870687 , 90782.88706913, 90782.88706914]))\n",
      "           fun: 90782.88706779895\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1239\n",
      "           nit: 485\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.36648091e-01, 9.30464598e-02, 3.80847363e-02, 4.89947091e+03,\n",
      "       8.76151963e+03, 1.02069801e+04, 1.80163114e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90921.60896941471, bestParams: [0.039651427, 0.066044815, 0.0449088, 8883.905, 17105.955, 21929.596, 18417.646]\n",
      "epoch 7\n",
      " final_simplex: (array([[4.04578591e-02, 6.31349507e-02, 4.17312360e-02, 7.30683351e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349508e-02, 4.17312359e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349506e-02, 4.17312361e-02, 7.30683352e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130547e+04],\n",
      "       [4.04578590e-02, 6.31349505e-02, 4.17312361e-02, 7.30683351e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578592e-02, 6.31349508e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655049e+04, 1.98816064e+04, 2.07130547e+04],\n",
      "       [4.04578590e-02, 6.31349507e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349509e-02, 4.17312359e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04],\n",
      "       [4.04578591e-02, 6.31349508e-02, 4.17312360e-02, 7.30683352e+03,\n",
      "        2.06655050e+04, 1.98816064e+04, 2.07130546e+04]]), array([90653.65813487, 90653.65813493, 90653.65813495, 90653.65813495,\n",
      "       90653.65813502, 90653.65813511, 90653.65813513, 90653.65813515]))\n",
      "           fun: 90653.65813486525\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1328\n",
      "           nit: 534\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.04578591e-02, 6.31349507e-02, 4.17312360e-02, 7.30683351e+03,\n",
      "       2.06655049e+04, 1.98816064e+04, 2.07130546e+04])\n",
      "minPrevious 90648.44593427246\n",
      "best ll: 90906.03571837083, bestParams: [0.046865396, 0.021055793, 0.022448916, 5707.723, 14474.583, 22354.312, 23248.088]\n",
      "epoch 8\n",
      " final_simplex: (array([[4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083142e-02, 2.66136979e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04]]), array([90636.62833643, 90636.62833654, 90636.6283387 , 90636.62833873,\n",
      "       90636.62833876, 90636.62833878, 90636.628347  , 90636.62834702]))\n",
      "           fun: 90636.62833642976\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1308\n",
      "           nit: 446\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "       1.71687415e+04, 1.90909270e+04, 1.19123748e+04])\n",
      "minPrevious 90648.44593427246\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083142e-02, 2.66136979e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083141e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123748e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04],\n",
      "       [4.05083140e-02, 2.66136980e-02, 3.47685568e-02, 5.40501828e+03,\n",
      "        1.71687415e+04, 1.90909270e+04, 1.19123747e+04]]), array([90636.62833643, 90636.62833654, 90636.6283387 , 90636.62833873,\n",
      "       90636.62833876, 90636.62833878, 90636.628347  , 90636.62834702]))\n",
      "           fun: 90636.62833642976\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1308\n",
      "           nit: 446\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05083140e-02, 2.66136980e-02, 3.47685567e-02, 5.40501829e+03,\n",
      "       1.71687415e+04, 1.90909270e+04, 1.19123748e+04])\n",
      "best ll: 91011.59666077793, bestParams: [0.1238161, 0.015511246, 0.058201686, 9525.396, 21616.701, 17512.54, 22892.9]\n",
      "epoch 9\n",
      " final_simplex: (array([[1.03603268e-01, 1.67256257e-02, 5.42323187e-02, 8.78604866e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256257e-02, 5.42323187e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603268e-01, 1.67256256e-02, 5.42323188e-02, 8.78604868e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603268e-01, 1.67256256e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256256e-02, 5.42323188e-02, 8.78604866e+03,\n",
      "        1.78020607e+04, 2.35306881e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256256e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020608e+04, 2.35306880e+04, 2.62310911e+04],\n",
      "       [1.03603269e-01, 1.67256255e-02, 5.42323190e-02, 8.78604870e+03,\n",
      "        1.78020607e+04, 2.35306880e+04, 2.62310912e+04],\n",
      "       [1.03603269e-01, 1.67256255e-02, 5.42323188e-02, 8.78604867e+03,\n",
      "        1.78020607e+04, 2.35306881e+04, 2.62310912e+04]]), array([90724.66721506, 90724.66721543, 90724.66721548, 90724.66721562,\n",
      "       90724.66721583, 90724.6672159 , 90724.667216  , 90724.66721622]))\n",
      "           fun: 90724.66721505724\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1140\n",
      "           nit: 379\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.03603268e-01, 1.67256257e-02, 5.42323187e-02, 8.78604866e+03,\n",
      "       1.78020607e+04, 2.35306880e+04, 2.62310912e+04])\n",
      "minPrevious 90636.62833642976\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0405, 0.0266, 0.0348], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8832, 0.0633, 0.0280, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8564, 0.0816, 0.0256, 0.0363], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8810, 0.0279, 0.0632, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8486, 0.0255, 0.0899, 0.0360], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7405, 0.0996, 0.0999, 0.0624], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6942, 0.1121, 0.1194, 0.0742], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[1.7906, 2.9352, 4.7581],\n",
      "        [3.0976, 2.9503, 4.8961],\n",
      "        [3.5549, 4.4150, 6.2209],\n",
      "        ...,\n",
      "        [3.0932, 3.6773, 5.4842],\n",
      "        [4.8924, 3.0446, 5.1291],\n",
      "        [3.6147, 3.7954, 6.7355]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.719698190689087\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[39.,  1.,  0.,  3.],\n",
      "        [52.,  5.,  1.,  1.],\n",
      "        [48.,  1.,  0.,  3.],\n",
      "        ...,\n",
      "        [56.,  1.,  2.,  2.],\n",
      "        [43.,  4.,  0.,  1.],\n",
      "        [47.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([43., 59., 52.,  ..., 61., 48., 49.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 5., 1.,  ..., 1., 4., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 0.,  ..., 2., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 3.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[39.,  1.,  0.,  3.],\n",
      "        [52.,  5.,  1.,  1.],\n",
      "        [48.,  1.,  0.,  3.],\n",
      "        ...,\n",
      "        [56.,  1.,  2.,  2.],\n",
      "        [43.,  4.,  0.,  1.],\n",
      "        [47.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0013, 0.0021, 0.0015,  ..., 0.0100, 0.0030, 0.0702],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3ea70>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90741.90852394194, bestParams: [0.07122339, 0.0030399286, 0.054159407, 10150.92, 21346.87, 23431.73, 21332.012]\n",
      "epoch 0\n",
      " final_simplex: (array([[6.75587190e-02, 3.35212914e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212913e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587193e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587193e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587191e-02, 3.35212914e-03, 5.38820011e-02, 8.95523095e+03,\n",
      "        2.17844697e+04, 2.55800586e+04, 2.21139824e+04],\n",
      "       [6.75587194e-02, 3.35212913e-03, 5.38820010e-02, 8.95523096e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139824e+04],\n",
      "       [6.75587194e-02, 3.35212913e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "        2.17844698e+04, 2.55800585e+04, 2.21139825e+04]]), array([90648.67312646, 90648.6731265 , 90648.67312653, 90648.67312653,\n",
      "       90648.6731266 , 90648.67312662, 90648.67312669, 90648.67312672]))\n",
      "           fun: 90648.67312645877\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1299\n",
      "           nit: 485\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.75587190e-02, 3.35212914e-03, 5.38820010e-02, 8.95523095e+03,\n",
      "       2.17844698e+04, 2.55800586e+04, 2.21139824e+04])\n",
      "best ll: 90681.83730196144, bestParams: [0.009099581, 0.0579189, 0.04930118, 3433.2517, 15866.488, 10614.559, 6043.5835]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482751e+03],\n",
      "       [3.97041955e-02, 3.83571503e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482756e+03],\n",
      "       [3.97041953e-02, 3.83571506e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482753e+03],\n",
      "       [3.97041955e-02, 3.83571505e-02, 4.01668990e-02, 1.65787189e+03,\n",
      "        5.10452657e+03, 4.99800959e+03, 3.89482751e+03],\n",
      "       [3.97041957e-02, 3.83571504e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452653e+03, 4.99800953e+03, 3.89482757e+03],\n",
      "       [3.97041957e-02, 3.83571501e-02, 4.01668989e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482757e+03],\n",
      "       [3.97041956e-02, 3.83571500e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452651e+03, 4.99800959e+03, 3.89482750e+03],\n",
      "       [3.97041950e-02, 3.83571509e-02, 4.01668988e-02, 1.65787188e+03,\n",
      "        5.10452655e+03, 4.99800972e+03, 3.89482750e+03]]), array([90476.89262346, 90476.89262354, 90476.89262355, 90476.89262356,\n",
      "       90476.89262359, 90476.89262365, 90476.89262374, 90476.89262375]))\n",
      "           fun: 90476.89262346049\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1303\n",
      "           nit: 537\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "       5.10452656e+03, 4.99800963e+03, 3.89482751e+03])\n",
      "minPrevious 90648.67312645877\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482751e+03],\n",
      "       [3.97041955e-02, 3.83571503e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482756e+03],\n",
      "       [3.97041953e-02, 3.83571506e-02, 4.01668991e-02, 1.65787189e+03,\n",
      "        5.10452656e+03, 4.99800963e+03, 3.89482753e+03],\n",
      "       [3.97041955e-02, 3.83571505e-02, 4.01668990e-02, 1.65787189e+03,\n",
      "        5.10452657e+03, 4.99800959e+03, 3.89482751e+03],\n",
      "       [3.97041957e-02, 3.83571504e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452653e+03, 4.99800953e+03, 3.89482757e+03],\n",
      "       [3.97041957e-02, 3.83571501e-02, 4.01668989e-02, 1.65787189e+03,\n",
      "        5.10452655e+03, 4.99800958e+03, 3.89482757e+03],\n",
      "       [3.97041956e-02, 3.83571500e-02, 4.01668991e-02, 1.65787188e+03,\n",
      "        5.10452651e+03, 4.99800959e+03, 3.89482750e+03],\n",
      "       [3.97041950e-02, 3.83571509e-02, 4.01668988e-02, 1.65787188e+03,\n",
      "        5.10452655e+03, 4.99800972e+03, 3.89482750e+03]]), array([90476.89262346, 90476.89262354, 90476.89262355, 90476.89262356,\n",
      "       90476.89262359, 90476.89262365, 90476.89262374, 90476.89262375]))\n",
      "           fun: 90476.89262346049\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1303\n",
      "           nit: 537\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97041951e-02, 3.83571511e-02, 4.01668993e-02, 1.65787188e+03,\n",
      "       5.10452656e+03, 4.99800963e+03, 3.89482751e+03])\n",
      "best ll: 90717.3162355351, bestParams: [0.06359781, 0.10405803, 0.046771917, 7625.652, 24112.361, 18915.994, 16105.375]\n",
      "epoch 2\n",
      " final_simplex: (array([[5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102427e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340928e+04],\n",
      "       [5.17102420e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102419e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102418e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04],\n",
      "       [5.17102419e-02, 4.69123671e-02, 4.81104713e-02, 7.98712622e+03,\n",
      "        2.04976104e+04, 2.06011943e+04, 2.24340927e+04]]), array([90500.47796516, 90500.47796518, 90500.47796518, 90500.47796519,\n",
      "       90500.47796527, 90500.47796527, 90500.47796527, 90500.47796528]))\n",
      "           fun: 90500.47796516292\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 4652\n",
      "           nit: 2308\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.17102428e-02, 4.69123675e-02, 4.81104714e-02, 7.98712622e+03,\n",
      "       2.04976104e+04, 2.06011943e+04, 2.24340928e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90929.14797453234, bestParams: [0.021989336, 0.024018025, 0.07503793, 7889.689, 16223.559, 6951.5303, 24633.479]\n",
      "epoch 3\n",
      " final_simplex: (array([[2.99085125e-02, 2.41263715e-02, 4.27982693e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577086e+03],\n",
      "       [2.99085127e-02, 2.41263716e-02, 4.27982671e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577085e+03],\n",
      "       [2.99085125e-02, 2.41263714e-02, 4.27982700e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577081e+03],\n",
      "       [2.99085123e-02, 2.41263714e-02, 4.27982701e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577087e+03],\n",
      "       [2.99085125e-02, 2.41263713e-02, 4.27982700e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577081e+03],\n",
      "       [2.99085124e-02, 2.41263712e-02, 4.27982710e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577083e+03],\n",
      "       [2.99085124e-02, 2.41263713e-02, 4.27982702e-02, 4.40451852e+03,\n",
      "        1.47346393e+04, 1.45226304e+04, 8.34577086e+03],\n",
      "       [2.99085123e-02, 2.41263713e-02, 4.27982702e-02, 4.40451852e+03,\n",
      "        1.47346392e+04, 1.45226304e+04, 8.34577086e+03]]), array([90495.8006795 , 90495.80067955, 90495.80067955, 90495.8006796 ,\n",
      "       90495.80067963, 90495.80067969, 90495.80067975, 90495.80067979]))\n",
      "           fun: 90495.80067950126\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1186\n",
      "           nit: 463\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.99085125e-02, 2.41263715e-02, 4.27982693e-02, 4.40451852e+03,\n",
      "       1.47346392e+04, 1.45226304e+04, 8.34577086e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90864.35112277341, bestParams: [0.018510455, 0.058447286, 0.035942793, 6684.6064, 20323.559, 21613.281, 5399.623]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.43113091e-02, 2.92079757e-02, 4.39142700e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673893e+03],\n",
      "       [2.43113090e-02, 2.92079759e-02, 4.39142701e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03],\n",
      "       [2.43113090e-02, 2.92079760e-02, 4.39142702e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673896e+03],\n",
      "       [2.43113090e-02, 2.92079757e-02, 4.39142702e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905713e+04, 9.04673895e+03],\n",
      "       [2.43113090e-02, 2.92079757e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673892e+03],\n",
      "       [2.43113090e-02, 2.92079756e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03],\n",
      "       [2.43113090e-02, 2.92079758e-02, 4.39142706e-02, 4.97417024e+03,\n",
      "        1.72363324e+04, 1.66905711e+04, 9.04673894e+03],\n",
      "       [2.43113091e-02, 2.92079753e-02, 4.39142704e-02, 4.97417025e+03,\n",
      "        1.72363324e+04, 1.66905712e+04, 9.04673894e+03]]), array([90498.99775909, 90498.99775912, 90498.99775917, 90498.99775926,\n",
      "       90498.99775931, 90498.99775936, 90498.9977594 , 90498.99775941]))\n",
      "           fun: 90498.99775908835\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1218\n",
      "           nit: 417\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.43113091e-02, 2.92079757e-02, 4.39142700e-02, 4.97417025e+03,\n",
      "       1.72363324e+04, 1.66905712e+04, 9.04673893e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90989.41744427223, bestParams: [0.030847164, 0.029215563, 0.034289706, 2947.6792, 13085.451, 7149.294, 2870.779]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.08771419e-02, 3.15990099e-02, 4.33952910e-02, 2.10684217e+03,\n",
      "        6.80498898e+03, 6.67304328e+03, 4.34566725e+03],\n",
      "       [3.08771419e-02, 3.15990095e-02, 4.33952911e-02, 2.10684218e+03,\n",
      "        6.80498898e+03, 6.67304328e+03, 4.34566732e+03],\n",
      "       [3.08771415e-02, 3.15990100e-02, 4.33952912e-02, 2.10684217e+03,\n",
      "        6.80498897e+03, 6.67304334e+03, 4.34566724e+03],\n",
      "       [3.08771414e-02, 3.15990099e-02, 4.33952914e-02, 2.10684218e+03,\n",
      "        6.80498901e+03, 6.67304327e+03, 4.34566729e+03],\n",
      "       [3.08771412e-02, 3.15990097e-02, 4.33952913e-02, 2.10684219e+03,\n",
      "        6.80498900e+03, 6.67304332e+03, 4.34566733e+03],\n",
      "       [3.08771411e-02, 3.15990098e-02, 4.33952915e-02, 2.10684219e+03,\n",
      "        6.80498896e+03, 6.67304328e+03, 4.34566735e+03],\n",
      "       [3.08771410e-02, 3.15990097e-02, 4.33952914e-02, 2.10684220e+03,\n",
      "        6.80498899e+03, 6.67304331e+03, 4.34566735e+03],\n",
      "       [3.08771408e-02, 3.15990100e-02, 4.33952916e-02, 2.10684219e+03,\n",
      "        6.80498897e+03, 6.67304330e+03, 4.34566733e+03]]), array([90484.77045382, 90484.77045403, 90484.77045422, 90484.77045436,\n",
      "       90484.77045459, 90484.77045473, 90484.77045477, 90484.77045493]))\n",
      "           fun: 90484.7704538244\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1185\n",
      "           nit: 456\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.08771419e-02, 3.15990099e-02, 4.33952910e-02, 2.10684217e+03,\n",
      "       6.80498898e+03, 6.67304328e+03, 4.34566725e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90880.97895039347, bestParams: [0.024393914, 0.062279228, 0.049727906, 4949.1357, 22385.908, 15643.343, 17572.701]\n",
      "epoch 6\n",
      " final_simplex: (array([[3.06168610e-02, 4.95983339e-02, 4.25957054e-02, 6.09077079e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168609e-02, 4.95983338e-02, 4.25957054e-02, 6.09077077e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168610e-02, 4.95983339e-02, 4.25957053e-02, 6.09077077e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168608e-02, 4.95983342e-02, 4.25957057e-02, 6.09077079e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168608e-02, 4.95983345e-02, 4.25957059e-02, 6.09077080e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168606e-02, 4.95983349e-02, 4.25957058e-02, 6.09077083e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279572e+04],\n",
      "       [3.06168607e-02, 4.95983349e-02, 4.25957063e-02, 6.09077083e+03,\n",
      "        1.90729035e+04, 1.73021239e+04, 1.45279573e+04],\n",
      "       [3.06168606e-02, 4.95983351e-02, 4.25957061e-02, 6.09077086e+03,\n",
      "        1.90729034e+04, 1.73021239e+04, 1.45279573e+04]]), array([90486.75336569, 90486.75336575, 90486.75336577, 90486.75336609,\n",
      "       90486.75336629, 90486.75336661, 90486.75336662, 90486.75336664]))\n",
      "           fun: 90486.75336568736\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1230\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.06168610e-02, 4.95983339e-02, 4.25957054e-02, 6.09077079e+03,\n",
      "       1.90729035e+04, 1.73021239e+04, 1.45279573e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 91497.65906267175, bestParams: [0.054666173, 0.09095881, 0.06649772, 5459.7817, 5106.5513, 5879.891, 11712.161]\n",
      "epoch 7\n",
      " final_simplex: (array([[4.30860784e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "        9.78249630e+03, 9.13774297e+03, 7.77570167e+03],\n",
      "       [4.30860784e-02, 4.05039918e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249625e+03, 9.13774294e+03, 7.77570159e+03],\n",
      "       [4.30860785e-02, 4.05039917e-02, 4.19283439e-02, 3.17918518e+03,\n",
      "        9.78249632e+03, 9.13774297e+03, 7.77570168e+03],\n",
      "       [4.30860788e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "        9.78249631e+03, 9.13774300e+03, 7.77570166e+03],\n",
      "       [4.30860793e-02, 4.05039921e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249629e+03, 9.13774301e+03, 7.77570167e+03],\n",
      "       [4.30860797e-02, 4.05039928e-02, 4.19283441e-02, 3.17918518e+03,\n",
      "        9.78249627e+03, 9.13774295e+03, 7.77570175e+03],\n",
      "       [4.30860799e-02, 4.05039931e-02, 4.19283442e-02, 3.17918518e+03,\n",
      "        9.78249625e+03, 9.13774295e+03, 7.77570174e+03],\n",
      "       [4.30860800e-02, 4.05039930e-02, 4.19283442e-02, 3.17918518e+03,\n",
      "        9.78249624e+03, 9.13774295e+03, 7.77570174e+03]]), array([90480.57137342, 90480.57137345, 90480.57137348, 90480.57137366,\n",
      "       90480.57137391, 90480.571374  , 90480.57137409, 90480.57137411]))\n",
      "           fun: 90480.57137341992\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1357\n",
      "           nit: 569\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.30860784e-02, 4.05039918e-02, 4.19283440e-02, 3.17918518e+03,\n",
      "       9.78249630e+03, 9.13774297e+03, 7.77570167e+03])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 90748.30062683142, bestParams: [0.07419606, 0.039394133, 0.028832112, 6168.2896, 21175.932, 24372.55, 6964.5005]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.83425215e-02, 3.05141356e-02, 4.41328425e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425210e-02, 3.05141358e-02, 4.41328427e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425213e-02, 3.05141355e-02, 4.41328426e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575860e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644697e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425204e-02, 3.05141360e-02, 4.41328427e-02, 6.29920487e+03,\n",
      "        2.23644696e+04, 2.12074130e+04, 1.02575861e+04],\n",
      "       [2.83425212e-02, 3.05141356e-02, 4.41328426e-02, 6.29920489e+03,\n",
      "        2.23644696e+04, 2.12074130e+04, 1.02575860e+04],\n",
      "       [2.83425206e-02, 3.05141358e-02, 4.41328426e-02, 6.29920488e+03,\n",
      "        2.23644697e+04, 2.12074131e+04, 1.02575861e+04]]), array([90499.4328383 , 90499.43283833, 90499.43283834, 90499.4328384 ,\n",
      "       90499.43283843, 90499.43283848, 90499.43283849, 90499.43283851]))\n",
      "           fun: 90499.43283829854\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1204\n",
      "           nit: 459\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.83425215e-02, 3.05141356e-02, 4.41328425e-02, 6.29920489e+03,\n",
      "       2.23644697e+04, 2.12074130e+04, 1.02575860e+04])\n",
      "minPrevious 90476.89262346049\n",
      "best ll: 91296.27290015653, bestParams: [0.11290184, 0.13054714, 0.1386694, 5181.501, 8365.07, 8362.464, 14073.521]\n",
      "epoch 9\n",
      " final_simplex: (array([[9.02097583e-02, 1.10225090e-01, 5.28885652e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097588e-02, 1.10225090e-01, 5.28885651e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097587e-02, 1.10225090e-01, 5.28885651e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097504e-02, 1.10225090e-01, 5.28885671e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099462e+04],\n",
      "       [9.02097550e-02, 1.10225090e-01, 5.28885660e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097555e-02, 1.10225090e-01, 5.28885659e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097559e-02, 1.10225090e-01, 5.28885658e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04],\n",
      "       [9.02097561e-02, 1.10225090e-01, 5.28885658e-02, 5.25880194e+03,\n",
      "        1.01009865e+04, 1.00144483e+04, 1.76099461e+04]]), array([90626.40935142, 90626.40935145, 90626.40935145, 90626.40935773,\n",
      "       90626.40935794, 90626.40935797, 90626.40935799, 90626.40935799]))\n",
      "           fun: 90626.40935142341\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2984\n",
      "           nit: 1336\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([9.02097583e-02, 1.10225090e-01, 5.28885652e-02, 5.25880194e+03,\n",
      "       1.01009865e+04, 1.00144483e+04, 1.76099461e+04])\n",
      "minPrevious 90476.89262346049\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0397, 0.0384, 0.0402], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8799, 0.0645, 0.0279, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8632, 0.0797, 0.0259, 0.0312], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8797, 0.0279, 0.0630, 0.0252], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8646, 0.0259, 0.0782, 0.0313], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7380, 0.0977, 0.0978, 0.0611], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7017, 0.1143, 0.1130, 0.0710], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7900, 4.1484, 4.0321],\n",
      "        [3.0761, 4.3315, 6.6560],\n",
      "        [2.8822, 3.3881, 5.3680],\n",
      "        ...,\n",
      "        [2.3470, 2.6197, 4.9254],\n",
      "        [1.9785, 2.4099, 3.6386],\n",
      "        [2.8596, 1.1003, 4.5087]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.632166147232056\n",
      "Run: 0, 2\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[38.,  5.,  3.,  2.],\n",
      "        [46.,  6.,  0.,  4.],\n",
      "        [42.,  5.,  3.,  4.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [53.,  2.,  3.,  2.],\n",
      "        [47.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([48., 56., 54.,  ..., 70., 60., 50.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([5., 6., 5.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 3.,  ..., 2., 3., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 4., 4.,  ..., 2., 2., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[38.,  5.,  3.,  2.],\n",
      "        [46.,  6.,  0.,  4.],\n",
      "        [42.,  5.,  3.,  4.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [53.,  2.,  3.,  2.],\n",
      "        [47.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([5.5336e-05, 2.3030e-06, 3.0288e-06,  ..., 5.4883e-03, 4.3785e-03,\n",
      "        3.9273e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3eb90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90729.31401045548, bestParams: [0.04714876, 0.012392071, 0.053447075, 7013.6914, 12085.93, 22692.54, 17837.424]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.33117250e-02, 2.04074664e-02, 4.59170420e-02, 5.82361142e+03,\n",
      "        1.80858056e+04, 2.06137097e+04, 9.83484979e+03],\n",
      "       [3.33117247e-02, 2.04074666e-02, 4.59170423e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484977e+03],\n",
      "       [3.33117250e-02, 2.04074665e-02, 4.59170422e-02, 5.82361140e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484981e+03],\n",
      "       [3.33117246e-02, 2.04074667e-02, 4.59170427e-02, 5.82361135e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484984e+03],\n",
      "       [3.33117235e-02, 2.04074668e-02, 4.59170428e-02, 5.82361134e+03,\n",
      "        1.80858056e+04, 2.06137097e+04, 9.83484973e+03],\n",
      "       [3.33117244e-02, 2.04074666e-02, 4.59170425e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484982e+03],\n",
      "       [3.33117253e-02, 2.04074665e-02, 4.59170425e-02, 5.82361138e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484977e+03],\n",
      "       [3.33117247e-02, 2.04074666e-02, 4.59170427e-02, 5.82361137e+03,\n",
      "        1.80858055e+04, 2.06137097e+04, 9.83484979e+03]]), array([90493.42080322, 90493.42080323, 90493.42080334, 90493.42080338,\n",
      "       90493.4208034 , 90493.42080347, 90493.42080347, 90493.42080351]))\n",
      "           fun: 90493.42080322158\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1276\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.33117250e-02, 2.04074664e-02, 4.59170420e-02, 5.82361142e+03,\n",
      "       1.80858056e+04, 2.06137097e+04, 9.83484979e+03])\n",
      "best ll: 90732.75782383714, bestParams: [0.026286537, 0.090551235, 0.06254556, 6272.722, 16600.713, 17853.037, 18413.832]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379185e-02, 3.65881725e-02, 4.13337161e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379184e-02, 3.65881725e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379192e-02, 3.65881712e-02, 4.13337149e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379215e-02, 3.65881670e-02, 4.13337104e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379220e-02, 3.65881662e-02, 4.13337095e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04]]), array([90476.45793291, 90476.45793291, 90476.45793292, 90476.45793292,\n",
      "       90476.45793305, 90476.45793305, 90476.45793305, 90476.45793306]))\n",
      "           fun: 90476.45793290669\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2009\n",
      "           nit: 867\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "       2.20264360e+04, 2.27778555e+04, 1.56540855e+04])\n",
      "minPrevious 90493.42080322158\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379185e-02, 3.65881725e-02, 4.13337161e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379184e-02, 3.65881725e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379192e-02, 3.65881712e-02, 4.13337149e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540855e+04],\n",
      "       [3.30379215e-02, 3.65881670e-02, 4.13337104e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379216e-02, 3.65881670e-02, 4.13337103e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04],\n",
      "       [3.30379220e-02, 3.65881662e-02, 4.13337095e-02, 7.21767475e+03,\n",
      "        2.20264360e+04, 2.27778555e+04, 1.56540854e+04]]), array([90476.45793291, 90476.45793291, 90476.45793292, 90476.45793292,\n",
      "       90476.45793305, 90476.45793305, 90476.45793305, 90476.45793306]))\n",
      "           fun: 90476.45793290669\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2009\n",
      "           nit: 867\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.30379184e-02, 3.65881726e-02, 4.13337162e-02, 7.21767475e+03,\n",
      "       2.20264360e+04, 2.27778555e+04, 1.56540855e+04])\n",
      "best ll: 90768.5476276376, bestParams: [0.035219885, 0.09352289, 0.08136546, 7144.487, 12225.303, 11796.263, 16765.65]\n",
      "epoch 2\n",
      " final_simplex: (array([[4.65238400e-02, 6.44146076e-02, 4.12197981e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146078e-02, 4.12197982e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146078e-02, 4.12197982e-02, 5.96552759e+03,\n",
      "        1.68314529e+04, 1.52391460e+04, 1.52451012e+04],\n",
      "       [4.65238401e-02, 6.44146081e-02, 4.12197979e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238401e-02, 6.44146082e-02, 4.12197980e-02, 5.96552759e+03,\n",
      "        1.68314529e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146084e-02, 4.12197976e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451012e+04],\n",
      "       [4.65238401e-02, 6.44146083e-02, 4.12197978e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451011e+04],\n",
      "       [4.65238400e-02, 6.44146084e-02, 4.12197976e-02, 5.96552759e+03,\n",
      "        1.68314530e+04, 1.52391460e+04, 1.52451012e+04]]), array([90515.26528606, 90515.26528614, 90515.26528617, 90515.26528672,\n",
      "       90515.26528676, 90515.26528692, 90515.26528698, 90515.26528702]))\n",
      "           fun: 90515.26528606444\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1692\n",
      "           nit: 718\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.65238400e-02, 6.44146076e-02, 4.12197981e-02, 5.96552759e+03,\n",
      "       1.68314530e+04, 1.52391460e+04, 1.52451011e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 91066.53966861677, bestParams: [0.074466266, 0.08731467, 0.05386589, 5332.576, 21387.4, 14033.31, 14331.92]\n",
      "epoch 3\n",
      " final_simplex: (array([[6.01747648e-02, 4.74827058e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747647e-02, 4.74827060e-02, 4.25113519e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747646e-02, 4.74827057e-02, 4.25113525e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267154e+04],\n",
      "       [6.01747648e-02, 4.74827057e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747647e-02, 4.74827060e-02, 4.25113524e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267154e+04],\n",
      "       [6.01747649e-02, 4.74827058e-02, 4.25113522e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04],\n",
      "       [6.01747649e-02, 4.74827055e-02, 4.25113523e-02, 6.63523070e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267156e+04],\n",
      "       [6.01747651e-02, 4.74827060e-02, 4.25113520e-02, 6.63523071e+03,\n",
      "        1.67311435e+04, 1.85195322e+04, 1.85267155e+04]]), array([90504.39416636, 90504.39416637, 90504.39416639, 90504.3941664 ,\n",
      "       90504.39416647, 90504.39416659, 90504.39416662, 90504.39416662]))\n",
      "           fun: 90504.39416636349\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1256\n",
      "           nit: 502\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.01747648e-02, 4.74827058e-02, 4.25113521e-02, 6.63523071e+03,\n",
      "       1.67311435e+04, 1.85195322e+04, 1.85267155e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90970.57307666962, bestParams: [0.0472617, 0.06842829, 0.05356198, 8647.348, 17162.938, 13426.564, 15939.611]\n",
      "epoch 4\n",
      " final_simplex: (array([[4.82379986e-02, 6.64176122e-02, 5.29707453e-02, 6.53249533e+03,\n",
      "        1.67371434e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379985e-02, 6.64176126e-02, 5.29707455e-02, 6.53249532e+03,\n",
      "        1.67371435e+04, 1.62008374e+04, 1.69415655e+04],\n",
      "       [4.82379985e-02, 6.64176125e-02, 5.29707455e-02, 6.53249531e+03,\n",
      "        1.67371435e+04, 1.62008374e+04, 1.69415655e+04],\n",
      "       [4.82379987e-02, 6.64176129e-02, 5.29707456e-02, 6.53249531e+03,\n",
      "        1.67371434e+04, 1.62008374e+04, 1.69415654e+04],\n",
      "       [4.82379989e-02, 6.64176128e-02, 5.29707456e-02, 6.53249531e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379995e-02, 6.64176129e-02, 5.29707460e-02, 6.53249531e+03,\n",
      "        1.67371434e+04, 1.62008373e+04, 1.69415655e+04],\n",
      "       [4.82379992e-02, 6.64176132e-02, 5.29707460e-02, 6.53249530e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415654e+04],\n",
      "       [4.82379995e-02, 6.64176132e-02, 5.29707461e-02, 6.53249529e+03,\n",
      "        1.67371435e+04, 1.62008373e+04, 1.69415655e+04]]), array([90529.94631074, 90529.94631171, 90529.94631177, 90529.94631258,\n",
      "       90529.9463127 , 90529.94631417, 90529.94631475, 90529.94631492]))\n",
      "           fun: 90529.94631074075\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1416\n",
      "           nit: 580\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.82379986e-02, 6.64176122e-02, 5.29707453e-02, 6.53249533e+03,\n",
      "       1.67371434e+04, 1.62008373e+04, 1.69415655e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90676.96857508212, bestParams: [0.019758662, 0.040811747, 0.07994546, 5986.399, 18685.148, 19524.918, 7057.7544]\n",
      "epoch 5\n",
      " final_simplex: (array([[2.16419345e-02, 3.82889994e-02, 4.21537846e-02, 5.67924004e+03,\n",
      "        1.92461813e+04, 1.89292301e+04, 9.56055409e+03],\n",
      "       [2.16419346e-02, 3.82889993e-02, 4.21537843e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292300e+04, 9.56055415e+03],\n",
      "       [2.16419345e-02, 3.82889994e-02, 4.21537847e-02, 5.67924006e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055411e+03],\n",
      "       [2.16419346e-02, 3.82889994e-02, 4.21537843e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055413e+03],\n",
      "       [2.16419346e-02, 3.82889995e-02, 4.21537839e-02, 5.67924004e+03,\n",
      "        1.92461813e+04, 1.89292300e+04, 9.56055416e+03],\n",
      "       [2.16419345e-02, 3.82889994e-02, 4.21537847e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055411e+03],\n",
      "       [2.16419346e-02, 3.82889994e-02, 4.21537842e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292301e+04, 9.56055413e+03],\n",
      "       [2.16419345e-02, 3.82889995e-02, 4.21537854e-02, 5.67924005e+03,\n",
      "        1.92461812e+04, 1.89292302e+04, 9.56055403e+03]]), array([90489.89028648, 90489.89028649, 90489.8902865 , 90489.89028651,\n",
      "       90489.89028664, 90489.89029371, 90489.89029371, 90489.89029372]))\n",
      "           fun: 90489.89028647794\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1144\n",
      "           nit: 370\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.16419345e-02, 3.82889994e-02, 4.21537846e-02, 5.67924004e+03,\n",
      "       1.92461813e+04, 1.89292301e+04, 9.56055409e+03])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90614.04184293446, bestParams: [0.045280494, 0.037793145, 0.059227735, 7774.5674, 18537.154, 16869.389, 16223.571]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.63254603e-02, 4.03578762e-02, 4.26819493e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254605e-02, 4.03578763e-02, 4.26819491e-02, 6.80712184e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04],\n",
      "       [4.63254611e-02, 4.03578752e-02, 4.26819506e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254615e-02, 4.03578750e-02, 4.26819507e-02, 6.80712185e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254623e-02, 4.03578738e-02, 4.26819521e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254625e-02, 4.03578735e-02, 4.26819527e-02, 6.80712185e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04],\n",
      "       [4.63254627e-02, 4.03578731e-02, 4.26819533e-02, 6.80712183e+03,\n",
      "        1.93045360e+04, 2.10435576e+04, 1.53310997e+04],\n",
      "       [4.63254631e-02, 4.03578727e-02, 4.26819538e-02, 6.80712185e+03,\n",
      "        1.93045361e+04, 2.10435576e+04, 1.53310996e+04]]), array([90481.01067873, 90481.01067887, 90481.01067918, 90481.01067943,\n",
      "       90481.01067984, 90481.01068004, 90481.01068014, 90481.01068039]))\n",
      "           fun: 90481.0106787277\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1407\n",
      "           nit: 591\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.63254603e-02, 4.03578762e-02, 4.26819493e-02, 6.80712183e+03,\n",
      "       1.93045360e+04, 2.10435576e+04, 1.53310997e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 91118.26744689574, bestParams: [0.16203003, 0.019491551, 0.10167087, 9075.078, 17631.64, 23901.205, 12888.103]\n",
      "epoch 7\n",
      " final_simplex: (array([[5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136007e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469199e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136009e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136009e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136010e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04],\n",
      "       [5.61638884e-02, 2.35012714e-02, 4.89136010e-02, 8.46456823e+03,\n",
      "        2.06886979e+04, 2.46288633e+04, 2.07469198e+04]]), array([90512.80037146, 90512.80037147, 90512.80037148, 90512.80037158,\n",
      "       90512.80037168, 90512.80037168, 90512.8003717 , 90512.80037172]))\n",
      "           fun: 90512.80037145794\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2992\n",
      "           nit: 1354\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.61638885e-02, 2.35012713e-02, 4.89136005e-02, 8.46456823e+03,\n",
      "       2.06886979e+04, 2.46288633e+04, 2.07469199e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90838.88955760052, bestParams: [0.01900933, 0.062275536, 0.047462903, 11755.048, 22521.502, 21961.916, 23298.01]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299854e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727420e-02, 9.19299854e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431254e+04],\n",
      "       [2.01924312e-02, 6.12219301e-02, 5.02727421e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04],\n",
      "       [2.01924312e-02, 6.12219300e-02, 5.02727421e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04],\n",
      "       [2.01924312e-02, 6.12219301e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "        2.50541339e+04, 2.34886631e+04, 2.30431255e+04]]), array([90532.29920238, 90532.29920238, 90532.2992024 , 90532.29920254,\n",
      "       90532.29920259, 90532.2992027 , 90532.2992027 , 90532.29920271]))\n",
      "           fun: 90532.2992023793\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2184\n",
      "           nit: 1013\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.01924313e-02, 6.12219300e-02, 5.02727420e-02, 9.19299853e+03,\n",
      "       2.50541339e+04, 2.34886631e+04, 2.30431254e+04])\n",
      "minPrevious 90476.45793290669\n",
      "best ll: 90645.41395072266, bestParams: [0.03879742, 0.05967664, 0.0748788, 9502.963, 20872.686, 20331.674, 22603.602]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04],\n",
      "       [4.06434334e-02, 5.88736021e-02, 5.93604534e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04],\n",
      "       [4.06434335e-02, 5.88736021e-02, 5.93604534e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434334e-02, 5.88736020e-02, 5.93604535e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434335e-02, 5.88736020e-02, 5.93604536e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434334e-02, 5.88736019e-02, 5.93604537e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734048e+04],\n",
      "       [4.06434333e-02, 5.88736020e-02, 5.93604536e-02, 9.06739990e+03,\n",
      "        2.27999522e+04, 2.37345303e+04, 2.21734049e+04]]), array([90534.19459469, 90534.19459469, 90534.19459501, 90534.19459519,\n",
      "       90534.1945955 , 90534.19459563, 90534.19459592, 90534.19459592]))\n",
      "           fun: 90534.1945946857\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1561\n",
      "           nit: 650\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.06434335e-02, 5.88736021e-02, 5.93604533e-02, 9.06739990e+03,\n",
      "       2.27999522e+04, 2.37345303e+04, 2.21734048e+04])\n",
      "minPrevious 90476.45793290669\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0330, 0.0366, 0.0413], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8823, 0.0643, 0.0280, 0.0257], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8625, 0.0789, 0.0259, 0.0327], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8854, 0.0280, 0.0632, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8602, 0.0258, 0.0814, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7355, 0.0985, 0.0995, 0.0613], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7058, 0.1106, 0.1127, 0.0709], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4515, 3.4402, 6.3490],\n",
      "        [3.4732, 3.5567, 6.1192],\n",
      "        [2.5983, 1.4514, 4.2065],\n",
      "        ...,\n",
      "        [2.9968, 3.2012, 6.9698],\n",
      "        [3.0024, 3.0444, 5.9488],\n",
      "        [3.8132, 4.7613, 6.0924]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.432267189025879\n",
      "Run: 0, 3\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  0.],\n",
      "        [45.,  6.,  2.,  3.],\n",
      "        [35.,  6.,  2.,  3.],\n",
      "        ...,\n",
      "        [52.,  0.,  0.,  0.],\n",
      "        [49.,  2.,  0.,  0.],\n",
      "        [45.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "n tensor([45., 56., 46.,  ..., 52., 51., 49.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 6.,  ..., 0., 2., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 2.,  ..., 0., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 3., 3.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[43.,  1.,  1.,  0.],\n",
      "        [45.,  6.,  2.,  3.],\n",
      "        [35.,  6.,  2.,  3.],\n",
      "        ...,\n",
      "        [52.,  0.,  0.,  0.],\n",
      "        [49.,  2.,  0.,  0.],\n",
      "        [45.,  1.,  2.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([7.8009e-02, 1.5891e-05, 2.8535e-06,  ..., 2.6907e-02, 3.3099e-02,\n",
      "        2.7306e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3e8c0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90687.73814175435, bestParams: [0.020037124, 0.0016247494, 0.040445533, 5294.021, 10814.926, 12456.389, 21372.918]\n",
      "epoch 0\n",
      " final_simplex: (array([[6.23123949e-02, 6.27163447e-03, 4.18681284e-02, 1.50217719e+03,\n",
      "        4.00664783e+03, 5.09986993e+03, 3.23227687e+03],\n",
      "       [6.23123948e-02, 6.27163447e-03, 4.18681283e-02, 1.50217718e+03,\n",
      "        4.00664785e+03, 5.09986989e+03, 3.23227688e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681282e-02, 1.50217718e+03,\n",
      "        4.00664787e+03, 5.09986996e+03, 3.23227683e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681282e-02, 1.50217718e+03,\n",
      "        4.00664788e+03, 5.09986997e+03, 3.23227683e+03],\n",
      "       [6.23123949e-02, 6.27163448e-03, 4.18681281e-02, 1.50217718e+03,\n",
      "        4.00664789e+03, 5.09986998e+03, 3.23227682e+03],\n",
      "       [6.23123947e-02, 6.27163449e-03, 4.18681278e-02, 1.50217718e+03,\n",
      "        4.00664791e+03, 5.09986998e+03, 3.23227682e+03],\n",
      "       [6.23123950e-02, 6.27163449e-03, 4.18681283e-02, 1.50217718e+03,\n",
      "        4.00664785e+03, 5.09986993e+03, 3.23227683e+03],\n",
      "       [6.23123948e-02, 6.27163449e-03, 4.18681280e-02, 1.50217718e+03,\n",
      "        4.00664789e+03, 5.09986997e+03, 3.23227682e+03]]), array([90272.52946674, 90272.52946678, 90272.52946686, 90272.52946687,\n",
      "       90272.52946696, 90272.52946701, 90272.52946703, 90272.52946704]))\n",
      "           fun: 90272.52946674361\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1461\n",
      "           nit: 666\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.23123949e-02, 6.27163447e-03, 4.18681284e-02, 1.50217719e+03,\n",
      "       4.00664783e+03, 5.09986993e+03, 3.23227687e+03])\n",
      "best ll: 90497.28227752695, bestParams: [0.06955907, 0.049383625, 0.019450903, 993.1664, 3395.9521, 4111.0713, 3434.7034]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "        3.48913750e+03, 3.62500697e+03, 2.81886087e+03],\n",
      "       [4.14664508e-02, 3.51992356e-02, 3.96515439e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500699e+03, 2.81886085e+03],\n",
      "       [4.14664512e-02, 3.51992344e-02, 3.96515438e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500696e+03, 2.81886087e+03],\n",
      "       [4.14664522e-02, 3.51992339e-02, 3.96515431e-02, 1.18685429e+03,\n",
      "        3.48913748e+03, 3.62500698e+03, 2.81886091e+03],\n",
      "       [4.14664516e-02, 3.51992308e-02, 3.96515449e-02, 1.18685428e+03,\n",
      "        3.48913748e+03, 3.62500705e+03, 2.81886082e+03],\n",
      "       [4.14664515e-02, 3.51992312e-02, 3.96515447e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500707e+03, 2.81886080e+03],\n",
      "       [4.14664519e-02, 3.51992301e-02, 3.96515453e-02, 1.18685429e+03,\n",
      "        3.48913751e+03, 3.62500700e+03, 2.81886079e+03],\n",
      "       [4.14664531e-02, 3.51992354e-02, 3.96515419e-02, 1.18685429e+03,\n",
      "        3.48913745e+03, 3.62500700e+03, 2.81886093e+03]]), array([90173.52423769, 90173.52423776, 90173.52423781, 90173.52423785,\n",
      "       90173.52423792, 90173.52423796, 90173.52423814, 90173.52423952]))\n",
      "           fun: 90173.52423769064\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1084\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "       3.48913750e+03, 3.62500697e+03, 2.81886087e+03])\n",
      "minPrevious 90272.52946674361\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "        3.48913750e+03, 3.62500697e+03, 2.81886087e+03],\n",
      "       [4.14664508e-02, 3.51992356e-02, 3.96515439e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500699e+03, 2.81886085e+03],\n",
      "       [4.14664512e-02, 3.51992344e-02, 3.96515438e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500696e+03, 2.81886087e+03],\n",
      "       [4.14664522e-02, 3.51992339e-02, 3.96515431e-02, 1.18685429e+03,\n",
      "        3.48913748e+03, 3.62500698e+03, 2.81886091e+03],\n",
      "       [4.14664516e-02, 3.51992308e-02, 3.96515449e-02, 1.18685428e+03,\n",
      "        3.48913748e+03, 3.62500705e+03, 2.81886082e+03],\n",
      "       [4.14664515e-02, 3.51992312e-02, 3.96515447e-02, 1.18685429e+03,\n",
      "        3.48913749e+03, 3.62500707e+03, 2.81886080e+03],\n",
      "       [4.14664519e-02, 3.51992301e-02, 3.96515453e-02, 1.18685429e+03,\n",
      "        3.48913751e+03, 3.62500700e+03, 2.81886079e+03],\n",
      "       [4.14664531e-02, 3.51992354e-02, 3.96515419e-02, 1.18685429e+03,\n",
      "        3.48913745e+03, 3.62500700e+03, 2.81886093e+03]]), array([90173.52423769, 90173.52423776, 90173.52423781, 90173.52423785,\n",
      "       90173.52423792, 90173.52423796, 90173.52423814, 90173.52423952]))\n",
      "           fun: 90173.52423769064\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1084\n",
      "           nit: 418\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.14664503e-02, 3.51992338e-02, 3.96515445e-02, 1.18685429e+03,\n",
      "       3.48913750e+03, 3.62500697e+03, 2.81886087e+03])\n",
      "best ll: 90579.49768806256, bestParams: [0.03288942, 0.02397951, 0.07897693, 8103.033, 16135.493, 20025.127, 11541.397]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.42412644e-02, 2.66188892e-02, 4.06631400e-02, 6.36961886e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707348e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631401e-02, 6.36961884e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631400e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412646e-02, 2.66188891e-02, 4.06631403e-02, 6.36961884e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631402e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412645e-02, 2.66188891e-02, 4.06631403e-02, 6.36961883e+03,\n",
      "        1.97342763e+04, 2.11661146e+04, 1.37707349e+04],\n",
      "       [3.42412646e-02, 2.66188891e-02, 4.06631406e-02, 6.36961883e+03,\n",
      "        1.97342763e+04, 2.11661147e+04, 1.37707349e+04],\n",
      "       [3.42412644e-02, 2.66188891e-02, 4.06631404e-02, 6.36961883e+03,\n",
      "        1.97342764e+04, 2.11661147e+04, 1.37707348e+04]]), array([90179.97233838, 90179.9723385 , 90179.97233857, 90179.97233863,\n",
      "       90179.97233866, 90179.97233875, 90179.97233881, 90179.97233886]))\n",
      "           fun: 90179.97233838026\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1185\n",
      "           nit: 451\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.42412644e-02, 2.66188892e-02, 4.06631400e-02, 6.36961886e+03,\n",
      "       1.97342764e+04, 2.11661147e+04, 1.37707348e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90290.6061973017, bestParams: [0.03196858, 0.025042191, 0.034106273, 8508.276, 24321.596, 20359.771, 22960.518]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.41951284e-02, 2.69611168e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757822e+04],\n",
      "       [3.41951285e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951284e-02, 2.69611167e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "        2.34625869e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951286e-02, 2.69611168e-02, 3.76004125e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04],\n",
      "       [3.41951285e-02, 2.69611168e-02, 3.76004126e-02, 7.56702868e+03,\n",
      "        2.34625868e+04, 2.45893096e+04, 1.64757823e+04]]), array([90177.91638654, 90177.91638655, 90177.91638656, 90177.91638657,\n",
      "       90177.91638659, 90177.9163866 , 90177.9163866 , 90177.91638661]))\n",
      "           fun: 90177.91638654124\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1191\n",
      "           nit: 457\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.41951284e-02, 2.69611168e-02, 3.76004127e-02, 7.56702868e+03,\n",
      "       2.34625869e+04, 2.45893096e+04, 1.64757822e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90575.35435100387, bestParams: [0.0060032983, 0.026933348, 0.054366462, 7137.234, 10640.545, 9179.854, 21404.568]\n",
      "epoch 4\n",
      " final_simplex: (array([[8.03986655e-03, 2.82214893e-02, 4.14128756e-02, 4.25668422e+03,\n",
      "        1.54685785e+04, 1.41980696e+04, 6.95569755e+03],\n",
      "       [8.03986660e-03, 2.82214881e-02, 4.14128762e-02, 4.25668422e+03,\n",
      "        1.54685784e+04, 1.41980697e+04, 6.95569753e+03],\n",
      "       [8.03986647e-03, 2.82214902e-02, 4.14128754e-02, 4.25668422e+03,\n",
      "        1.54685786e+04, 1.41980695e+04, 6.95569755e+03],\n",
      "       [8.03986655e-03, 2.82214896e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569747e+03],\n",
      "       [8.03986653e-03, 2.82214897e-02, 4.14128750e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569756e+03],\n",
      "       [8.03986652e-03, 2.82214897e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685786e+04, 1.41980696e+04, 6.95569756e+03],\n",
      "       [8.03986652e-03, 2.82214894e-02, 4.14128750e-02, 4.25668422e+03,\n",
      "        1.54685785e+04, 1.41980696e+04, 6.95569755e+03],\n",
      "       [8.03986650e-03, 2.82214895e-02, 4.14128749e-02, 4.25668423e+03,\n",
      "        1.54685785e+04, 1.41980697e+04, 6.95569751e+03]]), array([90268.35024825, 90268.35024842, 90268.35024844, 90268.35024859,\n",
      "       90268.3502486 , 90268.3502487 , 90268.35024901, 90268.35024905]))\n",
      "           fun: 90268.35024824677\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1183\n",
      "           nit: 456\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.03986655e-03, 2.82214893e-02, 4.14128756e-02, 4.25668422e+03,\n",
      "       1.54685785e+04, 1.41980696e+04, 6.95569755e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90520.96658633223, bestParams: [0.006762284, 0.055848576, 0.053748373, 5909.411, 13514.936, 18434.523, 10014.059]\n",
      "epoch 5\n",
      " final_simplex: (array([[8.16848907e-03, 4.04653276e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848907e-03, 4.04653277e-02, 4.27240406e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848906e-03, 4.04653277e-02, 4.27240406e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751150e+04],\n",
      "       [8.16848904e-03, 4.04653280e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848902e-03, 4.04653284e-02, 4.27240407e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751149e+04],\n",
      "       [8.16848900e-03, 4.04653289e-02, 4.27240411e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453744e+04, 1.08751149e+04],\n",
      "       [8.16848899e-03, 4.04653285e-02, 4.27240409e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453745e+04, 1.08751150e+04],\n",
      "       [8.16848898e-03, 4.04653292e-02, 4.27240411e-02, 5.21143811e+03,\n",
      "        1.78493877e+04, 1.54453744e+04, 1.08751149e+04]]), array([90267.56486031, 90267.56486033, 90267.5648605 , 90267.56486061,\n",
      "       90267.56486088, 90267.56486105, 90267.56486109, 90267.56486112]))\n",
      "           fun: 90267.56486031177\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1342\n",
      "           nit: 543\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.16848907e-03, 4.04653276e-02, 4.27240407e-02, 5.21143812e+03,\n",
      "       1.78493877e+04, 1.54453745e+04, 1.08751149e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90581.20782424859, bestParams: [0.10886746, 0.06707341, 0.07024887, 10999.218, 23754.08, 24885.004, 19561.732]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.83275297e-02, 5.67416707e-02, 3.65272603e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573896e+04, 3.13480199e+04],\n",
      "       [4.83275299e-02, 5.67416707e-02, 3.65272602e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573896e+04, 3.13480199e+04],\n",
      "       [4.83275332e-02, 5.67416700e-02, 3.65272598e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480198e+04],\n",
      "       [4.83275290e-02, 5.67416709e-02, 3.65272605e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275295e-02, 5.67416707e-02, 3.65272600e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275297e-02, 5.67416707e-02, 3.65272600e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04],\n",
      "       [4.83275298e-02, 5.67416707e-02, 3.65272599e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480200e+04],\n",
      "       [4.83275303e-02, 5.67416706e-02, 3.65272598e-02, 1.05765347e+04,\n",
      "        2.91787862e+04, 2.91573897e+04, 3.13480199e+04]]), array([90189.04135044, 90189.04135049, 90189.0413505 , 90189.04135052,\n",
      "       90189.04135053, 90189.04135054, 90189.04135061, 90189.04135062]))\n",
      "           fun: 90189.04135044114\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1331\n",
      "           nit: 546\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83275297e-02, 5.67416707e-02, 3.65272603e-02, 1.05765347e+04,\n",
      "       2.91787862e+04, 2.91573896e+04, 3.13480199e+04])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90555.35314912771, bestParams: [0.075666025, 0.008240507, 0.07280902, 4451.4316, 14403.895, 18652.873, 7124.4673]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.75345528e-02, 1.18217802e-02, 4.36060567e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302072e+03],\n",
      "       [3.75345531e-02, 1.18217801e-02, 4.36060564e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302069e+03],\n",
      "       [3.75345538e-02, 1.18217800e-02, 4.36060561e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249052e+04, 8.93302064e+03],\n",
      "       [3.75345535e-02, 1.18217800e-02, 4.36060565e-02, 4.78113062e+03,\n",
      "        1.46175003e+04, 1.68249052e+04, 8.93302072e+03],\n",
      "       [3.75345529e-02, 1.18217799e-02, 4.36060556e-02, 4.78113062e+03,\n",
      "        1.46175004e+04, 1.68249053e+04, 8.93302074e+03],\n",
      "       [3.75345543e-02, 1.18217799e-02, 4.36060568e-02, 4.78113064e+03,\n",
      "        1.46175002e+04, 1.68249052e+04, 8.93302079e+03],\n",
      "       [3.75345536e-02, 1.18217798e-02, 4.36060554e-02, 4.78113063e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302072e+03],\n",
      "       [3.75345542e-02, 1.18217797e-02, 4.36060553e-02, 4.78113064e+03,\n",
      "        1.46175003e+04, 1.68249053e+04, 8.93302075e+03]]), array([90221.61895767, 90221.61895817, 90221.61895843, 90221.61895862,\n",
      "       90221.61895898, 90221.61895898, 90221.61895918, 90221.61895972]))\n",
      "           fun: 90221.61895766677\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1194\n",
      "           nit: 489\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.75345528e-02, 1.18217802e-02, 4.36060567e-02, 4.78113062e+03,\n",
      "       1.46175003e+04, 1.68249053e+04, 8.93302072e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90395.4796038286, bestParams: [0.06134892, 0.003452808, 0.03632547, 3497.0854, 10186.098, 13472.928, 3790.0637]\n",
      "epoch 8\n",
      " final_simplex: (array([[3.49284716e-02, 4.18222349e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580012e+03],\n",
      "       [3.49284732e-02, 4.18222342e-03, 4.69575910e-02, 3.10646349e+03,\n",
      "        9.64244548e+03, 1.13777085e+04, 4.91580008e+03],\n",
      "       [3.49284699e-02, 4.18222349e-03, 4.69575907e-02, 3.10646349e+03,\n",
      "        9.64244538e+03, 1.13777085e+04, 4.91580018e+03],\n",
      "       [3.49284715e-02, 4.18222344e-03, 4.69575909e-02, 3.10646349e+03,\n",
      "        9.64244541e+03, 1.13777085e+04, 4.91580014e+03],\n",
      "       [3.49284719e-02, 4.18222343e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "        9.64244541e+03, 1.13777085e+04, 4.91580014e+03],\n",
      "       [3.49284714e-02, 4.18222340e-03, 4.69575908e-02, 3.10646349e+03,\n",
      "        9.64244538e+03, 1.13777086e+04, 4.91580016e+03],\n",
      "       [3.49284753e-02, 4.18222328e-03, 4.69575913e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580006e+03],\n",
      "       [3.49284752e-02, 4.18222327e-03, 4.69575913e-02, 3.10646350e+03,\n",
      "        9.64244544e+03, 1.13777085e+04, 4.91580007e+03]]), array([90285.22832312, 90285.22832343, 90285.22832362, 90285.22832367,\n",
      "       90285.22832372, 90285.22832417, 90285.22832441, 90285.22832463]))\n",
      "           fun: 90285.22832312356\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1258\n",
      "           nit: 492\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.49284716e-02, 4.18222349e-03, 4.69575909e-02, 3.10646350e+03,\n",
      "       9.64244544e+03, 1.13777085e+04, 4.91580012e+03])\n",
      "minPrevious 90173.52423769064\n",
      "best ll: 90804.47701967844, bestParams: [0.02829881, 0.04583288, 0.060337245, 3230.8723, 12052.119, 7720.8174, 1496.0844]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809893e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809893e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809891e+03, 5.06995532e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809891e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167376e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995533e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995534e+03, 3.69568086e+03],\n",
      "       [3.10835390e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "        5.11809892e+03, 5.06995534e+03, 3.69568086e+03]]), array([90177.73267181, 90177.73267182, 90177.73267233, 90177.73267234,\n",
      "       90177.73267234, 90177.73267235, 90177.73267237, 90177.73267239]))\n",
      "           fun: 90177.73267181247\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1430\n",
      "           nit: 545\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.10835389e-02, 3.63167375e-02, 3.91209164e-02, 1.63866888e+03,\n",
      "       5.11809893e+03, 5.06995534e+03, 3.69568086e+03])\n",
      "minPrevious 90173.52423769064\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0415, 0.0352, 0.0397], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8723, 0.0624, 0.0276, 0.0250], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8661, 0.0763, 0.0259, 0.0318], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8843, 0.0280, 0.0639, 0.0256], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8633, 0.0259, 0.0792, 0.0316], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7430, 0.0978, 0.0982, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7028, 0.1122, 0.1146, 0.0705], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.4822, 2.8212, 6.3377],\n",
      "        [4.2235, 4.4837, 6.1296],\n",
      "        [1.2765, 2.0591, 4.8962],\n",
      "        ...,\n",
      "        [4.5062, 4.2377, 5.8085],\n",
      "        [1.4207, 1.4554, 5.4347],\n",
      "        [4.4840, 3.6525, 6.3723]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.543172121047974\n",
      "Run: 0, 4\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[49., 11.,  0.,  0.],\n",
      "        [39.,  2.,  1.,  1.],\n",
      "        [35.,  3.,  1.,  4.],\n",
      "        ...,\n",
      "        [42.,  4.,  2.,  0.],\n",
      "        [43.,  0.,  1.,  4.],\n",
      "        [55.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "n tensor([60., 43., 43.,  ..., 48., 48., 57.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([11.,  2.,  3.,  ...,  4.,  0.,  1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 4.,  ..., 0., 4., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[49., 11.,  0.,  0.],\n",
      "        [39.,  2.,  1.,  1.],\n",
      "        [35.,  3.,  1.,  4.],\n",
      "        ...,\n",
      "        [42.,  4.,  2.,  0.],\n",
      "        [43.,  0.,  1.,  4.],\n",
      "        [55.,  1.,  1.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([9.3661e-08, 2.4138e-02, 3.4307e-05,  ..., 4.7683e-03, 1.8925e-04,\n",
      "        5.4601e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3ed40>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91158.47332401684, bestParams: [0.014721362, 0.040411327, 0.04527418, 4070.2559, 20366.186, 16429.271, 14589.068]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.72872707e-02, 4.17161449e-02, 4.35534533e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534529e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514173e+04, 1.15286872e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534536e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514175e+04, 1.15286870e+04],\n",
      "       [1.72872708e-02, 4.17161450e-02, 4.35534534e-02, 5.36272838e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161450e-02, 4.35534530e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04],\n",
      "       [1.72872707e-02, 4.17161449e-02, 4.35534535e-02, 5.36272840e+03,\n",
      "        1.76994581e+04, 1.59514175e+04, 1.15286871e+04],\n",
      "       [1.72872706e-02, 4.17161451e-02, 4.35534529e-02, 5.36272841e+03,\n",
      "        1.76994581e+04, 1.59514173e+04, 1.15286872e+04],\n",
      "       [1.72872706e-02, 4.17161446e-02, 4.35534535e-02, 5.36272842e+03,\n",
      "        1.76994581e+04, 1.59514174e+04, 1.15286871e+04]]), array([90634.76874514, 90634.76874517, 90634.7687452 , 90634.76874525,\n",
      "       90634.76874526, 90634.76874527, 90634.76874536, 90634.76874539]))\n",
      "           fun: 90634.76874513857\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1217\n",
      "           nit: 489\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.72872707e-02, 4.17161449e-02, 4.35534533e-02, 5.36272840e+03,\n",
      "       1.76994581e+04, 1.59514174e+04, 1.15286871e+04])\n",
      "best ll: 91029.49863072427, bestParams: [0.000116868476, 0.083636425, 0.05230697, 6775.021, 20220.621, 12728.145, 23588.809]\n",
      "epoch 1\n",
      " final_simplex: (array([[1.18818834e-04, 8.64093273e-02, 5.59627736e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818831e-04, 8.64093286e-02, 5.59627736e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818831e-04, 8.64093282e-02, 5.59627739e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008582e+04],\n",
      "       [1.18818830e-04, 8.64093284e-02, 5.59627741e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818829e-04, 8.64093286e-02, 5.59627741e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008582e+04],\n",
      "       [1.18818827e-04, 8.64093296e-02, 5.59627742e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04],\n",
      "       [1.18818824e-04, 8.64093300e-02, 5.59627745e-02, 7.16703302e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008580e+04],\n",
      "       [1.18818824e-04, 8.64093304e-02, 5.59627745e-02, 7.16703301e+03,\n",
      "        1.82555166e+04, 1.55257759e+04, 1.81008581e+04]]), array([90829.02245938, 90829.02246006, 90829.02246008, 90829.02246026,\n",
      "       90829.02246044, 90829.02246087, 90829.02246132, 90829.02246156]))\n",
      "           fun: 90829.02245937861\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1663\n",
      "           nit: 713\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.18818834e-04, 8.64093273e-02, 5.59627736e-02, 7.16703301e+03,\n",
      "       1.82555166e+04, 1.55257759e+04, 1.81008581e+04])\n",
      "minPrevious 90634.76874513857\n",
      "best ll: 90847.93749848523, bestParams: [0.07447942, 0.020183373, 0.01751763, 5548.3296, 16806.486, 18398.387, 15708.237]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368230e+03],\n",
      "       [3.32608952e-02, 2.91607544e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786958e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598481e+04, 9.34368237e+03],\n",
      "       [3.32608968e-02, 2.91607543e-02, 3.74786956e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368236e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786957e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368233e+03],\n",
      "       [3.32608950e-02, 2.91607544e-02, 3.74786960e-02, 4.76599757e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608951e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117015e+04, 1.59598482e+04, 9.34368238e+03],\n",
      "       [3.32608951e-02, 2.91607543e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03]]), array([90610.2728004 , 90610.27280042, 90610.27280048, 90610.27280051,\n",
      "       90610.27280056, 90610.27280063, 90610.27280069, 90610.27280072]))\n",
      "           fun: 90610.27280040468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "       1.59117016e+04, 1.59598482e+04, 9.34368230e+03])\n",
      "minPrevious 90634.76874513857\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368230e+03],\n",
      "       [3.32608952e-02, 2.91607544e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786958e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598481e+04, 9.34368237e+03],\n",
      "       [3.32608968e-02, 2.91607543e-02, 3.74786956e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368236e+03],\n",
      "       [3.32608963e-02, 2.91607543e-02, 3.74786957e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368233e+03],\n",
      "       [3.32608950e-02, 2.91607544e-02, 3.74786960e-02, 4.76599757e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03],\n",
      "       [3.32608951e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "        1.59117015e+04, 1.59598482e+04, 9.34368238e+03],\n",
      "       [3.32608951e-02, 2.91607543e-02, 3.74786960e-02, 4.76599758e+03,\n",
      "        1.59117016e+04, 1.59598482e+04, 9.34368228e+03]]), array([90610.2728004 , 90610.27280042, 90610.27280048, 90610.27280051,\n",
      "       90610.27280056, 90610.27280063, 90610.27280069, 90610.27280072]))\n",
      "           fun: 90610.27280040468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32608955e-02, 2.91607544e-02, 3.74786959e-02, 4.76599758e+03,\n",
      "       1.59117016e+04, 1.59598482e+04, 9.34368230e+03])\n",
      "best ll: 90890.4621477907, bestParams: [0.028222447, 0.017594956, 0.0381772, 3712.175, 18208.807, 12144.222, 4784.1777]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.32745082e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086204e+03],\n",
      "       [3.32745080e-02, 2.12040114e-02, 4.29595582e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595581e-02, 3.36413636e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086202e+03],\n",
      "       [3.32745081e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742536e+04, 5.79086205e+03],\n",
      "       [3.32745080e-02, 2.12040113e-02, 4.29595581e-02, 3.36413636e+03,\n",
      "        1.12159341e+04, 1.19742537e+04, 5.79086204e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595582e-02, 3.36413635e+03,\n",
      "        1.12159340e+04, 1.19742537e+04, 5.79086205e+03],\n",
      "       [3.32745081e-02, 2.12040113e-02, 4.29595583e-02, 3.36413636e+03,\n",
      "        1.12159339e+04, 1.19742536e+04, 5.79086203e+03]]), array([90628.72181675, 90628.72181677, 90628.72181677, 90628.72181681,\n",
      "       90628.72181681, 90628.72181685, 90628.7218169 , 90628.7218169 ]))\n",
      "           fun: 90628.72181674631\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1181\n",
      "           nit: 436\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.32745082e-02, 2.12040114e-02, 4.29595581e-02, 3.36413635e+03,\n",
      "       1.12159340e+04, 1.19742536e+04, 5.79086204e+03])\n",
      "minPrevious 90610.27280040468\n",
      "best ll: 90804.34225338264, bestParams: [0.023374725, 0.09260894, 0.04005881, 8117.6123, 16497.006, 16204.368, 24964.37]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274795e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190240e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190239e-02, 3.86819772e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190242e-02, 3.86819771e-02, 6.92017778e+03,\n",
      "        2.38232316e+04, 2.13472490e+04, 1.47274796e+04],\n",
      "       [2.53037902e-02, 4.64190238e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472490e+04, 1.47274795e+04],\n",
      "       [2.53037902e-02, 4.64190240e-02, 3.86819774e-02, 6.92017779e+03,\n",
      "        2.38232317e+04, 2.13472489e+04, 1.47274796e+04]]), array([90610.97812776, 90610.97812779, 90610.9781278 , 90610.9781278 ,\n",
      "       90610.97812784, 90610.97812801, 90610.97814434, 90610.97814438]))\n",
      "           fun: 90610.97812776301\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1231\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.53037902e-02, 4.64190239e-02, 3.86819773e-02, 6.92017779e+03,\n",
      "       2.38232317e+04, 2.13472490e+04, 1.47274795e+04])\n",
      "minPrevious 90610.27280040468\n",
      "best ll: 91012.84705452244, bestParams: [0.06232762, 0.034690365, 0.038248792, 3659.6003, 12318.186, 6756.515, 8484.942]\n",
      "epoch 5\n",
      " final_simplex: (array([[4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861992e+03],\n",
      "       [4.83273467e-02, 4.23176213e-02, 4.03140866e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861993e+03],\n",
      "       [4.83273481e-02, 4.23176224e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273481e-02, 4.23176225e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273487e-02, 4.23176230e-02, 4.03140823e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862000e+03],\n",
      "       [4.83273490e-02, 4.23176232e-02, 4.03140817e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273491e-02, 4.23176233e-02, 4.03140815e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273494e-02, 4.23176235e-02, 4.03140810e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862002e+03]]), array([90604.5572683 , 90604.55726843, 90604.55726955, 90604.55726956,\n",
      "       90604.55727007, 90604.55727031, 90604.55727036, 90604.55727057]))\n",
      "           fun: 90604.5572682951\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 3106\n",
      "           nit: 1429\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "       9.51034532e+03, 9.65504541e+03, 7.93861992e+03])\n",
      "minPrevious 90610.27280040468\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861992e+03],\n",
      "       [4.83273467e-02, 4.23176213e-02, 4.03140866e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861993e+03],\n",
      "       [4.83273481e-02, 4.23176224e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273481e-02, 4.23176225e-02, 4.03140836e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93861998e+03],\n",
      "       [4.83273487e-02, 4.23176230e-02, 4.03140823e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862000e+03],\n",
      "       [4.83273490e-02, 4.23176232e-02, 4.03140817e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273491e-02, 4.23176233e-02, 4.03140815e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862001e+03],\n",
      "       [4.83273494e-02, 4.23176235e-02, 4.03140810e-02, 3.23135266e+03,\n",
      "        9.51034532e+03, 9.65504541e+03, 7.93862002e+03]]), array([90604.5572683 , 90604.55726843, 90604.55726955, 90604.55726956,\n",
      "       90604.55727007, 90604.55727031, 90604.55727036, 90604.55727057]))\n",
      "           fun: 90604.5572682951\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 3106\n",
      "           nit: 1429\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.83273465e-02, 4.23176212e-02, 4.03140869e-02, 3.23135266e+03,\n",
      "       9.51034532e+03, 9.65504541e+03, 7.93861992e+03])\n",
      "best ll: 90973.150105765, bestParams: [0.0043483237, 0.1723103, 0.063694075, 5563.539, 10523.814, 9726.051, 20610.318]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.48004476e-03, 1.69499920e-01, 6.10019645e-02, 5.98757017e+03,\n",
      "        1.11423656e+04, 9.44868017e+03, 1.84977817e+04],\n",
      "       [4.48004475e-03, 1.69499920e-01, 6.10019649e-02, 5.98757013e+03,\n",
      "        1.11423657e+04, 9.44868016e+03, 1.84977817e+04],\n",
      "       [4.48004478e-03, 1.69499921e-01, 6.10019649e-02, 5.98757011e+03,\n",
      "        1.11423657e+04, 9.44868014e+03, 1.84977817e+04],\n",
      "       [4.48004476e-03, 1.69499921e-01, 6.10019650e-02, 5.98757014e+03,\n",
      "        1.11423657e+04, 9.44868013e+03, 1.84977817e+04],\n",
      "       [4.48004475e-03, 1.69499922e-01, 6.10019654e-02, 5.98757014e+03,\n",
      "        1.11423656e+04, 9.44868012e+03, 1.84977818e+04],\n",
      "       [4.48004474e-03, 1.69499924e-01, 6.10019654e-02, 5.98757012e+03,\n",
      "        1.11423656e+04, 9.44868008e+03, 1.84977818e+04],\n",
      "       [4.48004471e-03, 1.69499924e-01, 6.10019651e-02, 5.98757016e+03,\n",
      "        1.11423657e+04, 9.44868010e+03, 1.84977816e+04],\n",
      "       [4.48004469e-03, 1.69499924e-01, 6.10019655e-02, 5.98757013e+03,\n",
      "        1.11423657e+04, 9.44868009e+03, 1.84977817e+04]]), array([90875.20110852, 90875.2011087 , 90875.20110879, 90875.20110889,\n",
      "       90875.20110966, 90875.20111022, 90875.2011103 , 90875.20111065]))\n",
      "           fun: 90875.20110852493\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1082\n",
      "           nit: 377\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.48004476e-03, 1.69499920e-01, 6.10019645e-02, 5.98757017e+03,\n",
      "       1.11423656e+04, 9.44868017e+03, 1.84977817e+04])\n",
      "minPrevious 90604.5572682951\n",
      "best ll: 91007.53714748367, bestParams: [0.03484704, 0.027896117, 0.062791444, 4148.296, 18361.578, 16205.281, 10942.79]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529420e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334977e+04],\n",
      "       [3.58243337e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111420e+04, 1.57094699e+04, 1.04334975e+04]]), array([90602.51359827, 90602.51359829, 90602.51359829, 90602.51359829,\n",
      "       90602.51359833, 90602.51359836, 90602.51359864, 90602.51360201]))\n",
      "           fun: 90602.51359826833\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1241\n",
      "           nit: 441\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "       1.57111421e+04, 1.57094699e+04, 1.04334976e+04])\n",
      "minPrevious 90604.5572682951\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094699e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529417e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334976e+04],\n",
      "       [3.58243336e-02, 3.34954072e-02, 4.44529420e-02, 4.96880825e+03,\n",
      "        1.57111421e+04, 1.57094698e+04, 1.04334977e+04],\n",
      "       [3.58243337e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "        1.57111420e+04, 1.57094699e+04, 1.04334975e+04]]), array([90602.51359827, 90602.51359829, 90602.51359829, 90602.51359829,\n",
      "       90602.51359833, 90602.51359836, 90602.51359864, 90602.51360201]))\n",
      "           fun: 90602.51359826833\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1241\n",
      "           nit: 441\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.58243336e-02, 3.34954072e-02, 4.44529416e-02, 4.96880825e+03,\n",
      "       1.57111421e+04, 1.57094699e+04, 1.04334976e+04])\n",
      "best ll: 91015.41612460106, bestParams: [0.12024945, 0.09470742, 0.06604782, 6515.7124, 9441.274, 11384.588, 14921.515]\n",
      "epoch 8\n",
      " final_simplex: (array([[1.15905749e-01, 8.86839476e-02, 6.41709445e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839473e-02, 6.41709447e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839465e-02, 6.41709450e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181450e+04, 1.75717270e+04],\n",
      "       [1.15905750e-01, 8.86839466e-02, 6.41709449e-02, 5.67383150e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839466e-02, 6.41709453e-02, 5.67383149e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839466e-02, 6.41709455e-02, 5.67383148e+03,\n",
      "        1.04222081e+04, 1.12181452e+04, 1.75717269e+04],\n",
      "       [1.15905749e-01, 8.86839461e-02, 6.41709455e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717270e+04],\n",
      "       [1.15905749e-01, 8.86839464e-02, 6.41709457e-02, 5.67383147e+03,\n",
      "        1.04222081e+04, 1.12181451e+04, 1.75717269e+04]]), array([90791.50925081, 90791.50925131, 90791.509252  , 90791.50925231,\n",
      "       90791.50925269, 90791.50925337, 90791.50925357, 90791.50925369]))\n",
      "           fun: 90791.50925081424\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1149\n",
      "           nit: 380\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.15905749e-01, 8.86839476e-02, 6.41709445e-02, 5.67383148e+03,\n",
      "       1.04222081e+04, 1.12181451e+04, 1.75717269e+04])\n",
      "minPrevious 90602.51359826833\n",
      "best ll: 91011.46463348175, bestParams: [0.06312266, 0.029164523, 0.039597854, 8029.851, 24910.959, 18420.938, 11092.687]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093559e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093560e-02, 3.06041703e-02, 4.03519653e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04],\n",
      "       [4.55093562e-02, 3.06041703e-02, 4.03519654e-02, 6.77126978e+03,\n",
      "        2.11833428e+04, 2.21593122e+04, 1.38361985e+04]]), array([90610.3734693 , 90610.37346932, 90610.37346938, 90610.37346949,\n",
      "       90610.3734696 , 90610.37346963, 90610.37346964, 90610.37346966]))\n",
      "           fun: 90610.37346929763\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2680\n",
      "           nit: 1248\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.55093558e-02, 3.06041703e-02, 4.03519652e-02, 6.77126978e+03,\n",
      "       2.11833428e+04, 2.21593122e+04, 1.38361985e+04])\n",
      "minPrevious 90602.51359826833\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0358, 0.0335, 0.0445], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8858, 0.0647, 0.0281, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8600, 0.0815, 0.0258, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8860, 0.0281, 0.0646, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8600, 0.0258, 0.0816, 0.0326], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7406, 0.0995, 0.0989, 0.0619], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7059, 0.1114, 0.1115, 0.0713], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.0054, 3.8620, 6.9140],\n",
      "        [2.8371, 3.1236, 4.0172],\n",
      "        [3.2060, 4.0941, 6.7157],\n",
      "        ...,\n",
      "        [2.7681, 3.9681, 4.6108],\n",
      "        [2.3565, 2.2976, 6.9109],\n",
      "        [2.9001, 2.6971, 4.8654]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.674013376235962\n",
      "Run: 0, 5\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  1.],\n",
      "        [51.,  2.,  1.,  1.],\n",
      "        [47.,  3.,  1.,  1.],\n",
      "        ...,\n",
      "        [48.,  2.,  3.,  1.],\n",
      "        [59.,  2.,  0.,  1.],\n",
      "        [63.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "n tensor([44., 55., 52.,  ..., 54., 62., 66.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 2., 3.,  ..., 2., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 3., 0., 3.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 1., 1.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  1.],\n",
      "        [51.,  2.,  1.,  1.],\n",
      "        [47.,  3.,  1.,  1.],\n",
      "        ...,\n",
      "        [48.,  2.,  3.,  1.],\n",
      "        [59.,  2.,  0.,  1.],\n",
      "        [63.,  0.,  3.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0248, 0.0290, 0.0136,  ..., 0.0106, 0.0165, 0.0126],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad035f0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 91090.3604514042, bestParams: [0.043571133, 0.095463604, 0.0505203, 5832.7603, 16079.994, 12313.426, 8391.266]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.59893537e-02, 5.64996138e-02, 4.31957835e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996138e-02, 4.31957836e-02, 5.33859644e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893539e-02, 5.64996138e-02, 4.31957834e-02, 5.33859642e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996138e-02, 4.31957836e-02, 5.33859643e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996140e-02, 4.31957838e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893536e-02, 5.64996140e-02, 4.31957838e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028399e+04],\n",
      "       [3.59893535e-02, 5.64996143e-02, 4.31957837e-02, 5.33859643e+03,\n",
      "        1.57706472e+04, 1.39949641e+04, 1.36028398e+04],\n",
      "       [3.59893536e-02, 5.64996143e-02, 4.31957839e-02, 5.33859643e+03,\n",
      "        1.57706471e+04, 1.39949641e+04, 1.36028398e+04]]), array([90799.07161255, 90799.07161264, 90799.07161274, 90799.07161275,\n",
      "       90799.07161278, 90799.0716128 , 90799.07161297, 90799.07161297]))\n",
      "           fun: 90799.07161254974\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 443\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.59893537e-02, 5.64996138e-02, 4.31957835e-02, 5.33859643e+03,\n",
      "       1.57706471e+04, 1.39949641e+04, 1.36028399e+04])\n",
      "best ll: 91093.57377619602, bestParams: [0.04420233, 0.06357479, 0.03340114, 4500.3525, 14206.233, 8924.385, 19454.049]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.49744082e-02, 6.21665645e-02, 4.15310181e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744086e-02, 6.21665646e-02, 4.15310186e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128040e+04],\n",
      "       [4.49744083e-02, 6.21665648e-02, 4.15310179e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128040e+04],\n",
      "       [4.49744083e-02, 6.21665651e-02, 4.15310180e-02, 4.61027368e+03,\n",
      "        1.30328999e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744086e-02, 6.21665651e-02, 4.15310186e-02, 4.61027367e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744088e-02, 6.21665655e-02, 4.15310183e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128039e+04],\n",
      "       [4.49744091e-02, 6.21665658e-02, 4.15310189e-02, 4.61027368e+03,\n",
      "        1.30329000e+04, 1.18758442e+04, 1.20128039e+04],\n",
      "       [4.49744092e-02, 6.21665660e-02, 4.15310189e-02, 4.61027367e+03,\n",
      "        1.30329000e+04, 1.18758441e+04, 1.20128039e+04]]), array([90804.01018453, 90804.01018466, 90804.01018486, 90804.01018504,\n",
      "       90804.01018508, 90804.01018544, 90804.01018563, 90804.0101859 ]))\n",
      "           fun: 90804.01018452992\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1264\n",
      "           nit: 490\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.49744082e-02, 6.21665645e-02, 4.15310181e-02, 4.61027368e+03,\n",
      "       1.30329000e+04, 1.18758442e+04, 1.20128039e+04])\n",
      "minPrevious 90799.07161254974\n",
      "best ll: 91258.20962960232, bestParams: [0.0017469097, 0.01823081, 0.084255494, 10602.629, 13127.086, 18705.941, 23800.89]\n",
      "epoch 2\n",
      " final_simplex: (array([[2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294313e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864185e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864181e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864183e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864182e+03],\n",
      "       [2.11020781e-03, 2.95814602e-02, 5.19149980e-02, 6.74294312e+03,\n",
      "        2.45263190e+04, 2.07048135e+04, 9.00864184e+03],\n",
      "       [2.11020782e-03, 2.95814602e-02, 5.19149978e-02, 6.74294313e+03,\n",
      "        2.45263191e+04, 2.07048135e+04, 9.00864183e+03]]), array([90955.06447395, 90955.06447396, 90955.06447396, 90955.06447397,\n",
      "       90955.06447398, 90955.06447399, 90955.06447401, 90955.06447402]))\n",
      "           fun: 90955.06447394771\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1358\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.11020781e-03, 2.95814602e-02, 5.19149981e-02, 6.74294313e+03,\n",
      "       2.45263190e+04, 2.07048135e+04, 9.00864185e+03])\n",
      "minPrevious 90799.07161254974\n",
      "best ll: 91230.90592004443, bestParams: [0.1362636, 0.18482453, 0.031719703, 2449.1853, 4716.1143, 3088.015, 11587.606]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "        7.21950271e+03, 6.88453503e+03, 5.45878630e+03],\n",
      "       [3.67651936e-02, 4.28943901e-02, 4.23365698e-02, 2.39682393e+03,\n",
      "        7.21950274e+03, 6.88453506e+03, 5.45878628e+03],\n",
      "       [3.67651929e-02, 4.28943907e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950270e+03, 6.88453500e+03, 5.45878628e+03],\n",
      "       [3.67651926e-02, 4.28943908e-02, 4.23365705e-02, 2.39682392e+03,\n",
      "        7.21950270e+03, 6.88453498e+03, 5.45878633e+03],\n",
      "       [3.67651912e-02, 4.28943931e-02, 4.23365699e-02, 2.39682394e+03,\n",
      "        7.21950278e+03, 6.88453496e+03, 5.45878628e+03],\n",
      "       [3.67651901e-02, 4.28943919e-02, 4.23365704e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453499e+03, 5.45878620e+03],\n",
      "       [3.67651903e-02, 4.28943912e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453498e+03, 5.45878626e+03],\n",
      "       [3.67651909e-02, 4.28943884e-02, 4.23365714e-02, 2.39682393e+03,\n",
      "        7.21950273e+03, 6.88453499e+03, 5.45878636e+03]]), array([90793.71585391, 90793.71585413, 90793.71585419, 90793.71585449,\n",
      "       90793.71585464, 90793.71585486, 90793.7158549 , 90793.7158549 ]))\n",
      "           fun: 90793.71585391468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1238\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "       7.21950271e+03, 6.88453503e+03, 5.45878630e+03])\n",
      "minPrevious 90799.07161254974\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "        7.21950271e+03, 6.88453503e+03, 5.45878630e+03],\n",
      "       [3.67651936e-02, 4.28943901e-02, 4.23365698e-02, 2.39682393e+03,\n",
      "        7.21950274e+03, 6.88453506e+03, 5.45878628e+03],\n",
      "       [3.67651929e-02, 4.28943907e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950270e+03, 6.88453500e+03, 5.45878628e+03],\n",
      "       [3.67651926e-02, 4.28943908e-02, 4.23365705e-02, 2.39682392e+03,\n",
      "        7.21950270e+03, 6.88453498e+03, 5.45878633e+03],\n",
      "       [3.67651912e-02, 4.28943931e-02, 4.23365699e-02, 2.39682394e+03,\n",
      "        7.21950278e+03, 6.88453496e+03, 5.45878628e+03],\n",
      "       [3.67651901e-02, 4.28943919e-02, 4.23365704e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453499e+03, 5.45878620e+03],\n",
      "       [3.67651903e-02, 4.28943912e-02, 4.23365706e-02, 2.39682394e+03,\n",
      "        7.21950277e+03, 6.88453498e+03, 5.45878626e+03],\n",
      "       [3.67651909e-02, 4.28943884e-02, 4.23365714e-02, 2.39682393e+03,\n",
      "        7.21950273e+03, 6.88453499e+03, 5.45878636e+03]]), array([90793.71585391, 90793.71585413, 90793.71585419, 90793.71585449,\n",
      "       90793.71585464, 90793.71585486, 90793.7158549 , 90793.7158549 ]))\n",
      "           fun: 90793.71585391468\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1238\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.67651934e-02, 4.28943884e-02, 4.23365712e-02, 2.39682395e+03,\n",
      "       7.21950271e+03, 6.88453503e+03, 5.45878630e+03])\n",
      "best ll: 91326.84358438406, bestParams: [0.02248766, 0.032484304, 0.052385617, 8575.685, 11063.958, 10108.009, 22795.377]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.84420417e-02, 3.46959567e-02, 4.26539702e-02, 4.46333716e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539702e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930251e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539704e-02, 4.46333716e+03,\n",
      "        1.44521197e+04, 1.37119075e+04, 9.14930251e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539703e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930248e+03],\n",
      "       [2.84420417e-02, 3.46959568e-02, 4.26539703e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930251e+03],\n",
      "       [2.84420416e-02, 3.46959568e-02, 4.26539705e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420416e-02, 3.46959568e-02, 4.26539705e-02, 4.46333715e+03,\n",
      "        1.44521197e+04, 1.37119076e+04, 9.14930242e+03],\n",
      "       [2.84420418e-02, 3.46959566e-02, 4.26539705e-02, 4.46333716e+03,\n",
      "        1.44521198e+04, 1.37119075e+04, 9.14930237e+03]]), array([90801.40632214, 90801.40632216, 90801.40632217, 90801.40632218,\n",
      "       90801.40632219, 90801.40632224, 90801.40632224, 90801.40632478]))\n",
      "           fun: 90801.40632214482\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1364\n",
      "           nit: 549\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.84420417e-02, 3.46959567e-02, 4.26539702e-02, 4.46333716e+03,\n",
      "       1.44521197e+04, 1.37119076e+04, 9.14930242e+03])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91152.77248384545, bestParams: [0.029007705, 0.047266837, 0.042739347, 3103.6965, 9688.097, 14387.982, 6064.706]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.05385898e-02, 4.40237968e-02, 4.16521419e-02, 3.36519154e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03],\n",
      "       [3.05385899e-02, 4.40237969e-02, 4.16521414e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845911e+03],\n",
      "       [3.05385899e-02, 4.40237970e-02, 4.16521414e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845912e+03],\n",
      "       [3.05385898e-02, 4.40237970e-02, 4.16521415e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845910e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521424e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845895e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521419e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845903e+03],\n",
      "       [3.05385894e-02, 4.40237969e-02, 4.16521421e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03],\n",
      "       [3.05385892e-02, 4.40237968e-02, 4.16521421e-02, 3.36519155e+03,\n",
      "        1.10735933e+04, 1.00880013e+04, 6.82845902e+03]]), array([90798.38403306, 90798.3840331 , 90798.38403313, 90798.38403316,\n",
      "       90798.38403323, 90798.38403329, 90798.3840333 , 90798.38403332]))\n",
      "           fun: 90798.38403306226\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1259\n",
      "           nit: 438\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.05385898e-02, 4.40237968e-02, 4.16521419e-02, 3.36519154e+03,\n",
      "       1.10735933e+04, 1.00880013e+04, 6.82845902e+03])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91270.70408583432, bestParams: [0.015127707, 0.041919302, 0.03150278, 4334.455, 22769.922, 24498.379, 190.21886]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.75785932e-02, 1.95895246e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895245e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233751e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895247e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785932e-02, 1.95895246e-02, 4.58603911e-02, 5.09205005e+03,\n",
      "        2.27880383e+04, 2.20233750e+04, 2.36272117e+02],\n",
      "       [1.75785931e-02, 1.95895251e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895251e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895247e-02, 4.58603912e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02],\n",
      "       [1.75785931e-02, 1.95895250e-02, 4.58603909e-02, 5.09205005e+03,\n",
      "        2.27880384e+04, 2.20233750e+04, 2.36272116e+02]]), array([90949.33571342, 90949.33571344, 90949.33571346, 90949.33571348,\n",
      "       90949.33571358, 90949.3357136 , 90949.3357136 , 90949.33571367]))\n",
      "           fun: 90949.33571342296\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1312\n",
      "           nit: 515\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.75785932e-02, 1.95895246e-02, 4.58603910e-02, 5.09205005e+03,\n",
      "       2.27880384e+04, 2.20233750e+04, 2.36272116e+02])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91344.40237445639, bestParams: [0.03907052, 0.037808415, 0.034087338, 9922.918, 22659.93, 13472.755, 21920.426]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.74444807e-02, 4.19909125e-02, 4.05683430e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04],\n",
      "       [3.74444808e-02, 4.19909125e-02, 4.05683430e-02, 6.81299451e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909126e-02, 4.05683430e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444807e-02, 4.19909125e-02, 4.05683429e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04],\n",
      "       [3.74444808e-02, 4.19909127e-02, 4.05683430e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909127e-02, 4.05683429e-02, 6.81299450e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444808e-02, 4.19909126e-02, 4.05683429e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412557e+04],\n",
      "       [3.74444807e-02, 4.19909125e-02, 4.05683428e-02, 6.81299449e+03,\n",
      "        2.13149873e+04, 2.03928135e+04, 1.47412558e+04]]), array([90794.23716006, 90794.23716007, 90794.23716007, 90794.23716008,\n",
      "       90794.23716009, 90794.23716009, 90794.2371601 , 90794.23716011]))\n",
      "           fun: 90794.2371600552\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1301\n",
      "           nit: 543\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.74444807e-02, 4.19909125e-02, 4.05683430e-02, 6.81299449e+03,\n",
      "       2.13149873e+04, 2.03928135e+04, 1.47412558e+04])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91361.03540276109, bestParams: [0.045425393, 0.07026239, 0.050605606, 5734.493, 18005.092, 5601.4487, 22472.11]\n",
      "epoch 8\n",
      " final_simplex: (array([[5.31215249e-02, 7.05228155e-02, 4.47838949e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215248e-02, 7.05228156e-02, 4.47838951e-02, 4.51425556e+03,\n",
      "        1.17898264e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228154e-02, 4.47838952e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215251e-02, 7.05228153e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228152e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215250e-02, 7.05228154e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898264e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215251e-02, 7.05228155e-02, 4.47838954e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939908e+04],\n",
      "       [5.31215252e-02, 7.05228155e-02, 4.47838958e-02, 4.51425556e+03,\n",
      "        1.17898265e+04, 1.08016156e+04, 1.24939907e+04]]), array([90817.22476695, 90817.22476704, 90817.22476722, 90817.22476724,\n",
      "       90817.22476725, 90817.22476726, 90817.22476734, 90817.22476763]))\n",
      "           fun: 90817.22476694567\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1196\n",
      "           nit: 465\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.31215249e-02, 7.05228155e-02, 4.47838949e-02, 4.51425556e+03,\n",
      "       1.17898265e+04, 1.08016156e+04, 1.24939908e+04])\n",
      "minPrevious 90793.71585391468\n",
      "best ll: 91309.75771624263, bestParams: [0.02029038, 0.014870982, 0.010115627, 4392.174, 19204.947, 19952.209, 9782.406]\n",
      "epoch 9\n",
      " final_simplex: (array([[2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587151e+02,\n",
      "        8.13689375e+02, 7.66991520e+02, 4.17404243e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689369e+02, 7.66991516e+02, 4.17404245e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689365e+02, 7.66991513e+02, 4.17404247e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587150e+02,\n",
      "        8.13689378e+02, 7.66991522e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587148e+02,\n",
      "        8.13689380e+02, 7.66991520e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587147e+02,\n",
      "        8.13689364e+02, 7.66991510e+02, 4.17404239e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587146e+02,\n",
      "        8.13689362e+02, 7.66991506e+02, 4.17404237e+02],\n",
      "       [2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587146e+02,\n",
      "        8.13689362e+02, 7.66991507e+02, 4.17404237e+02]]), array([90811.60778462, 90811.60778465, 90811.60778467, 90811.60778474,\n",
      "       90811.60778501, 90811.60778518, 90811.60778533, 90811.60778536]))\n",
      "           fun: 90811.60778462133\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1301\n",
      "           nit: 541\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.15077192e-02, 2.71528440e-02, 4.09891428e-02, 2.41587151e+02,\n",
      "       8.13689375e+02, 7.66991520e+02, 4.17404243e+02])\n",
      "minPrevious 90793.71585391468\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0368, 0.0429, 0.0423], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8815, 0.0637, 0.0279, 0.0255], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8660, 0.0782, 0.0259, 0.0299], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8880, 0.0282, 0.0649, 0.0260], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8691, 0.0260, 0.0749, 0.0299], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7411, 0.0987, 0.0971, 0.0616], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7086, 0.1125, 0.1095, 0.0694], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9130, 3.9638, 4.5806],\n",
      "        [4.8477, 3.1204, 4.6859],\n",
      "        [2.5043, 3.4648, 5.4998],\n",
      "        ...,\n",
      "        [2.2138, 3.9310, 6.0372],\n",
      "        [3.0004, 1.5042, 4.5456],\n",
      "        [3.2652, 3.3443, 5.2215]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.484266996383667\n",
      "Run: 0, 6\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[51.,  4.,  1.,  2.],\n",
      "        [40.,  2.,  0.,  0.],\n",
      "        [55.,  3.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  1.,  2.,  1.],\n",
      "        [59.,  0.,  4.,  0.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([58., 42., 61.,  ..., 52., 63., 44.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 2., 3.,  ..., 1., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 0., 2.,  ..., 2., 4., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 1.,  ..., 1., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[51.,  4.,  1.,  2.],\n",
      "        [40.,  2.,  0.,  0.],\n",
      "        [55.,  3.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  1.,  2.,  1.],\n",
      "        [59.,  0.,  4.,  0.],\n",
      "        [41.,  1.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0020, 0.0418, 0.0140,  ..., 0.0283, 0.0060, 0.0503],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7cad03950>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90705.78630343798, bestParams: [0.042797178, 0.03189743, 0.0427665, 7865.0444, 19529.307, 18785.924, 20957.984]\n",
      "epoch 0\n",
      " final_simplex: (array([[4.53094590e-02, 3.29430425e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289733e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675401e-02, 7.16461646e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718439e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718441e+04],\n",
      "       [4.53094589e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04],\n",
      "       [4.53094590e-02, 3.29430424e-02, 4.13675400e-02, 7.16461645e+03,\n",
      "        2.07289734e+04, 2.24192353e+04, 1.77718440e+04]]), array([90617.68016446, 90617.68016449, 90617.68016451, 90617.68016452,\n",
      "       90617.68016454, 90617.68016455, 90617.68016455, 90617.68016455]))\n",
      "           fun: 90617.68016446201\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1139\n",
      "           nit: 416\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.53094590e-02, 3.29430425e-02, 4.13675399e-02, 7.16461645e+03,\n",
      "       2.07289734e+04, 2.24192353e+04, 1.77718440e+04])\n",
      "best ll: 91238.05435765057, bestParams: [0.05948744, 0.04102097, 0.013038766, 4660.9634, 18500.773, 21041.572, 23418.262]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.42696088e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799659e+03],\n",
      "       [3.42696092e-02, 3.41024516e-02, 3.87974592e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799652e+03],\n",
      "       [3.42696087e-02, 3.41024514e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799661e+03],\n",
      "       [3.42696086e-02, 3.41024513e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799663e+03],\n",
      "       [3.42696086e-02, 3.41024513e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799663e+03],\n",
      "       [3.42696085e-02, 3.41024512e-02, 3.87974590e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799664e+03],\n",
      "       [3.42696089e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799657e+03],\n",
      "       [3.42696082e-02, 3.41024511e-02, 3.87974589e-02, 4.56798217e+03,\n",
      "        1.46360708e+04, 1.49596490e+04, 9.92799669e+03]]), array([90618.91761162, 90618.91761169, 90618.91761169, 90618.91761183,\n",
      "       90618.91761185, 90618.91761194, 90618.91761205, 90618.91761219]))\n",
      "           fun: 90618.91761162136\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1909\n",
      "           nit: 848\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.42696088e-02, 3.41024514e-02, 3.87974591e-02, 4.56798217e+03,\n",
      "       1.46360708e+04, 1.49596490e+04, 9.92799659e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90799.13652237343, bestParams: [0.08314967, 0.07155339, 0.06358579, 7604.4014, 13512.055, 14740.179, 23051.545]\n",
      "epoch 2\n",
      " final_simplex: (array([[8.04633027e-02, 7.18090937e-02, 5.02449341e-02, 7.23852176e+03,\n",
      "        1.58024603e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633030e-02, 7.18090935e-02, 5.02449344e-02, 7.23852175e+03,\n",
      "        1.58024603e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633039e-02, 7.18090933e-02, 5.02449343e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286440e+04],\n",
      "       [8.04633037e-02, 7.18090932e-02, 5.02449345e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286440e+04],\n",
      "       [8.04633047e-02, 7.18090929e-02, 5.02449349e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633055e-02, 7.18090926e-02, 5.02449354e-02, 7.23852177e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04],\n",
      "       [8.04633062e-02, 7.18090923e-02, 5.02449354e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840773e+04, 2.23286441e+04],\n",
      "       [8.04633062e-02, 7.18090921e-02, 5.02449357e-02, 7.23852176e+03,\n",
      "        1.58024604e+04, 1.67840772e+04, 2.23286441e+04]]), array([90698.9332218 , 90698.93322237, 90698.93322263, 90698.93322275,\n",
      "       90698.933224  , 90698.93322516, 90698.93322544, 90698.93322595]))\n",
      "           fun: 90698.93322179955\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1389\n",
      "           nit: 554\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.04633027e-02, 7.18090937e-02, 5.02449341e-02, 7.23852176e+03,\n",
      "       1.58024603e+04, 1.67840772e+04, 2.23286441e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91004.02822016623, bestParams: [0.16847368, 0.006867244, 0.057000216, 9718.201, 20643.424, 24615.924, 21438.463]\n",
      "epoch 3\n",
      " final_simplex: (array([[1.02033897e-01, 7.74125429e-03, 5.54624499e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125427e-03, 5.54624498e-02, 9.58666804e+03,\n",
      "        1.95816961e+04, 2.80791649e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033898e-01, 7.74125426e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624499e-02, 9.58666804e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624498e-02, 9.58666805e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624498e-02, 9.58666804e+03,\n",
      "        1.95816961e+04, 2.80791648e+04, 2.53911261e+04],\n",
      "       [1.02033897e-01, 7.74125428e-03, 5.54624500e-02, 9.58666803e+03,\n",
      "        1.95816962e+04, 2.80791648e+04, 2.53911261e+04]]), array([90777.40346946, 90777.40346956, 90777.40346965, 90777.40347029,\n",
      "       90777.40348193, 90777.40348194, 90777.40348196, 90777.40348204]))\n",
      "           fun: 90777.40346946282\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1171\n",
      "           nit: 404\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.02033897e-01, 7.74125429e-03, 5.54624499e-02, 9.58666803e+03,\n",
      "       1.95816962e+04, 2.80791648e+04, 2.53911261e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91187.95797366982, bestParams: [0.025342675, 0.00792712, 0.07620231, 7194.6675, 7506.416, 14323.318, 16886.123]\n",
      "epoch 4\n",
      " final_simplex: (array([[4.70038040e-02, 1.84890042e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "        7.18730002e+03, 8.35538060e+03, 5.06572632e+03],\n",
      "       [4.70038039e-02, 1.84890042e-02, 4.10251852e-02, 2.37962911e+03,\n",
      "        7.18730004e+03, 8.35538056e+03, 5.06572636e+03],\n",
      "       [4.70038041e-02, 1.84890043e-02, 4.10251854e-02, 2.37962910e+03,\n",
      "        7.18729996e+03, 8.35538056e+03, 5.06572631e+03],\n",
      "       [4.70038043e-02, 1.84890043e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "        7.18729999e+03, 8.35538061e+03, 5.06572625e+03],\n",
      "       [4.70038041e-02, 1.84890041e-02, 4.10251853e-02, 2.37962912e+03,\n",
      "        7.18730005e+03, 8.35538060e+03, 5.06572628e+03],\n",
      "       [4.70038039e-02, 1.84890042e-02, 4.10251854e-02, 2.37962909e+03,\n",
      "        7.18730002e+03, 8.35538059e+03, 5.06572628e+03],\n",
      "       [4.70038044e-02, 1.84890041e-02, 4.10251855e-02, 2.37962911e+03,\n",
      "        7.18729996e+03, 8.35538050e+03, 5.06572636e+03],\n",
      "       [4.70038042e-02, 1.84890042e-02, 4.10251853e-02, 2.37962910e+03,\n",
      "        7.18729999e+03, 8.35538054e+03, 5.06572629e+03]]), array([90641.67199394, 90641.67199403, 90641.6719941 , 90641.67199412,\n",
      "       90641.67199429, 90641.67199461, 90641.67199472, 90641.67199474]))\n",
      "           fun: 90641.67199393519\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1292\n",
      "           nit: 503\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.70038040e-02, 1.84890042e-02, 4.10251854e-02, 2.37962911e+03,\n",
      "       7.18730002e+03, 8.35538060e+03, 5.06572632e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90934.9975112686, bestParams: [0.059806045, 0.055613108, 0.043168016, 2348.8328, 6146.4946, 8322.338, 10317.607]\n",
      "epoch 5\n",
      " final_simplex: (array([[5.42056891e-02, 4.70911906e-02, 4.19282268e-02, 2.83251915e+03,\n",
      "        7.79437423e+03, 8.19122192e+03, 7.15410411e+03],\n",
      "       [5.42056896e-02, 4.70911906e-02, 4.19282266e-02, 2.83251915e+03,\n",
      "        7.79437421e+03, 8.19122190e+03, 7.15410413e+03],\n",
      "       [5.42056846e-02, 4.70911897e-02, 4.19282289e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122191e+03, 7.15410401e+03],\n",
      "       [5.42056853e-02, 4.70911896e-02, 4.19282286e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122192e+03, 7.15410403e+03],\n",
      "       [5.42056859e-02, 4.70911898e-02, 4.19282282e-02, 2.83251916e+03,\n",
      "        7.79437423e+03, 8.19122191e+03, 7.15410403e+03],\n",
      "       [5.42056850e-02, 4.70911905e-02, 4.19282288e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122186e+03, 7.15410404e+03],\n",
      "       [5.42056864e-02, 4.70911897e-02, 4.19282281e-02, 2.83251916e+03,\n",
      "        7.79437420e+03, 8.19122190e+03, 7.15410405e+03],\n",
      "       [5.42056863e-02, 4.70911901e-02, 4.19282281e-02, 2.83251916e+03,\n",
      "        7.79437421e+03, 8.19122190e+03, 7.15410405e+03]]), array([90626.22011514, 90626.22011537, 90626.22012032, 90626.22012065,\n",
      "       90626.22012113, 90626.22012132, 90626.22012138, 90626.22012175]))\n",
      "           fun: 90626.22011513563\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1256\n",
      "           nit: 501\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.42056891e-02, 4.70911906e-02, 4.19282268e-02, 2.83251915e+03,\n",
      "       7.79437423e+03, 8.19122192e+03, 7.15410411e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90970.36604372214, bestParams: [0.054490186, 0.02661631, 0.0485164, 5726.952, 16087.912, 22577.627, 24207.025]\n",
      "epoch 6\n",
      " final_simplex: (array([[5.10958411e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958412e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636176e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958411e-02, 3.04632786e-02, 4.19672827e-02, 7.06673511e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958418e-02, 3.04632787e-02, 4.19672826e-02, 7.06673511e+03,\n",
      "        1.98636178e+04, 2.25615731e+04, 1.60116670e+04],\n",
      "       [5.10958411e-02, 3.04632785e-02, 4.19672830e-02, 7.06673513e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116672e+04],\n",
      "       [5.10958419e-02, 3.04632787e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "        1.98636176e+04, 2.25615731e+04, 1.60116671e+04],\n",
      "       [5.10958414e-02, 3.04632786e-02, 4.19672828e-02, 7.06673512e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04],\n",
      "       [5.10958415e-02, 3.04632785e-02, 4.19672829e-02, 7.06673512e+03,\n",
      "        1.98636177e+04, 2.25615730e+04, 1.60116671e+04]]), array([90621.57495985, 90621.57495994, 90621.57496008, 90621.57496039,\n",
      "       90621.5749604 , 90621.57496041, 90621.57496041, 90621.57496047]))\n",
      "           fun: 90621.57495984525\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1245\n",
      "           nit: 492\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.10958411e-02, 3.04632789e-02, 4.19672824e-02, 7.06673511e+03,\n",
      "       1.98636177e+04, 2.25615730e+04, 1.60116671e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90804.903153182, bestParams: [0.014491759, 0.01909757, 0.026884345, 5839.411, 24984.732, 21505.56, 5679.6772]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.54264133e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "        8.02301535e+03, 8.15135230e+03, 5.64047497e+03],\n",
      "       [3.54264126e-02, 3.62265995e-02, 4.01003738e-02, 2.57159949e+03,\n",
      "        8.02301536e+03, 8.15135231e+03, 5.64047505e+03],\n",
      "       [3.54264131e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "        8.02301538e+03, 8.15135232e+03, 5.64047498e+03],\n",
      "       [3.54264143e-02, 3.62266000e-02, 4.01003715e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047488e+03],\n",
      "       [3.54264139e-02, 3.62266001e-02, 4.01003719e-02, 2.57159949e+03,\n",
      "        8.02301538e+03, 8.15135232e+03, 5.64047489e+03],\n",
      "       [3.54264141e-02, 3.62266000e-02, 4.01003716e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047490e+03],\n",
      "       [3.54264137e-02, 3.62265999e-02, 4.01003720e-02, 2.57159949e+03,\n",
      "        8.02301533e+03, 8.15135230e+03, 5.64047495e+03],\n",
      "       [3.54264137e-02, 3.62266000e-02, 4.01003719e-02, 2.57159949e+03,\n",
      "        8.02301537e+03, 8.15135233e+03, 5.64047494e+03]]), array([90617.76238034, 90617.76238038, 90617.76238043, 90617.76238056,\n",
      "       90617.76238057, 90617.7623806 , 90617.76238062, 90617.7623807 ]))\n",
      "           fun: 90617.76238033785\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1396\n",
      "           nit: 595\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.54264133e-02, 3.62265998e-02, 4.01003732e-02, 2.57159949e+03,\n",
      "       8.02301535e+03, 8.15135230e+03, 5.64047497e+03])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 91071.9845670912, bestParams: [0.031488296, 0.07208441, 0.074685715, 6185.3647, 13709.426, 18131.521, 23476.797]\n",
      "epoch 8\n",
      " final_simplex: (array([[4.05461957e-02, 6.34717350e-02, 4.05830887e-02, 6.92152710e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461958e-02, 6.34717351e-02, 4.05830884e-02, 6.92152710e+03,\n",
      "        1.97748038e+04, 1.88326454e+04, 1.90989072e+04],\n",
      "       [4.05461960e-02, 6.34717351e-02, 4.05830884e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989071e+04],\n",
      "       [4.05461959e-02, 6.34717351e-02, 4.05830885e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461962e-02, 6.34717354e-02, 4.05830879e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989071e+04],\n",
      "       [4.05461953e-02, 6.34717350e-02, 4.05830889e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461959e-02, 6.34717353e-02, 4.05830882e-02, 6.92152708e+03,\n",
      "        1.97748038e+04, 1.88326455e+04, 1.90989072e+04],\n",
      "       [4.05461954e-02, 6.34717352e-02, 4.05830887e-02, 6.92152709e+03,\n",
      "        1.97748038e+04, 1.88326454e+04, 1.90989073e+04]]), array([90642.89946052, 90642.89946059, 90642.8994606 , 90642.89946067,\n",
      "       90642.89946078, 90642.89946086, 90642.89946098, 90642.899461  ]))\n",
      "           fun: 90642.89946051945\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1339\n",
      "           nit: 563\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.05461957e-02, 6.34717350e-02, 4.05830887e-02, 6.92152710e+03,\n",
      "       1.97748038e+04, 1.88326455e+04, 1.90989072e+04])\n",
      "minPrevious 90617.68016446201\n",
      "best ll: 90978.47709523376, bestParams: [0.052268486, 0.059164874, 0.029479917, 3384.196, 9466.865, 13828.556, 13715.061]\n",
      "epoch 9\n",
      " final_simplex: (array([[4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228951e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202685e+03],\n",
      "       [4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202684e+03],\n",
      "       [4.94145725e-02, 3.66047327e-02, 4.05901828e-02, 4.08228951e+03,\n",
      "        1.18931871e+04, 1.29963842e+04, 9.45202687e+03],\n",
      "       [4.94145723e-02, 3.66047329e-02, 4.05901829e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202687e+03],\n",
      "       [4.94145725e-02, 3.66047330e-02, 4.05901828e-02, 4.08228951e+03,\n",
      "        1.18931871e+04, 1.29963842e+04, 9.45202685e+03],\n",
      "       [4.94145724e-02, 3.66047332e-02, 4.05901828e-02, 4.08228952e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202689e+03],\n",
      "       [4.94145725e-02, 3.66047332e-02, 4.05901829e-02, 4.08228951e+03,\n",
      "        1.18931870e+04, 1.29963842e+04, 9.45202689e+03],\n",
      "       [4.94145724e-02, 3.66047334e-02, 4.05901830e-02, 4.08228952e+03,\n",
      "        1.18931871e+04, 1.29963843e+04, 9.45202682e+03]]), array([90618.74920601, 90618.74920613, 90618.74920624, 90618.74920633,\n",
      "       90618.74920639, 90618.74920644, 90618.74920651, 90618.7492066 ]))\n",
      "           fun: 90618.74920601156\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1229\n",
      "           nit: 488\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.94145723e-02, 3.66047322e-02, 4.05901830e-02, 4.08228951e+03,\n",
      "       1.18931870e+04, 1.29963842e+04, 9.45202685e+03])\n",
      "minPrevious 90617.68016446201\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0453, 0.0329, 0.0414], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8794, 0.0631, 0.0279, 0.0253], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8663, 0.0752, 0.0260, 0.0325], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8795, 0.0279, 0.0647, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8611, 0.0258, 0.0808, 0.0323], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7352, 0.0984, 0.0988, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.6986, 0.1126, 0.1175, 0.0713], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.1919, 3.2663, 5.4709],\n",
      "        [4.1986, 3.8897, 7.2400],\n",
      "        [3.3917, 2.4035, 5.7041],\n",
      "        ...,\n",
      "        [4.9667, 4.5339, 5.2203],\n",
      "        [3.8287, 3.7274, 4.9386],\n",
      "        [3.6731, 2.6413, 5.4393]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 17.216406106948853\n",
      "Run: 0, 7\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[57.,  3.,  2.,  0.],\n",
      "        [54.,  1.,  1.,  0.],\n",
      "        [40.,  2.,  2.,  3.],\n",
      "        ...,\n",
      "        [59.,  0.,  1.,  0.],\n",
      "        [57.,  2.,  0.,  2.],\n",
      "        [46.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([62., 56., 47.,  ..., 60., 61., 48.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 1., 2.,  ..., 0., 2., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 2.,  ..., 1., 0., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 0., 3.,  ..., 0., 2., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[57.,  3.,  2.,  0.],\n",
      "        [54.,  1.,  1.,  0.],\n",
      "        [40.,  2.,  2.,  3.],\n",
      "        ...,\n",
      "        [59.,  0.,  1.,  0.],\n",
      "        [57.,  2.,  0.,  2.],\n",
      "        [46.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0211, 0.0565, 0.0007,  ..., 0.0278, 0.0058, 0.0361],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7d8437830>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90698.00966445002, bestParams: [0.03601381, 0.05376842, 0.037697803, 4858.81, 17559.475, 15117.588, 10296.187]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695246e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397107e-02, 5.12695245e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708269e-02, 4.24062757e-02, 4.20397107e-02, 5.12695246e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498577e+04],\n",
      "       [3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695247e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498577e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397106e-02, 5.12695245e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062758e-02, 4.20397103e-02, 5.12695247e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062756e-02, 4.20397105e-02, 5.12695248e+03,\n",
      "        1.55116198e+04, 1.47037155e+04, 1.20498578e+04],\n",
      "       [3.70708268e-02, 4.24062755e-02, 4.20397105e-02, 5.12695246e+03,\n",
      "        1.55116197e+04, 1.47037155e+04, 1.20498578e+04]]), array([90642.85781501, 90642.85781503, 90642.85781505, 90642.85781506,\n",
      "       90642.85781507, 90642.8578153 , 90642.85781912, 90642.85781919]))\n",
      "           fun: 90642.85781500832\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1221\n",
      "           nit: 451\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.70708269e-02, 4.24062757e-02, 4.20397106e-02, 5.12695246e+03,\n",
      "       1.55116198e+04, 1.47037155e+04, 1.20498578e+04])\n",
      "best ll: 90989.10931874896, bestParams: [0.055018455, 0.058657233, 0.013274319, 6479.689, 24181.266, 18899.627, 20080.443]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.85959234e-02, 2.70830341e-02, 3.75888685e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959248e-02, 2.70830345e-02, 3.75888666e-02, 5.60836646e+03,\n",
      "        1.79338975e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959256e-02, 2.70830349e-02, 3.75888652e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959263e-02, 2.70830352e-02, 3.75888641e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154940e+04],\n",
      "       [3.85959273e-02, 2.70830354e-02, 3.75888626e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959274e-02, 2.70830356e-02, 3.75888624e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959275e-02, 2.70830356e-02, 3.75888623e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154939e+04],\n",
      "       [3.85959273e-02, 2.70830360e-02, 3.75888620e-02, 5.60836646e+03,\n",
      "        1.79338974e+04, 1.86206826e+04, 1.15154940e+04]]), array([90650.21241961, 90650.21242353, 90650.21242637, 90650.21242847,\n",
      "       90650.21243156, 90650.21243183, 90650.21243221, 90650.2124325 ]))\n",
      "           fun: 90650.21241961051\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1903\n",
      "           nit: 830\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.85959234e-02, 2.70830341e-02, 3.75888685e-02, 5.60836646e+03,\n",
      "       1.79338974e+04, 1.86206826e+04, 1.15154939e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91231.4553234166, bestParams: [0.0892526, 0.12577815, 0.064923555, 8575.71, 16426.484, 17164.031, 13682.164]\n",
      "epoch 2\n",
      " final_simplex: (array([[6.24537414e-02, 6.15992439e-02, 4.87048961e-02, 8.10050348e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666122e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537410e-02, 6.15992442e-02, 4.87048963e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537408e-02, 6.15992444e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385009e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537410e-02, 6.15992443e-02, 4.87048963e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048964e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667490e+04, 2.46666122e+04],\n",
      "       [6.24537413e-02, 6.15992439e-02, 4.87048963e-02, 8.10050348e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666121e+04],\n",
      "       [6.24537407e-02, 6.15992445e-02, 4.87048965e-02, 8.10050349e+03,\n",
      "        1.87385010e+04, 1.77667491e+04, 2.46666122e+04]]), array([90678.49280484, 90678.49280488, 90678.49280488, 90678.4928049 ,\n",
      "       90678.49280491, 90678.49280492, 90678.49280495, 90678.49280495]))\n",
      "           fun: 90678.49280484293\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1336\n",
      "           nit: 527\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.24537414e-02, 6.15992439e-02, 4.87048961e-02, 8.10050348e+03,\n",
      "       1.87385010e+04, 1.77667491e+04, 2.46666122e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91162.11827079224, bestParams: [0.028731208, 0.08052614, 0.038748782, 6678.704, 9787.624, 20217.812, 20754.006]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.70904892e-02, 3.81834950e-02, 4.32858909e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550785e+04, 1.31698874e+04],\n",
      "       [3.70904891e-02, 3.81834947e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550785e+04, 1.31698875e+04],\n",
      "       [3.70904891e-02, 3.81834950e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339736e+04, 1.72550784e+04, 1.31698875e+04],\n",
      "       [3.70904892e-02, 3.81834948e-02, 4.32858908e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698873e+04],\n",
      "       [3.70904892e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698874e+04],\n",
      "       [3.70904891e-02, 3.81834949e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550785e+04, 1.31698875e+04],\n",
      "       [3.70904891e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550784e+04, 1.31698874e+04],\n",
      "       [3.70904890e-02, 3.81834948e-02, 4.32858907e-02, 5.98454029e+03,\n",
      "        1.81339737e+04, 1.72550784e+04, 1.31698875e+04]]), array([90642.60568465, 90642.60568466, 90642.60568467, 90642.60568468,\n",
      "       90642.60568469, 90642.60568473, 90642.60568474, 90642.60568475]))\n",
      "           fun: 90642.60568464609\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1275\n",
      "           nit: 507\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.70904892e-02, 3.81834950e-02, 4.32858909e-02, 5.98454029e+03,\n",
      "       1.81339736e+04, 1.72550785e+04, 1.31698874e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91382.86227142713, bestParams: [0.061809793, 0.19442773, 0.026268564, 4953.1294, 21892.15, 9520.106, 16782.123]\n",
      "epoch 4\n",
      " final_simplex: (array([[6.27800301e-02, 1.23767454e-01, 3.50697812e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800298e-02, 1.23767455e-01, 3.50697812e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800299e-02, 1.23767454e-01, 3.50697811e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604067e+04],\n",
      "       [6.27800297e-02, 1.23767455e-01, 3.50697811e-02, 5.48175073e+03,\n",
      "        1.28766665e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767454e-01, 3.50697811e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767455e-01, 3.50697810e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604065e+04],\n",
      "       [6.27800302e-02, 1.23767454e-01, 3.50697809e-02, 5.48175073e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04],\n",
      "       [6.27800300e-02, 1.23767455e-01, 3.50697810e-02, 5.48175072e+03,\n",
      "        1.28766666e+04, 1.04008147e+04, 1.94604066e+04]]), array([90777.06158995, 90777.06159034, 90777.06159078, 90777.0615909 ,\n",
      "       90777.06159123, 90777.06159134, 90777.06159178, 90777.06159179]))\n",
      "           fun: 90777.06158994799\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1222\n",
      "           nit: 491\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.27800301e-02, 1.23767454e-01, 3.50697812e-02, 5.48175072e+03,\n",
      "       1.28766666e+04, 1.04008147e+04, 1.94604066e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91244.41189886695, bestParams: [0.10861425, 0.073448956, 0.058375053, 7751.9844, 24126.418, 15650.825, 13502.183]\n",
      "epoch 5\n",
      " final_simplex: (array([[4.98106413e-02, 4.31442532e-02, 4.55770178e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106415e-02, 4.31442537e-02, 4.55770179e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106417e-02, 4.31442545e-02, 4.55770180e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106419e-02, 4.31442552e-02, 4.55770181e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106422e-02, 4.31442562e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106423e-02, 4.31442564e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106423e-02, 4.31442564e-02, 4.55770183e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04],\n",
      "       [4.98106424e-02, 4.31442567e-02, 4.55770184e-02, 8.17344313e+03,\n",
      "        2.22304248e+04, 2.16693584e+04, 2.17261576e+04]]), array([90645.14444341, 90645.14444347, 90645.14444356, 90645.14444367,\n",
      "       90645.14444379, 90645.14444382, 90645.14444382, 90645.14444386]))\n",
      "           fun: 90645.14444341193\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 4867\n",
      "           nit: 2501\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.98106413e-02, 4.31442532e-02, 4.55770178e-02, 8.17344313e+03,\n",
      "       2.22304248e+04, 2.16693584e+04, 2.17261576e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 90929.83437789878, bestParams: [0.042998888, 0.0036338635, 0.08923576, 6261.846, 20105.752, 21534.959, 8484.541]\n",
      "epoch 6\n",
      " final_simplex: (array([[4.07350802e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004541e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790768e-03, 4.90472196e-02, 6.49933175e+03,\n",
      "        1.96476728e+04, 2.31004541e+04, 1.06442170e+04],\n",
      "       [4.07350803e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350800e-02, 4.32790766e-03, 4.90472198e-02, 6.49933176e+03,\n",
      "        1.96476727e+04, 2.31004541e+04, 1.06442172e+04],\n",
      "       [4.07350800e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476727e+04, 2.31004541e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790766e-03, 4.90472196e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350804e-02, 4.32790766e-03, 4.90472196e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04],\n",
      "       [4.07350801e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "        1.96476728e+04, 2.31004540e+04, 1.06442171e+04]]), array([90729.51111848, 90729.51111852, 90729.51111854, 90729.51111854,\n",
      "       90729.51111856, 90729.51111859, 90729.51111859, 90729.51111861]))\n",
      "           fun: 90729.51111847878\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1384\n",
      "           nit: 534\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.07350802e-02, 4.32790766e-03, 4.90472197e-02, 6.49933176e+03,\n",
      "       1.96476728e+04, 2.31004541e+04, 1.06442171e+04])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 91338.66029620953, bestParams: [0.029967176, 0.105418496, 0.045315336, 5352.596, 2545.1953, 7796.2197, 16043.894]\n",
      "epoch 7\n",
      " final_simplex: (array([[3.44726379e-02, 3.49043068e-02, 4.37101311e-02, 2.02821194e+03,\n",
      "        6.23612173e+03, 6.14653739e+03, 4.45542382e+03],\n",
      "       [3.44726355e-02, 3.49043034e-02, 4.37101328e-02, 2.02821196e+03,\n",
      "        6.23612174e+03, 6.14653748e+03, 4.45542375e+03],\n",
      "       [3.44726365e-02, 3.49043101e-02, 4.37101292e-02, 2.02821195e+03,\n",
      "        6.23612173e+03, 6.14653742e+03, 4.45542384e+03],\n",
      "       [3.44726357e-02, 3.49043114e-02, 4.37101301e-02, 2.02821195e+03,\n",
      "        6.23612168e+03, 6.14653744e+03, 4.45542382e+03],\n",
      "       [3.44726353e-02, 3.49043095e-02, 4.37101309e-02, 2.02821194e+03,\n",
      "        6.23612172e+03, 6.14653741e+03, 4.45542374e+03],\n",
      "       [3.44726354e-02, 3.49043147e-02, 4.37101280e-02, 2.02821196e+03,\n",
      "        6.23612170e+03, 6.14653740e+03, 4.45542391e+03],\n",
      "       [3.44726344e-02, 3.49043115e-02, 4.37101279e-02, 2.02821195e+03,\n",
      "        6.23612180e+03, 6.14653744e+03, 4.45542372e+03],\n",
      "       [3.44726337e-02, 3.49043122e-02, 4.37101303e-02, 2.02821194e+03,\n",
      "        6.23612172e+03, 6.14653737e+03, 4.45542377e+03]]), array([90642.45046539, 90642.45046608, 90642.45046658, 90642.45046711,\n",
      "       90642.45046727, 90642.45046771, 90642.45046814, 90642.45046855]))\n",
      "           fun: 90642.45046539283\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1428\n",
      "           nit: 638\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.44726379e-02, 3.49043068e-02, 4.37101311e-02, 2.02821194e+03,\n",
      "       6.23612173e+03, 6.14653739e+03, 4.45542382e+03])\n",
      "minPrevious 90642.85781500832\n",
      "best ll: 90822.19754322112, bestParams: [0.010888182, 0.014153072, 0.046646245, 3893.9783, 13470.374, 10266.924, 8581.38]\n",
      "epoch 8\n",
      " final_simplex: (array([[3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "        1.12126544e+03, 1.14623685e+03, 8.33927990e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580955e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623686e+03, 8.33927984e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903620e+02,\n",
      "        1.12126543e+03, 1.14623683e+03, 8.33927991e+02],\n",
      "       [3.82086249e-02, 3.13148454e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623682e+03, 8.33927983e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623684e+03, 8.33927993e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903611e+02,\n",
      "        1.12126540e+03, 1.14623683e+03, 8.33927973e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903626e+02,\n",
      "        1.12126544e+03, 1.14623684e+03, 8.33928033e+02],\n",
      "       [3.82086251e-02, 3.13148453e-02, 4.25580949e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623685e+03, 8.33928012e+02]]), array([90635.50396325, 90635.5039651 , 90635.5039652 , 90635.50396555,\n",
      "       90635.50396556, 90635.50396586, 90635.50397008, 90635.50397061]))\n",
      "           fun: 90635.50396325192\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 561\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "       1.12126544e+03, 1.14623685e+03, 8.33927990e+02])\n",
      "minPrevious 90642.85781500832\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "        1.12126544e+03, 1.14623685e+03, 8.33927990e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580955e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623686e+03, 8.33927984e+02],\n",
      "       [3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903620e+02,\n",
      "        1.12126543e+03, 1.14623683e+03, 8.33927991e+02],\n",
      "       [3.82086249e-02, 3.13148454e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623682e+03, 8.33927983e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580953e-02, 3.78903615e+02,\n",
      "        1.12126541e+03, 1.14623684e+03, 8.33927993e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903611e+02,\n",
      "        1.12126540e+03, 1.14623683e+03, 8.33927973e+02],\n",
      "       [3.82086249e-02, 3.13148453e-02, 4.25580952e-02, 3.78903626e+02,\n",
      "        1.12126544e+03, 1.14623684e+03, 8.33928033e+02],\n",
      "       [3.82086251e-02, 3.13148453e-02, 4.25580949e-02, 3.78903621e+02,\n",
      "        1.12126543e+03, 1.14623685e+03, 8.33928012e+02]]), array([90635.50396325, 90635.5039651 , 90635.5039652 , 90635.50396555,\n",
      "       90635.50396556, 90635.50396586, 90635.50397008, 90635.50397061]))\n",
      "           fun: 90635.50396325192\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 561\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.82086248e-02, 3.13148453e-02, 4.25580954e-02, 3.78903623e+02,\n",
      "       1.12126544e+03, 1.14623685e+03, 8.33927990e+02])\n",
      "best ll: 90795.9848434706, bestParams: [0.023895113, 0.04085701, 0.05497067, 7981.157, 15722.58, 17191.658, 21199.53]\n",
      "epoch 9\n",
      " final_simplex: (array([[2.82889394e-02, 4.02806717e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889394e-02, 4.02806719e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889396e-02, 4.02806716e-02, 4.32251584e-02, 6.71342930e+03,\n",
      "        2.14952765e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889396e-02, 4.02806717e-02, 4.32251585e-02, 6.71342930e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889395e-02, 4.02806717e-02, 4.32251589e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889396e-02, 4.02806717e-02, 4.32251583e-02, 6.71342930e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04],\n",
      "       [2.82889395e-02, 4.02806718e-02, 4.32251588e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146669e+04],\n",
      "       [2.82889395e-02, 4.02806717e-02, 4.32251587e-02, 6.71342931e+03,\n",
      "        2.14952764e+04, 1.98861867e+04, 1.47146670e+04]]), array([90649.70138782, 90649.70138796, 90649.70139572, 90649.70139578,\n",
      "       90649.70139578, 90649.70139579, 90649.7013958 , 90649.7013958 ]))\n",
      "           fun: 90649.70138781719\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1123\n",
      "           nit: 377\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.82889394e-02, 4.02806717e-02, 4.32251591e-02, 6.71342931e+03,\n",
      "       2.14952764e+04, 1.98861867e+04, 1.47146669e+04])\n",
      "minPrevious 90635.50396325192\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0382, 0.0313, 0.0426], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8729, 0.0646, 0.0277, 0.0258], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8656, 0.0769, 0.0261, 0.0314], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8894, 0.0282, 0.0649, 0.0259], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8639, 0.0260, 0.0787, 0.0314], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7354, 0.0989, 0.0981, 0.0615], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7093, 0.1098, 0.1113, 0.0696], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.0017, 4.0782, 5.5325],\n",
      "        [2.8935, 2.9939, 5.7539],\n",
      "        [3.9443, 2.9939, 5.9781],\n",
      "        ...,\n",
      "        [4.9808, 4.8651, 7.1442],\n",
      "        [3.4877, 2.3421, 6.7752],\n",
      "        [2.0068, 2.9318, 5.2629]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.899680852890015\n",
      "Run: 0, 8\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[32.,  4.,  0.,  2.],\n",
      "        [48.,  2.,  2.,  0.],\n",
      "        [50.,  7.,  1.,  3.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [49.,  0.,  1.,  1.],\n",
      "        [50.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "n tensor([38., 52., 61.,  ..., 70., 51., 53.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([4., 2., 7.,  ..., 0., 0., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 1.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 0., 3.,  ..., 2., 1., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[32.,  4.,  0.,  2.],\n",
      "        [48.,  2.,  2.,  0.],\n",
      "        [50.,  7.,  1.,  3.],\n",
      "        ...,\n",
      "        [66.,  0.,  2.,  2.],\n",
      "        [49.,  0.,  1.,  1.],\n",
      "        [50.,  1.,  1.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([3.4400e-04, 3.5403e-02, 9.0049e-06,  ..., 5.4883e-03, 2.6479e-02,\n",
      "        3.8102e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe7d8437680>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90866.38670202054, bestParams: [0.04227104, 0.043204933, 0.035604723, 4999.505, 6446.358, 10356.963, 18687.867]\n",
      "epoch 0\n",
      " final_simplex: (array([[3.78586233e-02, 4.97323902e-02, 4.39350770e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147190e+04, 8.49245920e+03],\n",
      "       [3.78586235e-02, 4.97323902e-02, 4.39350773e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147190e+04, 8.49245919e+03],\n",
      "       [3.78586232e-02, 4.97323905e-02, 4.39350767e-02, 3.58313190e+03,\n",
      "        1.04477020e+04, 1.02147190e+04, 8.49245911e+03],\n",
      "       [3.78586227e-02, 4.97323902e-02, 4.39350774e-02, 3.58313190e+03,\n",
      "        1.04477020e+04, 1.02147191e+04, 8.49245916e+03],\n",
      "       [3.78586228e-02, 4.97323899e-02, 4.39350782e-02, 3.58313192e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245925e+03],\n",
      "       [3.78586223e-02, 4.97323901e-02, 4.39350782e-02, 3.58313191e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245913e+03],\n",
      "       [3.78586225e-02, 4.97323904e-02, 4.39350773e-02, 3.58313189e+03,\n",
      "        1.04477020e+04, 1.02147191e+04, 8.49245911e+03],\n",
      "       [3.78586225e-02, 4.97323902e-02, 4.39350780e-02, 3.58313191e+03,\n",
      "        1.04477019e+04, 1.02147191e+04, 8.49245913e+03]]), array([90487.06109292, 90487.06109304, 90487.06109312, 90487.06109314,\n",
      "       90487.06109322, 90487.06109331, 90487.06109333, 90487.06109339]))\n",
      "           fun: 90487.06109292197\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1122\n",
      "           nit: 395\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.78586233e-02, 4.97323902e-02, 4.39350770e-02, 3.58313192e+03,\n",
      "       1.04477019e+04, 1.02147190e+04, 8.49245920e+03])\n",
      "best ll: 90778.79449381144, bestParams: [0.08165928, 0.087960355, 0.063273296, 6014.191, 7127.5513, 11117.987, 22590.318]\n",
      "epoch 1\n",
      " final_simplex: (array([[8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994274e-02, 7.17538081e-02, 4.81073032e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994274e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118784e+04],\n",
      "       [8.64994276e-02, 7.17538080e-02, 4.81073031e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04],\n",
      "       [8.64994276e-02, 7.17538083e-02, 4.81073030e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04],\n",
      "       [8.64994279e-02, 7.17538081e-02, 4.81073029e-02, 5.31945629e+03,\n",
      "        1.14898833e+04, 1.26010591e+04, 1.55118783e+04]]), array([90562.47709194, 90562.47709201, 90562.47709202, 90562.47709211,\n",
      "       90562.47709213, 90562.47709218, 90562.47709236, 90562.47709241]))\n",
      "           fun: 90562.47709193993\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1227\n",
      "           nit: 471\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.64994273e-02, 7.17538082e-02, 4.81073031e-02, 5.31945630e+03,\n",
      "       1.14898833e+04, 1.26010591e+04, 1.55118784e+04])\n",
      "minPrevious 90487.06109292197\n",
      "best ll: 90970.5610899757, bestParams: [0.09997445, 0.12198489, 0.051259637, 7826.5796, 23443.818, 14464.848, 18766.902]\n",
      "epoch 2\n",
      " final_simplex: (array([[8.71740907e-02, 9.11163488e-02, 5.16494257e-02, 8.27206657e+03,\n",
      "        1.61201928e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740909e-02, 9.11163489e-02, 5.16494256e-02, 8.27206655e+03,\n",
      "        1.61201928e+04, 1.78121709e+04, 2.57831929e+04],\n",
      "       [8.71740908e-02, 9.11163492e-02, 5.16494255e-02, 8.27206658e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740912e-02, 9.11163500e-02, 5.16494251e-02, 8.27206657e+03,\n",
      "        1.61201928e+04, 1.78121709e+04, 2.57831930e+04],\n",
      "       [8.71740911e-02, 9.11163504e-02, 5.16494251e-02, 8.27206659e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740911e-02, 9.11163502e-02, 5.16494252e-02, 8.27206659e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740914e-02, 9.11163510e-02, 5.16494248e-02, 8.27206657e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831930e+04],\n",
      "       [8.71740915e-02, 9.11163513e-02, 5.16494247e-02, 8.27206658e+03,\n",
      "        1.61201929e+04, 1.78121708e+04, 2.57831931e+04]]), array([90589.73553078, 90589.73553096, 90589.73553098, 90589.73553157,\n",
      "       90589.73553194, 90589.73553196, 90589.73553245, 90589.73553278]))\n",
      "           fun: 90589.73553077558\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1493\n",
      "           nit: 613\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([8.71740907e-02, 9.11163488e-02, 5.16494257e-02, 8.27206657e+03,\n",
      "       1.61201928e+04, 1.78121708e+04, 2.57831930e+04])\n",
      "minPrevious 90487.06109292197\n",
      "best ll: 90702.98167128472, bestParams: [0.03473026, 0.046426747, 0.061863348, 9696.083, 24623.559, 19582.648, 17360.992]\n",
      "epoch 3\n",
      " final_simplex: (array([[3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639317e-02, 4.45271009e-02, 4.57781923e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639318e-02, 4.45271006e-02, 4.57781931e-02, 8.53728467e+03,\n",
      "        2.49527256e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639319e-02, 4.45271002e-02, 4.57781944e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639321e-02, 4.45270995e-02, 4.57781964e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639323e-02, 4.45270990e-02, 4.57781979e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639324e-02, 4.45270989e-02, 4.57781981e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966649e+04, 1.98905847e+04],\n",
      "       [3.66639324e-02, 4.45270987e-02, 4.57781989e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04]]), array([90482.69509499, 90482.69509598, 90482.69509679, 90482.69509802,\n",
      "       90482.69510007, 90482.69510157, 90482.69510186, 90482.69510255]))\n",
      "           fun: 90482.69509499139\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1646\n",
      "           nit: 743\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "       2.49527257e+04, 2.45966650e+04, 1.98905847e+04])\n",
      "minPrevious 90487.06109292197\n",
      "better by at >= 1; new ll:  final_simplex: (array([[3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639317e-02, 4.45271009e-02, 4.57781923e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639318e-02, 4.45271006e-02, 4.57781931e-02, 8.53728467e+03,\n",
      "        2.49527256e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639319e-02, 4.45271002e-02, 4.57781944e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639321e-02, 4.45270995e-02, 4.57781964e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04],\n",
      "       [3.66639323e-02, 4.45270990e-02, 4.57781979e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905848e+04],\n",
      "       [3.66639324e-02, 4.45270989e-02, 4.57781981e-02, 8.53728467e+03,\n",
      "        2.49527257e+04, 2.45966649e+04, 1.98905847e+04],\n",
      "       [3.66639324e-02, 4.45270987e-02, 4.57781989e-02, 8.53728468e+03,\n",
      "        2.49527257e+04, 2.45966650e+04, 1.98905847e+04]]), array([90482.69509499, 90482.69509598, 90482.69509679, 90482.69509802,\n",
      "       90482.69510007, 90482.69510157, 90482.69510186, 90482.69510255]))\n",
      "           fun: 90482.69509499139\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1646\n",
      "           nit: 743\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.66639317e-02, 4.45271012e-02, 4.57781913e-02, 8.53728467e+03,\n",
      "       2.49527257e+04, 2.45966650e+04, 1.98905847e+04])\n",
      "best ll: 90867.56193183556, bestParams: [0.0098387115, 0.062886804, 0.053461675, 6239.042, 23488.914, 22569.387, 434.96948]\n",
      "epoch 4\n",
      " final_simplex: (array([[1.15378583e-02, 2.04791823e-02, 4.61124020e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670302e+04, 6.11843483e+02],\n",
      "       [1.15378583e-02, 2.04791820e-02, 4.61124014e-02, 5.84323512e+03,\n",
      "        2.64481986e+04, 2.49670302e+04, 6.11843490e+02],\n",
      "       [1.15378582e-02, 2.04791827e-02, 4.61124012e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843491e+02],\n",
      "       [1.15378581e-02, 2.04791822e-02, 4.61124010e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843498e+02],\n",
      "       [1.15378580e-02, 2.04791818e-02, 4.61124008e-02, 5.84323512e+03,\n",
      "        2.64481986e+04, 2.49670302e+04, 6.11843501e+02],\n",
      "       [1.15378578e-02, 2.04791817e-02, 4.61124003e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843513e+02],\n",
      "       [1.15378578e-02, 2.04791814e-02, 4.61124005e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670301e+04, 6.11843513e+02],\n",
      "       [1.15378578e-02, 2.04791806e-02, 4.61124008e-02, 5.84323512e+03,\n",
      "        2.64481985e+04, 2.49670302e+04, 6.11843515e+02]]), array([90612.29504722, 90612.29504755, 90612.29504758, 90612.29504799,\n",
      "       90612.29504825, 90612.29504873, 90612.29504883, 90612.29504907]))\n",
      "           fun: 90612.29504722435\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1277\n",
      "           nit: 481\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.15378583e-02, 2.04791823e-02, 4.61124020e-02, 5.84323512e+03,\n",
      "       2.64481985e+04, 2.49670302e+04, 6.11843483e+02])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90725.9879271773, bestParams: [0.043563887, 0.012296107, 0.08686379, 4552.979, 12478.696, 12336.921, 8655.909]\n",
      "epoch 5\n",
      " final_simplex: (array([[3.38270526e-02, 2.14812023e-02, 4.24158900e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403708e+03],\n",
      "       [3.38270531e-02, 2.14812022e-02, 4.24158901e-02, 4.15356910e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403705e+03],\n",
      "       [3.38270544e-02, 2.14812014e-02, 4.24158909e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212583e+04, 6.94403701e+03],\n",
      "       [3.38270549e-02, 2.14812012e-02, 4.24158914e-02, 4.15356913e+03,\n",
      "        1.34924801e+04, 1.44212583e+04, 6.94403698e+03],\n",
      "       [3.38270561e-02, 2.14812008e-02, 4.24158918e-02, 4.15356911e+03,\n",
      "        1.34924801e+04, 1.44212582e+04, 6.94403707e+03],\n",
      "       [3.38270559e-02, 2.14812006e-02, 4.24158918e-02, 4.15356913e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403715e+03],\n",
      "       [3.38270568e-02, 2.14812003e-02, 4.24158922e-02, 4.15356911e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403715e+03],\n",
      "       [3.38270567e-02, 2.14812002e-02, 4.24158924e-02, 4.15356912e+03,\n",
      "        1.34924800e+04, 1.44212582e+04, 6.94403709e+03]]), array([90506.88456244, 90506.8845628 , 90506.88456515, 90506.88456571,\n",
      "       90506.88456661, 90506.8845673 , 90506.8845681 , 90506.88456827]))\n",
      "           fun: 90506.88456243879\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1294\n",
      "           nit: 525\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.38270526e-02, 2.14812023e-02, 4.24158900e-02, 4.15356911e+03,\n",
      "       1.34924801e+04, 1.44212582e+04, 6.94403708e+03])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90707.96802735567, bestParams: [0.01074106, 0.056317706, 0.062326808, 6906.7803, 14660.881, 12282.025, 20889.7]\n",
      "epoch 6\n",
      " final_simplex: (array([[1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948854e-02, 4.49989146e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948855e-02, 4.49989148e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948855e-02, 4.49989147e-02, 5.80778321e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778318e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948857e-02, 4.49989150e-02, 5.80778323e+03,\n",
      "        1.99696317e+04, 1.68266748e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948856e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266749e+04, 1.13317168e+04],\n",
      "       [1.54083838e-02, 5.45948856e-02, 4.49989148e-02, 5.80778320e+03,\n",
      "        1.99696318e+04, 1.68266748e+04, 1.13317168e+04]]), array([90513.85897781, 90513.85897782, 90513.85897782, 90513.8589779 ,\n",
      "       90513.85897801, 90513.85897812, 90513.85897819, 90513.85897819]))\n",
      "           fun: 90513.85897780894\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1223\n",
      "           nit: 484\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.54083839e-02, 5.45948854e-02, 4.49989147e-02, 5.80778320e+03,\n",
      "       1.99696318e+04, 1.68266749e+04, 1.13317168e+04])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 91208.12679174251, bestParams: [0.018939186, 0.13372447, 0.09658249, 7547.9326, 16754.46, 12379.46, 9450.32]\n",
      "epoch 7\n",
      " final_simplex: (array([[2.38771336e-02, 4.86939481e-02, 4.37289625e-02, 6.16011838e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658889e+04],\n",
      "       [2.38771335e-02, 4.86939479e-02, 4.37289625e-02, 6.16011839e+03,\n",
      "        1.88306626e+04, 1.72063936e+04, 1.41658889e+04],\n",
      "       [2.38771332e-02, 4.86939487e-02, 4.37289632e-02, 6.16011841e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771331e-02, 4.86939495e-02, 4.37289634e-02, 6.16011841e+03,\n",
      "        1.88306626e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771334e-02, 4.86939500e-02, 4.37289621e-02, 6.16011839e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771332e-02, 4.86939498e-02, 4.37289632e-02, 6.16011840e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771332e-02, 4.86939496e-02, 4.37289630e-02, 6.16011839e+03,\n",
      "        1.88306625e+04, 1.72063936e+04, 1.41658888e+04],\n",
      "       [2.38771331e-02, 4.86939479e-02, 4.37289631e-02, 6.16011840e+03,\n",
      "        1.88306626e+04, 1.72063937e+04, 1.41658888e+04]]), array([90493.66767072, 90493.66767083, 90493.667671  , 90493.66767111,\n",
      "       90493.66767112, 90493.66767118, 90493.66767124, 90493.66767134]))\n",
      "           fun: 90493.6676707186\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1261\n",
      "           nit: 515\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.38771336e-02, 4.86939481e-02, 4.37289625e-02, 6.16011838e+03,\n",
      "       1.88306625e+04, 1.72063936e+04, 1.41658889e+04])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90946.33073211275, bestParams: [0.06552671, 0.03858188, 0.027416045, 5274.589, 17153.447, 15913.322, 3718.8213]\n",
      "epoch 8\n",
      " final_simplex: (array([[2.66046495e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111184e+03],\n",
      "       [2.66046496e-02, 3.30193378e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046496e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046495e-02, 3.30193379e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111182e+03],\n",
      "       [2.66046494e-02, 3.30193379e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060088e+04, 6.71111183e+03],\n",
      "       [2.66046494e-02, 3.30193379e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314351e+04, 1.28060088e+04, 6.71111184e+03],\n",
      "       [2.66046493e-02, 3.30193377e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "        1.31314350e+04, 1.28060087e+04, 6.71111188e+03],\n",
      "       [2.66046494e-02, 3.30193377e-02, 4.58178952e-02, 3.89486732e+03,\n",
      "        1.31314350e+04, 1.28060087e+04, 6.71111185e+03]]), array([90491.11260967, 90491.11260969, 90491.1126097 , 90491.11260972,\n",
      "       90491.11260973, 90491.11260974, 90491.11260981, 90491.11260981]))\n",
      "           fun: 90491.11260967342\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1209\n",
      "           nit: 424\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.66046495e-02, 3.30193378e-02, 4.58178952e-02, 3.89486731e+03,\n",
      "       1.31314350e+04, 1.28060088e+04, 6.71111184e+03])\n",
      "minPrevious 90482.69509499139\n",
      "best ll: 90979.13690442877, bestParams: [0.03663157, 0.05130152, 0.088229544, 6370.648, 15553.35, 12778.411, 7697.9907]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.97788087e-02, 4.67508439e-02, 4.20900894e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412336e+04],\n",
      "       [3.97788089e-02, 4.67508438e-02, 4.20900895e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412336e+04],\n",
      "       [3.97788088e-02, 4.67508436e-02, 4.20900896e-02, 5.37312917e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412336e+04],\n",
      "       [3.97788087e-02, 4.67508442e-02, 4.20900896e-02, 5.37312916e+03,\n",
      "        1.61818614e+04, 1.60830102e+04, 1.16412335e+04],\n",
      "       [3.97788087e-02, 4.67508442e-02, 4.20900894e-02, 5.37312917e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412335e+04],\n",
      "       [3.97788085e-02, 4.67508446e-02, 4.20900899e-02, 5.37312915e+03,\n",
      "        1.61818613e+04, 1.60830102e+04, 1.16412335e+04],\n",
      "       [3.97788087e-02, 4.67508439e-02, 4.20900892e-02, 5.37312918e+03,\n",
      "        1.61818614e+04, 1.60830103e+04, 1.16412336e+04],\n",
      "       [3.97788084e-02, 4.67508448e-02, 4.20900899e-02, 5.37312916e+03,\n",
      "        1.61818613e+04, 1.60830102e+04, 1.16412335e+04]]), array([90485.31169553, 90485.31169555, 90485.31169556, 90485.31169564,\n",
      "       90485.31169573, 90485.31169573, 90485.31169582, 90485.31169587]))\n",
      "           fun: 90485.31169552742\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1246\n",
      "           nit: 478\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.97788087e-02, 4.67508439e-02, 4.20900894e-02, 5.37312916e+03,\n",
      "       1.61818614e+04, 1.60830103e+04, 1.16412336e+04])\n",
      "minPrevious 90482.69509499139\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([2.0000, 2.0000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0367, 0.0445, 0.0458], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8773, 0.0628, 0.0278, 0.0251], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8679, 0.0761, 0.0260, 0.0300], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8874, 0.0282, 0.0652, 0.0261], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8687, 0.0261, 0.0751, 0.0301], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7379, 0.0985, 0.0987, 0.0616], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7085, 0.1116, 0.1107, 0.0692], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([2.0000, 2.0000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.7394, 3.1648, 4.3888],\n",
      "        [3.2083, 2.9599, 5.7800],\n",
      "        [2.2675, 2.0366, 4.9875],\n",
      "        ...,\n",
      "        [3.8538, 3.8462, 5.9722],\n",
      "        [3.6667, 5.0235, 5.9005],\n",
      "        [5.0420, 4.6122, 7.5952]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.200846195220947\n",
      "Run: 0, 9\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[50.,  1.,  1.,  2.],\n",
      "        [61.,  3.,  1.,  1.],\n",
      "        [52.,  2.,  1.,  1.],\n",
      "        ...,\n",
      "        [53.,  0.,  1.,  1.],\n",
      "        [56.,  1.,  1.,  0.],\n",
      "        [47.,  2.,  1.,  2.]], dtype=torch.float64)\n",
      "n tensor([54., 66., 56.,  ..., 55., 58., 52.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 2.,  ..., 0., 1., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 1., 1.,  ..., 1., 0., 2.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[50.,  1.,  1.,  2.],\n",
      "        [61.,  3.,  1.,  1.],\n",
      "        [52.,  2.,  1.,  1.],\n",
      "        ...,\n",
      "        [53.,  0.,  1.,  1.],\n",
      "        [56.,  1.,  1.,  0.],\n",
      "        [47.,  2.,  1.,  2.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0115, 0.0177, 0.0291,  ..., 0.0234, 0.0528, 0.0082],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fe798c3f200>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 90761.7781549094, bestParams: [0.04600825, 0.034627862, 0.03320431, 3705.6182, 7804.2446, 11532.189, 11376.845]\n",
      "epoch 0\n",
      " final_simplex: (array([[4.79401002e-02, 3.59860707e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126223e+03],\n",
      "       [4.79401001e-02, 3.59860709e-02, 4.02713562e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126223e+03],\n",
      "       [4.79401002e-02, 3.59860711e-02, 4.02713562e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126226e+03],\n",
      "       [4.79401004e-02, 3.59860708e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043620e+04, 7.70126228e+03],\n",
      "       [4.79401003e-02, 3.59860708e-02, 4.02713564e-02, 3.34189612e+03,\n",
      "        9.83545166e+03, 1.05043621e+04, 7.70126227e+03],\n",
      "       [4.79401006e-02, 3.59860705e-02, 4.02713567e-02, 3.34189612e+03,\n",
      "        9.83545165e+03, 1.05043620e+04, 7.70126230e+03],\n",
      "       [4.79401005e-02, 3.59860707e-02, 4.02713564e-02, 3.34189612e+03,\n",
      "        9.83545164e+03, 1.05043621e+04, 7.70126229e+03],\n",
      "       [4.79401005e-02, 3.59860705e-02, 4.02713563e-02, 3.34189612e+03,\n",
      "        9.83545165e+03, 1.05043621e+04, 7.70126227e+03]]), array([90616.66706736, 90616.66706748, 90616.66706754, 90616.66706756,\n",
      "       90616.66706758, 90616.66706764, 90616.66706774, 90616.66706778]))\n",
      "           fun: 90616.66706735565\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1129\n",
      "           nit: 411\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.79401002e-02, 3.59860707e-02, 4.02713565e-02, 3.34189612e+03,\n",
      "       9.83545164e+03, 1.05043621e+04, 7.70126223e+03])\n",
      "best ll: 91516.6859835903, bestParams: [0.026306985, 0.08133267, 0.024871472, 6414.625, 13429.396, 3964.474, 20765.12]\n",
      "epoch 1\n",
      " final_simplex: (array([[3.28815934e-02, 8.33975562e-02, 4.81044641e-02, 2.66958385e+03,\n",
      "        7.24460965e+03, 6.30083680e+03, 7.38755573e+03],\n",
      "       [3.28815935e-02, 8.33975565e-02, 4.81044639e-02, 2.66958386e+03,\n",
      "        7.24460964e+03, 6.30083682e+03, 7.38755570e+03],\n",
      "       [3.28815934e-02, 8.33975568e-02, 4.81044637e-02, 2.66958386e+03,\n",
      "        7.24460973e+03, 6.30083679e+03, 7.38755579e+03],\n",
      "       [3.28815934e-02, 8.33975564e-02, 4.81044642e-02, 2.66958386e+03,\n",
      "        7.24460969e+03, 6.30083679e+03, 7.38755583e+03],\n",
      "       [3.28815934e-02, 8.33975567e-02, 4.81044638e-02, 2.66958386e+03,\n",
      "        7.24460967e+03, 6.30083680e+03, 7.38755576e+03],\n",
      "       [3.28815935e-02, 8.33975571e-02, 4.81044636e-02, 2.66958386e+03,\n",
      "        7.24460967e+03, 6.30083682e+03, 7.38755564e+03],\n",
      "       [3.28815934e-02, 8.33975570e-02, 4.81044637e-02, 2.66958386e+03,\n",
      "        7.24460966e+03, 6.30083681e+03, 7.38755572e+03],\n",
      "       [3.28815934e-02, 8.33975569e-02, 4.81044638e-02, 2.66958385e+03,\n",
      "        7.24460973e+03, 6.30083679e+03, 7.38755575e+03]]), array([90672.74759503, 90672.74759516, 90672.74759536, 90672.74759546,\n",
      "       90672.7475955 , 90672.74759568, 90672.74759569, 90672.74759581]))\n",
      "           fun: 90672.74759502892\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1175\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.28815934e-02, 8.33975562e-02, 4.81044641e-02, 2.66958385e+03,\n",
      "       7.24460965e+03, 6.30083680e+03, 7.38755573e+03])\n",
      "minPrevious 90616.66706735565\n",
      "best ll: 91198.52576890608, bestParams: [0.06617981, 0.0026062375, 0.052282184, 5632.2466, 15811.634, 23665.295, 21685.236]\n",
      "epoch 2\n",
      " final_simplex: (array([[5.97788174e-02, 2.86239567e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788175e-02, 2.86239567e-03, 5.14519103e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788175e-02, 2.86239566e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766147e+04, 1.54040265e+04],\n",
      "       [5.97788177e-02, 2.86239567e-03, 5.14519102e-02, 7.10048603e+03,\n",
      "        1.78954598e+04, 2.16766145e+04, 1.54040266e+04],\n",
      "       [5.97788177e-02, 2.86239565e-03, 5.14519106e-02, 7.10048604e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04],\n",
      "       [5.97788175e-02, 2.86239568e-03, 5.14519099e-02, 7.10048600e+03,\n",
      "        1.78954599e+04, 2.16766146e+04, 1.54040265e+04],\n",
      "       [5.97788178e-02, 2.86239566e-03, 5.14519104e-02, 7.10048604e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04],\n",
      "       [5.97788177e-02, 2.86239566e-03, 5.14519103e-02, 7.10048602e+03,\n",
      "        1.78954598e+04, 2.16766146e+04, 1.54040266e+04]]), array([90761.99558966, 90761.99558975, 90761.99558987, 90761.99558988,\n",
      "       90761.99558996, 90761.99559001, 90761.99559002, 90761.99559008]))\n",
      "           fun: 90761.99558965943\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1259\n",
      "           nit: 478\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([5.97788174e-02, 2.86239567e-03, 5.14519104e-02, 7.10048603e+03,\n",
      "       1.78954598e+04, 2.16766146e+04, 1.54040265e+04])\n",
      "minPrevious 90616.66706735565\n",
      "best ll: 90782.52717622745, bestParams: [0.028903035, 0.05556211, 0.03673761, 6341.9014, 12760.6875, 16858.322, 19627.572]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5c67a24bbe10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    586\u001b[0m                       callback=callback, **options)\n\u001b[1;32m    587\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mxbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxbar\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mfxr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mdoshrink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0ma1Both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1Both\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0ma21\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "resSim = {\n",
    "        \"allRes\": None,\n",
    "        \"nEpochs\": None,\n",
    "        \"bestRes\": {\n",
    "            \"pis\": None,\n",
    "            \"alphas\": None,\n",
    "            \"PDV_c1true\": None,\n",
    "            \"PDV_c2true\": None,\n",
    "            \"PDV_cBothTrue\": None,\n",
    "            \"PDV_c1inferred\": None,\n",
    "            \"PDV_c2inferred\": None,\n",
    "            \"PDV_cBothInferred\": None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cached6NormalSimResNonAnnealing = []\n",
    "\n",
    "rrsSim = tensor([[2, 2, 1.5]])\n",
    "pisSim = tensor([[.05, .05, .05]])\n",
    "\n",
    "nCases = tensor([15e3, 15e3, 6e3])\n",
    "nCtrls = tensor(5e5)\n",
    "i = 0\n",
    "for rrsSimRun in rrsSim:\n",
    "    for pisSimRun in pisSim:\n",
    "        afMeanRun = 1e-4\n",
    "        generatingFn = genData.v6normal\n",
    "        # In DSB:\n",
    "        # \tNo ID\tID\t\n",
    "        #         ASD+ADHD\t684\t217\t\n",
    "        #         ASD\t3091\t871\t\n",
    "        #         ADHD\t3206\t271\t\n",
    "        #         Control\t5002\t-\t\n",
    "\n",
    "        #         gnomAD\t44779\t(Non-Finnish Europeans in non-psychiatric exome subset)\t\n",
    "\n",
    "        #         Case total:\t8340\t\t\n",
    "        #         Control total:\t49781\t\t\n",
    "        # so we can use pDBoth = .1 * total_cases\n",
    "        # needs tensor for shapes, otherwise \"gamma_cpu not implemente for long\", e.g rrShape=50.0 doesn't work...\n",
    "        paramsRun = genData.genParams(rrMeans=rrsSimRun, pis=pisSimRun, afMean=afMeanRun, rrShape=tensor(50.), afShape=tensor(50.), nCases=nCases, nCtrls=nCtrls)[0]\n",
    "        \n",
    "        pDsRun = paramsRun[\"pDs\"]\n",
    "        pisRun = paramsRun[\"diseaseFractions\"]\n",
    "        print(\"params are:\", paramsRun)\n",
    "        \n",
    "        cached6NormalSimResNonAnnealing.append({\"params\": paramsRun, \"runs\": []})\n",
    "        for y in range(0, 10):\n",
    "            start = time.time()\n",
    "            r = generatingFn(**paramsRun)\n",
    "            print(\"took\", time.time() - start)\n",
    "            \n",
    "            resPointer = {\n",
    "                **r,\n",
    "                \"generatingFn\": generatingFn,\n",
    "                \"results\": None,\n",
    "            }\n",
    "\n",
    "            cached6NormalSimResNonAnnealing[i][\"runs\"].append(resPointer)\n",
    "            \n",
    "            print(f\"Run: {i}, {y}\")\n",
    "            \n",
    "            xsRun = resPointer[\"altCounts\"]\n",
    "            afsRun = resPointer[\"afs\"]\n",
    "            affectedGenesRun = resPointer[\"affectedGenes\"]\n",
    "            unaffectedGenesRun = resPointer[\"unaffectedGenes\"]\n",
    "\n",
    "            runCostFnIdx = 16\n",
    "\n",
    "            nEpochsRun = 10\n",
    "            print(\"nEpochsRun\", nEpochsRun)\n",
    "            \n",
    "            res = likelihoods.fitFnBivariate(xsRun, pDsRun, nEpochs=nEpochsRun, minLLThresholdCount=20, debug=True, costFnIdx=runCostFnIdx)\n",
    "            bestRes = res[\"params\"][-1]\n",
    "\n",
    "            inferredPis = tensor(bestRes[0:3]) # 3-vector\n",
    "            inferredAlphas = tensor(bestRes[3:]) # 4-vector, idx0 is P(!D|V)\n",
    "\n",
    "            #### Calculate actual ###\n",
    "            component1Afs = afsRun[affectedGenesRun[0]]\n",
    "            c1true = (component1Afs / afMeanRun).mean(0)\n",
    "\n",
    "            component2Afs = afsRun[affectedGenesRun[1]]\n",
    "            c2true = (component2Afs / afMeanRun).mean(0)\n",
    "\n",
    "            componentBothAfs = afsRun[affectedGenesRun[2]]\n",
    "            cBothTrue = (componentBothAfs / afMeanRun).mean(0)\n",
    "\n",
    "            ### calculate inferred values\n",
    "            pds = tensor([1-pDsRun.sum(), *pDsRun])\n",
    "            alphas = inferredAlphas.numpy()\n",
    "            c1inferred = Dirichlet(tensor([alphas[0], alphas[1], alphas[0], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            c2inferred = Dirichlet(tensor([alphas[0], alphas[0], alphas[2], alphas[2]]) * pds).sample([10_000]).mean(0)\n",
    "            cBothInferred = Dirichlet(tensor([alphas[0], (alphas[1] + alphas[3]), (alphas[2] + alphas[3]), (alphas[1] + alphas[2] + alphas[3])]) * pds).sample([10_000]).mean(0)\n",
    "\n",
    "            print(f\"\\n\\nrun {i} results for rrs: {rrsSimRun}, pis: {pisSimRun}\")\n",
    "            print(\"Inferred pis:\", inferredPis)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c1true)\n",
    "            print(\"P(D|V) inferred in component 1:\", c1inferred)\n",
    "            print(\"\\nP(D|V) true ans in component 1:\", c2true)\n",
    "            print(\"P(D|V) inferred in component both:\", c2inferred)\n",
    "            print(\"\\nP(D|V) true ans in component both:\", cBothTrue)\n",
    "            print(\"P(D|V) inferred in component both:\", cBothInferred,\"\\n\\n\")\n",
    "\n",
    "            resToStore = copy.deepcopy(resSim)\n",
    "            resToStore[\"allRes\"] = res\n",
    "            resToStore[\"nEpochs\"] = nEpochsRun\n",
    "            br = resToStore[\"bestRes\"]\n",
    "            br[\"pis\"] = inferredPis\n",
    "            br[\"alphas\"] = inferredAlphas\n",
    "            br[\"PDV_c1true\"] = c1true\n",
    "            br[\"PDV_c2true\"] = c2true\n",
    "            br[\"PDV_cBothTrue\"] = cBothTrue\n",
    "            br[\"PDV_c1inferred\"] = c1inferred\n",
    "            br[\"PDV_c2inferred\"] = c2inferred\n",
    "            br[\"PDV_cBothInferred\"] = cBothInferred\n",
    "\n",
    "            resPointer[\"results\"] = resToStore\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([1.5000, 1.5000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[3.8293, 2.6289, 3.8956],\n",
      "        [2.4995, 2.3651, 2.9228],\n",
      "        [2.9986, 3.1782, 5.7793],\n",
      "        ...,\n",
      "        [1.6170, 2.4270, 3.9871],\n",
      "        [2.6860, 2.5748, 3.5131],\n",
      "        [3.5057, 4.4161, 3.9715]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 8.05718994140625\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  0.],\n",
      "        [44.,  6.,  1.,  1.],\n",
      "        [50.,  2.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  3.,  2.,  0.],\n",
      "        [53.,  1.,  1.,  3.],\n",
      "        [53.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "n tensor([50., 52., 55.,  ..., 53., 58., 55.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 6., 2.,  ..., 3., 1., 1.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 2.,  ..., 2., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 1., 1.,  ..., 0., 3., 1.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  0.],\n",
      "        [44.,  6.,  1.,  1.],\n",
      "        [50.,  2.,  2.,  1.],\n",
      "        ...,\n",
      "        [48.,  3.,  2.,  0.],\n",
      "        [53.,  1.,  1.,  3.],\n",
      "        [53.,  1.,  0.,  1.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0164, 0.0003, 0.0222,  ..., 0.0175, 0.0025, 0.0234],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa6304e8440>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89254.57939981687, bestParams: [0.09598137, 0.18161891, 0.066081025, 8628.348, 19064.254, 11141.051, 24336.697]\n",
      "epoch 0\n",
      "     fun: 89087.15867372246\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 17512\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([9.06655157e-01, 8.05196165e-03, 8.52313234e-02, 1.51882047e+04,\n",
      "       1.59563997e+04, 2.49997166e+04, 2.49999993e+04])\n",
      "took 263.1990089416504\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([1.5000, 1.5000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.9067, 0.0081, 0.0852], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8974, 0.0550, 0.0281, 0.0220], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.9248, 0.0291, 0.0277, 0.0183], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8934, 0.0280, 0.0558, 0.0223], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.9098, 0.0273, 0.0449, 0.0180], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7746, 0.0863, 0.0874, 0.0510], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8119, 0.0657, 0.0802, 0.0423], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.0191, 2.4042, 5.8232],\n",
      "        [1.0840, 2.3261, 4.9498],\n",
      "        [3.7891, 1.8827, 4.6055],\n",
      "        ...,\n",
      "        [4.0709, 3.3965, 6.2600],\n",
      "        [1.4524, 3.2465, 4.9516],\n",
      "        [2.2135, 1.7095, 4.1531]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.519060134887695\n",
      "Run: 0, 1\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  2.],\n",
      "        [45.,  6.,  4.,  3.],\n",
      "        [54.,  5.,  1.,  0.],\n",
      "        ...,\n",
      "        [59.,  3.,  2.,  3.],\n",
      "        [44.,  1.,  3.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "n tensor([45., 58., 60.,  ..., 67., 48., 45.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 6., 5.,  ..., 3., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 4., 1.,  ..., 2., 3., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([2., 3., 0.,  ..., 3., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[40.,  1.,  2.,  2.],\n",
      "        [45.,  6.,  4.,  3.],\n",
      "        [54.,  5.,  1.,  0.],\n",
      "        ...,\n",
      "        [59.,  3.,  2.,  3.],\n",
      "        [44.,  1.,  3.,  0.],\n",
      "        [45.,  0.,  0.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([6.2383e-03, 3.4287e-06, 3.3784e-03,  ..., 1.4544e-03, 2.2402e-02,\n",
      "        4.3776e-02], dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa6411153b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89545.34098332483, bestParams: [0.019650858, 0.005765289, 0.015805295, 8096.601, 15435.601, 23816.336, 12740.194]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-087714822751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunSim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1387c87bde79>\u001b[0m in \u001b[0;36mrunSim\u001b[0;34m(rrs, pis, nCases, nCtrls, afMean, rrShape, afShape, generatingFn, fitMethod)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nEpochsRun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitFnBivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnEpochsRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLLThresholdCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcostFnIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunCostFnIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitMethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mbestRes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mfitFnBivariate\u001b[0;34m(altCountsByGene, pDs, nEpochs, minLLThresholdCount, K, debug, costFnIdx, method)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Nelder-Mead'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adaptive\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"annealing\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"basinhopping\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasinhopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcostFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mdual_annealing\u001b[0;34m(func, bounds, args, maxiter, local_search_options, initial_temp, restart_temp_ratio, visit, accept, maxfun, seed, no_local_search, callback, x0)\u001b[0m\n\u001b[1;32m    663\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;31m# starting strategy chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, step, temperature)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 self.energy_state.current_location, j, temperature)\n\u001b[1;32m    290\u001b[0m             \u001b[0;31m# Calling the objective function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_visit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_energy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;31m# We have got a better energy value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/optimize/_dual_annealing.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/likelihoods.py\u001b[0m in \u001b[0;36mlikelihood2m\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0maBothBoth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malphaBoth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         \u001b[0mh3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiBoth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBoth1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBoth2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maBothBoth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsFlat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mh0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return (_log_beta_1(alpha.sum(-1), value.sum(-1), self.is_sparse) -\n\u001b[0;32m--> 162\u001b[0;31m                 _log_beta_1(alpha, value, self.is_sparse).sum(-1))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m_log_beta_1\u001b[0;34m(alpha, value, is_sparse)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runSim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN\n",
      "pDs are: tensor([0.0280, 0.0280, 0.0112])\n",
      "params are: {'nGenes': 20000, 'nCases': tensor([15000., 15000.,  6000.]), 'nCtrls': tensor(500000.), 'pDs': tensor([0.0280, 0.0280, 0.0112]), 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]), 'rrShape': tensor(50.), 'rrMeans': tensor([1.5000, 1.5000, 1.5000]), 'afShape': tensor(50.), 'afMean': 0.0001}\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[2.9334, 2.5262, 4.5972],\n",
      "        [2.9295, 2.6827, 4.2659],\n",
      "        [3.4033, 4.0980, 4.6098],\n",
      "        ...,\n",
      "        [3.2606, 1.8734, 3.4271],\n",
      "        [2.4874, 2.7894, 4.5732],\n",
      "        [3.8228, 2.9923, 4.2592]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n",
      "took 7.798516273498535\n",
      "Run: 0, 0\n",
      "nEpochsRun 10\n",
      "shape torch.Size([20000, 4])\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  1.],\n",
      "        [51.,  0.,  2.,  3.],\n",
      "        [41.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [55.,  1.,  4.,  0.],\n",
      "        [40.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "n tensor([51., 56., 44.,  ..., 60., 42., 43.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([3., 0., 0.,  ..., 1., 1., 0.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([0., 2., 2.,  ..., 4., 1., 2.], dtype=torch.float64)\n",
      "xCase1, xCase2, xCase12 tensor([1., 3., 1.,  ..., 0., 0., 0.], dtype=torch.float64)\n",
      "altCountsFlat tensor([[47.,  3.,  0.,  1.],\n",
      "        [51.,  0.,  2.,  3.],\n",
      "        [41.,  0.,  2.,  1.],\n",
      "        ...,\n",
      "        [55.,  1.,  4.,  0.],\n",
      "        [40.,  1.,  1.,  0.],\n",
      "        [41.,  0.,  2.,  0.]], dtype=torch.float64)\n",
      "allNull2 tensor([0.0093, 0.0012, 0.0201,  ..., 0.0102, 0.0836, 0.0409],\n",
      "       dtype=torch.float64)\n",
      "pd1, pd2, pdBoth, pdCtrl tensor(0.0280) tensor(0.0280) tensor(0.0112) tensor(0.9328)\n",
      "past <function likelihoodBivariateFast.<locals>.likelihood2m at 0x7fa60809c050>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexkotlar/projects/tada/mvl/likelihoods.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  altCountsFlat = tensor(altCountsFlat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ll: 89504.27484045511, bestParams: [0.01460946, 0.02944035, 0.03863643, 3142.4583, 3569.245, 5062.629, 6662.2]\n",
      "epoch 0\n",
      " final_simplex: (array([[1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112738e+03,\n",
      "        5.21052634e+03, 4.99263541e+03, 2.62354673e+03],\n",
      "       [1.98604401e-02, 3.41540280e-02, 3.55878742e-02, 1.65112738e+03,\n",
      "        5.21052633e+03, 4.99263546e+03, 2.62354667e+03],\n",
      "       [1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112737e+03,\n",
      "        5.21052636e+03, 4.99263542e+03, 2.62354672e+03],\n",
      "       [1.98604400e-02, 3.41540281e-02, 3.55878741e-02, 1.65112738e+03,\n",
      "        5.21052634e+03, 4.99263542e+03, 2.62354670e+03],\n",
      "       [1.98604401e-02, 3.41540283e-02, 3.55878742e-02, 1.65112737e+03,\n",
      "        5.21052638e+03, 4.99263537e+03, 2.62354673e+03],\n",
      "       [1.98604401e-02, 3.41540280e-02, 3.55878744e-02, 1.65112737e+03,\n",
      "        5.21052634e+03, 4.99263546e+03, 2.62354667e+03],\n",
      "       [1.98604400e-02, 3.41540281e-02, 3.55878747e-02, 1.65112738e+03,\n",
      "        5.21052627e+03, 4.99263541e+03, 2.62354677e+03],\n",
      "       [1.98604400e-02, 3.41540282e-02, 3.55878745e-02, 1.65112738e+03,\n",
      "        5.21052630e+03, 4.99263539e+03, 2.62354675e+03]]), array([89097.20969999, 89097.20970001, 89097.20970011, 89097.20970015,\n",
      "       89097.20970023, 89097.20970029, 89097.2097003 , 89097.20970032]))\n",
      "           fun: 89097.20969998793\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1187\n",
      "           nit: 474\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.98604401e-02, 3.41540281e-02, 3.55878743e-02, 1.65112738e+03,\n",
      "       5.21052634e+03, 4.99263541e+03, 2.62354673e+03])\n",
      "best ll: 89661.97322291948, bestParams: [0.03616922, 0.032769334, 0.045829535, 10727.266, 24210.703, 12838.759, 15205.117]\n",
      "epoch 1\n",
      " final_simplex: (array([[4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514215e-02, 7.07864376e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259062e+04],\n",
      "       [4.19236529e-02, 3.25639602e-02, 3.48514220e-02, 7.07864378e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236527e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514220e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041261e+04, 2.08219659e+04, 1.43259061e+04]]), array([89076.07821087, 89076.07821088, 89076.07821092, 89076.07821098,\n",
      "       89076.07821101, 89076.07821117, 89076.07821118, 89076.07821121]))\n",
      "           fun: 89076.07821086713\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1248\n",
      "           nit: 473\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "       1.96041260e+04, 2.08219659e+04, 1.43259061e+04])\n",
      "minPrevious 89097.20969998793\n",
      "better by at >= 1; new ll:  final_simplex: (array([[4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514215e-02, 7.07864376e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259062e+04],\n",
      "       [4.19236529e-02, 3.25639602e-02, 3.48514220e-02, 7.07864378e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236527e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864379e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236530e-02, 3.25639603e-02, 3.48514220e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219658e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041260e+04, 2.08219659e+04, 1.43259061e+04],\n",
      "       [4.19236528e-02, 3.25639602e-02, 3.48514222e-02, 7.07864377e+03,\n",
      "        1.96041261e+04, 2.08219659e+04, 1.43259061e+04]]), array([89076.07821087, 89076.07821088, 89076.07821092, 89076.07821098,\n",
      "       89076.07821101, 89076.07821117, 89076.07821118, 89076.07821121]))\n",
      "           fun: 89076.07821086713\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1248\n",
      "           nit: 473\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([4.19236529e-02, 3.25639603e-02, 3.48514217e-02, 7.07864377e+03,\n",
      "       1.96041260e+04, 2.08219659e+04, 1.43259061e+04])\n",
      "best ll: 89396.0603735198, bestParams: [0.02752898, 0.02535716, 0.018690322, 5718.255, 12018.066, 19256.404, 19616.584]\n",
      "epoch 2\n",
      " final_simplex: (array([[3.03046914e-02, 2.79128625e-02, 2.73070996e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259645e+03],\n",
      "       [3.03046915e-02, 2.79128625e-02, 2.73070995e-02, 4.82605052e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259643e+03],\n",
      "       [3.03046916e-02, 2.79128625e-02, 2.73070995e-02, 4.82605052e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259641e+03],\n",
      "       [3.03046916e-02, 2.79128625e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259646e+03],\n",
      "       [3.03046915e-02, 2.79128626e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259648e+03],\n",
      "       [3.03046916e-02, 2.79128626e-02, 2.73070995e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259646e+03],\n",
      "       [3.03046918e-02, 2.79128627e-02, 2.73070993e-02, 4.82605053e+03,\n",
      "        1.52177116e+04, 1.57090374e+04, 7.96259651e+03],\n",
      "       [3.03046916e-02, 2.79128624e-02, 2.73070996e-02, 4.82605052e+03,\n",
      "        1.52177117e+04, 1.57090374e+04, 7.96259636e+03]]), array([89090.52106561, 89090.52106562, 89090.52106564, 89090.52106565,\n",
      "       89090.52106566, 89090.52106567, 89090.52106586, 89090.52107062]))\n",
      "           fun: 89090.52106561436\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1246\n",
      "           nit: 440\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.03046914e-02, 2.79128625e-02, 2.73070996e-02, 4.82605053e+03,\n",
      "       1.52177116e+04, 1.57090374e+04, 7.96259645e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89159.98797501124, bestParams: [0.07087075, 0.035208993, 0.046770897, 7998.9688, 20401.977, 21096.521, 20626.426]\n",
      "epoch 3\n",
      " final_simplex: (array([[6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623725e+04],\n",
      "       [6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730239e+04, 1.97623725e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623724e+04],\n",
      "       [6.71874810e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874810e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04],\n",
      "       [6.71874811e-02, 3.83149247e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730240e+04, 1.97623724e+04],\n",
      "       [6.71874809e-02, 3.83149247e-02, 4.41265078e-02, 8.65586571e+03,\n",
      "        1.97499805e+04, 2.14730241e+04, 1.97623724e+04]]), array([89100.40359353, 89100.40359355, 89100.40359361, 89100.40359362,\n",
      "       89100.40359366, 89100.40359367, 89100.40359371, 89100.40359375]))\n",
      "           fun: 89100.40359352919\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1309\n",
      "           nit: 496\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.71874812e-02, 3.83149248e-02, 4.41265077e-02, 8.65586571e+03,\n",
      "       1.97499805e+04, 2.14730240e+04, 1.97623725e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89266.87360477714, bestParams: [0.02102224, 0.0073940502, 0.04933069, 9835.428, 20614.709, 23006.111, 24559.834]\n",
      "epoch 4\n",
      " final_simplex: (array([[2.81792183e-02, 1.00385350e-02, 4.10791068e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436391e+03],\n",
      "       [2.81792178e-02, 1.00385350e-02, 4.10791081e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436387e+03],\n",
      "       [2.81792169e-02, 1.00385350e-02, 4.10791109e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436386e+03],\n",
      "       [2.81792169e-02, 1.00385350e-02, 4.10791111e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436397e+03],\n",
      "       [2.81792162e-02, 1.00385350e-02, 4.10791133e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436397e+03],\n",
      "       [2.81792161e-02, 1.00385351e-02, 4.10791135e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436386e+03],\n",
      "       [2.81792156e-02, 1.00385350e-02, 4.10791151e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436393e+03],\n",
      "       [2.81792146e-02, 1.00385351e-02, 4.10791183e-02, 7.92193726e+03,\n",
      "        2.46257826e+04, 2.70287627e+04, 8.82436391e+03]]), array([89131.49405002, 89131.49405098, 89131.49405308, 89131.49405339,\n",
      "       89131.49405506, 89131.49405509, 89131.4940564 , 89131.4940588 ]))\n",
      "           fun: 89131.49405001549\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2322\n",
      "           nit: 1097\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.81792183e-02, 1.00385350e-02, 4.10791068e-02, 7.92193726e+03,\n",
      "       2.46257826e+04, 2.70287627e+04, 8.82436391e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89362.65263565104, bestParams: [0.012687951, 0.011631452, 0.07809705, 6797.328, 13523.173, 17862.2, 14069.145]\n",
      "epoch 5\n",
      " final_simplex: (array([[1.84218776e-02, 1.37973849e-02, 3.77607203e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083500e+03],\n",
      "       [1.84218775e-02, 1.37973850e-02, 3.77607202e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083503e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607205e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083504e+03],\n",
      "       [1.84218776e-02, 1.37973850e-02, 3.77607202e-02, 5.59975530e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083499e+03],\n",
      "       [1.84218777e-02, 1.37973848e-02, 3.77607207e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083490e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607205e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083495e+03],\n",
      "       [1.84218776e-02, 1.37973850e-02, 3.77607202e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083502e+03],\n",
      "       [1.84218776e-02, 1.37973849e-02, 3.77607204e-02, 5.59975531e+03,\n",
      "        1.89100468e+04, 1.95686277e+04, 5.99083499e+03]]), array([89133.97795553, 89133.97795554, 89133.97795572, 89133.9779627 ,\n",
      "       89133.97796275, 89133.97796276, 89133.97796276, 89133.97796277]))\n",
      "           fun: 89133.97795552979\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1228\n",
      "           nit: 425\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([1.84218776e-02, 1.37973849e-02, 3.77607203e-02, 5.59975531e+03,\n",
      "       1.89100468e+04, 1.95686277e+04, 5.99083500e+03])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89212.69924155968, bestParams: [0.025522236, 0.07102064, 0.04095869, 6469.978, 23772.977, 16247.678, 7731.7466]\n",
      "epoch 6\n",
      " final_simplex: (array([[2.70476141e-02, 4.01468282e-02, 3.26248241e-02, 6.48001244e+03,\n",
      "        1.99119150e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476140e-02, 4.01468277e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394004e+04],\n",
      "       [2.70476141e-02, 4.01468286e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476141e-02, 4.01468292e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394002e+04],\n",
      "       [2.70476141e-02, 4.01468287e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394003e+04],\n",
      "       [2.70476141e-02, 4.01468291e-02, 3.26248240e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394002e+04],\n",
      "       [2.70476141e-02, 4.01468290e-02, 3.26248239e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927180e+04, 1.18394003e+04],\n",
      "       [2.70476142e-02, 4.01468298e-02, 3.26248239e-02, 6.48001245e+03,\n",
      "        1.99119151e+04, 1.85927181e+04, 1.18394002e+04]]), array([89083.15977387, 89083.15977388, 89083.15977389, 89083.15977391,\n",
      "       89083.15977393, 89083.15977395, 89083.15977396, 89083.15977396]))\n",
      "           fun: 89083.15977387255\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1306\n",
      "           nit: 540\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([2.70476141e-02, 4.01468282e-02, 3.26248241e-02, 6.48001244e+03,\n",
      "       1.99119150e+04, 1.85927180e+04, 1.18394003e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89330.68493643744, bestParams: [0.082257316, 0.027428642, 0.07051255, 7407.681, 12604.67, 11728.0625, 22984.412]\n",
      "epoch 7\n",
      " final_simplex: (array([[7.22722643e-02, 4.08138975e-02, 3.35494221e-02, 6.23642624e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722643e-02, 4.08138976e-02, 3.35494214e-02, 6.23642621e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722637e-02, 4.08138975e-02, 3.35494209e-02, 6.23642626e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722640e-02, 4.08138976e-02, 3.35494211e-02, 6.23642624e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722644e-02, 4.08138975e-02, 3.35494216e-02, 6.23642623e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722642e-02, 4.08138974e-02, 3.35494214e-02, 6.23642625e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103739e+04],\n",
      "       [7.22722651e-02, 4.08138974e-02, 3.35494229e-02, 6.23642620e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04],\n",
      "       [7.22722644e-02, 4.08138975e-02, 3.35494217e-02, 6.23642623e+03,\n",
      "        1.45974907e+04, 1.66629287e+04, 1.42103738e+04]]), array([89092.78697749, 89092.78697752, 89092.78697752, 89092.78697755,\n",
      "       89092.78697766, 89092.78697766, 89092.78697766, 89092.78697769]))\n",
      "           fun: 89092.78697748706\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1211\n",
      "           nit: 458\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([7.22722643e-02, 4.08138975e-02, 3.35494221e-02, 6.23642624e+03,\n",
      "       1.45974907e+04, 1.66629287e+04, 1.42103738e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89389.45489296163, bestParams: [0.060271375, 0.042252373, 0.050650936, 6876.2065, 11556.726, 21871.658, 21758.736]\n",
      "epoch 8\n",
      " final_simplex: (array([[6.51869746e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869748e-02, 5.30897589e-02, 3.51516079e-02, 7.05962329e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869746e-02, 5.30897590e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869746e-02, 5.30897590e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869748e-02, 5.30897588e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123699e+04, 1.75684742e+04],\n",
      "       [6.51869746e-02, 5.30897591e-02, 3.51516078e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123701e+04, 1.75684741e+04],\n",
      "       [6.51869747e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04],\n",
      "       [6.51869747e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "        1.66074072e+04, 1.75123700e+04, 1.75684742e+04]]), array([89093.22690281, 89093.22690282, 89093.22690284, 89093.22690284,\n",
      "       89093.22690285, 89093.22690287, 89093.22690287, 89093.2269029 ]))\n",
      "           fun: 89093.22690280867\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1255\n",
      "           nit: 513\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([6.51869746e-02, 5.30897589e-02, 3.51516079e-02, 7.05962328e+03,\n",
      "       1.66074072e+04, 1.75123700e+04, 1.75684742e+04])\n",
      "minPrevious 89076.07821086713\n",
      "best ll: 89479.24696850716, bestParams: [0.0029611788, 0.048730392, 0.018831836, 9358.529, 19040.064, 23882.67, 18005.031]\n",
      "epoch 9\n",
      " final_simplex: (array([[3.08114659e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147293e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147292e+03],\n",
      "       [3.08114658e-03, 4.42532136e-02, 3.99157607e-02, 6.77894951e+03,\n",
      "        2.23243264e+04, 1.88557299e+04, 9.53147285e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147293e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157607e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147291e+03],\n",
      "       [3.08114658e-03, 4.42532135e-02, 3.99157606e-02, 6.77894953e+03,\n",
      "        2.23243264e+04, 1.88557300e+04, 9.53147294e+03]]), array([89195.54214277, 89195.54214282, 89195.54214284, 89195.54214284,\n",
      "       89195.54214303, 89195.54216626, 89195.54216627, 89195.54216628]))\n",
      "           fun: 89195.5421427736\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1323\n",
      "           nit: 487\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([3.08114659e-03, 4.42532135e-02, 3.99157606e-02, 6.77894952e+03,\n",
      "       2.23243264e+04, 1.88557300e+04, 9.53147293e+03])\n",
      "minPrevious 89076.07821086713\n",
      "took 407.44111680984497\n",
      "\n",
      "\n",
      "run 0 results for rrs: tensor([1.5000, 1.5000, 1.5000]), pis: tensor([0.0500, 0.0500, 0.0500])\n",
      "Inferred pis: tensor([0.0419, 0.0326, 0.0349], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8933, 0.0569, 0.0280, 0.0227], dtype=torch.float64)\n",
      "P(D|V) inferred in component 1: tensor([0.8708, 0.0723, 0.0261, 0.0307], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component 1: tensor([0.8975, 0.0281, 0.0563, 0.0225], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.8670, 0.0260, 0.0765, 0.0305], dtype=torch.float64)\n",
      "\n",
      "P(D|V) true ans in component both: tensor([0.7772, 0.0856, 0.0853, 0.0511], dtype=torch.float64)\n",
      "P(D|V) inferred in component both: tensor([0.7218, 0.1037, 0.1075, 0.0670], dtype=torch.float64) \n",
      "\n",
      "\n",
      "TESTING WITH: nCases tensor([15000., 15000.,  6000.]) nCtrls tensor(500000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0280, 0.0280, 0.0112])\n",
      "tensor([[4.4937, 4.8385, 5.2157],\n",
      "        [3.3180, 2.5832, 3.6836],\n",
      "        [4.3122, 2.5246, 4.8452],\n",
      "        ...,\n",
      "        [2.7396, 4.5652, 3.7115],\n",
      "        [1.9112, 3.0687, 5.9062],\n",
      "        [1.3352, 2.5593, 3.5319]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 536000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-879fdf1954c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunSim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitMethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1387c87bde79>\u001b[0m in \u001b[0;36mrunSim\u001b[0;34m(rrs, pis, nCases, nCtrls, afMean, rrShape, afShape, generatingFn, fitMethod)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneratingFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparamsRun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/tada/mvl/genData.py\u001b[0m in \u001b[0;36mv6normal\u001b[0;34m(nCases, nCtrls, pDs, diseaseFractions, rrShape, rrMeans, afMean, afShape, nGenes)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mmarginalAlleleCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalProbability\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotalSamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0maltCountsGene\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarginalAlleleCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0maltCounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCountsGene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/distributions/multinomial.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# samples.shape is (total_count, sample_shape, batch_shape), need to change it to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# (sample_shape, batch_shape, total_count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mshifted_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mshifted_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshifted_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshifted_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runSim(fitMethod='nelder-mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f646b1ec66d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./mvln-sim-mvln.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf_should_read_directly\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = np.load(\"./mvln-sim-mvln.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resByParams = []\n",
    "for runSet in res:\n",
    "    params = (runSet[\"params\"][\"diseaseFractions\"], runSet[\"params\"][\"rrMeans\"], runSet[\"params\"][\"rrShape\"])\n",
    "#     print(\"param\", params)\n",
    "    res = []\n",
    "#     if params not in resByParam:\n",
    "#         resByParams[params] = []\n",
    "    \n",
    "    for run in runSet[\"runs\"]:\n",
    "        if run is None or \"results\" not in run or run[\"results\"] is None:\n",
    "            print(f\"no results found for {params}\")\n",
    "            continue\n",
    "        res.append(run[\"results\"])\n",
    "    resByParams.append([params, res])\n",
    "\n",
    "np.save(\"mvln-sim-mvln-results2\", resByParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resByParams = np.load(\"mvln-sim-mvln-results.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[(tensor([0.0500, 0.0500, 0.0500]), tensor([2.0000, 2.0000, 1.5000]), tensor(50.)),\n",
       "        list([{'allRes': {'lls': [90916.4783589971, 90708.31368424412, 90689.04874179952, 90677.23983613223], 'params': [array([3.87333861e-02, 1.40812486e-01, 7.59025824e-02, 9.31141067e+03,\n",
       "       2.18500134e+04, 1.68652588e+04, 2.63598593e+04]), array([1.67543257e-02, 3.13060638e-02, 4.29277051e-02, 2.50496081e+03,\n",
       "       8.64518025e+03, 8.37694873e+03, 4.74332877e+03]), array([4.07980539e-02, 5.92690249e-02, 4.06981218e-02, 4.76417261e+03,\n",
       "       1.30584069e+04, 1.28133394e+04, 1.26034808e+04]), array([3.56317955e-02, 3.20989858e-02, 4.08777915e-02, 5.02625412e+03,\n",
       "       1.52388589e+04, 1.62573997e+04, 1.10763793e+04])], 'llTrajectory': [90916.4783589971, 90708.31368424412, 90727.26669070916, 90689.04874179952, 90677.23983613223, 90676.96371994552, 90738.01226968745, 90784.31279984681, 90787.42281897092, 90677.4934384852]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0356, 0.0321, 0.0409], dtype=torch.float64), 'alphas': tensor([ 5026.2541, 15238.8589, 16257.3997, 11076.3793], dtype=torch.float64), 'PDV_c1true': tensor([0.8812, 0.0628, 0.0279, 0.0251], dtype=torch.float64), 'PDV_c2true': tensor([0.8833, 0.0281, 0.0651, 0.0261], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7405, 0.0993, 0.0996, 0.0623], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8622, 0.0785, 0.0259, 0.0335], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8577, 0.0257, 0.0832, 0.0333], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7032, 0.1105, 0.1148, 0.0715], dtype=torch.float64)}}, {'allRes': {'lls': [90645.57342181327, 90644.31351623876, 90641.27069583946], 'params': [array([3.63755073e-02, 4.57749896e-02, 4.18899664e-02, 1.42087064e+03,\n",
       "       4.35121665e+03, 4.00355358e+03, 3.50070375e+03]), array([4.66029047e-02, 4.53761282e-02, 4.29744549e-02, 6.07873461e+03,\n",
       "       1.78237112e+04, 1.71242042e+04, 1.58362642e+04]), array([4.33810405e-02, 4.52988838e-02, 4.13633647e-02, 6.96476709e+02,\n",
       "       2.04656915e+03, 1.91605097e+03, 1.77271015e+03])], 'llTrajectory': [90645.57342181327, 90651.2118646526, 90719.94317753878, 90644.31351623876, 90666.92657482934, 90653.34651654988, 90641.27069583946, 90651.3464135098, 90680.92933323765, 90792.21030335355]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0434, 0.0453, 0.0414], dtype=torch.float64), 'alphas': tensor([ 696.4767, 2046.5691, 1916.0510, 1772.7101], dtype=torch.float64), 'PDV_c1true': tensor([0.8797, 0.0642, 0.0279, 0.0257], dtype=torch.float64), 'PDV_c2true': tensor([0.8793, 0.0278, 0.0627, 0.0251], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7303, 0.0996, 0.0971, 0.0614], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8686, 0.0767, 0.0261, 0.0286], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8730, 0.0261, 0.0721, 0.0288], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7034, 0.1153, 0.1118, 0.0695], dtype=torch.float64)}}, {'allRes': {'lls': [90748.6465155581, 90711.14503326186], 'params': [array([6.27341823e-02, 4.63341146e-02, 3.75087980e-02, 6.10706763e+03,\n",
       "       1.62508186e+04, 1.74873704e+04, 1.57440691e+04]), array([3.54220726e-02, 4.85500888e-02, 4.49141211e-02, 2.28821775e+02,\n",
       "       6.42604102e+02, 6.38308739e+02, 5.08927552e+02])], 'llTrajectory': [90748.6465155581, 90711.14503326186, 90744.77986211523, 90876.14512541448, 90742.77190618007, 90800.03142956684, 90875.49917612775, 90747.52190318814, 90775.94721973015, 90878.82993506195]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0354, 0.0486, 0.0449], dtype=torch.float64), 'alphas': tensor([228.8218, 642.6041, 638.3087, 508.9276], dtype=torch.float64), 'PDV_c1true': tensor([0.8907, 0.0641, 0.0282, 0.0257], dtype=torch.float64), 'PDV_c2true': tensor([0.8856, 0.0281, 0.0643, 0.0257], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7492, 0.0969, 0.0963, 0.0615], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8712, 0.0735, 0.0262, 0.0291], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8716, 0.0263, 0.0729, 0.0293], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7170, 0.1081, 0.1075, 0.0673], dtype=torch.float64)}}, {'allRes': {'lls': [90933.72918146176, 90838.29602316262], 'params': [array([9.06864522e-02, 6.50148984e-02, 5.37885695e-02, 7.24642505e+03,\n",
       "       1.56345132e+04, 1.71235809e+04, 2.05677764e+04]), array([3.85649052e-02, 4.20795687e-02, 4.01053337e-02, 1.89342510e+03,\n",
       "       5.93866294e+03, 5.77638420e+03, 4.21878917e+03])], 'llTrajectory': [90933.72918146176, 90838.29602316262, 90868.60640369028, 90882.07712309291, 90847.74550284173, 90896.76813160375, 91157.13067761659, 90877.09566313706, 90838.3988977742, 90894.50289291705]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0386, 0.0421, 0.0401], dtype=torch.float64), 'alphas': tensor([1893.4251, 5938.6629, 5776.3842, 4218.7892], dtype=torch.float64), 'PDV_c1true': tensor([0.8888, 0.0641, 0.0282, 0.0256], dtype=torch.float64), 'PDV_c2true': tensor([0.8769, 0.0278, 0.0635, 0.0254], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7435, 0.0972, 0.0976, 0.0616], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8615, 0.0811, 0.0258, 0.0315], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8636, 0.0258, 0.0790, 0.0316], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7040, 0.1134, 0.1116, 0.0710], dtype=torch.float64)}}, {'allRes': {'lls': [90747.7696123132, 90585.67194419992, 90566.73709957347], 'params': [array([5.91826890e-02, 1.44589234e-01, 6.69387920e-02, 7.98395162e+03,\n",
       "       1.52393288e+04, 1.31918445e+04, 2.25971498e+04]), array([3.23620186e-02, 2.38361870e-02, 3.69261663e-02, 6.10035669e+03,\n",
       "       2.08475809e+04, 2.21919581e+04, 9.74581440e+03]), array([3.78255556e-02, 3.46743998e-02, 4.08244155e-02, 3.95583458e+03,\n",
       "       1.26977546e+04, 1.28829457e+04, 7.45632495e+03])], 'llTrajectory': [90747.7696123132, 90749.95843612179, 90585.67194419992, 90878.04322170046, 90566.73709957347, 90566.96453252305, 90861.6203819377, 90571.64204209404, 90615.46630737893, 90606.66331600855]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0378, 0.0347, 0.0408], dtype=torch.float64), 'alphas': tensor([ 3955.8346, 12697.7546, 12882.9457,  7456.3249], dtype=torch.float64), 'PDV_c1true': tensor([0.8825, 0.0635, 0.0280, 0.0254], dtype=torch.float64), 'PDV_c2true': tensor([0.8835, 0.0280, 0.0631, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7426, 0.0973, 0.0990, 0.0610], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8581, 0.0826, 0.0257, 0.0336], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8570, 0.0257, 0.0838, 0.0335], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7106, 0.1086, 0.1096, 0.0712], dtype=torch.float64)}}, {'allRes': {'lls': [90830.07972194639, 90562.237920496], 'params': [array([1.69463338e-01, 1.98575139e-01, 6.22025970e-02, 4.41316805e+03,\n",
       "       6.28159370e+03, 5.39738695e+03, 1.63099014e+04]), array([4.85819986e-02, 4.43267999e-02, 4.25625903e-02, 2.84641270e+02,\n",
       "       7.71902383e+02, 7.79988251e+02, 7.35633621e+02])], 'llTrajectory': [90830.07972194639, 90562.237920496, 90774.41540520656, 90774.76133135978, 90857.23196144999, 90587.14554848513, 90638.69745056726, 90581.18297009883, 90642.92672963747, 90596.53639301992]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0486, 0.0443, 0.0426], dtype=torch.float64), 'alphas': tensor([284.6413, 771.9024, 779.9883, 735.6336], dtype=torch.float64), 'PDV_c1true': tensor([0.8809, 0.0633, 0.0279, 0.0253], dtype=torch.float64), 'PDV_c2true': tensor([0.8849, 0.0280, 0.0629, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7376, 0.1000, 0.0991, 0.0615], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8736, 0.0712, 0.0264, 0.0288], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8738, 0.0261, 0.0714, 0.0286], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7067, 0.1122, 0.1130, 0.0681], dtype=torch.float64)}}, {'allRes': {'lls': [90541.19690546543, 90485.83852292394, 90450.04864336646], 'params': [array([1.05198885e-01, 5.61385155e-02, 4.30683468e-02, 7.16649842e+03,\n",
       "       1.50831749e+04, 1.90234287e+04, 2.11213115e+04]), array([1.45415926e-02, 3.60020275e-02, 4.32792564e-02, 5.79867892e+03,\n",
       "       2.10841845e+04, 1.86303955e+04, 1.00095742e+04]), array([4.04756141e-02, 2.69877192e-02, 4.02918327e-02, 5.89913599e+03,\n",
       "       1.83048623e+04, 1.99880264e+04, 1.21531034e+04])], 'llTrajectory': [90541.19690546543, 90485.83852292394, 90640.86004954319, 90450.04864336646, 90702.5564634097, 90557.9040388632, 90460.6229193173, 90467.91167992419, 90520.90760929213, 90557.50718726793]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0405, 0.0270, 0.0403], dtype=torch.float64), 'alphas': tensor([ 5899.1360, 18304.8623, 19988.0264, 12153.1034], dtype=torch.float64), 'PDV_c1true': tensor([0.8760, 0.0640, 0.0278, 0.0256], dtype=torch.float64), 'PDV_c2true': tensor([0.8838, 0.0280, 0.0630, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7420, 0.0999, 0.0992, 0.0621], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8593, 0.0800, 0.0258, 0.0349], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8530, 0.0256, 0.0868, 0.0346], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7038, 0.1090, 0.1150, 0.0722], dtype=torch.float64)}}, {'allRes': {'lls': [90757.56968553299, 90527.69242737578, 90521.27001448293], 'params': [array([1.61995075e-03, 1.05690047e-01, 5.31147218e-02, 7.83678126e+03,\n",
       "       2.34720398e+04, 1.67885869e+04, 1.81920206e+04]), array([3.75891039e-02, 3.93849894e-02, 4.27479940e-02, 3.83229961e+03,\n",
       "       1.20099977e+04, 1.13342312e+04, 9.03855526e+03]), array([3.71189801e-02, 3.75458264e-02, 4.12923202e-02, 9.18698687e+02,\n",
       "       2.84332494e+03, 2.78552088e+03, 2.18573783e+03])], 'llTrajectory': [90757.56968553299, 90527.69242737578, 90711.2276505137, 90521.27001448293, 90578.02820961754, 90562.84654239606, 90559.02988606176, 90559.19154174202, 90661.38357505882, 90574.89262462722]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0371, 0.0375, 0.0413], dtype=torch.float64), 'alphas': tensor([ 918.6987, 2843.3249, 2785.5209, 2185.7378], dtype=torch.float64), 'PDV_c1true': tensor([0.8806, 0.0645, 0.0280, 0.0258], dtype=torch.float64), 'PDV_c2true': tensor([0.8815, 0.0279, 0.0636, 0.0254], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7461, 0.1002, 0.0990, 0.0622], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8627, 0.0800, 0.0259, 0.0314], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8642, 0.0259, 0.0785, 0.0314], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.6999, 0.1150, 0.1135, 0.0715], dtype=torch.float64)}}, {'allRes': {'lls': [90897.96160983646, 90822.30100460075, 90813.7933164202], 'params': [array([4.94523337e-02, 8.98534427e-02, 5.08059703e-02, 9.33431412e+03,\n",
       "       2.31980772e+04, 2.01782677e+04, 2.67851825e+04]), array([5.22288505e-02, 3.94783721e-02, 3.29460235e-02, 6.27854966e+03,\n",
       "       1.81322217e+04, 2.01847985e+04, 1.56110186e+04]), array([4.59210324e-02, 3.17754408e-02, 3.75392591e-02, 2.79599712e+03,\n",
       "       8.37452682e+03, 9.36512056e+03, 6.22258891e+03])], 'llTrajectory': [90897.96160983646, 90822.30100460075, 90813.7933164202, 91195.13795952266, 90824.4409889472, 90948.83020724998, 90833.29153831744, 90914.45047672343, 90828.49674330515, 90894.21608835603]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0459, 0.0318, 0.0375], dtype=torch.float64), 'alphas': tensor([2795.9971, 8374.5268, 9365.1206, 6222.5889], dtype=torch.float64), 'PDV_c1true': tensor([0.8817, 0.0646, 0.0280, 0.0258], dtype=torch.float64), 'PDV_c2true': tensor([0.8855, 0.0281, 0.0642, 0.0257], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7387, 0.0989, 0.0991, 0.0620], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8621, 0.0774, 0.0258, 0.0346], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8541, 0.0256, 0.0859, 0.0344], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.7009, 0.1097, 0.1173, 0.0721], dtype=torch.float64)}}, {'allRes': {'lls': [90674.24682333917, 90639.08503812845, 90635.38566081121], 'params': [array([8.25512430e-02, 4.47077237e-02, 3.81560217e-02, 4.85958175e+03,\n",
       "       1.15702661e+04, 1.34392115e+04, 1.46426684e+04]), array([3.22876832e-02, 3.94240441e-02, 4.00764617e-02, 7.08816185e+03,\n",
       "       2.15671201e+04, 2.13042256e+04, 1.77545086e+04]), array([4.38503233e-02, 4.14981181e-02, 4.02783387e-02, 4.39219918e+03,\n",
       "       1.27983245e+04, 1.36739819e+04, 1.11025385e+04])], 'llTrajectory': [90674.24682333917, 90639.08503812845, 90824.46248323756, 90645.51300320614, 90877.98499150135, 90635.38566081121, 90641.18017866093, 90640.17212894236, 90647.75311221162, 90634.58400619372]}, 'nEpochs': 10, 'bestRes': {'pis': tensor([0.0439, 0.0415, 0.0403], dtype=torch.float64), 'alphas': tensor([ 4392.1992, 12798.3245, 13673.9819, 11102.5385], dtype=torch.float64), 'PDV_c1true': tensor([0.8838, 0.0650, 0.0281, 0.0260], dtype=torch.float64), 'PDV_c2true': tensor([0.8842, 0.0280, 0.0629, 0.0252], dtype=torch.float64), 'PDV_cBothTrue': tensor([0.7435, 0.0991, 0.0996, 0.0620], dtype=torch.float64), 'PDV_c1inferred': tensor([0.8659, 0.0758, 0.0260, 0.0323], dtype=torch.float64), 'PDV_c2inferred': tensor([0.8616, 0.0258, 0.0804, 0.0322], dtype=torch.float64), 'PDV_cBothInferred': tensor([0.6969, 0.1137, 0.1179, 0.0715], dtype=torch.float64)}}])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resByParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.subplot([1,len(resByParams)])\n",
    "i = 0\n",
    "with open(\"mvln-sim-mvln-res.tsv\", \"w\") as file:\n",
    "    file.write(f\"Notes: 15000 samples1, 15000 samples2, 6000 samplesBoth; rrs generated from normal distribution with. 1 variance, .4 covariance, and individual effect rr summed with shared-effect rr in genes affecting both conditions\\n\")\n",
    "    file.write(f\"\\tmean\\tstd\\n\")\n",
    "    for res in resByParams:\n",
    "        i += 1\n",
    "\n",
    "        paramsRun = res[0]\n",
    "        resRun = res[1]\n",
    "\n",
    "        pis = tensor([x[\"bestRes\"][\"pis\"].numpy() for x in resRun])\n",
    "        PDV_c1true = tensor([x[\"bestRes\"][\"PDV_c1true\"].numpy() for x in resRun])\n",
    "        PDV_c2true = tensor([x[\"bestRes\"][\"PDV_c2true\"].numpy() for x in resRun])\n",
    "        PDV_c3true = tensor([x[\"bestRes\"][\"PDV_cBothTrue\"].numpy() for x in resRun])\n",
    "        PDV_c1inferred = tensor([x[\"bestRes\"][\"PDV_c1inferred\"].numpy() for x in resRun])\n",
    "        PDV_c2inferred = tensor([x[\"bestRes\"][\"PDV_c2inferred\"].numpy() for x in resRun])\n",
    "        PDV_c3inferred = tensor([x[\"bestRes\"][\"PDV_cBothInferred\"].numpy() for x in resRun])\n",
    "\n",
    "        file.write(f\"\\n\\ntrue params: \\t{paramsRun} \\n\\n\")\n",
    "\n",
    "        file.write(f\"pi\\t {pis.mean(0).numpy()} \\t  {pis.std(0).numpy()} \\n\")\n",
    "\n",
    "        file.write(f\"PDV_c1inferred \\t {PDV_c1inferred.mean(0).numpy()}\\t {PDV_c1inferred.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c1true \\t {PDV_c1true.mean(0).numpy()} \\t {PDV_c1true.std(0).numpy()}\\n\")\n",
    "        file.write(f\"PDV_c2inferred \\t {PDV_c2inferred.mean(0).numpy()} \\t {PDV_c2inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c2true \\t {PDV_c2true.mean(0).numpy()} \\t {PDV_c2true.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3inferred \\t {PDV_c3inferred.mean(0).numpy()} \\t {PDV_c3inferred.std(0).numpy()}\\n\")\n",
    "        \n",
    "        file.write(f\"PDV_c3true \\t {PDV_c3true.mean(0).numpy()} \\t {PDV_c3true.std(0).numpy()}\\n\")\n",
    "\n",
    "    #     plt.figure(i)\n",
    "    #     plt.plot(t, s1)\n",
    "    #     plt.plot(t, 2*s1)\n",
    "        # plt.subplot(222)\n",
    "        # plt.plot(t, 2*s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Tensor is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5cb54c57e780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mvln-sim-mvn.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached6NormalSimRes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Tensor is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open('./mvln-sim-mvn.json', 'w') as outfile:\n",
    "    json.dump(cached6NormalSimRes, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 5\n"
     ]
    }
   ],
   "source": [
    "def one(a, b, c, d = 5):\n",
    "    print(a, b, c, d)\n",
    "    \n",
    "def two(*args, **kwargs):\n",
    "    one(*args, **kwargs)\n",
    "    \n",
    "two(1, 2, c = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size = multiprocessing.cpu_count()\n",
    "os.system('taskset -cp 0-%d %s' % (pool_size, os.getpid()))\n",
    "\n",
    "genData.runSim(fitMethod=\"nelder-mead\", mt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('taskset -p %s' %os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "def compute_something(t):\n",
    "    a = 0.\n",
    "    for i in range(10000000):\n",
    "        a = math.sqrt(t)\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Pool size:\", pool_size)\n",
    "pool = multiprocessing.Pool(processes=pool_size)\n",
    "\n",
    "inputs = range(10)\n",
    "\n",
    "tic = time.time()\n",
    "builtin_outputs = map(compute_something, inputs)\n",
    "print('Built-in:', time.time() - tic)\n",
    "\n",
    "tic = time.time()\n",
    "pool_outputs = pool.map(compute_something, inputs)\n",
    "print('Pool    :', time.time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    "# import pyro\n",
    "# from torch.multiprocessing import Process\n",
    "# from torch.distributions import Uniform\n",
    "# import time\n",
    "# import numpy as np\n",
    "# def writer():\n",
    "#     message = f\"I am Process {i}\"\n",
    "#     print(torch.utils.data.get_worker_info())\n",
    "#     x = np.random.seed()\n",
    "#     x = np.random.randint(1000)\n",
    "#     print('seed', x)\n",
    "#     torch.manual_seed(x)\n",
    "#     pis = Uniform(1/100, .5).rsample([3])\n",
    "#     print(\"r is\", pis)\n",
    "#     time.sleep(1)\n",
    "\n",
    "# def reader(i,q):\n",
    "#     message = q.get()\n",
    "#     print(\"got message\", message)\n",
    "\n",
    "# for i in range(10):\n",
    "   \n",
    "#     Process(target=writer, args=()).start()\n",
    "#     time.sleep(.5)\n",
    "#    # Create multiprocessing pool\n",
    "#     p = Pool(10)\n",
    "#    # Create a group of parallel readers and start them\n",
    "#    # Number of readers is matching the number of writers\n",
    "#    # However, the number of simultaneously running\n",
    "#    # readers is constrained to the pool size\n",
    "#     readers = []\n",
    "#     for i in range(10):\n",
    "#         readers.append(p.apply_async(reader, (i,q,)))\n",
    "#     # Wait for the asynchrounous reader threads to finish\n",
    "#     [r.get() for r in readers]\n",
    "    \n",
    "    \n",
    "#     # Establish communication queues\n",
    "#     tasks = torch.multiprocessing.JoinableQueue()\n",
    "#     results = torch.multiprocessing.Queue()\n",
    "    \n",
    "#     # Start consumers\n",
    "#     num_consumers = torch.multiprocessing.cpu_count()\n",
    "#     print('Creating %d consumers' % num_consumers)\n",
    "#     consumers = [ Consumer(tasks, results)\n",
    "#                   for i in range(num_consumers) ]\n",
    "#     for w in consumers:\n",
    "#         w.start()\n",
    "    \n",
    "#     # Enqueue jobs\n",
    "#     for i in range(nEpochs):\n",
    "#         tasks.put(Task(altCountsByGene, pDs, 1, minLLThresholdCount, K, debug, costFnIdx, method))\n",
    "    \n",
    "#     # Add a poison pill for each consumer\n",
    "#     for i in range(nEpochs):\n",
    "#         tasks.put(None)\n",
    "\n",
    "#     # Wait for all of the tasks to finish\n",
    "#     tasks.join()\n",
    "    \n",
    "#     # Start printing results\n",
    "#     while nEpochs:\n",
    "#         result = results.get()\n",
    "#         print('Result:', result)\n",
    "#         num_jobs -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e0d0c7993644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msmoke_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'CI'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.3.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genData.runSim(fitMethod=\"nelder-mead\", mt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.distributions import DirichletMultinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c19e38a749ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDirichletMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pyro/distributions/conjugate.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, concentration, total_count, is_sparse, validate_args)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtotal_count_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_count_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "DirichletMultinomial(total_count=1000, concentration=[1, 1, 1, 1]).log_prob([10, 10, 10, 10.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0309, 0.0309, 0.0123])\n",
      "TESTING WITH: nCases tensor([10000., 10000.,  4000.]) nCtrls tensor(300000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0309, 0.0309, 0.0123]) covShared tensor([[1.0000, 0.4000, 0.4000],\n",
      "        [0.4000, 1.0000, 0.4000],\n",
      "        [0.4000, 0.4000, 1.0000]]) covSingle tensor([[1, 0],\n",
      "        [0, 1]])\n",
      "\n",
      "\n",
      "test tensor 1.0,0.4,0.4,0.4,1.0,0.4,0.4,0.4,1.0\n",
      "tensor([[1.9867, 2.1042, 3.2338],\n",
      "        [4.5166, 3.9892, 6.5085],\n",
      "        [2.1628, 4.0168, 2.9383],\n",
      "        ...,\n",
      "        [3.4382, 1.6703, 4.7380],\n",
      "        [3.7114, 4.2180, 5.0796],\n",
      "        [2.4717, 1.4380, 4.2203]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 324000\n"
     ]
    }
   ],
   "source": [
    "rrs = tensor([1.5, 1.5, 1.5])\n",
    "pis = tensor([.05, .05, .05])\n",
    "nCases = tensor([10e3, 10e3, 4e3])\n",
    "nCtrls = tensor(3e5)\n",
    "afMean = 1e-4\n",
    "rrShape=tensor(50.)\n",
    "afShape=tensor(50.)\n",
    "generatingFn =  genData.v6normal\n",
    "fitMethod = 'nelder-mead'\n",
    "nEpochs=20\n",
    "mt = True\n",
    "covShared=tensor([[1,.4,.4], [.4, 1, .4], [.4, .4, 1]])\n",
    "covSingle=tensor([[1, 0], [0, 1]])\n",
    "\n",
    "try:\n",
    "    params = genData.genParams(rrMeans=rrs, pis=pis, afMean=afMean, rrShape=rrShape, afShape=afShape, nCases=nCases, nCtrls=nCtrls)[0]\n",
    "    testData = generatingFn(**params, covShared=covShared, covSingle=covSingle)\n",
    "except Exception as e:\n",
    "    print(f\"Run failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0309, 0.0309, 0.0123])\n",
      "TESTING WITH: nCases tensor([10000., 10000.,  4000.]) nCtrls tensor(300000.) rrMeans tensor([5, 5, 5]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0497, 0.0464, 0.0399], dtype=torch.float64) pDs tensor([0.0309, 0.0309, 0.0123]) covShared tensor([[1.0000, 0.4000, 0.4000],\n",
      "        [0.4000, 1.0000, 0.4000],\n",
      "        [0.4000, 0.4000, 1.0000]]) covSingle tensor([[1, 0],\n",
      "        [0, 1]])\n",
      "\n",
      "\n",
      "test tensor 1.0,0.4,0.4,0.4,1.0,0.4,0.4,0.4,1.0\n",
      "tensor([[10.3081,  9.4097, 15.2060],\n",
      "        [ 8.1203,  9.3432, 13.5178],\n",
      "        [ 8.8127,  9.7096, 14.0267],\n",
      "        ...,\n",
      "        [10.4118, 11.9602, 17.1313],\n",
      "        [11.5200,  9.3873, 14.7469],\n",
      "        [10.2958,  9.7454, 14.2432]], dtype=torch.float64)\n",
      "startIndices [0, tensor(993.4008, dtype=torch.float64), tensor(1921.1444, dtype=torch.float64)] endIndices tensor([ 993.4008, 1921.1444, 2719.5345], dtype=torch.float64)\n",
      "totalSamples 324000\n"
     ]
    }
   ],
   "source": [
    "rrsLarge = tensor([5, 5, 5])\n",
    "\n",
    "try:\n",
    "    paramsLarge = genData.genParams(rrMeans=rrsLarge, pis=pis, afMean=afMean, rrShape=rrShape, afShape=afShape, nCases=nCases, nCtrls=nCtrls)[0]\n",
    "    testDataLarge = generatingFn(**paramsLarge, covShared=covShared, covSingle=covSingle)\n",
    "except Exception as e:\n",
    "    print(f\"Run failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nGenes': 20000,\n",
       " 'nCases': tensor([10000., 10000.,  4000.]),\n",
       " 'nCtrls': tensor(300000.),\n",
       " 'pDs': tensor([0.0309, 0.0309, 0.0123]),\n",
       " 'diseaseFractions': tensor([0.0500, 0.0500, 0.0500]),\n",
       " 'rrShape': tensor(50.),\n",
       " 'rrMeans': tensor([1.5000, 1.5000, 1.5000]),\n",
       " 'afShape': tensor(50.),\n",
       " 'afMean': 0.0001}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 4])\n",
      "pdCtrl, pd1, pd2, pdBoth:  tensor([0.9259, 0.0309, 0.0309, 0.0123], dtype=torch.float64)\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7f9589d62cb0>\n",
      "best ll: 74255.85016436226, bestParams: [0.096755035, 0.077788964, 0.07774635, 10181.05, 19670.508, 15529.679, 18778.402]\n",
      "Epoch took 239.9891939163208\n"
     ]
    }
   ],
   "source": [
    "testFit = likelihoods.fitFnBivariate(testData[\"altCounts\"], params[\"pDs\"], nEpochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 4])\n",
      "pdCtrl, pd1, pd2, pdBoth:  tensor([0.9259, 0.0309, 0.0309, 0.0123], dtype=torch.float64)\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7f958bb49050>\n",
      "best ll: 83377.69977565794, bestParams: [0.036576215, 0.022326665, 0.05933401, 803.6931, 7893.184, 9348.684, 18137.139]\n",
      "Epoch took 58.76386499404907\n"
     ]
    }
   ],
   "source": [
    "testFitLarge = likelihoods.fitFnBivariate(testDataLarge[\"altCounts\"], paramsLarge[\"pDs\"], nEpochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.96700407e-02, 4.63871772e-02, 3.99195082e-02, 3.74160080e+02,\n",
       "        8.27225743e+02, 8.64313147e+02, 7.68432063e+02])]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFit[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.63864639e-02, 4.03900172e-02, 3.97658043e-02, 1.70694632e+02,\n",
       "        1.10274908e+03, 1.18464482e+03, 7.13244313e+03])]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFitLarge[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lls', 'llsAll', 'params', 'trajectoryLLs', 'trajectoryPi', 'trajectoryAlphas'])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFit.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = tensor(testFit[\"trajectoryAlphas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "taLarge = tensor(testFitLarge[\"trajectoryAlphas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-869cdce3ce85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestFit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbestLL\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbestLL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mbestParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mbestLL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "bestLL = None\n",
    "bestParams = None\n",
    "for x in testFit:\n",
    "    if bestLL is None or x[\"lls\"][0] < bestLL:\n",
    "        bestParams = x[\"params\"][0]\n",
    "        bestLL = x[\"lls\"][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9589a4f050>]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(testFit[\"trajectoryLLs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9589acdf50>]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAb60lEQVR4nO3de5Ad5X3m8e+j0QUQ6C5koQuSbcXLxWwQE6x1gk0MKwT2WtjBXpF4kQll1mvY2JVsxXLIGpcxDsSVdRVrG5YsCoLFXIJNUIEICIKh4rIAcbEkrhruUnRDEhJX3ea3f5x3RM/M6Zk599bo+VRNTZ/f6e7znh6pn9Pv26dbEYGZmVk5Q1rdADMzKy6HhJmZ5XJImJlZLoeEmZnlckiYmVmuoa1uQL1NmDAhZsyY0epmmJkdUB5//PE3ImJiz/qgC4kZM2awcuXKVjfDzOyAIunVcnV3N5mZWS6HhJmZ5XJImJlZLoeEmZnlckiYmVkuh4SZmeVySJiZWS6HRAtEBL94fB3v79nX6qaYmfXJIdEC/9rxBn/xj7/lh8uebXVTzMz61G9ISFosabOkNZnaZZJWSXpK0n2Sjkp1SbpKUkd6fnZmmYWS1qafhZn6SZJWp2WukqRUHydpeZp/uaSx9X3rrfP2+3sB2LxzV4tbYmbWt4EcSVwPzOtR+1FEnBARvwvcBXw31c8EZqWfC4GrobTDBy4FPgGcDFya2elfDXwts1zXay0CHoiIWcAD6fGgEviugGZWbP2GREQ8DGzrUduZeTgS9u/t5gM3RMkKYIykycAZwPKI2BYR24HlwLz03KiIWBGl+6jeAJydWdeSNL0kU2+5v7pjNe0/uL/VzTAza7iqL/An6XLgPGAH8IepPAV4PTPbulTrq76uTB1gUkRsSNMbgUl9tOVCSkcuTJ8+vYp3U5mfP/Jaw1/DzKwIqh64johLImIacBNwcf2aVPa1AvL7ZiLi2ohoj4j2iRN7Xem2cEqjLhDubTKzgqvH2U03AX+UptcD0zLPTU21vupTy9QBNqXuKNLvzXVoq5mZVaCqkJA0K/NwPvBcml4KnJfOcpoD7EhdRvcCcyWNTQPWc4F703M7Jc1JZzWdB9yZWVfXWVALM/XCeOiFLVUtt3ufDyHM7MAwkFNgbwZ+A3xM0jpJFwBXSFojaRWlHf430+zLgJeADuDvgW8ARMQ24DLgsfTz/VQjzfN/0zIvAvek+hXAf5S0Fjg9PS6UhYsfrWq5P7v5yTq3xMysMfoduI6Ic8uUr8uZN4CLcp5bDCwuU18JHF+mvhU4rb/21duefZ383X0v8N9O/QijDx1W0bL/56EXGTliKF+ZczQAr297l1P+9kGu/S8nMfe4DzWiuWZmDeVvXPewbPUGrnnoRa6454NvQ7+3e2CXz/ibe57jr/9p/3cOWb1+BwB3PLk+bxEzs0JzSPSwe28nALvS7xUvbeWY7/4zv+54o+J1dabTl4Z0nc4ELP7Xl+vQSjOz5qj6exKD0a2Pvcbdqzd2qz36cmnoZMVLW7nsrmf4+JTR/a7n2odfZPfeTo4eP7JU+CAj+P5dz+yfvu+ZTcxYdDevXPHZ2htvZtYADomMb/9idZ/PP7fxLZ7b+Fav+q2Pvcbk0Yfuf/zDZaWTva4690SgW0aUFRFI/c1lZtZ8Dokcv3xiPVPGHMqwtv575PLCJVJ3012rNnDXqru586LfLzvfe3v2cdhw/ynMrHg8JtGHG37zKq+88Q5Q3bejv3nLU90ez//pr8vO1+mvTZhZQTkk+jD60GH8Mp2ZdP+zm1rcGjOz5nNIDNC2d3Y3bN2/et5XHDGzYnJI9CF7v4fOBl6N7+Kf+xvYZlZMDolk69t93yVunwcOzOwg5JBIbn6073tEbH93T5NaYmZWHA6JPvh+D2Z2sHNI9MEhYWYHO4dEH9a/+V6rm2Bm1lIOCTMzy+WQMDOzXA6JpNUX2PMptmZWRA6Jgjj/+sda3QQzs14cEgXx8AtbWt0EM7NeHBI12rV3YLc2NTM7EDkkavRXv1zT/0wDdOOKV7nyn5+r2/rMzGrlkKjRE69tr9u6/uc/reHqX71Yt/WZmdXKIVEj33TUzAYzh0StGpASz23cWf+VmplVwSFRo0YcSby85Z0GrNXMrHIOiRq1+kt4ZmaN5JCoUSMi4icPdjRgrWZmlXNI1KgRBxJP/5vHJMysGBwSNZLPbzKzQcwhUSMPSZjZYOaQMDOzXA6JGvnsJjMbzPoNCUmLJW2WtCZT+5Gk5yStknSHpDGZ574jqUPS85LOyNTnpVqHpEWZ+kxJj6T6rZKGp/qI9LgjPT+jXm+6noY4I8xsEBvIkcT1wLweteXA8RFxAvAC8B0ASccCC4Dj0jI/k9QmqQ34KXAmcCxwbpoX4ErgxxHxUWA7cEGqXwBsT/Ufp/kKxwcSZjaY9RsSEfEwsK1H7b6I2JsergCmpun5wC0RsSsiXgY6gJPTT0dEvBQRu4FbgPkq9dV8Brg9Lb8EODuzriVp+nbgNLlvx8ysqeoxJvGnwD1pegrweua5damWVx8PvJkJnK56t3Wl53ek+XuRdKGklZJWbtnS3Jv3DHFumdkgVlNISLoE2AvcVJ/mVCciro2I9ohonzhxYlXrqHZf74gws8FsaLULSvoq8DngtIiIVF4PTMvMNjXVyKlvBcZIGpqOFrLzd61rnaShwOg0f7H4SMLMBrGqjiQkzQP+Evh8RLybeWopsCCdmTQTmAU8CjwGzEpnMg2nNLi9NIXLg8A5afmFwJ2ZdS1M0+cA/5IJo8JwRJjZYNbvkYSkm4FTgQmS1gGXUjqbaQSwPI0lr4iIr0fE05JuA56h1A11UUTsS+u5GLgXaAMWR8TT6SW+Ddwi6QfAk8B1qX4dcKOkDkoD5wvq8H7rzgcSZjaY9RsSEXFumfJ1ZWpd818OXF6mvgxYVqb+EqWzn3rW3we+1F/7Ws0ZYWaDmb9xXSOflWtmg5lDokaOCDMbzBwSNfKBhJkNZg6JGvl+EmY2mDkkauWMMLNBzCGRVHtE4Iwws8HMIVEjj0mY2WDmkKiRL/BnZoOZQ6JGzggzG8wcEjX6dUfxrjloZlYvDgkzM8vlkDAzs1wOCTMzy+WQMDOzXA4JMzPL5ZBIfCqrmVlvDgkzM8vlkDAzs1wOCTMzy+WQSCJa3QIzs+JxSJiZWS6HhJmZ5XJImJlZLodEEnhQwsysJ4eEmZnlckgkPrvJzKw3h4SZmeVySJiZWS6HhJmZ5XJImJlZLodEEh65NjPrxSFhZma5+g0JSYslbZa0JlP7kqSnJXVKau8x/3ckdUh6XtIZmfq8VOuQtChTnynpkVS/VdLwVB+RHnek52fU4w2bmdnADeRI4npgXo/aGuCLwMPZoqRjgQXAcWmZn0lqk9QG/BQ4EzgWODfNC3Al8OOI+CiwHbgg1S8Atqf6j9N8ZmbWRP2GREQ8DGzrUXs2Ip4vM/t84JaI2BURLwMdwMnppyMiXoqI3cAtwHxJAj4D3J6WXwKcnVnXkjR9O3Bamr8hPCRhZtZbvcckpgCvZx6vS7W8+njgzYjY26PebV3p+R1p/l4kXShppaSVW7ZsqdNbMTOzQTFwHRHXRkR7RLRPnDixunXUuU1mZoNBvUNiPTAt83hqquXVtwJjJA3tUe+2rvT86DS/mZk1Sb1DYimwIJ2ZNBOYBTwKPAbMSmcyDac0uL00Sl9OeBA4Jy2/ELgzs66Fafoc4F/CX2YwM2uqof3NIOlm4FRggqR1wKWUBrL/NzARuFvSUxFxRkQ8Lek24BlgL3BRROxL67kYuBdoAxZHxNPpJb4N3CLpB8CTwHWpfh1wo6SO9HoL6vGG8zh+zMx66zckIuLcnKfuyJn/cuDyMvVlwLIy9Zconf3Us/4+8KX+2mdmZo0zKAau68F3pjMz680hYWZmuRwSZmaWyyGReODazKw3h4SZmeVySCSVHEhMOHx4w9phZlYkDgkzM8vlkDAzs1wOiao07IrlZmaF4pDo4tObzMx6cUhUoXG3PjIzKxaHhJmZ5XJIJJV0NvlAwswOFg6JKri7ycwOFg6JZOxh/oKcmVlPDonk8EP6vbXGfu/u3tfAlpiZFYdDogpvvb+31U0wM2sKh0QXf03CzKwXh0RBhb/cZ2YF4JBIinb70s5iNcfMDlIOiYLykYSZFYFDoqAcEWZWBA6JpGgf3IvWHjM7ODkkzMwsl0MiyX5wP6KCL9Y1StEG0s3s4OSQKOOEqaNb3QQzs0JwSJShAlzn1WMSZlYEDonEO2Uzs94cEmX4UuBmZiUOiaRoA8U+sjGzInBImJlZrn5DQtJiSZslrcnUxklaLmlt+j021SXpKkkdklZJmp1ZZmGaf62khZn6SZJWp2WukkqdPXmv0QwqQH9T0Y5szOzgNJAjieuBeT1qi4AHImIW8EB6DHAmMCv9XAhcDaUdPnAp8AngZODSzE7/auBrmeXm9fMaDZHt3ml9RJiZFUO/IRERDwPbepTnA0vS9BLg7Ez9hihZAYyRNBk4A1geEdsiYjuwHJiXnhsVESuidEW7G3qsq9xrHDD+66c/XPWyHpMwsyKodkxiUkRsSNMbgUlpegrwema+danWV31dmXpfr9EQjdgn//HJ0xuwVjOz5ql54DodATT0c29/ryHpQkkrJa3csmVLza9XryGJoW3Vb14fSJhZEVS7F9uUuopIvzen+npgWma+qanWV31qmXpfr9FLRFwbEe0R0T5x4sTq3lED+ncOHdZW9bK+n4SZFUG1IbEU6DpDaSFwZ6Z+XjrLaQ6wI3UZ3QvMlTQ2DVjPBe5Nz+2UNCed1XRej3WVe42GaMQuuZaQMDMrgn4vdyrpZuBUYIKkdZTOUroCuE3SBcCrwJfT7MuAs4AO4F3gfICI2CbpMuCxNN/3I6JrMPwblM6gOhS4J/3Qx2s0RPaD+5A69TcNa6t+PT6OMLMi6DckIuLcnKdOKzNvABflrGcxsLhMfSVwfJn61nKv0SjZ7h2fAmtmVuJvXCf1/uR+zklT+5+pDx6SMLMicEgk9d4pTx93WLdvbn/xxCl9zG1mVkwOiSSbEfUYktjX2T11BnKpj5/9yewPHvhIwswKwCGRDPSU01eu+CzDB/D9h//8e9O6PR4ygOBxF5OZFY1Doqx+9ugD2OEfNebQbrNVenTiC/yZWRE4JJJuF/irPSN6GchptQW4+KyZWTcOiaSST+7V7MwHMiaRDSp3PZlZETgkkkouFa4BHktkc6Hy7iYzs9ZzSCSN3im7J8nMDkQOiaSiMYmc508/Jv9q5pVe6sMX+DOzInBIJJWMSeTtv/vKAQ9Km9mByCGRVPLBfc++zgHNlx2srvhIoqK5zcwawyFRRn8D03s7K9+Fn3Hch6ptjplZyzgkks4KdvxHjOj34rm9jDlsWEXze0jCzIrAIZFUsk+eNPqQitc/kN6mWu4/YWbWCA6JpAif3E8/ZhKTRo0AfFkOMysGh0SS3Sk34kykgXwBb8gQ8d8/M6urQWZmLeeQSModSUwde2jOvI3bg/tUWTMrEodEUrQP7kVrj5kdnBwSXcocHVR6wFCPg4CBXhfKzKwZHBJJPe5MN7SOZycVYSDdzMwhkZTbKX8o51TXvP33ZfOPz13/QIPHYxJmViQOiaTcKacLPzmDa74yu8zcvR09/jDGHz6ioe0xM2s2h0TS/X4SpY/zQwTzjp88oOU769Q/5AMJMysSh0RS6y6+s59r/lW68/eYhJkVgUMiqWin3MAduMckzKxIHBJJuTGASoKjXt1N+1+7rmszM6uOQ6JLt3Ngy8/y9U9/JHfx/kJiwGc3pRf3nenMrAgqv+b1IDWQXfKiM/9d/vI5K/iH83+P17e9O/CGuLvJzArEIZGU++SeFxzl6nm3o/jDjx0JQMfmtypsT0Wzm5k1hLubks5up8BWrl7dQz6QMLMicUgklezjs4Hw+F+fDgxk4Nq7fzM78NQUEpK+KWmNpKclfSvVxklaLmlt+j021SXpKkkdklZJmp1Zz8I0/1pJCzP1kyStTstcJTXuBNFqv+E8JDWpXr1DDXyLZmYVqzokJB0PfA04Gfj3wOckfRRYBDwQEbOAB9JjgDOBWennQuDqtJ5xwKXAJ9K6Lu0KljTP1zLLzau2vf0pdyAwkC6krpCo5B7Z1bbHzKzZajmSOAZ4JCLejYi9wEPAF4H5wJI0zxLg7DQ9H7ghSlYAYyRNBs4AlkfEtojYDiwH5qXnRkXEiijtrW/IrKuh+vs0323/nWbtb6c+8FNgzcyKo5aQWAOcImm8pMOAs4BpwKSI2JDm2QhMStNTgNczy69Ltb7q68rUe5F0oaSVklZu2bKlqjeTPWo45aMTAJh15BH9LjekKyT6me/II8pf/G/auJy73/nrdGZWAFWfAhsRz0q6ErgPeAd4CtjXY56Q1PC9XURcC1wL0N7eXtXrZRf6UvtUTjvmyAFd1XV/d1M/hxJHHDKMVd+by/Z3dvPpH/0KgDu+8UmmjzuMk35w//75NMAjEzOzZqhp4DoirouIkyLiU8B24AVgU+oqIv3enGZfT+lIo8vUVOurPrVMvSG6XQVWGvBlvwcaEgCjDhnG0eNH7n984vSxvV7H49ZmViS1nt10ZPo9ndJ4xM+BpUDXGUoLgTvT9FLgvHSW0xxgR+qWuheYK2lsGrCeC9ybntspaU46q+m8zLrqrpLunWweDEt3o/vqJ2fWuT1mZq1X6zeufyFpPLAHuCgi3pR0BXCbpAuAV4Evp3mXURq36ADeBc4HiIhtki4DHkvzfT8itqXpbwDXA4cC96SfhvjCiVP5fyteq3i5oW1DeOWKz9atHb7HtZkVSU0hERGnlKltBU4rUw/gopz1LAYWl6mvBPLvCVpHJx09tv+Z6uQnf3wiHxpV/taoXXyBPzMrAl+7qQb3//mnq1rucycclfucxyTMrEh8WY4qdI1fdI1HNOY1zMxazyFRg3qNHxw1uu+uJzOzVnF3UxXqPVxw15+dwoYd7zX0NczMquGQKIBxI4czbuRwwBf4M7NicXdTYflQwsxazyFRg0Z86O9apbubzKwIHBJVaOQO3L1NZlYkDomC8oGEmRWBQ6JgfFkOMysSh0RBeUzCzIrAp8DW2TVfmb3/8uHV8JiEmRWJQ2IAbv/6f2DPvoF9tJ93/OS6vKbvTGdmReCQGID2GeOa9lo+kDCzIvGYRMb0cYdVNH8ju4Y8JmFmReAjiYw7L/p9Nu58v9/5GnmvB9/j2syKxCGRMXbkcMamaygNRGOus+QOJzMrDnc3FZQHrs2sCBwSBeNTYM2sSBwSVWjGZ3yPSZhZETgkatDIEYm/uO237Hx/TwNewcxs4BwSVTjnpKkAjDp0WN3XPf7wEQA8v+ktTvjefSy49jfc+JtX2PxW/2ddmZnVmxp5OmcrtLe3x8qVKxv6GhHBrr2dHDKsrSHr37DjPVa+sp0163dw/7ObeHHLO0hw8oxxfPaEyXzyI+M5evxIhrU5482sPiQ9HhHtveoOiWKLCF7Y9DZ3r97AstUb6Nj89v7nvtw+lVM/diRvvL0LSUwedQjTxh3GIcOGMP7wEbSlUfARQ4fQGcFQh4qZ5XBIDBIvbHqL8//hMda/+d6Alxki6IxSWATQ2RmMGDqEtiHa/10PqTQeIin9BhBSafnsJcyzZ2DljcsU/V7d9WpePd9mvS4TX7f3Vp/V1PXfQt3WVLBtBPXZTj/8wsc5eWZ1lxHKCwl/me4A8zuTjuDXiz4DwNP/toNV63aw9e1dbNz5Ppt27uLjU0az+a33mT7uMPZ1wr7OTt7bs4/hbW28u3svkhgi2LW3k32dpQ8IEaVvZUSUvp/R9bmh9HTQ2fnB62e/v5H3+aJcuUifRer2HZQ6vqd6rapeH/rq1546rYjBu43qubKRI+rfBe6QOIAdd9RojjtqdKubYWaDmDupzcwsl0PCzMxyOSTMzCyXQ8LMzHI5JMzMLJdDwszMcjkkzMwsl0PCzMxyDbrLckjaArxa5eITgDfq2JxGclsbw22tvwOlnXBwt/XoiJjYszjoQqIWklaWu3ZJEbmtjeG21t+B0k5wW8txd5OZmeVySJiZWS6HRHfXtroBFXBbG8Ntrb8DpZ3gtvbiMQkzM8vlIwkzM8vlkDAzs1wOiUTSPEnPS+qQtKjFbZkm6UFJz0h6WtI3U/17ktZLeir9nJVZ5jup7c9LOqPJ7X1F0urUppWpNk7Scklr0++xqS5JV6W2rpI0u4nt/Fhm2z0laaekbxVlu0paLGmzpDWZWsXbUdLCNP9aSQub2NYfSXoutecOSWNSfYak9zLb95rMMielfzsd6f3U/b63OW2t+G/ejH1ETltvzbTzFUlPpXpztmtEHPQ/QBvwIvBhYDjwW+DYFrZnMjA7TR8BvAAcC3wP+B9l5j82tXkEMDO9l7YmtvcVYEKP2t8Ci9L0IuDKNH0WcA+l2wPPAR5p4d98I3B0UbYr8ClgNrCm2u0IjANeSr/HpumxTWrrXGBomr4y09YZ2fl6rOfR1H6l93Nmk9pa0d+8WfuIcm3t8fzfAd9t5nb1kUTJyUBHRLwUEbuBW4D5rWpMRGyIiCfS9FvAs8CUPhaZD9wSEbsi4mWgg9J7aqX5wJI0vQQ4O1O/IUpWAGMkTW5B+04DXoyIvr6d39TtGhEPA9vKtKGS7XgGsDwitkXEdmA5MK8ZbY2I+yJib3q4Apja1zpSe0dFxIoo7dlu4IP319C29iHvb96UfURfbU1HA18Gbu5rHfXerg6JkinA65nH6+h7p9w0kmYAJwKPpNLF6XB+cVfXA61vfwD3SXpc0oWpNikiNqTpjcCkNN3qtnZZQPf/bEXcrlD5dixCmwH+lNIn2C4zJT0p6SFJp6TaFErt69LstlbyNy/Cdj0F2BQRazO1hm9Xh0SBSToc+AXwrYjYCVwNfAT4XWADpUPPIviDiJgNnAlcJOlT2SfTp5nCnGstaTjweeAfU6mo27Wbom3HPJIuAfYCN6XSBmB6RJwI/Dnwc0mjWtW+5ID4m/dwLt0/2DRluzokStYD0zKPp6Zay0gaRikgboqIXwJExKaI2BcRncDf80HXR0vbHxHr0+/NwB2pXZu6upHS781FaGtyJvBERGyC4m7XpNLt2NI2S/oq8DngT1Kokbputqbpxyn17f9Oale2S6ppba3ib97q7ToU+CJwa1etWdvVIVHyGDBL0sz0KXMBsLRVjUl9j9cBz0bE/8rUs333XwC6zoBYCiyQNELSTGAWpYGrZrR1pKQjuqYpDV6uSW3qOrNmIXBnpq3npbNz5gA7Mt0pzdLtE1kRt2tGpdvxXmCupLGpC2VuqjWcpHnAXwKfj4h3M/WJktrS9IcpbceXUnt3SpqT/s2fl3l/jW5rpX/zVu8jTgeei4j93UhN2671Hp0/UH8onS3yAqU0vqTFbfkDSt0Kq4Cn0s9ZwI3A6lRfCkzOLHNJavvzNOAMkT7a+mFKZ3r8Fni6a9sB44EHgLXA/cC4VBfw09TW1UB7k7ftSGArMDpTK8R2pRRcG4A9lPqRL6hmO1IaD+hIP+c3sa0dlPrtu/7NXpPm/aP0b+Mp4AngP2XW005pB/0i8BPSVSCa0NaK/+bN2EeUa2uqXw98vce8TdmuviyHmZnlcneTmZnlckiYmVkuh4SZmeVySJiZWS6HhJmZ5XJImJlZLoeEmZnl+v+wy8ghjpGQUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(testFitLarge[\"trajectoryLLs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9588e7eb90>]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAeuUlEQVR4nO3df5iUdb3/8ed7Zn/ALiwssNLKjxYNU9REJKQys0hETh200yntnKTyROdKr6Pf6lxi9v3qUSs7p+zklVmUJJxjmVfZJUcxIo5mlqIrKQikrIgKIb+RHyv7Y+b9/WPuhWGZZXdnZ+aemfv1uK659p7P3Pe97w+zzGvuz/2Ze8zdERGRaIuFXYCIiIRPYSAiIgoDERFRGIiICAoDEREBKsIuIFujRo3ypqamsMsQESkpzz777E53b+jeXrJh0NTURHNzc9hliIiUFDN7NVO7holERERhICIiCgMREUFhICIi9CEMzGycmT1qZuvMbK2ZXRO032RmW8zsueA2O22b682sxcxeNLOL0tpnBW0tZjY/rX2Cma0M2n9hZlW57qiIiPSsL0cGncCX3X0SMB24yswmBY99190nB7elAMFjlwGnA7OAH5hZ3MziwJ3AxcAk4PK0/Xwr2Nc7gD3AlTnqn4iI9EGvYeDuW919VbC8H1gPjDnOJnOA+9y9zd1fAVqAacGtxd03uns7cB8wx8wM+BDwy2D7RcAl2XZIRET6r1/nDMysCTgbWBk0XW1mq81soZnVB21jgNfTNtsctPXUPhLY6+6d3doz/f55ZtZsZs07duzoT+k9WrlxFy3b9+dkXyIiparPYWBmQ4BfAde6+z7gLuBkYDKwFfhOXipM4+4L3H2qu09taDjmA3RZ+eSCp/jw7Y8f0/7Mpt3sPtiek98hIlLs+hQGZlZJKgjudfcHANx9m7sn3D0J/JjUMBDAFmBc2uZjg7ae2ncBw82solt7wf3mha3MW9zMn1p28vc/fJJP/ujJMMoQESm4Xi9HEYzp3w2sd/fb09ob3X1rcPdS4IVgeQnwMzO7HTgRmAg8DRgw0cwmkHqxvwz4lLu7mT0KfJzUeYS5wIO56Fx//fN/rwLgt+u2AbBh+4EwyhARKbi+XJvofcCngTVm9lzQ9lVSs4EmAw5sAr4A4O5rzex+YB2pmUhXuXsCwMyuBpYBcWChu68N9ncdcJ+Z3Qr8mVT4iIhIgfQaBu7+BKl39d0tPc42Xwe+nqF9aabt3H0jR4aZRESkwPQJZBERiV4YJJPOXY+9zP5DHWGXIiJSNCIXBiv+sp1v/eYv3PrQ+rBLEREpGpELg45EEoA33xr4kcFP/rCRB1ZtHvB+RETCVrLfdJatmKXOhSfcB7yvWx9OHV18bMrYAe9LRCRMkTsyiMdSYeBZhIG7s2L9NpLJgQeJiEgxiVwYBFlAIosX9F+t2sKVi5o56+bf5rgqEZFwRS4Muo4M3tjX1u+jgzfefAuA/Yc6e1lTRKS0RDYM1m/dx8+efq1f267fqqubikh5il4Y2JEPU3/j4d6nl7a2d9I0/2EWPvEKD6/Z2uv6IiKlKHJhYGlhcLA90ev69z6VOnq4+aF1eatJRCRskQuDWKarLImIRFzkwiD9yEBERFIiFwbZfL5ARKTcRS4MRETkWAoDERFRGIiIiMIgJw51JGia/zA/+v3LYZciIpIVhUEOHGhLXZ5iweMbQ65ERCQ7CoPA71/akfW2XZNVk5qpJCIlSmEQmLvw6ay37frsgqJAREpV5MIgHy/YXZ9q1oGBiJSqyIVBPlgwUKRhIhEpVQqDXOg6aaAsEJESpTDIga7LHe1v05feiEhpUhjkgC59JyKlTmGQAxodEpFSpzAQEZHohYEm/IiIHCtyYZAPChgRKXWRCwN90ZmIyLF6DQMzG2dmj5rZOjNba2bXBO0jzGy5mW0IftYH7WZmd5hZi5mtNrMpafuaG6y/wczmprWfY2Zrgm3uMH03pYhIQfXlyKAT+LK7TwKmA1eZ2SRgPrDC3ScCK4L7ABcDE4PbPOAuSIUHcCNwLjANuLErQIJ1Pp+23ayBdy2zvAzpaJhIREpcr2Hg7lvdfVWwvB9YD4wB5gCLgtUWAZcEy3OAxZ7yFDDczBqBi4Dl7r7b3fcAy4FZwWN17v6Up76geHHavkrCoc5E2CWIiAxIv84ZmFkTcDawEhjt7luDh94ARgfLY4DX0zbbHLQdr31zhvZMv3+emTWbWfOOHdlfcjoXOhLJw8s3P7QuxEpERAauz2FgZkOAXwHXuvu+9MeCd/R5Hyxx9wXuPtXdpzY0NOT71wE9n3Be9KdNh5f/uvetgtQiIpIvfQoDM6skFQT3uvsDQfO2YIiH4Of2oH0LMC5t87FB2/Hax2ZoLwo9nWPYd0jXIRKR8tGX2UQG3A2sd/fb0x5aAnTNCJoLPJjWfkUwq2g68GYwnLQMmGlm9cGJ45nAsuCxfWY2PfhdV6TtK+ee2rirX+s/2dP6+nCBiJSRij6s8z7g08AaM3suaPsqcBtwv5ldCbwKfCJ4bCkwG2gBWoHPArj7bjO7BXgmWO9md98dLH8RuAcYDDwS3PLieys29Gv9//3L9ozt6VGgXBCRUtdrGLj7E/R8Yc4ZGdZ34Koe9rUQWJihvRk4o7daipWyQERKXeQ+gSwiIsdSGIiIiMIgW66TBiJSRhQGWXp60+7Dy4oCESl1CoMsHUj7nMGhDl2OQkRKm8IgB0zfgiwiJU5hkKWjThlooEhESpzCIEuedtJY549FpNQpDHJAWSAipU5hkANJHRqISIlTGOSAskBESp3CIEvpAeBKAxEpcQqDHFAUiEipUxjkgA4MRKTUKQyylP7ZAn3OQERKncIgB3RkICKlTmGQAwoDESl1CoMspQeAPmcgIqVOYZAlfZ2BiJQThUGW0q9TqhPIIlLqFAZZSn/5TyoLRKTEKQyypKuWikg5URjkhNJAREqbwiAHNEwkIqVOYZClts7k4WVdqE5ESp3CIEub97x1eFlHBiJS6hQGOaAjAxEpdQqDHFAUiEipUxjkgtJAREqcwiAHdG0iESl1CoMc0AlkESl1vYaBmS00s+1m9kJa201mtsXMngtus9Meu97MWszsRTO7KK19VtDWYmbz09onmNnKoP0XZlaVyw6KiEjv+nJkcA8wK0P7d919cnBbCmBmk4DLgNODbX5gZnEziwN3AhcDk4DLg3UBvhXs6x3AHuDKgXQoDBomEpFS12sYuPvjwO4+7m8OcJ+7t7n7K0ALMC24tbj7RndvB+4D5piZAR8Cfhlsvwi4pJ99CJ2iQERK3UDOGVxtZquDYaT6oG0M8HraOpuDtp7aRwJ73b2zW3tGZjbPzJrNrHnHjh0DKD3HlAYiUuKyDYO7gJOBycBW4Ds5q+g43H2Bu09196kNDQ2F+JV9ou8zEJFSV5HNRu6+rWvZzH4MPBTc3QKMS1t1bNBGD+27gOFmVhEcHaSvXzI6EgoDESltWR0ZmFlj2t1Lga6ZRkuAy8ys2swmABOBp4FngInBzKEqUieZl3jqOg6PAh8Ptp8LPJhNTSIikr1ejwzM7OfABcAoM9sM3AhcYGaTSY2WbwK+AODua83sfmAd0Alc5e6JYD9XA8uAOLDQ3dcGv+I64D4zuxX4M3B3znonIiJ90msYuPvlGZp7fMF2968DX8/QvhRYmqF9I6nZRiIiEhJ9AllERBQGIiKiMBARERQGIiKCwkBERFAYiIgICgMREUFhICIiKAxERASFgYiIoDAQEREUBiIigsJARERQGIiICAoDERFBYSAiIigMREQEhYGIiKAwEBERFAYiIoLCQEREUBiIiAgKg7zZvKeV13e3hl2GiEifVIRdQLk671uPArDptr8JuRIRkd7pyCDHDnUkaJr/cNhliIj0i8Igx/7n+b8edX/KLctDqkREpO8UBjn2r79cfdT93QfbaetM9Hs/v39pB3sOtuPuAGzYtp/frduWkxpFRLrTOYMCONiWoLoi3uf1D3UkmLvw6cP3n7z+Q1z43ccBeOWbszGznNcoItGmI4MCuGnJ2n6t/70VG466/55v/u/h5T2tHYeX97a2D6wwEZGAwqAAljz/V865ZTmbdh7sdd1Vr+3hrsde7vHx//OL57jz0Rbu+eMrTL55OTctWUtbZ4InX97FL5/dnMuyRSRCrGtMutRMnTrVm5ub+71doWb63DD7NL6+dP0x7T++Yio7D7Rx2bvHHR7u2X2wnaGDKlj85Kvc8tC6nNVwyughvO8do6gbVEl9TSVtnUkmnVhHfU0VhzoS1NdWAWCAmREziJkRix1ZNoO4WardDIul2uPBY7Fu24lIcTOzZ919avf2Xs8ZmNlC4CPAdnc/I2gbAfwCaAI2AZ9w9z2WenX7HjAbaAU+4+6rgm3mAl8Ldnuruy8K2s8B7gEGA0uBa7xUEyrw2Fcu4O0jazKGwecXpwLs+gfWcO6EEUweP5wf/X5jr/v80oWncPvyl/pVx0vbDvDStgP92maghlRXMKK2ivraKhqGVHH2+HreP3EUp584jLjCQqRo9eUE8j3A94HFaW3zgRXufpuZzQ/uXwdcDEwMbucCdwHnBuFxIzAVcOBZM1vi7nuCdT4PrCQVBrOARwbetXDU11TSNKq2T+uufGU3K1/ZnfGxfzpvAj954hUAJjXW8S8zJvJWR+K4Q0jphlRXcKCtE4Caqjit7QmqK2JcevYYxo2oYWRtFZXx1ChhLBgsdIdE0nGHpDvJ4Ke7k0im3z/68WTwWMKdA4c62X2wjV0H23l1Vyu/W7+d/1j2IsNrKpl9ZiPXzJjI6LpBfeqDiBROr2Hg7o+bWVO35jnABcHyIuAxUmEwB1gcvLN/ysyGm1ljsO5yd98NYGbLgVlm9hhQ5+5PBe2LgUso4TB48KrzDi9/bMoYHli1Jav9fHnmO3miZSfzzj+Jj00ZC8B1s07lulmn8um7V7J9Xxsnn1DLF84/mTPHDCPhfvjFvZjs2N/GH1t2snz9Nn628jV+tvI1/ufq8zhz7LCwSxORNNlOLR3t7luD5TeA0cHyGOD1tPU2B23Ha9+coT0jM5sHzAMYP358lqXnz52fmsL4kTWH79/+icn9CoPKuPGjT5/D+yc2UBmP8Ztrz8+43n9dee4xbTGKcwimYWg1l5w9hkvOHsOV5+3hYz/4Ex/9/hP8y4yJfOnCU8IuT0QCA/6cgbu7mRVkjN/dFwALIHUCuRC/sz8yTf9/+qszmPaNFT1u8/z/m0lbIsEJQ8t/6GTK+Hoe/coFfPDbj3HHig3EDK79sAJBpBhkO66wLRj+Ifi5PWjfAoxLW29s0Ha89rEZ2vPm7Wnv3AvhhLpB3HrJGce0zzj1BJ654cMMq6mMRBB0mTCqlh/+4xQA/vN3G+hIJEOuSEQg+zBYAswNlucCD6a1X2Ep04E3g+GkZcBMM6s3s3pgJrAseGyfmU0PZiJdkbavsvGpaeP5t789nTsuPxuA+Refyt2feTcNQ6tDriwcs85o5P0TRwHwuXueCbkaEYG+TS39OakTwKPMbDOpWUG3Afeb2ZXAq8AngtWXkppW2kJqaulnAdx9t5ndAnT9z7+562Qy8EWOTC19hDyfPM7npNWeRu1jMWPue5twd4ZUx/nAKSfkr4gS8cN/PIfTb1zGHzbsJJl0fUZBJGR9mU10eQ8PzciwrgNX9bCfhcDCDO3NwLHjKGXIzPjQqaN7XzECaqsr+N5lk7nmvud48PktXHr22N43EpG8Kb65iBIZHzw1dYT00z9uCrcQEYleGDj5GyfSxUT7p25QJZ95bxNrtrzJvkMdvW8gInkTvTAougmp0TbjtBNwh1826yJ7ImGKXBhIcTlr3HAAbs7hBfpEpP8UBjmlcaL+6rqiKkCJX59QpKRFLgz0elN8Lp+WurTIhu2FvcKqiBwRuTCQ4nNe8AG0tX99M+RKRKJLYZBDmk2UnWlNI6iKx1i/dX/YpYhEVuTCQOPSxaciHuOUtw3p8bsdRCT/IhcGUpwmjxvOhm37FdYiIVEY5JBGibI3YdQQWtsT7GnVh89EwhC5MND7zuI0ZvhgAF7b3RpyJSLRFL0wUBoUpa4w+MxPnw65EpFoilwY5JNpOlHWRg2tAmCvholEQhG5MMjnheoke43DUkcG73vHyJArEYmmyIWBFK8p44fzx5ZdYZchEkkKgxzSINHArHptLwCb9+gkskihRS4MdAK5+B1sS4RdgkjkRC8Mwi5AevTTz74bgD2t7SFXIhI9kQuDfNJkooF5W90gAHYfVBiIFJrCQIrGyCGp6aU7D7SFXIlI9EQuDHTOoHiNqKnCDHbuVxiIFFrkwiCfNEw0MBXxGCNrq1inS1mLFFwEw0CHBsXs3U0jWL91X9hliERO5MIgqSwoao3DBrPvLV2SQqTQIhgG+UsD08fOBmx4TSX72zrpSCTDLkUkUiIXBgkdGhS14TWVADo6ECmwyIVBPmcTvakXsAEbNjgVBvqSG5HCilwY5HOY6KVtmgUzUEMHVQBwsK0z5EpEokVhkEMVMZ0zGKhBFXEANu06GHIlItESvTDI4XnJb//9WUfdj8ci98+Zc3XBMNFTG3Upa5FCGtCrl5ltMrM1ZvacmTUHbSPMbLmZbQh+1gftZmZ3mFmLma02sylp+5kbrL/BzOYOrEvHl8sjg4+fM/ao+xVxHRkM1GmNdQCcMHRQyJWIREsu3sp+0N0nu/vU4P58YIW7TwRWBPcBLgYmBrd5wF2QCg/gRuBcYBpwY1eA5IOGiYpbPGbUDarQyXiRAsvHuMYcYFGwvAi4JK19sac8BQw3s0bgImC5u+929z3AcmBWHuoC8vuhs7jCICfqa6t0GWuRAhtoGDjwWzN71szmBW2j3X1rsPwGMDpYHgO8nrbt5qCtp/ZjmNk8M2s2s+YdO3ZkVfANs0/Laru+qKrQOYNcGD64kr2aWipSUAN99TrP3aeQGgK6yszOT3/Q3Z0cXgzI3Re4+1R3n9rQ0JDVPj5//km5KucYuiJqbgyrqWKvjgxECmpAYeDuW4Kf24Ffkxrz3xYM/xD83B6svgUYl7b52KCtp3aJqPqaSvbqnIFIQWUdBmZWa2ZDu5aBmcALwBKga0bQXODBYHkJcEUwq2g68GYwnLQMmGlm9cGJ45lBm0TYq7taaevUdyGLFErFALYdDfzaUhfxrwB+5u6/MbNngPvN7ErgVeATwfpLgdlAC9AKfBbA3Xeb2S3AM8F6N7v77gHUFRrXOFFONAypBmBvawej6+IhVyMSDVmHgbtvBM7K0L4LmJGh3YGretjXQmBhtrVIeTljzDBAl6QQKSRNf5GiU1vddX0iDROJFIrCIIc0SJQbtVWpoaGPfv8JntiwM+RqRKJBYSBFp6b6yOjlgj9sDLESkehQGEjRGVJ95KTx4y9l9+FCEekfhUEOaTJRbtRUDWSSm4hkQ2EgRadWYSBScAoDKTo11fpsgUihKQxySKNEuVEZP/rPUp9EFsk/hYEUvXd+7TdhlyBS9hQGIiKiMMglXZsof/RvK5JfCgMpCf+98rWwSxApawoDKUrdvzXugVWbQ6pEJBoUBln60oWnhF1CWRtcefT00j+/tpe32jWrSCRfFAZZuuI9bw+7hLI2qPLYP81t+w6FUIlINCgMpCh1/6wBwAXffqzwhYhEhMIghzThJXe6DxOJSH4pDLJkWNgllLWGodVhlyASKQoDKUoVGYaJRCR/9D8uS57hSkSZ2iQ7FbHMR16HOjSjSCQfFAY9mNRYx+LPTQu7jMjqKQymf3NFgSsRiQaFwXFY8Ho0tLqCukEVrPjyB6gbpGvtF8Ipo4dmbN/b2sFru1oLXI1I+VMY9OCdbxt6+CTxu8YNY/VNF3Fyw5DDj2c6gazZRLlz7Ycn8pMrpmZ87Pz/eLTA1YiUP73NzeC+edM5a+xwVr22B4BkMuSCIqgiHuPDk0aHXYZIZOjIIIPpJ41kcFX88Ht/nRgOz9vqBmVs//nTunCdSC4pDI7DgpMGfR3+UWTk3semjMnYfv0Da3RZa5EcUhgcR9cJ5PSXnB/8wzm87x0jGaoTyQVRXdHzJ5Gv+9VqOhIawxPJhUiGwYjaKv5uyti+b5CWBudNHMW9/zSdWA9THyW3JjTU9vjY/c2bmXjDI7y840ABKxIpT5EMg1X/90Ju+7sze10v1jVMdJwBoGkTRhy+jo5GLXLvo+9q7HWdGd/5PU3zH+aMG5exdM3WAlQlUn4iO9aR6aqY3XUNEyWP8yJ//xfew91PvMItD61j5JCqHFUnXbrO2/TFgbZOvnjvquOu856TRjK8ppLTT6w7at/ufjjM+3LUl6ms7tONM69z/P0MrqpgcGWc9s4klfHe64jHjHjMiFnq1hlMfeu6n1pO9cmAwVVxKmIxzKAjkaQjkaS9M8mY4TW0tndSVRE75v+G2ZE3Ou7QmUyS9NQHA2uq4iS72pLwVkeCYYMrSbqTSDp7WztoGFpNPJb6jEjTqFrqa6qI68i66EQ2DAB+8A9T+Msb+7ljxYaMjx+eTdTLW/7PvLeJhqHVfOTM3t/FSv/VVsU5mKMvtnly4y4AHnnhjZzsTwamcdggThhazcs7DnLGmDreak9QGY+lwiyWCjX3owNJYNHnph3zbYADVTRhYGazgO8BceAn7n5bvn/n7DMbmX1m41FhcNa44YeXa6pS/zyje5je2CUeM/72rBPzU6Twuy9/gE07W5l0Yh1n/dtvM64zYVQtFTFjdN0gqitiNI2q5V1jh/G2ukEMHVRJLAajhw7iUGeC+pojR3BmR97RHzkSTL3qdL34dH/33pcXpUzrdB9u7L6OA3tb2+lMeJ/fOSeSTsIddyeRhIp4qjdd7TEzEkkn6U5bZ+oowD31eFtngj2tHQyqPHI00NreSU1VRfAifKTi9GoqK2IYsP9QJw7EzQ4foSSSSTqTqd8bjxlvvHmIEbVVtLZ38pc39jO0uoKXdx7k4dVbD+93065WBlXGOdDWyZDqimA/qSOLDnfiZiSDvvT4741H6krC+ZjuXhRhYGZx4E7gQmAz8IyZLXH3dYWq4dPT387XPnIa8bQ/uEkn1vHdT57FjNP04acwNQ4bTOOwwUe1/etF7+Qj72qkIh5jzPDBPWxZeoZUF8V/yby781NhVyDdFctf3jSgxd03ApjZfcAcoCBhsOm2v+nxsUvP7sesI8m7b1x6Jqc2DmXK+PqwSxEpK8USBmOA19PubwbO7b6Smc0D5gGMHz++MJVJUfnUuXreRfKhpKaWuvsCd5/q7lMbGhrCLkdEpGwUSxhsAcal3R8btImISAEUSxg8A0w0swlmVgVcBiwJuSYRkcgoinMG7t5pZlcDy0hNLV3o7mtDLktEJDKKIgwA3H0psDTsOkREoqhYholERCRECgMREVEYiIgIWKl+W5SZ7QBezXLzUcDOHJZTTMq5b1De/VPfSlOp9e3t7n7MB7VKNgwGwsya3X1q2HXkQzn3Dcq7f+pbaSqXvmmYSEREFAYiIhLdMFgQdgF5VM59g/Lun/pWmsqib5E8ZyAiIkeL6pGBiIikURiIiEi0wsDMZpnZi2bWYmbzw64nW2a2yczWmNlzZtYctI0ws+VmtiH4WR+0m5ndEfR5tZlNCbf6o5nZQjPbbmYvpLX1uy9mNjdYf4OZzQ2jL9310LebzGxL8Nw9Z2az0x67Pujbi2Z2UVp70f3dmtk4M3vUzNaZ2VozuyZoL5fnrqf+lcXzl5EHX6Zd7jdSV0N9GTgJqAKeByaFXVeWfdkEjOrW9u/A/GB5PvCtYHk28Aip7x6fDqwMu/5udZ8PTAFeyLYvwAhgY/CzPliuL9K+3QR8JcO6k4K/yWpgQvC3Gi/Wv1ugEZgSLA8FXgr6UC7PXU/9K4vnL9MtSkcGh79n2d3bga7vWS4Xc4BFwfIi4JK09sWe8hQw3MwawygwE3d/HNjdrbm/fbkIWO7uu919D7AcmJX/6o+vh771ZA5wn7u3ufsrQAupv9mi/Lt1963uvipY3g+sJ/X1teXy3PXUv56U1POXSZTCINP3LB/vyS1mDvzWzJ4NvhcaYLS7bw2W3wBGB8ul2O/+9qXU+nh1MFSysGsYhRLum5k1AWcDKynD565b/6DMnr8uUQqDcnKeu08BLgauMrPz0x/01HFrWcwZLqe+BO4CTgYmA1uB74RbzsCY2RDgV8C17r4v/bFyeO4y9K+snr90UQqDsvmeZXffEvzcDvya1KHotq7hn+Dn9mD1Uux3f/tSMn10923unnD3JPBjUs8dlGDfzKyS1Avlve7+QNBcNs9dpv6V0/PXXZTCoCy+Z9nMas1saNcyMBN4gVRfumZizAUeDJaXAFcEszmmA2+mHcYXq/72ZRkw08zqg8P2mUFb0el2vuZSUs8dpPp2mZlVm9kEYCLwNEX6d2tmBtwNrHf329MeKovnrqf+lcvzl1HYZ7ALeSM1o+ElUmf3bwi7niz7cBKpGQnPA2u7+gGMBFYAG4DfASOCdgPuDPq8Bpgadh+69efnpA63O0iNp16ZTV+Az5E6adcCfDbsfh2nb/8V1L6a1ItCY9r6NwR9exG4uJj/boHzSA0BrQaeC26zy+i566l/ZfH8ZbrpchQiIhKpYSIREemBwkBERBQGIiKiMBARERQGIiKCwkBERFAYiIgI8P8BccoVvYBuqwoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(ta[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95ccd42c50>]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(taLarge[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9589279850>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(ta[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95794516d0>]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(taLarge[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9589e68790>]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(ta[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95cd0ab150>]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(taLarge[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95600c66d0>]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(ta[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9599cdab90>]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(taLarge[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "pisTraj = tensor(testFit[\"trajectoryPi\"])\n",
    "pisTrajLarge = tensor(testFitLarge[\"trajectoryPi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95a94a77d0>]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTraj[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95b95a7390>]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTrajLarge[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95a911a490>]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAc3klEQVR4nO3de5hUd53n8fenq7u53y8J4RLAECfEKMm0oMbgOOZCdJ8Qd3VEd1bUjEzWoM4486y4OlHx0dG4q7vzDKNhHHwyamQyOrqoKGJMvMUkdO6BSNIhhEAIkHBLwqUv9d0/6jQUTTVd3V3V1XXq83qefjjnd86p/v66ik+d+p1T5ygiMDOz9KqrdAFmZlZeDnozs5Rz0JuZpZyD3sws5Rz0ZmYpV1/pArqaOHFizJw5s9JlmJlVlfvuu+/5iJhUaNmgC/qZM2fS3Nxc6TLMzKqKpKe7W+ahGzOzlHPQm5mlnIPezCzlHPRmZinnoDczSzkHvZlZyhUV9JIWSdoqqUXSigLLr5f0iKQHJf1W0tykfaako0n7g5K+XuoOmJnZmfV4Hr2kDLAKuALYCWyStC4ituStdmtEfD1Z/xrgK8CiZNmTETGvtGUPnN2HjrLl2cO85YKzKl2KmVmfFLNHPx9oiYhtEdEKrAUW568QEYfzZkcAqbnI/bWrfsd1t/gLXGZWvYoJ+qnAM3nzO5O2U0i6QdKTwE3AR/IWzZL0gKRfSbqs0C+QtExSs6Tmffv29aL88ttz+HilSzAz65eSHYyNiFUR8Qrg48CnkubdwIyIuBj4GHCrpNEFtl0dEU0R0TRpUsFLNZiZWR8VE/S7gOl589OStu6sBa4FiIjjEfFCMn0f8CRwft9KNTOzvigm6DcBcyTNktQILAHW5a8gaU7e7NuAJ5L2ScnBXCTNBuYA20pRuJmZFafHs24iol3ScmADkAHWRMRmSSuB5ohYByyXdDnQBhwAliabLwRWSmoDssD1EbG/HB0xM7PCirpMcUSsB9Z3absxb/qj3Wz3feD7/SmwXNY/spumc8cxefTQSpdiZlZWNfnN2KOtHXzoO/fzX79xT6VLMTMru5oM+o7Ineb/7MGjFa7EzKz8ajLozcxqSU0HfWq+vmtmdgY1GfSqdAFmZgOoJoPee/JmVktqMujNzGpJTQa9h27MrJbUZNCbmdWSmg768GC9mdWAmg56M7NaUNNBLw/Wm1kNqOmg99CNmdWCmgx678mbWS2pyaA3M6slRV2PvhZls8FvW56vdBlmZv3moO/GN+/azud+vKXSZZiZ9ZuHbrqx44WXK12CmVlJ1HTQhy9vZmY1oKigl7RI0lZJLZJWFFh+vaRHJD0o6beS5uYt+0Sy3VZJV5Wy+L6Sr3ZjZjWkx6CXlAFWAVcDc4F35wd54taIuCgi5gE3AV9Jtp0LLAEuBBYB/5Q83oD48cPPsmHzc33aVj4H08xSopg9+vlAS0Rsi4hWYC2wOH+FiDicNzuCk5d8XwysjYjjEfEU0JI83oBYfusD/OW37jutvZghm/C3qcwsJYo562Yq8Eze/E5gQdeVJN0AfAxoBP40b9u7u2w7tcC2y4BlADNmzCimbjMzK1LJDsZGxKqIeAXwceBTvdx2dUQ0RUTTpEmTSlVSv3joxszSopig3wVMz5uflrR1Zy1wbR+3NTOzEism6DcBcyTNktRI7uDquvwVJM3Jm30b8EQyvQ5YImmIpFnAHODe/pfdO4/veZF9Lx4/rd3D8GZWC3oco4+IdknLgQ1ABlgTEZslrQSaI2IdsFzS5UAbcABYmmy7WdJtwBagHbghIjrK1JduXfnVXzO0oY4/fO7qpE+9f4yI8HCOmVWloi6BEBHrgfVd2m7Mm/7oGbb9PPD5vhZYKsfasqe1ObfNrBbU9jdjPXRjZjWgpoM+37G2Dg4dbat0GWZmJVdzQd/anmXXwaOntb/r5t/zms/+vAIVmZmVV81dpvjj33+YHzxw+hmeD+08VIFqzMzKr+b26O/YurfSJZiZDaiaC/q+8oFbM6tWNR30zm4zqwU1HfRnsvW5FytdgplZSTjoC3hgxwF+v+2FSpdhZlYSDvoCdh44/fRLM7Nq5aA3M0u5mgr6Tdv3c/CIv/1qZrWlpoL+5l9tO7WhF6fd+AwdM6tWNRX0db5apZnVoJoK+q6XJW7PZtn/cmtlijEzGyA1FfR1XZI+G3DJ5zZyvH3A74ViZjZgairou9PW4RF4M0uvmgr6nz76XKVLMDMbcDUV9P0RvqqZmVWpooJe0iJJWyW1SFpRYPnHJG2R9LCk2yWdm7esQ9KDyc+6UhZvZmY96/HGI5IywCrgCmAnsEnSuojYkrfaA0BTRByR9N+Bm4B3JcuORsS8EtddVr5puJmlSTF79POBlojYFhGtwFpgcf4KEXFHRBxJZu8GppW2zIHzrbuf5ueb91S6DDOzkinmVoJTgWfy5ncCC86w/nXAT/Pmh0pqBtqBL0bED7tuIGkZsAxgxowZRZRUPn/3w0cr+vvNzEqtpPeMlfTnQBPwprzmcyNil6TZwC8lPRIRT+ZvFxGrgdUATU1NPuppZlZCxQzd7AKm581PS9pOIely4JPANRFxvLM9InYl/24D7gQu7ke9ZeEheTNLs2KCfhMwR9IsSY3AEuCUs2ckXQzcTC7k9+a1j5M0JJmeCFwK5B/EHRSK+QjhjxlmVq16HLqJiHZJy4ENQAZYExGbJa0EmiNiHfBlYCTw78qdsrIjIq4BLgBulpQl96byxS5n65iZWZkVNUYfEeuB9V3absybvryb7e4CLupPgWZm1j/+ZiweozezdHPQm5mlnIMeaOvIVroEM7OycdAD81ZurHQJZmZl46Avki9eaWbVykFvZpZyDnozs5Rz0JuZpZyD3sws5Rz0ZmYp56A3M0s5B32RwtevNLMq5aA3M0s5B72ZWco56M3MUs5Bb2aWcg56M7OUc9AXyRc1M7Nq5aA3M0u5ooJe0iJJWyW1SFpRYPnHJG2R9LCk2yWdm7dsqaQnkp+lpSzezMx61mPQS8oAq4CrgbnAuyXN7bLaA0BTRLwa+B5wU7LteODTwAJgPvBpSeNKV76ZmfWkmD36+UBLRGyLiFZgLbA4f4WIuCMijiSzdwPTkumrgI0RsT8iDgAbgUWlKd3MzIpRTNBPBZ7Jm9+ZtHXnOuCnvdlW0jJJzZKa9+3bV0RJhf3hucPcctf2Pm9vZpZG9aV8MEl/DjQBb+rNdhGxGlgN0NTU1OfzWxb9n98AsPQNM/v6EGZmqVPMHv0uYHre/LSk7RSSLgc+CVwTEcd7s62ZmZVPMUG/CZgjaZakRmAJsC5/BUkXAzeTC/m9eYs2AFdKGpcchL0yaTMzswHS49BNRLRLWk4uoDPAmojYLGkl0BwR64AvAyOBf5cEsCMiromI/ZI+R+7NAmBlROwvS0/MzKygosboI2I9sL5L241505efYds1wJq+FmhmZv3jb8aamaWcg97MLOVKenrlYBER/OKxvT2vaGZWA1IZ9Bs2P8f1376/pI/pq1eaWbVK5dDNvheP97ySmVmNSGXQJ6d4mpkZqQ36SldgZjZ4pDPocdKbmXVKZ9A7583MTkhn0JfhMQOfdmNm1SmVQf/N322vdAlmZoNGKoN+654XK12CmdmgkcqgNzOzkxz0ZmYp56Av0s8efa7SJZiZ9YmDvkgbt+ypdAlmZn3ioDczSzkHvZlZyjnozcxSrqigl7RI0lZJLZJWFFi+UNL9ktolvaPLsg5JDyY/60pVuJmZFafHG49IygCrgCuAncAmSesiYkveajuA9wF/W+AhjkbEvBLUamZmfVDMHabmAy0RsQ1A0lpgMXAi6CNie7IsW4YaBwVfKM3MqlUxQzdTgWfy5ncmbcUaKqlZ0t2Sru1Vdb0QvtefmVlBA3HP2HMjYpek2cAvJT0SEU/mryBpGbAMYMaMGX36Jc55M7PCitmj3wVMz5uflrQVJSJ2Jf9uA+4ELi6wzuqIaIqIpkmTJhX70GZmVoRign4TMEfSLEmNwBKgqLNnJI2TNCSZnghcSt7Yfil5h97MrLAegz4i2oHlwAbgMeC2iNgsaaWkawAkvVbSTuCdwM2SNiebXwA0S3oIuAP4YpezdUrGY/RmZoUVNUYfEeuB9V3absyb3kRuSKfrdncBF/WzRjMz64fUfDPW+/NmZoWlJ+id9GZmBaUm6MtNZbnluJlZ+aUm6KPMgzflfnwzs3JJT9A7h83MCkpN0Jebh27MrFo56M3MUs5Bb2aWcqkJeo/Rm5kVlp6g91kxZmYFpSbozcyssNQEvYduzMwKS0/Ql/sX+OxKM6tSqQl6MzMrLDVB7+vRm5kVlp6gr3QBZmaDVGqC3szMCktN0HvkxsyssNQEvZmZFZaeoC/zHr3PrjSzalVU0EtaJGmrpBZJKwosXyjpfkntkt7RZdlSSU8kP0tLVXhXvgSCmVlhPQa9pAywCrgamAu8W9LcLqvtAN4H3Npl2/HAp4EFwHzg05LG9b9sMzMrVjF79POBlojYFhGtwFpgcf4KEbE9Ih4Gsl22vQrYGBH7I+IAsBFYVIK6T+ODsWZmhRUT9FOBZ/LmdyZtxShqW0nLJDVLat63b1+RD30q57yZWWGD4mBsRKyOiKaIaJo0aVKlyzEzS5Vign4XMD1vflrSVoz+bNsrvgSCmVlhxQT9JmCOpFmSGoElwLoiH38DcKWkcclB2CuTtpLL1PkESDOzQnoM+ohoB5aTC+jHgNsiYrOklZKuAZD0Wkk7gXcCN0vanGy7H/gcuTeLTcDKpK3kxg5vLMfDmplVvfpiVoqI9cD6Lm035k1vIjcsU2jbNcCaftQ4KEj+xGBm1WlQHIytBj4GYGbVykFvZpZyRQ3d2Mmhm4NHWtmx/whjhzXSns1y+Fg786aPrXB1Zmbdc9AX6UcPPcvVrzqbD33n/oLLt33hrdT5zB8zG4Q8dNML3YU8wOz/uZ49h49xy13b2bS9LCcWmZn1iffoS2jBF24/MX3rXyzggimjGTfCp32aWWU56MvkPd+4B4D/9Oop/ON7LqlwNWZWyxz0vfSLjy1kyphhrH9kN9uef5mv3fnkGdf/8cO7+fHDP+F/LHolH/qT8waoSjOzkxz0vbDxrxdy3uRRALyzaToRwfjhjSyYPZ77nz5Apk5s2LyH0cPquerCs/no2gdPbHvTz7ay7LLZ1Gd8WMTMBpaDvhfmnDXqlHlJfHDhbABePS13iuV/e/3ME8sXzJrAov/7aw4eaQPg23c/zfsunTUwxZqZJbx7WUZnjxnKXSv+9MT8Z360hfuePlDBisysFjnoy2x4Yz3bv/i2E/P/5Wt3VbAaM6tFDvoBsv4jl52YfmDHAVrbu9510cysPBz0A2TuOaNPTL/9n+7ibf/wmwpWY2a1xEE/gL7w9otOTD+x9yVmrvgJO144wt4Xj1WwKjNLOwf9AHrPghlcPOPUC6At/PIdzP/87d1sYWbWfw76AdbeUfi69sfbOwa4EjOrFQ76AbZy8YUF21/5qZ/x9AsvD3A1ZlYLHPQD7OIZ49iy8ipWXP1Hpy178/+6c+ALMrPUKyroJS2StFVSi6QVBZYPkfRvyfJ7JM1M2mdKOirpweTn66UtvzoNb6xn2WWz+eb7X8ubzp90oj0b8PmfbKlgZWaWRj0GvaQMsAq4GpgLvFvS3C6rXQcciIjzgK8CX8pb9mREzEt+ri9R3VWvrk68+ZWTueUD809p/+ffPMWvH99HNut71JpZaRRzrZv5QEtEbAOQtBZYDOTvei4GPpNMfw/4R3Xee8969Ohnr+K3TzzP9d++D4D3rrkXyF3T/g3nTaxkaVZl9r54jHuf2s892/az88ARjrVl2XP4GG+cM5FHdh1i0YVnc97kkRw40sbmZw/xx+eOY/zwRlo7skwYMYSjbR1kI8hGMKKxnpFD6xk/vJH6jKivq6Oxvg6B76ZWZYoJ+qnAM3nzO4EF3a0TEe2SDgETkmWzJD0AHAY+FRGnfVNI0jJgGcCMGTN61YE0GDmknkWvOvu09vd84x6e+vu3AifvWWvVKSJ48Xg77R1Bpk5k6sSIxgzZgLaOLBHQns0SQGQhCLKR2y4bufkIiICXjrdzpLWdo60dPP9SK88ePMojuw6x7qFnu/39257PHeh/YMfBU9q/+bvt/erX2OENfPCy2bz5lZOZNXEEzxw4wpQxQznwchuZjDhnzFDaOoL6OvnNoYLKffXK3cCMiHhB0h8DP5R0YUQczl8pIlYDqwGamppqdszioU9fyWs++/NT2mZ9Yv0p83/yyklc98ZZdGSDedPHMnZ47g5WETHo3wyOtnbw5L6X+Nffb+e25p380dmjaNn7Eu9sms60ccPYc/gYwxvrGdGY4eDRNqaMGcqR1o4Te5ANmVz/osyvkEh+x8lwTf7t2p4U0xnWR9s6ONrawdG2Do61dXCktYNDR9vYfegYB4+00nU0Tip9X2ZPGsHsiSM4d8IIfvX4PiaPGsLY4Q0smDWB3YeOMXXsUM6bPIqDR1rZdfAor5s9gecOHSNTJ1o7srR3BI31uT33420dPHf4GA8+c5DnX2rl4JFWntl/hAPJ1VgBDh5p48sbtvLlDVuLrnF4Y4aRQ+o5cKSVyaOG0pENOl+6hT4tdPc3GuQv9z6ZO2U0q9/bVPLHLSbodwHT8+anJW2F1tkpqR4YA7wQEQEcB4iI+yQ9CZwPNPe38IGW/63WchkzrIE5k0fyxN6Xul3nzq37uHPrvjM+zmumjyWbDY63d9CQqaMjSZg6ibo6EErmT27T+X+p8z9VZ5h1knLb1Sn36aJOuW3qJOqTPdQ6KbeeRGt7LuhePt7OkdYODh5p42jbqd8V+MNzLwLw3Xt39PzHGaRyfxdorK9jWEOGYQ0ZhjZmGFqfYVhjhrNHD+WiqWMY1pjhWFsHj+46zPTxwzh79DBGDMlQX1dHQ72IgIZM598w+TuTCz2R+5tKub93Q6aOkUMyDKnPcNbooZwzdihjhjWc9kb/d0X24VVTx5xx+XtfX7j9+ZeO8917dvCjh5/l8T3dv2a7etP5kxgzrIEjrR1kkjfwjuzJv2Xn6xWRe5Hp5Gu2U9Al/ZP1qt2540eU5XGLCfpNwBxJs8gF+hLgPV3WWQcsBX4PvAP4ZUSEpEnA/ojokDQbmANsK1n1A+iCKaN6XqkE/v4/X8RNG7Zyw5vPY2kyVt9bdYLRwxuABhozdbR2ZBnWkEnGXnPrdA4J5GdD52RnYOQCpnN9yEbuv1c2by83G0F7NmjryJJN5rMBQzJ1TBjRyPTxwxnWkKFOMHHkEMYMa2DG+OHse+k4MyeM4KzRQ5k4spGG+jrqJF461p57AxIMyWSoq4P6ujokaM9GXo0n6zrTnl1Py7sjOt+08qaTv03n32Wwf4Iqt4kjh/Dht8zhw2+ZA8Cxtg4aM3XU1YmXjrczvCHj4ZpBosegT8bclwMbgAywJiI2S1oJNEfEOuBfgG9JagH2k3szAFgIrJTUBmSB6yNifzk6khZNM8dz21++no5s8P5LZzJ51FC+uvFxJoxs5AOXzuLPmqbT2pFl4sjGVAbNyCG+F061GtqQOTHt53FwUZR7wLOXmpqaorm5byM7M1f8pMTVnPSDD72Bi2eMK9vjm5n1h6T7IqLgAL+/GVukNO49m1ltcNAXyTFvZtXKQV/AuOENlS7BzKxkHPQFFDpq4ZEbM6tWDvoCCl1nput5vGZm1cJBX8DgOg/JzKx/HPSFOOnNLEUc9Ikxw04egM0W+G6Bx+jNrFo56AvwDr2ZpYmDvoBB9mVhM7N+SVXQX13gmu7Fyh+aOe3KeHjoxsyqV6qC/q8uP7/P2+bvxedfnKmTT680s2qVqqCfM3kkjZn+d+mr75p3WtvsSeW5TrSZWbmlKujr6sSnr+l63/Li5A/NTBo55LTlhfbyzcyqQaqC3szMTpe6oC/FGTM+68bM0iR1Qd9X3/mLBSemC511Y2ZWrWoq6O//uyu6XXbhOSdvkFzgmmZmZlWrpoJ+/IjG09rGDW/g9r95EwCvmT4WyN34+pwxQwe0NjOzcikq6CUtkrRVUoukFQWWD5H0b8nyeyTNzFv2iaR9q6SrSld6YZ0745fMGFvU+g/ceCWvmDQSOHkXqQBu/eDrAJgwopEHzvBJwMxssOvxVu2SMsAq4ApgJ7BJ0rqI2JK32nXAgYg4T9IS4EvAuyTNBZYAFwLnAL+QdH5EdJS6I11dMGU0//GhSwF4bPdhGjI9f+Gp8xTLiCBTl5sZ1phhXIFPAmZm1aKYPfr5QEtEbIuIVmAtsLjLOouBW5Lp7wFvUe5u2ouBtRFxPCKeAlqSxyubt100hQumjGbZwtkn2i6YMprzJo8CYOwZbhM4ckjufa9OOhH6Pn/ezKpdj3v0wFTgmbz5ncCC7taJiHZJh4AJSfvdXbad2vUXSFoGLAOYMWNGsbUXNH5EIz/96GXdLv/5Xy/k2YPHGDW0nqOtp36w+MqfzeO79+5gXjJW/zdXnM+1F59WrplZVSkm6MsuIlYDqwGamprKes7L5FFDmTyq8IHWSaOG8JG3zDkx/+G8aTOzalXM0M0uYHre/LSkreA6kuqBMcALRW5rZmZlVEzQbwLmSJolqZHcwdV1XdZZByxNpt8B/DIiImlfkpyVMwuYA9xbmtLNzKwYPQ7dJGPuy4ENQAZYExGbJa0EmiNiHfAvwLcktQD7yb0ZkKx3G7AFaAduGIgzbszM7CTFILuwS1NTUzQ3N1e6DDOzqiLpvohoKrSspr4Za2ZWixz0ZmYp56A3M0s5B72ZWcoNuoOxkvYBT/fjISYCz5eonMHGfateae6f+zY4nBsRkwotGHRB31+Smrs78lzt3Lfqleb+uW+Dn4duzMxSzkFvZpZyaQz61ZUuoIzct+qV5v65b4Nc6sbozczsVGncozczszwOejOzlEtN0Pd0A/NqIGm7pEckPSipOWkbL2mjpCeSf8cl7ZL0D0l/H5Z0SWWrP52kNZL2Sno0r63X/ZG0NFn/CUlLC/2ugdZN3z4jaVfy/D0o6a15yz6R9G2rpKvy2gfd61bSdEl3SNoiabOkjybtVf/cnaFvqXjuuhURVf9D7vLJTwKzgUbgIWBupevqQz+2AxO7tN0ErEimVwBfSqbfCvwUEPA64J5K11+gPwuBS4BH+9ofYDywLfl3XDI9bpD27TPA3xZYd27ymhwCzEpeq5nB+roFpgCXJNOjgMeTPlT9c3eGvqXiuevuJy179MXcwLxa5d94/Rbg2rz2f42cu4GxkqZUosDuRMSvyd2fIF9v+3MVsDEi9kfEAWAjsKj81Z9ZN33rzmJgbUQcj4ingBZyr9lB+bqNiN0RcX8y/SLwGLl7PVf9c3eGvnWnqp677qQl6AvdwLwa7+odwM8l3ZfcMB3grIjYnUw/B5yVTFdrn3vbn2rr5/Jk+GJN59AGVdw3STOBi4F7SNlz16VvkLLnLl9agj4t3hgRlwBXAzdIWpi/MHKfJVNzPmza+gN8DXgFMA/YDfzvypbTP5JGAt8H/ioiDucvq/bnrkDfUvXcdZWWoE/FTcgjYlfy717gB+Q+Hu7pHJJJ/t2brF6tfe5tf6qmnxGxJyI6IiIL/DO55w+qsG+SGsgF4Xci4j+S5lQ8d4X6lqbnrpC0BH0xNzAf1CSNkDSqcxq4EniUU2+8vhT4f8n0OuC9yRkPrwMO5X2sHsx6258NwJWSxiUfp69M2gadLsdI3k7u+YNc35ZIGiJpFjAHuJdB+rqVJHL3gX4sIr6St6jqn7vu+paW565blT4aXKofckf+Hyd3JPyTla6nD/XPJnfk/iFgc2cfgAnA7cATwC+A8Um7gFVJfx8BmirdhwJ9+i65j8Ft5MYwr+tLf4APkDsI1gK8v9L9OkPfvpXU/jC5//RT8tb/ZNK3rcDVg/l1C7yR3LDMw8CDyc9b0/DcnaFvqXjuuvvxJRDMzFIuLUM3ZmbWDQe9mVnKOejNzFLOQW9mlnIOejOzlHPQm5mlnIPezCzl/j+uOjk/ZLOabQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTraj[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95b95a7750>]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTrajLarge[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f95a9183110>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTraj[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9599e018d0>]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pisTrajLarge[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCounts = testData[\"altCounts\"]\n",
    "testCountsLarge = testDataLarge[\"altCounts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30.,  2.,  1.,  1.],\n",
       "        [26.,  4.,  0.,  1.],\n",
       "        [31.,  3.,  0.,  0.],\n",
       "        ...,\n",
       "        [33.,  0.,  0.,  1.],\n",
       "        [27.,  1.,  0.,  1.],\n",
       "        [24.,  0.,  0.,  0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30.,  6.,  2.,  4.],\n",
       "        [18.,  5.,  1.,  5.],\n",
       "        [24.,  3.,  0.,  3.],\n",
       "        ...,\n",
       "        [29.,  1.,  1.,  1.],\n",
       "        [29.,  0.,  0.,  0.],\n",
       "        [22.,  0.,  0.,  0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testCountsLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0309, 0.0309, 0.0123])\n",
      "TESTING WITH: nCases tensor([10000., 10000.,  4000.]) nCtrls tensor(300000.) rrMeans tensor([1.5000, 1.5000, 1.5000]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0500, 0.0500, 0.0500]) pDs tensor([0.0309, 0.0309, 0.0123]) covShared tensor([[1.0000, 0.4000, 0.4000],\n",
      "        [0.4000, 1.0000, 0.4000],\n",
      "        [0.4000, 0.4000, 1.0000]]) covSingle tensor([[1, 0],\n",
      "        [0, 1]])\n",
      "\n",
      "\n",
      "test tensor 1.0,0.4,0.4,0.4,1.0,0.4,0.4,0.4,1.0\n",
      "tensor([[3.4976, 1.9117, 5.1212],\n",
      "        [1.0413, 1.6491, 3.9424],\n",
      "        [3.7569, 3.9536, 6.3573],\n",
      "        ...,\n",
      "        [1.2476, 1.6519, 1.0696],\n",
      "        [3.1667, 2.5180, 5.4168],\n",
      "        [3.5974, 4.2134, 5.2786]], dtype=torch.float64)\n",
      "startIndices [0, tensor(1000.), tensor(2000.)] endIndices tensor([1000., 2000., 3000.])\n",
      "totalSamples 324000\n"
     ]
    }
   ],
   "source": [
    "rrsMisspecified = tensor([10, 10, 10])\n",
    "\n",
    "try:\n",
    "    paramsMisspecified = genData.genParams(rrMeans=rrsMisspecified, pis=pis, afMean=afMean, rrShape=rrShape, afShape=afShape, nCases=nCases, nCtrls=nCtrls)[0]\n",
    "    testDataMisspecified = generatingFn(**params, covShared=covShared, covSingle=covSingle)\n",
    "except Exception as e:\n",
    "    print(f\"Run failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdCtrl, pd1, pd2, pdBoth:  tensor([0.9259, 0.0309, 0.0309, 0.0123], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.0074e-02, 3.3766e-02, 1.5268e-02, 3.0953e-03],\n",
       "        [1.2868e-03, 1.3837e-02, 6.8732e-04, 1.6879e-03],\n",
       "        [1.6189e-02, 3.1906e-02, 2.9415e-03, 4.1956e-04],\n",
       "        ...,\n",
       "        [3.3114e-02, 1.4180e-02, 1.2976e-02, 8.1541e-05],\n",
       "        [3.8733e-02, 4.2336e-02, 1.7855e-02, 1.1432e-03],\n",
       "        [1.5770e-01, 5.0831e-02, 4.6236e-02, 5.8820e-04]], dtype=torch.float64)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "likelihoodFn, nullLike = likelihoods.effectLikelihood(4, pDs=params[\"pDs\"], altCountsFlat=testData[\"altCounts\"])\n",
    "pis = tensor(testFit[\"params\"][0][0:3])\n",
    "piNull = 1 - pis.sum()\n",
    "alphas = testFit[\"params\"][0][3:]\n",
    "affectedGenes1 = tensor(testData[\"affectedGenes\"][0])\n",
    "affectedGenes2 = tensor(testData[\"affectedGenes\"][1])\n",
    "affectedGenesBoth = tensor(testData[\"affectedGenes\"][2])\n",
    "\n",
    "unaffectedGenes = testData[\"unaffectedGenes\"]\n",
    "alphas\n",
    "mask1 = testData[\"altCounts\"][:,1][affectedGenes1] > 0\n",
    "affectedGenes1NonNull = torch.nonzero(mask1)\n",
    "affectedGenes1NonNull.shape\n",
    "\n",
    "like = likelihoodFn(*alphas)\n",
    "like\n",
    "\n",
    "likeWithNull = torch.stack([nullLike, like[:,0], like[:,1], like[:,2]]).T\n",
    "likeWithNull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdCtrl, pd1, pd2, pdBoth:  tensor([0.9259, 0.0309, 0.0309, 0.0123], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.9136e-07, 3.9622e-03, 9.0206e-06, 6.0266e-14],\n",
       "        [5.9499e-09, 1.6801e-03, 3.0895e-06, 4.0364e-09],\n",
       "        [1.0361e-04, 1.2931e-02, 5.5327e-05, 8.1300e-14],\n",
       "        ...,\n",
       "        [3.7564e-02, 2.1461e-03, 1.5068e-03, 1.8299e-17],\n",
       "        [1.0733e-01, 4.1332e-04, 2.6270e-04, 4.3904e-20],\n",
       "        [1.8394e-01, 2.4454e-03, 1.7249e-03, 1.4618e-15]], dtype=torch.float64)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihoodFnLarge, nullLikeLarge = likelihoods.effectLikelihood(4, pDs=paramsLarge[\"pDs\"], altCountsFlat=testDataLarge[\"altCounts\"])\n",
    "pisLarge = tensor(testFitLarge[\"params\"][0][0:3])\n",
    "piNullLarge = 1 - pisLarge.sum()\n",
    "alphasLarge = testFitLarge[\"params\"][0][3:]\n",
    "affectedGenes1Large = tensor(testDataLarge[\"affectedGenes\"][0])\n",
    "affectedGenes2Large = tensor(testDataLarge[\"affectedGenes\"][1])\n",
    "affectedGenesBothLarge = tensor(testDataLarge[\"affectedGenes\"][2])\n",
    "\n",
    "unaffectedGenesLarge = testDataLarge[\"unaffectedGenes\"]\n",
    "mask1Large = testDataLarge[\"altCounts\"][:,1][affectedGenes1Large] > 0\n",
    "affectedGenes1NonNullLarge = torch.nonzero(mask1Large)\n",
    "affectedGenes1NonNullLarge.shape\n",
    "\n",
    "likeLarge = likelihoodFnLarge(*alphasLarge)\n",
    "likeLarge\n",
    "\n",
    "likeLargeWithNull = torch.stack([nullLikeLarge, likeLarge[:,0], likeLarge[:,1], likeLarge[:,2]]).T\n",
    "likeLargeWithNull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = torch.max(likeLargeWithNull[affectedGenes1Large],1)\n",
    "maskLarge = indices != 1\n",
    "badIndices = torch.nonzero(maskLarge)\n",
    "print(\"n misclassified:\", badIndices.shape, \"out of\", affectedGenes1Large.shape, \"n genes\", \"is\", len(badIndices)/len(affectedGenes1Large))\n",
    "\n",
    "maskLargeAssumedNull = indices == 0\n",
    "badIndicesAssumedNull = torch.nonzero(maskLargeAssumedNull)\n",
    "print(\"n believed to be null:\", badIndicesAssumedNull.shape, \"out of\", affectedGenes1Large.shape, \"n genes\", \"is\", len(badIndicesAssumedNull)/len(affectedGenes1Large))\n",
    "badIndicesAssumedNull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = torch.max(likeWithNull[affectedGenes1],1)\n",
    "mask = indices != 1\n",
    "badIndices = torch.nonzero(mask)\n",
    "print(\"n misclassified:\", badIndices.shape, \"out of\", affectedGenes1.shape, \"genes\", \"; % correct: \", len(badIndices)/len(affectedGenes1))\n",
    "badIndices\n",
    "\n",
    "# maskAssumedNull = indices == 0\n",
    "# badIndicesAssumedNull = torch.nonzero(maskAssumedNull)\n",
    "# print(\"n believed to be null:\", badIndicesAssumedNull.shape, \"out of\", affectedGenes1.shape, \"n genes\", \"is\", len(badIndicesAssumedNull)/len(affectedGenes1))\n",
    "# badIndicesAssumedNull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskCount = testData[\"altCounts\"][affectedGenes1, 1] != 0\n",
    "torch.nonzero(maskCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([31.,  0.,  0.,  0.], dtype=torch.float64)\n",
      "tensor([9.2016e-02, 2.2061e-02, 1.9540e-02, 7.2670e-05], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "badIdx = 903\n",
    "print(testData[\"altCounts\"][affectedGenes1][badIdx])\n",
    "print(likeWithNull[badIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.2325e-06, 1.4781e-04, 5.4868e-04, 1.7416e-10], dtype=torch.float64)\n",
      "tensor([23.,  4.,  5.,  1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(likeLargeWithNull[102])\n",
    "print(testDataLarge[\"altCounts\"][102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n misclassified: torch.Size([2, 1]) out of torch.Size([798]) n genes is 0.002506265664160401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[287],\n",
       "        [534]])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, indices = torch.max(likeLargeWithNull[affectedGenesBothLarge],1)\n",
    "maskLarge = indices != 3\n",
    "badIndices = torch.nonzero(maskLarge)\n",
    "print(\"n misclassified:\", badIndices.shape, \"out of\", affectedGenesBothLarge.shape, \"n genes\", \"is\", len(badIndices)/len(affectedGenesBothLarge))\n",
    "badIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = torch.max(likeLargeWithNull[affectedGenes2Large],1)\n",
    "maskLarge = indices != 2\n",
    "badIndices = torch.nonzero(maskLarge)\n",
    "print(\"n misclassified:\", badIndices.shape, \"out of\", affectedGenes2Large.shape, \"n genes\", \"is\", len(badIndices)/len(affectedGenes2Large))\n",
    "badIndices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n misclassified: torch.Size([1375, 1]) out of 17280 n genes is 0.07957175925925926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    3],\n",
       "        [   16],\n",
       "        [   18],\n",
       "        ...,\n",
       "        [17235],\n",
       "        [17262],\n",
       "        [17270]])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, indices = torch.max(likeLargeWithNull[unaffectedGenesLarge],1)\n",
    "maskLarge = indices != 0\n",
    "badIndices = torch.nonzero(maskLarge)\n",
    "print(\"n misclassified:\", badIndices.shape, \"out of\", len(unaffectedGenesLarge), \"n genes\", \"is\", len(badIndices)/len(unaffectedGenesLarge))\n",
    "badIndices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26.,  3.,  2.,  0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataLarge[\"altCounts\"][982]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullLike[affectedGenes1NonNull]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullLike[affectedGenes1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesFactorsAffected1 = like[unaffectedGenes].sum(1)/nullLike[unaffectedGenes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6818, 1])\n",
      "17000\n"
     ]
    }
   ],
   "source": [
    "d = bayesFactorsAffected1 < 1\n",
    "print(torch.nonzero(d).shape)\n",
    "print(len(unaffectedGenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesFactorsAffectedNull1 = like[testUnaffectedGenes,0]/nullLike[testUnaffectedGenes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor(0.1546, dtype=torch.float64),\n",
       "indices=tensor(4985))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesFactorsAffectedNull1.min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 count: tensor([34.,  0.,  3.,  0.], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5028239d672c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maffectedGene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"count:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maffectedGene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtestCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestCountMisspecified\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maffectedGene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbfsAffected1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbayesFactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestCountMisspecified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestCountMisspecified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestAllPDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mbfsAffected1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbfsAffected1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "testCountMisspecified = testDataMisspecified[\"altCounts\"]\n",
    "\n",
    "# bayesFactor(n, altCount,pDs,rrMeans,rrsShape,afMeans,afShape,alpha0, alpha1, alpha2, alphaBoth):\n",
    "bfsAffected1 = []\n",
    "for affectedGene in testAffectedGenes[0]:\n",
    "    print(affectedGene, \"count:\", testCounts[affectedGene])\n",
    "    testCount = testCountMisspecified[affectedGene]\n",
    "    bfsAffected1.append(bayes.bayesFactor(testCountMisspecified.sum(), testCountMisspecified, testAllPDs, bestParams[0:3], bestParams[3:]))\n",
    "bfsAffected1 = tensor(bfsAffected1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['altCounts', 'afs', 'affectedGenes', 'unaffectedGenes', 'rrs'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testCounts.shape torch.Size([20000, 4])\n",
      "expanded torch.Size([20000, 3, 4])\n",
      "shapes: n torch.Size([20000, 3]), alphas: torch.Size([20000, 3, 4]) counts: torch.Size([20000, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "n = testCounts.sum(1).expand(3, len(testCounts)).T\n",
    "alphas = tensor([1.77041095e+02,\n",
    "       4.05096749e+02, 3.78310762e+02, 4.93211627e+02])\n",
    "a0 = alphas[0]\n",
    "a1 = alphas[1]\n",
    "a2 = alphas[2]\n",
    "a3 = alphas[3]\n",
    "alphas2 = testAllPDs * tensor([[a0,a1,a0,a1], [a0,a0,a1,a1], [a0, a1+a3, a2+a3, a1+a2+a3]])\n",
    "alphas2 = alphas2.expand(20_000, 3, 4)\n",
    "print(\"testCounts.shape\",testCounts.shape)\n",
    "testCounts2 = testCounts.expand(3, 20_000, 4).transpose(0,1)\n",
    "print(\"expanded\", testCounts.expand(3, 20_000, 4).transpose(0,1).shape)\n",
    "print(f\"shapes: n {n.shape}, alphas: {alphas2.shape} counts: {testCounts2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([20000, 3, 1]) torch.Size([20000, 3, 4])\n",
      "past\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.6811,  -7.6378,  -7.5507],\n",
       "        [ -9.4881, -13.3662,  -7.5881],\n",
       "        [ -8.8253,  -7.5478,  -5.7675],\n",
       "        ...,\n",
       "        [ -3.8760,  -5.3455,  -9.6926],\n",
       "        [ -5.9153,  -4.3251, -12.1820],\n",
       "        [ -3.7168,  -5.1863,  -8.7299]], dtype=torch.float64)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyro.distributions import DirichletMultinomial\n",
    "#. this output is: nGenes by nHypotheses; 1 hypothesis per column\n",
    "t = DirichletMultinomial(total_count = n, concentration=alphas2).log_prob(testCounts2)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.5507, dtype=torch.float64)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([34., 34., 34.], dtype=torch.float64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 genes, 3 hypothesis\n",
    "nt = tensor([1,1,1,1]).expand(3,4).T\n",
    "nt\n",
    "n.expand(3, len(n)).T[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([3, 1]) torch.Size([3, 4])\n",
      "past\n",
      "torch.Size([20000, 3, 4])\n",
      "shapes torch.Size([3, 1]) torch.Size([3, 4])\n",
      "past\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-4.2950, -2.3979, -3.3142],\n",
       "        [-3.1964, -3.0910, -3.0910],\n",
       "        [-2.9087, -1.9924, -2.3979],\n",
       "        ...,\n",
       "        [-1.9924, -3.0910, -4.7005],\n",
       "        [-3.1964, -2.2156, -1.9924],\n",
       "        [-2.3979, -2.2156, -3.0910]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = DirichletMultinomial(total_count=tensor([3., 3, 3.]),concentration=tensor([[1.,2.,3,4],[1.,2,3,4],[1.,2,3,4]])).sample([20_000])\n",
    "\n",
    "# total_count is hypotheses by 1 , concentration is hypotheses by sampleCategories, output is nGenes by hypotheses by sampleCategories\n",
    "r.shape\n",
    "\n",
    "print(r.shape)\n",
    "\n",
    "# the sample shape is compatible with log_prob\n",
    "DirichletMultinomial(total_count=tensor([3., 3, 3.]),concentration=tensor([[1.,2.,3,4],[1.,2,3,4],[1.,2,3,4]])).log_prob(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihoodBivariateFast(altCountsFlat, pDs, trajectoryPis, trajectoryAlphas, trajectoryLLs):\n",
    "    nGenes = altCountsByGene.shape[0]\n",
    "\n",
    "    # nGenes x 4\n",
    "    xCtrl = altCountsFlat[:, 0]\n",
    "    xCase1 = altCountsFlat[:, 1]\n",
    "    xCase2 = altCountsFlat[:, 2]\n",
    "    xCase12 = altCountsFlat[:, 3]\n",
    "    # nGenes x 1\n",
    "    n = xCtrl + xCase1 + xCase2 + xCase12\n",
    "\n",
    "    pd1 = pDs[0]\n",
    "    pd2 = pDs[1]\n",
    "    pdBoth = pDs[2]\n",
    "    pdCtrl = 1 - pDs.sum()\n",
    "\n",
    "    pDsAll = tensor([pdCtrl, pd1, pd2, pdBoth], dtype=torch.float64)\n",
    "    \n",
    "    print(\"pdCtrl, pd1, pd2, pdBoth: \", pDsAll)\n",
    "\n",
    "    allNull2 = nullLikelihood(pDsAll, altCountsFlat)\n",
    "    allNull2Log = torch.log(allNull2)\n",
    "\n",
    "    # TODO: make this flexible for multivariate\n",
    "    nConditions = 4\n",
    "    nHypothesesNonNull = 3\n",
    "\n",
    "    altCountsShaped = altCountsFlat.expand(nHypothesesNonNull, nGenes, nConditions).transpose(0, 1)\n",
    "    nShaped = n.expand(nHypothesesNonNull, nGenes).T\n",
    "    pdsAllShaped = pDsAll.expand(nHypothesesNonNull, nConditions)\n",
    "    def jointLikelihood(params):\n",
    "        pi1, pi2, piBoth, alpha0, alpha1, alpha2, alphaBoth = params\n",
    "\n",
    "        if alpha0 < 0 or alpha1 < 0 or alpha2 < 0 or alphaBoth < 0 or pi1 < 0 or pi2 < 0 or piBoth < 0:\n",
    "            return float(\"inf\")\n",
    "\n",
    "        pi0 = 1.0 - (pi1 + pi2 + piBoth)\n",
    "\n",
    "        if pi0 < 0:\n",
    "            return float(\"inf\")\n",
    "\n",
    "        h0 = pi0 * allNull2\n",
    "\n",
    "        trajectoryPis.append([pi1, pi2, piBoth])\n",
    "        trajectoryAlphas.append([alpha0, alpha1, alpha2, alphaBoth])\n",
    "\n",
    "        concentrations = pdsAllShaped * tensor([\n",
    "            [alpha0, alpha1, alpha0, alpha1],\n",
    "            [alpha0, alpha0, alpha2, alpha2],\n",
    "            [alpha0, alpha1 + alphaBoth, alpha2 + alphaBoth, alpha1 + alpha2 + alphaBoth]\n",
    "        ]).expand(nGenes, nHypothesesNonNull, nConditions)\n",
    "        \n",
    "        hs = tensor([[pi1, pi2, piBoth]]) * torch.exp(DirichletMultinomial(total_count=nShaped, concentration=concentrations).log_prob(altCountsShaped))\n",
    "\n",
    "        ll = -torch.log(h0 + hs.sum(1)).sum()\n",
    "        trajectoryLLs.append(ll)\n",
    "        return ll\n",
    "    return jointLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "dict_keys(['altCounts', 'afs', 'affectedGenes', 'unaffectedGenes', 'generatingFn', 'results'])\n",
      "tensor([0.0060, 0.0057, 0.0107], dtype=torch.float64)\n",
      "tensor([[3., 0., 0., 0.],\n",
      "        [3., 0., 0., 0.],\n",
      "        [1., 2., 0., 0.],\n",
      "        ...,\n",
      "        [3., 0., 0., 0.],\n",
      "        [2., 0., 0., 0.],\n",
      "        [2., 0., 0., 0.]], dtype=torch.float64)\n",
      "pis: mean: tensor(nan) std: tensor(nan)\n",
      "alphas: median: tensor([  280.3403, 13455.0194, 15702.6012, 93028.1288], dtype=torch.float64)\n",
      "pdv1 inferred: mean: tensor(nan) std: tensor(nan)\n",
      "pdv1 true: mean: tensor(nan) std: tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "folder = '/Users/alexkotlar/projects/tada/2020-05-251590382123'\n",
    "r = np.load(path.join(folder, 'results_list.npy'), allow_pickle=True)\n",
    "\n",
    "# print(\"done\", r)\n",
    "\n",
    "for i in range(len(r)):\n",
    "    print(f\"iteration {i}\")\n",
    "    params = r[i]\n",
    "#     print(\"params\", params)\n",
    "    data = np.load(path.join(folder, i.__str__(), 'data.npy'), allow_pickle=True).item()\n",
    "    runs = data[\"runs\"]\n",
    "    print(runs[0].keys())\n",
    "#     print(runs[0]['altCounts'])\n",
    "#     if 'error' in runs\n",
    "    altCountsRun = runs[0]['results'][\"bestRes\"][\"pis\"]\n",
    "    print(altCountsRun)\n",
    "#     break\n",
    "    \n",
    "    bestPis = []\n",
    "    bestAlphas = []\n",
    "    pdv1 = []\n",
    "    pdv1True = []\n",
    "    pdv2 = []\n",
    "    pdvBoth = []\n",
    "    pdNotv = []\n",
    "#     altCounts = []\n",
    "    i = 0\n",
    "    for run in runs:\n",
    "#         print(i)\n",
    "        bestRes = run['results'][\"bestRes\"]\n",
    "        bestAlphas.append(bestRes['alphas'].numpy())\n",
    "        print(run[\"altCounts\"][0:1000])\n",
    "        break\n",
    "#         print(bestRes)\n",
    "#         altCounts.append(run[\"altCounts\"][0:1000].numpy())\n",
    "        \n",
    "        bestPis.append(bestRes[\"pis\"].numpy())\n",
    "        pdv1.append(bestRes[\"PDV_c1inferred\"].numpy())\n",
    "#         print(bestRes[\"PDV_c1inferred\"].numpy())\n",
    "#         print(bestRes[\"PDV_cBothTrue\"].numpy(), bestRes[\"PDV_cBothInferred\"].numpy())\n",
    "        pdv1True.append(bestRes[\"PDV_c1true\"].numpy())\n",
    "        pdv2.append(bestRes[\"PDV_c2inferred\"].numpy())\n",
    "        pdvBoth.append(bestRes[\"PDV_cBothInferred\"].numpy())\n",
    "        i += 1\n",
    "        \n",
    "    bestPis = tensor(bestPis)\n",
    "    pdv1 = tensor(pdv1)\n",
    "    pdv1True = tensor(pdv1True)\n",
    "    bestAlphas = tensor(bestAlphas)\n",
    "    \n",
    "    print(\"pis:\", \"mean:\", bestPis.mean(0), \"std:\", bestPis.std(0))\n",
    "    print('alphas:','median:', bestAlphas.mean(0))\n",
    "    print(\"pdv1 inferred:\", \"mean:\", pdv1.mean(0), \"std:\", pdv1.std(0))\n",
    "    print(\"pdv1 true:\", \"mean:\", pdv1True.mean(0), \"std:\", pdv1True.std(0))\n",
    "#     print(\"altcount means\", tensor(altCounts).mean(1))\n",
    "    break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pDs are: tensor([0.0100, 0.0100, 0.0020])\n",
      "TESTING WITH: nCases tensor([10000., 10000.,  4000.]) nCtrls tensor(2000000.) rrMeans tensor([20, 20, 20]) rrShape tensor(50.) afMean 0.0001 afShape tensor(50.) diseaseFractions tensor([0.0100, 0.0100, 0.0100]) pDs tensor([0.0100, 0.0100, 0.0020]) covShared tensor([[1, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [0, 0, 1]]) covSingle tensor([[1, 0],\n",
      "        [0, 1]])\n",
      "\n",
      "\n",
      "test tensor 1,0,0,0,1,0,0,0,1\n",
      "tensor([[39.9553, 41.0368, 61.1132],\n",
      "        [39.7465, 40.2735, 61.6915],\n",
      "        [39.6398, 38.0867, 60.0413],\n",
      "        ...,\n",
      "        [39.1323, 40.3251, 59.1622],\n",
      "        [39.0603, 41.4878, 60.8894],\n",
      "        [41.0934, 40.2742, 60.0276]], dtype=torch.float64)\n",
      "startIndices [0, tensor(200.), tensor(400.)] endIndices tensor([200., 400., 600.])\n",
      "totalSamples 2024000\n"
     ]
    }
   ],
   "source": [
    "rrsUpscale = tensor([20, 20, 20])\n",
    "pisUpscale = tensor([.01, .01, .01])\n",
    "pDsUpscale = tensor([0.0100, 0.0100, 0.0020])\n",
    "nCasesUpscale = tensor([1e4, 1e4, 4e3])\n",
    "nCtrlsUpscale = tensor(2e6)\n",
    "afMeanUpscale = 1e-4\n",
    "covSharedUpscale = tensor([[1, 0, 0],\n",
    "        [0, 1, 0],\n",
    "        [0, 0, 1]])\n",
    "covSingleUpscale = tensor([[1, 0],\n",
    "        [0, 1]])\n",
    "\n",
    "generatingFn =  genData.v6normal\n",
    "fitMethod = 'nelder-mead'\n",
    "nEpochs=1\n",
    "mt = True\n",
    "\n",
    "try:\n",
    "    paramsUpscale = genData.genParams(rrMeans=rrsUpscale, pis=pisUpscale, afMean=afMeanUpscale, rrShape=rrShape, afShape=afShape, nCases=nCasesUpscale, nCtrls=nCtrlsUpscale, pDs=pDsUpscale, covShared=covSharedUpscale, covSingle=covSingleUpscale)[0]\n",
    "    testDataUpscale = generatingFn(**paramsUpscale)\n",
    "except Exception as e:\n",
    "    print(f\"Run failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([194.6316,   3.2027,   3.1717,   0.7880], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(testDataUpscale[\"altCounts\"].mean(0))\n",
    "testCountsUpscale = testDataUpscale[\"altCounts\"].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[147.,  43.,   1.,   8.],\n",
       "        [165.,  45.,   4.,  15.],\n",
       "        [178.,  43.,   2.,   9.],\n",
       "        ...,\n",
       "        [131.,   2.,   1.,   2.],\n",
       "        [142.,   3.,   4.,   0.],\n",
       "        [237.,   2.,   3.,   0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataUpscale[\"altCounts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 4])\n",
      "torch.Size([20000, 4])\n",
      "IN: altCountsFlat torch.Size([20000, 4])\n",
      "pdCtrl, pd1, pd2, pdBoth:  tensor([0.9780, 0.0100, 0.0100, 0.0020], dtype=torch.float64)\n",
      "method nelder-mead costFn <function likelihoodBivariateFast.<locals>.jointLikelihood at 0x7f957e154440>\n",
      "best ll: 109033.66468126149, bestParams: [0.069128215, 0.05666357, 0.049549818, 937.87415, 23846.834, 12701.304, 22054.56]\n",
      "Epoch took 72.7163360118866\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-669-27db3f66762f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestFitUpscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbestLLUpscale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbestLLUpscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mbestParamsUpscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mbestLLUpscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "print(testDataUpscale[\"altCounts\"].shape)\n",
    "\n",
    "testFitUpscale = likelihoods.fitFnBivariate(testDataUpscale[\"altCounts\"], paramsUpscale[\"pDs\"], nEpochs=1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upscalePis tensor([0.0100, 0.0100, 0.0100], dtype=torch.float64) upscaleAlphas tensor([  1184.2417,  30785.4173,  31317.5726, 589286.9084],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "upscalePis = tensor(testFitUpscale[\"params\"][0][0:3])\n",
    "upscaleAlphas = tensor(testFitUpscale[\"params\"][0][3:])\n",
    "print(\"upscalePis\", upscalePis, \"upscaleAlphas\", upscaleAlphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: altCountsFlat torch.Size([20000, 4])\n",
      "pdCtrl, pd1, pd2, pdBoth:  tensor([0.9780, 0.0100, 0.0100, 0.0020], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.1178e-53,  2.4460e-03,  9.2927e-47, 1.6640e-126],\n",
       "        [ 1.3822e-63,  9.8333e-05,  1.0919e-45, 1.1161e-136],\n",
       "        [ 1.4849e-50,  1.7088e-03,  1.4303e-45, 1.5538e-153],\n",
       "        ...,\n",
       "        [ 2.3431e-03,  1.2769e-12,  3.2573e-14, 2.4153e-136],\n",
       "        [ 4.1681e-03,  4.8917e-15,  6.0863e-14, 1.6670e-144],\n",
       "        [ 3.4052e-02,  8.0651e-25,  7.4913e-24, 1.6161e-245]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piNullUpscale = 1 - upscalePis.sum()\n",
    "\n",
    "likelihoodFnUpscale, nullLikeUpscale = likelihoods.effectLikelihood(4, pDs=paramsUpscale[\"pDs\"], altCountsFlat=testDataUpscale[\"altCounts\"])\n",
    "\n",
    "\n",
    "affectedGenes1Upscale = tensor(testDataUpscale[\"affectedGenes\"][0])\n",
    "affectedGenes2Upscale = tensor(testDataUpscale[\"affectedGenes\"][1])\n",
    "affectedGenesBothUpscale = tensor(testDataUpscale[\"affectedGenes\"][2])\n",
    "unaffectedGenesUpscale = testDataUpscale[\"unaffectedGenes\"]\n",
    "\n",
    "\n",
    "likeUpscale = likelihoodFnUpscale(*upscaleAlphas)\n",
    "likeUpscale\n",
    "\n",
    "likeUpscaleWithNull = torch.stack([nullLikeUpscale, likeUpscale[:,0], likeUpscale[:,1], likeUpscale[:,2]]).T\n",
    "likeUpscaleWithNull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%Correctly classfieid genes affecting 1: 100.0\n",
      "%Correct classfieid genes affecting 1 if we call correct non-H0: 100.0\n"
     ]
    }
   ],
   "source": [
    "valuesUpscale, indicesUpscale = torch.max(likeUpscaleWithNull[affectedGenes1Upscale],1)\n",
    "maskUpscale = indicesUpscale != 1\n",
    "badIndicesUpscale = torch.nonzero(maskUpscale)\n",
    "maskGoodUpscale = indicesUpscale == 1\n",
    "goodIndicesUpscale = torch.nonzero(maskGoodUpscale)\n",
    "# print(\"n misclassified:\", badIndicesUpscale.shape, \"out of\", affectedGenes1Upscale.shape, \"n genes\", \"fraction bad: \", len(badIndicesUpscale)/len(affectedGenes1Upscale))\n",
    "print(\"%Correctly classfieid genes affecting 1:\", len(goodIndicesUpscale) * 100/len(affectedGenes1Upscale))\n",
    "\n",
    "maskUpsacelAssumedNull = indicesUpscale != 0\n",
    "goodIndicesUpscaleAssumedNull = torch.nonzero(maskUpsacelAssumedNull)\n",
    "print(\"%Correct classfieid genes affecting 1 if we call correct non-H0:\", len(goodIndicesUpscaleAssumedNull) * 100/len(affectedGenes1Upscale))\n",
    "# maskUpscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%Correctly classfieid risk genes 2: 85.5\n"
     ]
    }
   ],
   "source": [
    "valuesUpscale, indicesUpscale = torch.max(likeUpscaleWithNull[affectedGenes2Upscale],1)\n",
    "maskUpscale = indicesUpscale != 2\n",
    "badIndicesUpscale = torch.nonzero(maskUpscale)\n",
    "maskGoodUpscale = indicesUpscale == 2\n",
    "goodIndicesUpscale = torch.nonzero(maskGoodUpscale)\n",
    "# print(\"n misclassified:\", badIndicesUpscale.shape, \"out of\", affectedGenes1Upscale.shape, \"n genes\", \"fraction bad: \", len(badIndicesUpscale)/len(affectedGenes1Upscale))\n",
    "print(\"%Correctly classfieid risk genes 2:\", len(goodIndicesUpscale) * 100/len(affectedGenes2Upscale))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "genAlleleCount() got an unexpected keyword argument 'nToSample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-684-4521e0b3f85f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnullBf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltCountsNullBfPerm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfNullGene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupscaleAlphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/tada/mvl/bayes.py\u001b[0m in \u001b[0;36mbfNullGene\u001b[0;34m(alphas, nCases, nCtrls, af, pDs, nIterations)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mrrs\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0maltCounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenAlleleCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalSamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotalSamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnToSample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnIterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapprox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltCounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: genAlleleCount() got an unexpected keyword argument 'nToSample'"
     ]
    }
   ],
   "source": [
    "nullBf, altCountsNullBfPerm = bayes.bfNullGene(upscaleAlphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altCountsNullBfPerm[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong %:  0.0023\n"
     ]
    }
   ],
   "source": [
    "mask = nullBf.max(1).values > 1\n",
    "# print(nullBf.max(1).values)\n",
    "\n",
    "wrong = torch.nonzero(mask)\n",
    "\n",
    "print(\"Wrong %: \", len(wrong) / len(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nullBf.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 3],\n",
       "        [2, 1]])"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=torch.tensor([[1,2],[3,4]])\n",
    "r=torch.randperm(2)\n",
    "c=torch.randperm(2)\n",
    "t=t[r[:, None], c]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3, 2])"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.randperm(t.nelement())\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27095, 13410, 25369,  ..., 29920, 15399,  7653])"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3162e-20, 6.5696e-07, 1.5893e-15],\n",
       "        [6.5757e-07, 8.6326e-13, 5.7114e-13],\n",
       "        [1.3162e-20, 1.4233e-08, 1.5026e-08],\n",
       "        ...,\n",
       "        [9.1238e-08, 6.5240e-11, 1.8144e-07],\n",
       "        [1.5565e-15, 6.5240e-11, 3.1668e-23],\n",
       "        [1.1713e-20, 1.4223e-03, 3.3371e-09]], dtype=torch.float64)"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2 = torch.randperm(nullBf.nelement())\n",
    "idx2\n",
    "\n",
    "nullBfPerm = nullBf.view(-1)[idx2].view(nullBf.size())\n",
    "nullBfPerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15.,  3.,  0.,  0.],\n",
       "        [18.,  6.,  0.,  0.],\n",
       "        [15.,  3.,  0.,  0.],\n",
       "        ...,\n",
       "        [16.,  1.,  0.,  0.],\n",
       "        [17.,  0.,  1.,  0.],\n",
       "        [18.,  0.,  1.,  0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataUpscale[\"altCounts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx [45425 47049 68437 ... 45489   975 75095]\n",
      "altCountsPermuted tensor([[ 0.,  0.,  0.,  0.],\n",
      "        [20.,  1., 16.,  0.],\n",
      "        [ 0., 20.,  1.,  1.],\n",
      "        ...,\n",
      "        [ 0.,  0., 20., 21.],\n",
      "        [ 0., 18., 24., 20.],\n",
      "        [ 0., 19.,  1.,  0.]], dtype=torch.float64)\n",
      "pdCtrl, pd1, pd2, pdBoth:  tensor([0.9780, 0.0100, 0.0100, 0.0020], dtype=torch.float64)\n",
      "bf tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00],\n",
      "        [ 2.0702e+02,  6.8678e+19,  1.0270e+08],\n",
      "        [ 2.4704e+31,  1.1142e+10,  2.1031e+35],\n",
      "        ...,\n",
      "        [ 8.2363e+40,  6.8615e+64,  2.3384e+67],\n",
      "        [ 2.4948e+68,  2.3120e+74, 7.0584e+100],\n",
      "        [ 2.5185e+28,  7.6836e+07,  1.1502e+32]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "bfPermuted, altCountsPermuted = bayes.permutedGeneCountBFs(testDataUpscale[\"altCounts\"], upscaleAlphas, paramsUpscale[\"pDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: altCountsFlat torch.Size([20000, 4])\n",
      "pdCtrl, pd1, pd2, pdBoth:  tensor([0.9780, 0.0100, 0.0100, 0.0020], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 3])"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfsUpscaled = bayes.bayesFactors(testDataUpscale[\"altCounts\"],  paramsUpscale[\"pDs\"], upscaleAlphas)\n",
    "bfsUpscaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pis tensor([0.0100, 0.0100, 0.0100], dtype=torch.float64) len 3 shape torch.Size([20000])\n",
      "[0, 1, 2]\n",
      "torch.Size([20000])\n",
      "bfSorted tensor([       inf,        inf,        inf,  ..., 2.9922e-31, 1.4293e-31,\n",
      "        1.2550e-31], dtype=torch.float64)\n",
      "bfSorted after tensor([4.8849e+206, 4.8849e+206, 4.8849e+206,  ...,  2.9922e-31,\n",
      "         1.4293e-31,  1.2550e-31], dtype=torch.float64)\n",
      "cumsum tensor([4.8849e+206, 9.7697e+206, 1.4655e+207,  ..., 1.9539e+208,\n",
      "        1.9539e+208, 1.9539e+208], dtype=torch.float64)\n",
      "qnull tensor([0., 0., 0.,  ..., 1., 1., 1.], dtype=torch.float64)\n",
      "range tensor([    1,     2,     3,  ..., 19998, 19999, 20000])\n",
      "fdr tensor([0.0000, 0.0000, 0.0000,  ..., 0.9724, 0.9724, 0.9724],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([20000])\n",
      "bfSorted tensor([       inf,        inf,        inf,  ..., 1.1015e-31, 9.0640e-32,\n",
      "        1.7466e-33], dtype=torch.float64)\n",
      "bfSorted after tensor([1.8172e+199, 1.8172e+199, 1.8172e+199,  ...,  1.1015e-31,\n",
      "         9.0640e-32,  1.7466e-33], dtype=torch.float64)\n",
      "cumsum tensor([1.8172e+199, 3.6343e+199, 5.4515e+199,  ..., 7.2924e+200,\n",
      "        7.2924e+200, 7.2924e+200], dtype=torch.float64)\n",
      "qnull tensor([0., 0., 0.,  ..., 1., 1., 1.], dtype=torch.float64)\n",
      "range tensor([    1,     2,     3,  ..., 19998, 19999, 20000])\n",
      "fdr tensor([0.0000, 0.0000, 0.0000,  ..., 0.9728, 0.9728, 0.9728],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([20000])\n",
      "bfSorted tensor([inf, inf, inf,  ..., 0., 0., 0.], dtype=torch.float64)\n",
      "bfSorted after tensor([2.4585e+306, 2.4585e+306, 2.4585e+306,  ...,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00], dtype=torch.float64)\n",
      "cumsum tensor([2.4585e+306, 4.9170e+306, 7.3756e+306,  ..., 1.2835e+308,\n",
      "        1.2835e+308, 1.2835e+308], dtype=torch.float64)\n",
      "qnull tensor([0., 0., 0.,  ..., 1., 1., 1.], dtype=torch.float64)\n",
      "range tensor([    1,     2,     3,  ..., 19998, 19999, 20000])\n",
      "fdr tensor([0.0000, 0.0000, 0.0000,  ..., 0.9900, 0.9900, 0.9900],\n",
      "       dtype=torch.float64)\n",
      "fdrs tensor([[4.4327e-11, 1.3189e-02, 2.5148e-09,  ..., 9.6678e-01, 8.7754e-01,\n",
      "         9.7119e-01],\n",
      "        [4.4856e-02, 4.4213e-12, 2.1169e-09,  ..., 9.3348e-01, 9.7072e-01,\n",
      "         8.7962e-01],\n",
      "        [5.7356e-01, 5.7537e-01, 5.4955e-01,  ..., 9.5570e-01, 9.8799e-01,\n",
      "         9.8757e-01]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "upscaleFDRs = bayes.bayesFDRs(bfsUpscaled, upscalePis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfPermuted[: 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altCountsPermuted[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
